This is python.info, produced by makeinfo version 4.8 from python.texi.

Generated by Sphinx 1.6.3.
INFO-DIR-SECTION Python
START-INFO-DIR-ENTRY
* Python: (python.info). The Python reference manual.
END-INFO-DIR-ENTRY

     Python 2.7.13, July 15, 2017

     Copyright (C) 1990-2017, Python Software Foundation


File: python.info,  Node: RLock Objects,  Next: Condition Objects,  Prev: Lock Objects,  Up: threading — Higher-level threading interface

5.16.2.3 RLock Objects
......................

A reentrant lock is a synchronization primitive that may be acquired
multiple times by the same thread.  Internally, it uses the concepts of
“owning thread” and “recursion level” in addition to the
locked/unlocked state used by primitive locks.  In the locked state,
some thread owns the lock; in the unlocked state, no thread owns it.

To lock the lock, a thread calls its `acquire()' method; this returns
once the thread owns the lock.  To unlock the lock, a thread calls its
`release()' method. `acquire()'/`release()' call pairs may be nested;
only the final `release()' (the `release()' of the outermost pair)
resets the lock to unlocked and allows another thread blocked in
`acquire()' to proceed.

 -- Method: RLock.acquire ([blocking=1])
     Acquire a lock, blocking or non-blocking.

     When invoked without arguments: if this thread already owns the
     lock, increment the recursion level by one, and return
     immediately.  Otherwise, if another thread owns the lock, block
     until the lock is unlocked.  Once the lock is unlocked (not owned
     by any thread), then grab ownership, set the recursion level to
     one, and return.  If more than one thread is blocked waiting until
     the lock is unlocked, only one at a time will be able to grab
     ownership of the lock.  There is no return value in this case.

     When invoked with the `blocking' argument set to true, do the same
     thing as when called without arguments, and return true.

     When invoked with the `blocking' argument set to false, do not
     block.  If a call without an argument would block, return false
     immediately; otherwise, do the same thing as when called without
     arguments, and return true.

 -- Method: RLock.release ()
     Release a lock, decrementing the recursion level.  If after the
     decrement it is zero, reset the lock to unlocked (not owned by any
     thread), and if any other threads are blocked waiting for the lock
     to become unlocked, allow exactly one of them to proceed.  If
     after the decrement the recursion level is still nonzero, the lock
     remains locked and owned by the calling thread.

     Only call this method when the calling thread owns the lock. A
     *Note RuntimeError: 3b3. is raised if this method is called when
     the lock is unlocked.

     There is no return value.


File: python.info,  Node: Condition Objects,  Next: Semaphore Objects,  Prev: RLock Objects,  Up: threading — Higher-level threading interface

5.16.2.4 Condition Objects
..........................

A condition variable is always associated with some kind of lock; this
can be passed in or one will be created by default.  (Passing one in is
useful when several condition variables must share the same lock.)

A condition variable has `acquire()' and `release()' methods that call
the corresponding methods of the associated lock. It also has a `wait()'
method, and `notify()' and `notifyAll()' methods.  These three must only
be called when the calling thread has acquired the lock, otherwise a
*Note RuntimeError: 3b3. is raised.

The `wait()' method releases the lock, and then blocks until it is
awakened by a `notify()' or `notifyAll()' call for the same condition
variable in another thread.  Once awakened, it re-acquires the lock and
returns.  It is also possible to specify a timeout.

The `notify()' method wakes up one of the threads waiting for the
condition variable, if any are waiting.  The `notifyAll()' method wakes
up all threads waiting for the condition variable.

Note: the `notify()' and `notifyAll()' methods don’t release the lock;
this means that the thread or threads awakened will not return from
their `wait()' call immediately, but only when the thread that called
`notify()' or `notifyAll()' finally relinquishes ownership of the lock.

Tip: the typical programming style using condition variables uses the
lock to synchronize access to some shared state; threads that are
interested in a particular change of state call `wait()' repeatedly
until they see the desired state, while threads that modify the state
call `notify()' or `notifyAll()' when they change the state in such a
way that it could possibly be a desired state for one of the waiters.
For example, the following code is a generic producer-consumer
situation with unlimited buffer capacity:

    # Consume one item
    cv.acquire()
    while not an_item_is_available():
        cv.wait()
    get_an_available_item()
    cv.release()

    # Produce one item
    cv.acquire()
    make_an_item_available()
    cv.notify()
    cv.release()

To choose between `notify()' and `notifyAll()', consider whether one
state change can be interesting for only one or several waiting
threads.  E.g.  in a typical producer-consumer situation, adding one
item to the buffer only needs to wake up one consumer thread.

 -- Class: threading.Condition ([lock])
     If the `lock' argument is given and not `None', it must be a *Note
     Lock: 1604.  or *Note RLock: 1606. object, and it is used as the
     underlying lock.  Otherwise, a new *Note RLock: 1606. object is
     created and used as the underlying lock.

      -- Method: acquire (*args)
          Acquire the underlying lock. This method calls the
          corresponding method on the underlying lock; the return value
          is whatever that method returns.

      -- Method: release ()
          Release the underlying lock. This method calls the
          corresponding method on the underlying lock; there is no
          return value.

      -- Method: wait ([timeout])
          Wait until notified or until a timeout occurs. If the calling
          thread has not acquired the lock when this method is called,
          a *Note RuntimeError: 3b3. is raised.

          This method releases the underlying lock, and then blocks
          until it is awakened by a *Note notify(): 1627. or *Note
          notifyAll(): 1628. call for the same condition variable in
          another thread, or until the optional timeout occurs.  Once
          awakened or timed out, it re-acquires the lock and returns.

          When the `timeout' argument is present and not `None', it
          should be a floating point number specifying a timeout for
          the operation in seconds (or fractions thereof).

          When the underlying lock is an *Note RLock: 1606, it is not
          released using its *Note release(): 1625. method, since this
          may not actually unlock the lock when it was acquired
          multiple times recursively.  Instead, an internal interface
          of the *Note RLock: 1606. class is used, which really unlocks
          it even when it has been recursively acquired several times.
          Another internal interface is then used to restore the
          recursion level when the lock is reacquired.

      -- Method: notify (n=1)
          By default, wake up one thread waiting on this condition, if
          any.  If the calling thread has not acquired the lock when
          this method is called, a *Note RuntimeError: 3b3. is raised.

          This method wakes up at most `n' of the threads waiting for
          the condition variable; it is a no-op if no threads are
          waiting.

          The current implementation wakes up exactly `n' threads, if
          at least `n' threads are waiting.  However, it’s not safe
          to rely on this behavior.  A future, optimized implementation
          may occasionally wake up more than `n' threads.

          Note: an awakened thread does not actually return from its
          *Note wait(): 1626.  call until it can reacquire the lock.
          Since *Note notify(): 1627. does not release the lock, its
          caller should.

      -- Method: notify_all ()
      -- Method: notifyAll ()
          Wake up all threads waiting on this condition.  This method
          acts like *Note notify(): 1627, but wakes up all waiting
          threads instead of one. If the calling thread has not
          acquired the lock when this method is called, a *Note
          RuntimeError: 3b3. is raised.

          Changed in version 2.6: Added `notify_all()' spelling.



File: python.info,  Node: Semaphore Objects,  Next: Event Objects,  Prev: Condition Objects,  Up: threading — Higher-level threading interface

5.16.2.5 Semaphore Objects
..........................

This is one of the oldest synchronization primitives in the history of
computer science, invented by the early Dutch computer scientist Edsger
W. Dijkstra (he used `P()' and `V()' instead of `acquire()' and
`release()').

A semaphore manages an internal counter which is decremented by each
`acquire()' call and incremented by each `release()' call.  The counter
can never go below zero; when `acquire()' finds that it is zero, it
blocks, waiting until some other thread calls `release()'.

 -- Class: threading.Semaphore ([value])
     The optional argument gives the initial `value' for the internal
     counter; it defaults to `1'. If the `value' given is less than 0,
     *Note ValueError: 236. is raised.

      -- Method: acquire ([blocking])
          Acquire a semaphore.

          When invoked without arguments: if the internal counter is
          larger than zero on entry, decrement it by one and return
          immediately.  If it is zero on entry, block, waiting until
          some other thread has called *Note release(): 162d. to make
          it larger than zero.  This is done with proper interlocking
          so that if multiple *Note acquire(): 162c. calls are blocked,
          *Note release(): 162d. will wake exactly one of them up.  The
          implementation may pick one at random, so the order in which
          blocked threads are awakened should not be relied on.  There
          is no return value in this case.

          When invoked with `blocking' set to true, do the same thing
          as when called without arguments, and return true.

          When invoked with `blocking' set to false, do not block.  If
          a call without an argument would block, return false
          immediately; otherwise, do the same thing as when called
          without arguments, and return true.

      -- Method: release ()
          Release a semaphore, incrementing the internal counter by
          one.  When it was zero on entry and another thread is waiting
          for it to become larger than zero again, wake up that thread.

* Menu:

* Semaphore Example::


File: python.info,  Node: Semaphore Example,  Up: Semaphore Objects

5.16.2.6 `Semaphore' Example
............................

Semaphores are often used to guard resources with limited capacity, for
example, a database server.  In any situation where the size of the
resource is fixed, you should use a bounded semaphore.  Before spawning
any worker threads, your main thread would initialize the semaphore:

    maxconnections = 5
    ...
    pool_sema = BoundedSemaphore(value=maxconnections)

Once spawned, worker threads call the semaphore’s acquire and release
methods when they need to connect to the server:

    pool_sema.acquire()
    conn = connectdb()
    ... use connection ...
    conn.close()
    pool_sema.release()

The use of a bounded semaphore reduces the chance that a programming
error which causes the semaphore to be released more than it’s
acquired will go undetected.


File: python.info,  Node: Event Objects,  Next: Timer Objects,  Prev: Semaphore Objects,  Up: threading — Higher-level threading interface

5.16.2.7 Event Objects
......................

This is one of the simplest mechanisms for communication between
threads: one thread signals an event and other threads wait for it.

An event object manages an internal flag that can be set to true with
the *Note set(): 1602. method and reset to false with the *Note
clear(): 1631.  method.  The *Note wait(): 269. method blocks until the
flag is true.

 -- Class: threading.Event
     The internal flag is initially false.

      -- Method: is_set ()
      -- Method: isSet ()
          Return true if and only if the internal flag is true.

          Changed in version 2.6: Added `is_set()' spelling.


      -- Method: set ()
          Set the internal flag to true. All threads waiting for it to
          become true are awakened. Threads that call *Note wait():
          269. once the flag is true will not block at all.

      -- Method: clear ()
          Reset the internal flag to false. Subsequently, threads
          calling *Note wait(): 269. will block until *Note set():
          1602. is called to set the internal flag to true again.

      -- Method: wait ([timeout])
          Block until the internal flag is true.  If the internal flag
          is true on entry, return immediately.  Otherwise, block until
          another thread calls *Note set(): 1602. to set the flag to
          true, or until the optional timeout occurs.

          When the timeout argument is present and not `None', it
          should be a floating point number specifying a timeout for
          the operation in seconds (or fractions thereof).

          This method returns the internal flag on exit, so it will
          always return `True' except if a timeout is given and the
          operation times out.

          Changed in version 2.7: Previously, the method always
          returned `None'.



File: python.info,  Node: Timer Objects,  Next: Using locks conditions and semaphores in the with statement,  Prev: Event Objects,  Up: threading — Higher-level threading interface

5.16.2.8 Timer Objects
......................

This class represents an action that should be run only after a certain
amount of time has passed — a timer.  *Note Timer: bf1. is a subclass
of *Note Thread: 1350.  and as such also functions as an example of
creating custom threads.

Timers are started, as with threads, by calling their `start()' method.
The timer can be stopped (before its action has begun) by calling the
*Note cancel(): 1635. method.  The interval the timer will wait before
executing its action may not be exactly the same as the interval
specified by the user.

For example:

    def hello():
        print "hello, world"

    t = Timer(30.0, hello)
    t.start()  # after 30 seconds, "hello, world" will be printed

 -- Class: threading.Timer (interval, function, args=[], kwargs={})
     Create a timer that will run `function' with arguments `args' and
     keyword arguments `kwargs', after `interval' seconds have passed.

      -- Method: cancel ()
          Stop the timer, and cancel the execution of the timer’s
          action.  This will only work if the timer is still in its
          waiting stage.


File: python.info,  Node: Using locks conditions and semaphores in the with statement,  Next: Importing in threaded code,  Prev: Timer Objects,  Up: threading — Higher-level threading interface

5.16.2.9 Using locks, conditions, and semaphores in the `with' statement
........................................................................

All of the objects provided by this module that have `acquire()' and
`release()' methods can be used as context managers for a *Note with:
1c1.  statement.  The `acquire()' method will be called when the block
is entered, and `release()' will be called when the block is exited.

Currently, *Note Lock: 1604, *Note RLock: 1606, *Note Condition: 1623,
*Note Semaphore: 162b, and *Note BoundedSemaphore: 1609. objects may be
used as *Note with: 1c1. statement context managers.  For example:

    import threading

    some_rlock = threading.RLock()

    with some_rlock:
        print "some_rlock is locked while this executes"


File: python.info,  Node: Importing in threaded code,  Prev: Using locks conditions and semaphores in the with statement,  Up: threading — Higher-level threading interface

5.16.2.10 Importing in threaded code
....................................

While the import machinery is thread-safe, there are two key
restrictions on threaded imports due to inherent limitations in the way
that thread-safety is provided:

   * Firstly, other than in the main module, an import should not have
     the side effect of spawning a new thread and then waiting for that
     thread in any way. Failing to abide by this restriction can lead
     to a deadlock if the spawned thread directly or indirectly
     attempts to import a module.

   * Secondly, all import attempts must be completed before the
     interpreter starts shutting itself down. This can be most easily
     achieved by only performing imports from non-daemon threads
     created through the threading module. Daemon threads and threads
     created directly with the thread module will require some other
     form of synchronization to ensure they do not attempt imports
     after system shutdown has commenced. Failure to abide by this
     restriction will lead to intermittent exceptions and crashes
     during interpreter shutdown (as the late imports attempt to access
     machinery which is no longer in a valid state).


File: python.info,  Node: thread — Multiple threads of control,  Next: dummy_threading — Drop-in replacement for the threading module,  Prev: threading — Higher-level threading interface,  Up: Optional Operating System Services

5.16.3 `thread' — Multiple threads of control
-----------------------------------------------

     Note: The *Note thread: 178. module has been renamed to `_thread'
     in Python 3.  The *Note 2to3: c05. tool will automatically adapt
     imports when converting your sources to Python 3; however, you
     should consider using the high-level *Note threading: 179. module
     instead.

This module provides low-level primitives for working with multiple
threads (also called `light-weight processes' or `tasks') — multiple
threads of control sharing their global data space.  For
synchronization, simple locks (also called `mutexes' or `binary
semaphores') are provided.  The *Note threading: 179. module provides
an easier to use and higher-level threading API built on top of this
module.

The module is optional.  It is supported on Windows, Linux, SGI IRIX,
Solaris 2.x, as well as on systems that have a POSIX thread (a.k.a.
“pthread”) implementation.  For systems lacking the *Note thread:
178. module, the *Note dummy_thread: b8. module is available. It
duplicates this module’s interface and can be used as a drop-in
replacement.

It defines the following constant and functions:

 -- Exception: thread.error
     Raised on thread-specific errors.

 -- Data: thread.LockType
     This is the type of lock objects.

 -- Function: thread.start_new_thread (function, args[, kwargs])
     Start a new thread and return its identifier.  The thread executes
     the function `function' with the argument list `args' (which must
     be a tuple).  The optional `kwargs' argument specifies a
     dictionary of keyword arguments. When the function returns, the
     thread silently exits.  When the function terminates with an
     unhandled exception, a stack trace is printed and then the thread
     exits (but other threads continue to run).

 -- Function: thread.interrupt_main ()
     Raise a *Note KeyboardInterrupt: 251. exception in the main
     thread.  A subthread can use this function to interrupt the main
     thread.

     New in version 2.3.


 -- Function: thread.exit ()
     Raise the *Note SystemExit: 346. exception.  When not caught, this
     will cause the thread to exit silently.

 -- Function: thread.allocate_lock ()
     Return a new lock object.  Methods of locks are described below.
     The lock is initially unlocked.

 -- Function: thread.get_ident ()
     Return the ‘thread identifier’ of the current thread.  This is
     a nonzero integer.  Its value has no direct meaning; it is
     intended as a magic cookie to be used e.g. to index a dictionary
     of thread-specific data.  Thread identifiers may be recycled when
     a thread exits and another thread is created.

 -- Function: thread.stack_size ([size])
     Return the thread stack size used when creating new threads.  The
     optional `size' argument specifies the stack size to be used for
     subsequently created threads, and must be 0 (use platform or
     configured default) or a positive integer value of at least 32,768
     (32kB). If `size' is not specified, 0 is used. If changing the
     thread stack size is unsupported, the *Note error: 163c. exception
     is raised.  If the specified stack size is invalid, a *Note
     ValueError: 236. is raised and the stack size is unmodified.  32kB
     is currently the minimum supported stack size value to guarantee
     sufficient stack space for the interpreter itself.  Note that some
     platforms may have particular restrictions on values for the stack
     size, such as requiring a minimum stack size > 32kB or requiring
     allocation in multiples of the system memory page size - platform
     documentation should be referred to for more information (4kB
     pages are common; using multiples of 4096 for the stack size is
     the suggested approach in the absence of more specific
     information).  Availability: Windows, systems with POSIX threads.

     New in version 2.5.


Lock objects have the following methods:

 -- Method: lock.acquire ([waitflag])
     Without the optional argument, this method acquires the lock
     unconditionally, if necessary waiting until it is released by
     another thread (only one thread at a time can acquire a lock —
     that’s their reason for existence).  If the integer `waitflag'
     argument is present, the action depends on its value: if it is
     zero, the lock is only acquired if it can be acquired immediately
     without waiting, while if it is nonzero, the lock is acquired
     unconditionally as before.  The return value is `True' if the lock
     is acquired successfully, `False' if not.

 -- Method: lock.release ()
     Releases the lock.  The lock must have been acquired earlier, but
     not necessarily by the same thread.

 -- Method: lock.locked ()
     Return the status of the lock: `True' if it has been acquired by
     some thread, `False' if not.

In addition to these methods, lock objects can also be used via the
*Note with: 1c1. statement, e.g.:

    import thread

    a_lock = thread.allocate_lock()

    with a_lock:
        print "a_lock is locked while this executes"

`Caveats:'

 
   * Threads interact strangely with interrupts: the *Note
     KeyboardInterrupt: 251.  exception will be received by an
     arbitrary thread.  (When the *Note signal: 155.  module is
     available, interrupts always go to the main thread.)

   * Calling *Note sys.exit(): 2aa. or raising the *Note SystemExit:
     346. exception is equivalent to calling *Note thread.exit(): 1640.

   * It is not possible to interrupt the `acquire()' method on a lock
     — the *Note KeyboardInterrupt: 251. exception will happen after
     the lock has been acquired.

   * When the main thread exits, it is system defined whether the other
     threads survive.  On SGI IRIX using the native thread
     implementation, they survive.  On most other systems, they are
     killed without executing *Note try: 3ad. … *Note finally: 3ae.
     clauses or executing object destructors.

   * When the main thread exits, it does not do any of its usual
     cleanup (except that *Note try: 3ad. … *Note finally: 3ae.
     clauses are honored), and the standard I/O files are not flushed.


File: python.info,  Node: dummy_threading — Drop-in replacement for the threading module,  Next: dummy_thread — Drop-in replacement for the thread module,  Prev: thread — Multiple threads of control,  Up: Optional Operating System Services

5.16.4 `dummy_threading' — Drop-in replacement for the `threading' module
---------------------------------------------------------------------------

`Source code:' Lib/dummy_threading.py(1)

__________________________________________________________________

This module provides a duplicate interface to the *Note threading: 179.
module.  It is meant to be imported when the *Note thread: 178. module
is not provided on a platform.

Suggested usage is:

    try:
        import threading as _threading
    except ImportError:
        import dummy_threading as _threading

Be careful to not use this module where deadlock might occur from a
thread being created that blocks waiting for another thread to be
created.  This  often occurs with blocking I/O.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/dummy_threading.py


File: python.info,  Node: dummy_thread — Drop-in replacement for the thread module,  Next: multiprocessing — Process-based “threading” interface,  Prev: dummy_threading — Drop-in replacement for the threading module,  Up: Optional Operating System Services

5.16.5 `dummy_thread' — Drop-in replacement for the `thread' module
---------------------------------------------------------------------

     Note: The *Note dummy_thread: b8. module has been renamed to
     `_dummy_thread' in Python 3.  The *Note 2to3: c05. tool will
     automatically adapt imports when converting your sources to Python
     3; however, you should consider using the high-lever *Note
     dummy_threading: b9. module instead.

`Source code:' Lib/dummy_thread.py(1)

__________________________________________________________________

This module provides a duplicate interface to the *Note thread: 178.
module.  It is meant to be imported when the *Note thread: 178. module
is not provided on a platform.

Suggested usage is:

    try:
        import thread as _thread
    except ImportError:
        import dummy_thread as _thread

Be careful to not use this module where deadlock might occur from a
thread being created that blocks waiting for another thread to be
created.  This  often occurs with blocking I/O.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/dummy_thread.py


File: python.info,  Node: multiprocessing — Process-based “threading” interface,  Next: mmap — Memory-mapped file support,  Prev: dummy_thread — Drop-in replacement for the thread module,  Up: Optional Operating System Services

5.16.6 `multiprocessing' — Process-based “threading” interface
--------------------------------------------------------------------

New in version 2.6.

* Menu:

* Introduction: Introduction<7>.
* Reference::
* Programming guidelines::
* Examples: Examples<7>.


File: python.info,  Node: Introduction<7>,  Next: Reference,  Up: multiprocessing — Process-based “threading” interface

5.16.6.1 Introduction
.....................

*Note multiprocessing: 11a. is a package that supports spawning
processes using an API similar to the *Note threading: 179. module.
The *Note multiprocessing: 11a. package offers both local and remote
concurrency, effectively side-stepping the *Note Global Interpreter
Lock: 1584. by using subprocesses instead of threads.  Due to this, the
*Note multiprocessing: 11a. module allows the programmer to fully
leverage multiple processors on a given machine.  It runs on both Unix
and Windows.

The *Note multiprocessing: 11a. module also introduces APIs which do
not have analogs in the *Note threading: 179. module.  A prime example
of this is the `Pool' object which offers a convenient means of
parallelizing the execution of a function across multiple input values,
distributing the input data across processes (data parallelism).  The
following example demonstrates the common practice of defining such
functions in a module so that child processes can successfully import
that module.  This basic example of data parallelism using `Pool',

    from multiprocessing import Pool

    def f(x):
        return x*x

    if __name__ == '__main__':
        p = Pool(5)
        print(p.map(f, [1, 2, 3]))

will print to standard output

    [1, 4, 9]

* Menu:

* The Process class::
* Exchanging objects between processes::
* Synchronization between processes::
* Sharing state between processes::
* Using a pool of workers::


File: python.info,  Node: The Process class,  Next: Exchanging objects between processes,  Up: Introduction<7>

5.16.6.2 The `Process' class
............................

In *Note multiprocessing: 11a, processes are spawned by creating a
*Note Process: 164e.  object and then calling its *Note start(): 164f.
method.  *Note Process: 164e.  follows the API of *Note
threading.Thread: 1350.  A trivial example of a multiprocess program is

    from multiprocessing import Process

    def f(name):
        print 'hello', name

    if __name__ == '__main__':
        p = Process(target=f, args=('bob',))
        p.start()
        p.join()

To show the individual process IDs involved, here is an expanded
example:

    from multiprocessing import Process
    import os

    def info(title):
        print title
        print 'module name:', __name__
        if hasattr(os, 'getppid'):  # only available on Unix
            print 'parent process:', os.getppid()
        print 'process id:', os.getpid()

    def f(name):
        info('function f')
        print 'hello', name

    if __name__ == '__main__':
        info('main line')
        p = Process(target=f, args=('bob',))
        p.start()
        p.join()

For an explanation of why (on Windows) the `if __name__ == '__main__''
part is necessary, see *Note Programming guidelines: 1650.


File: python.info,  Node: Exchanging objects between processes,  Next: Synchronization between processes,  Prev: The Process class,  Up: Introduction<7>

5.16.6.3 Exchanging objects between processes
.............................................

*Note multiprocessing: 11a. supports two types of communication channel
between processes:

`Queues'

     The *Note Queue: 1652. class is a near clone of *Note Queue.Queue:
     316.  For example:

         from multiprocessing import Process, Queue

         def f(q):
             q.put([42, None, 'hello'])

         if __name__ == '__main__':
             q = Queue()
             p = Process(target=f, args=(q,))
             p.start()
             print q.get()    # prints "[42, None, 'hello']"
             p.join()

     Queues are thread and process safe.

`Pipes'

     The *Note Pipe(): 1653. function returns a pair of connection
     objects connected by a pipe which by default is duplex (two-way).
     For example:

         from multiprocessing import Process, Pipe

         def f(conn):
             conn.send([42, None, 'hello'])
             conn.close()

         if __name__ == '__main__':
             parent_conn, child_conn = Pipe()
             p = Process(target=f, args=(child_conn,))
             p.start()
             print parent_conn.recv()   # prints "[42, None, 'hello']"
             p.join()

     The two connection objects returned by *Note Pipe(): 1653.
     represent the two ends of the pipe.  Each connection object has
     *Note send(): 1654. and *Note recv(): 1655. methods (among
     others).  Note that data in a pipe may become corrupted if two
     processes (or threads) try to read from or write to the `same' end
     of the pipe at the same time.  Of course there is no risk of
     corruption from processes using different ends of the pipe at the
     same time.


File: python.info,  Node: Synchronization between processes,  Next: Sharing state between processes,  Prev: Exchanging objects between processes,  Up: Introduction<7>

5.16.6.4 Synchronization between processes
..........................................

*Note multiprocessing: 11a. contains equivalents of all the
synchronization primitives from *Note threading: 179.  For instance one
can use a lock to ensure that only one process prints to standard
output at a time:

    from multiprocessing import Process, Lock

    def f(l, i):
        l.acquire()
        print 'hello world', i
        l.release()

    if __name__ == '__main__':
        lock = Lock()

        for num in range(10):
            Process(target=f, args=(lock, num)).start()

Without using the lock output from the different processes is liable to
get all mixed up.


File: python.info,  Node: Sharing state between processes,  Next: Using a pool of workers,  Prev: Synchronization between processes,  Up: Introduction<7>

5.16.6.5 Sharing state between processes
........................................

As mentioned above, when doing concurrent programming it is usually
best to avoid using shared state as far as possible.  This is
particularly true when using multiple processes.

However, if you really do need to use some shared data then *Note
multiprocessing: 11a. provides a couple of ways of doing so.

`Shared memory'

     Data can be stored in a shared memory map using *Note Value: 1658.
     or *Note Array: 1659.  For example, the following code

         from multiprocessing import Process, Value, Array

         def f(n, a):
             n.value = 3.1415927
             for i in range(len(a)):
                 a[i] = -a[i]

         if __name__ == '__main__':
             num = Value('d', 0.0)
             arr = Array('i', range(10))

             p = Process(target=f, args=(num, arr))
             p.start()
             p.join()

             print num.value
             print arr[:]

     will print

         3.1415927
         [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]

     The `'d'' and `'i'' arguments used when creating `num' and `arr'
     are typecodes of the kind used by the *Note array: e. module:
     `'d'' indicates a double precision float and `'i'' indicates a
     signed integer.  These shared objects will be process and
     thread-safe.

     For more flexibility in using shared memory one can use the *Note
     multiprocessing.sharedctypes: 11f. module which supports the
     creation of arbitrary ctypes objects allocated from shared memory.

`Server process'

     A manager object returned by `Manager()' controls a server process
     which holds Python objects and allows other processes to
     manipulate them using proxies.

     A manager returned by `Manager()' will support types *Note list:
     3d6, *Note dict: 319, *Note Namespace: 165a, *Note Lock: 165b,
     *Note RLock: 165c, *Note Semaphore: 165d, *Note BoundedSemaphore:
     165e, *Note Condition: 165f, *Note Event: 1660, *Note Queue: 1652,
     *Note Value: 1658. and *Note Array: 1659.  For example,

         from multiprocessing import Process, Manager

         def f(d, l):
             d[1] = '1'
             d['2'] = 2
             d[0.25] = None
             l.reverse()

         if __name__ == '__main__':
             manager = Manager()

             d = manager.dict()
             l = manager.list(range(10))

             p = Process(target=f, args=(d, l))
             p.start()
             p.join()

             print d
             print l

     will print

         {0.25: None, 1: '1', '2': 2}
         [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]

     Server process managers are more flexible than using shared memory
     objects because they can be made to support arbitrary object
     types.  Also, a single manager can be shared by processes on
     different computers over a network.  They are, however, slower
     than using shared memory.


File: python.info,  Node: Using a pool of workers,  Prev: Sharing state between processes,  Up: Introduction<7>

5.16.6.6 Using a pool of workers
................................

The `Pool' class represents a pool of worker processes.  It has methods
which allows tasks to be offloaded to the worker processes in a few
different ways.

For example:

    from multiprocessing import Pool, TimeoutError
    import time
    import os

    def f(x):
        return x*x

    if __name__ == '__main__':
        pool = Pool(processes=4)              # start 4 worker processes

        # print "[0, 1, 4,..., 81]"
        print pool.map(f, range(10))

        # print same numbers in arbitrary order
        for i in pool.imap_unordered(f, range(10)):
            print i

        # evaluate "f(20)" asynchronously
        res = pool.apply_async(f, (20,))      # runs in *only* one process
        print res.get(timeout=1)              # prints "400"

        # evaluate "os.getpid()" asynchronously
        res = pool.apply_async(os.getpid, ()) # runs in *only* one process
        print res.get(timeout=1)              # prints the PID of that process

        # launching multiple evaluations asynchronously *may* use more processes
        multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)]
        print [res.get(timeout=1) for res in multiple_results]

        # make a single worker sleep for 10 secs
        res = pool.apply_async(time.sleep, (10,))
        try:
            print res.get(timeout=1)
        except TimeoutError:
            print "We lacked patience and got a multiprocessing.TimeoutError"

Note that the methods of a pool should only ever be used by the process
which created it.

     Note: Functionality within this package requires that the
     `__main__' module be importable by the children. This is covered
     in *Note Programming guidelines: 1650.  however it is worth
     pointing out here. This means that some examples, such as the
     `Pool' examples will not work in the interactive interpreter.  For
     example:

         >>> from multiprocessing import Pool
         >>> p = Pool(5)
         >>> def f(x):
         ...     return x*x
         ...
         >>> p.map(f, [1,2,3])
         Process PoolWorker-1:
         Process PoolWorker-2:
         Process PoolWorker-3:
         Traceback (most recent call last):
         Traceback (most recent call last):
         Traceback (most recent call last):
         AttributeError: 'module' object has no attribute 'f'
         AttributeError: 'module' object has no attribute 'f'
         AttributeError: 'module' object has no attribute 'f'

     (If you try this it will actually output three full tracebacks
     interleaved in a semi-random fashion, and then you may have to
     stop the master process somehow.)


File: python.info,  Node: Reference,  Next: Programming guidelines,  Prev: Introduction<7>,  Up: multiprocessing — Process-based “threading” interface

5.16.6.7 Reference
..................

The *Note multiprocessing: 11a. package mostly replicates the API of the
*Note threading: 179. module.

* Menu:

* Process and exceptions::
* Pipes and Queues::
* Miscellaneous: Miscellaneous<2>.
* Connection Objects: Connection Objects<2>.
* Synchronization primitives::
* Shared ctypes Objects::
* Managers::
* Proxy Objects::
* Process Pools::
* Listeners and Clients::
* Authentication keys::
* Logging: Logging<2>.
* The multiprocessing.dummy module: The multiprocessing dummy module.


File: python.info,  Node: Process and exceptions,  Next: Pipes and Queues,  Up: Reference

5.16.6.8 `Process' and exceptions
.................................

 -- Class: multiprocessing.Process (group=None, target=None, name=None,
          args=(), kwargs={})
     Process objects represent activity that is run in a separate
     process. The *Note Process: 164e. class has equivalents of all the
     methods of *Note threading.Thread: 1350.

     The constructor should always be called with keyword arguments.
     `group' should always be `None'; it exists solely for
     compatibility with *Note threading.Thread: 1350.  `target' is the
     callable object to be invoked by the *Note run(): 1664. method.
     It defaults to `None', meaning nothing is called. `name' is the
     process name.  By default, a unique name is constructed of the
     form ‘Process-N[1]:N[2]:…:N[k]’ where N[1],N[2],…,N[k] is
     a sequence of integers whose length is determined by the
     `generation' of the process.  `args' is the argument tuple for the
     target invocation.  `kwargs' is a dictionary of keyword arguments
     for the target invocation.  By default, no arguments are passed to
     `target'.

     If a subclass overrides the constructor, it must make sure it
     invokes the base class constructor (`Process.__init__()') before
     doing anything else to the process.

      -- Method: run ()
          Method representing the process’s activity.

          You may override this method in a subclass.  The standard
          *Note run(): 1664.  method invokes the callable object passed
          to the object’s constructor as the target argument, if any,
          with sequential and keyword arguments taken from the `args'
          and `kwargs' arguments, respectively.

      -- Method: start ()
          Start the process’s activity.

          This must be called at most once per process object.  It
          arranges for the object’s *Note run(): 1664. method to be
          invoked in a separate process.

      -- Method: join ([timeout])
          Block the calling thread until the process whose *Note
          join(): 1665. method is called terminates or until the
          optional timeout occurs.

          If `timeout' is `None' then there is no timeout.

          A process can be joined many times.

          A process cannot join itself because this would cause a
          deadlock.  It is an error to attempt to join a process before
          it has been started.

      -- Attribute: name
          The process’s name.

          The name is a string used for identification purposes only.
          It has no semantics.  Multiple processes may be given the
          same name.  The initial name is set by the constructor.

      -- Method: is_alive ()
          Return whether the process is alive.

          Roughly, a process object is alive from the moment the *Note
          start(): 164f.  method returns until the child process
          terminates.

      -- Attribute: daemon
          The process’s daemon flag, a Boolean value.  This must be
          set before *Note start(): 164f. is called.

          The initial value is inherited from the creating process.

          When a process exits, it attempts to terminate all of its
          daemonic child processes.

          Note that a daemonic process is not allowed to create child
          processes.  Otherwise a daemonic process would leave its
          children orphaned if it gets terminated when its parent
          process exits. Additionally, these are `not' Unix daemons or
          services, they are normal processes that will be terminated
          (and not joined) if non-daemonic processes have exited.

     In addition to the  *Note threading.Thread: 1350. API, *Note
     Process: 164e. objects also support the following attributes and
     methods:

      -- Attribute: pid
          Return the process ID.  Before the process is spawned, this
          will be `None'.

      -- Attribute: exitcode
          The child’s exit code.  This will be `None' if the process
          has not yet terminated.  A negative value `-N' indicates that
          the child was terminated by signal `N'.

      -- Attribute: authkey
          The process’s authentication key (a byte string).

          When *Note multiprocessing: 11a. is initialized the main
          process is assigned a random string using *Note os.urandom():
          2e6.

          When a *Note Process: 164e. object is created, it will
          inherit the authentication key of its parent process,
          although this may be changed by setting *Note authkey: 166b.
          to another byte string.

          See *Note Authentication keys: 166c.

      -- Method: terminate ()
          Terminate the process.  On Unix this is done using the
          `SIGTERM' signal; on Windows `TerminateProcess()' is used.
          Note that exit handlers and finally clauses, etc., will not
          be executed.

          Note that descendant processes of the process will `not' be
          terminated – they will simply become orphaned.

               Warning: If this method is used when the associated
               process is using a pipe or queue then the pipe or queue
               is liable to become corrupted and may become unusable by
               other process.  Similarly, if the process has acquired a
               lock or semaphore etc. then terminating it is liable to
               cause other processes to deadlock.

     Note that the *Note start(): 164f, *Note join(): 1665, *Note
     is_alive(): 1667, *Note terminate(): 166d. and *Note exitcode:
     166a. methods should only be called by the process that created
     the process object.

     Example usage of some of the methods of *Note Process: 164e.:

         >>> import multiprocessing, time, signal
         >>> p = multiprocessing.Process(target=time.sleep, args=(1000,))
         >>> print p, p.is_alive()
         <Process(Process-1, initial)> False
         >>> p.start()
         >>> print p, p.is_alive()
         <Process(Process-1, started)> True
         >>> p.terminate()
         >>> time.sleep(0.1)
         >>> print p, p.is_alive()
         <Process(Process-1, stopped[SIGTERM])> False
         >>> p.exitcode == -signal.SIGTERM
         True

 -- Exception: multiprocessing.BufferTooShort
     Exception raised by *Note Connection.recv_bytes_into(): 166f. when
     the supplied buffer object is too small for the message read.

     If `e' is an instance of *Note BufferTooShort: 166e. then
     `e.args[0]' will give the message as a byte string.


File: python.info,  Node: Pipes and Queues,  Next: Miscellaneous<2>,  Prev: Process and exceptions,  Up: Reference

5.16.6.9 Pipes and Queues
.........................

When using multiple processes, one generally uses message passing for
communication between processes and avoids having to use any
synchronization primitives like locks.

For passing messages one can use *Note Pipe(): 1653. (for a connection
between two processes) or a queue (which allows multiple producers and
consumers).

The *Note Queue: 1652, *Note multiprocessing.queues.SimpleQueue: 1671.
and *Note JoinableQueue: 1672. types are multi-producer, multi-consumer
FIFO queues modelled on the *Note Queue.Queue: 316. class in the
standard library.  They differ in that *Note Queue: 1652. lacks the
*Note task_done(): c12. and *Note join(): c13. methods introduced into
Python 2.5’s *Note Queue.Queue: 316. class.

If you use *Note JoinableQueue: 1672. then you `must' call *Note
JoinableQueue.task_done(): 1673. for each task removed from the queue
or else the semaphore used to count the number of unfinished tasks may
eventually overflow, raising an exception.

Note that one can also create a shared queue by using a manager object
– see *Note Managers: 1674.

     Note: *Note multiprocessing: 11a. uses the usual *Note
     Queue.Empty: 841. and *Note Queue.Full: c0a. exceptions to signal
     a timeout.  They are not available in the *Note multiprocessing:
     11a. namespace so you need to import them from *Note Queue: 141.

     Note: When an object is put on a queue, the object is pickled and a
     background thread later flushes the pickled data to an underlying
     pipe.  This has some consequences which are a little surprising,
     but should not cause any practical difficulties – if they really
     bother you then you can instead use a queue created with a *Note
     manager: 1674.

       1. After putting an object on an empty queue there may be an
          infinitesimal delay before the queue’s *Note empty(): 1675.
          method returns *Note False: 3c9. and *Note get_nowait():
          1676. can return without raising *Note Queue.Empty: 841.

       2. If multiple processes are enqueuing objects, it is possible
          for the objects to be received at the other end out-of-order.
          However, objects enqueued by the same process will always be
          in the expected order with respect to each other.

     Warning: If a process is killed using *Note Process.terminate():
     166d. or *Note os.kill(): 2d4.  while it is trying to use a *Note
     Queue: 1652, then the data in the queue is likely to become
     corrupted.  This may cause any other process to get an exception
     when it tries to use the queue later on.

     Warning: As mentioned above, if a child process has put items on a
     queue (and it has not used *Note JoinableQueue.cancel_join_thread:
     1677.), then that process will not terminate until all buffered
     items have been flushed to the pipe.

     This means that if you try joining that process you may get a
     deadlock unless you are sure that all items which have been put on
     the queue have been consumed.  Similarly, if the child process is
     non-daemonic then the parent process may hang on exit when it
     tries to join all its non-daemonic children.

     Note that a queue created using a manager does not have this
     issue.  See *Note Programming guidelines: 1650.

For an example of the usage of queues for interprocess communication see
*Note Examples: 1678.

 -- Function: multiprocessing.Pipe ([duplex])
     Returns a pair `(conn1, conn2)' of *Note Connection: 1679. objects
     representing the ends of a pipe.

     If `duplex' is `True' (the default) then the pipe is
     bidirectional.  If `duplex' is `False' then the pipe is
     unidirectional: `conn1' can only be used for receiving messages
     and `conn2' can only be used for sending messages.

 -- Class: multiprocessing.Queue ([maxsize])
     Returns a process shared queue implemented using a pipe and a few
     locks/semaphores.  When a process first puts an item on the queue
     a feeder thread is started which transfers objects from a buffer
     into the pipe.

     The usual *Note Queue.Empty: 841. and *Note Queue.Full: c0a.
     exceptions from the standard library’s *Note Queue: 141. module
     are raised to signal timeouts.

     *Note Queue: 1652. implements all the methods of *Note
     Queue.Queue: 316. except for *Note task_done(): c12. and *Note
     join(): c13.

      -- Method: qsize ()
          Return the approximate size of the queue.  Because of
          multithreading/multiprocessing semantics, this number is not
          reliable.

          Note that this may raise *Note NotImplementedError: 978. on
          Unix platforms like Mac OS X where `sem_getvalue()' is not
          implemented.

      -- Method: empty ()
          Return `True' if the queue is empty, `False' otherwise.
          Because of multithreading/multiprocessing semantics, this is
          not reliable.

      -- Method: full ()
          Return `True' if the queue is full, `False' otherwise.
          Because of multithreading/multiprocessing semantics, this is
          not reliable.

      -- Method: put (obj[, block[, timeout]])
          Put obj into the queue.  If the optional argument `block' is
          `True' (the default) and `timeout' is `None' (the default),
          block if necessary until a free slot is available.  If
          `timeout' is a positive number, it blocks at most `timeout'
          seconds and raises the *Note Queue.Full: c0a. exception if no
          free slot was available within that time.  Otherwise (`block'
          is `False'), put an item on the queue if a free slot is
          immediately available, else raise the *Note Queue.Full: c0a.
          exception (`timeout' is ignored in that case).

      -- Method: put_nowait (obj)
          Equivalent to `put(obj, False)'.

      -- Method: get ([block[, timeout]])
          Remove and return an item from the queue.  If optional args
          `block' is `True' (the default) and `timeout' is `None' (the
          default), block if necessary until an item is available.  If
          `timeout' is a positive number, it blocks at most `timeout'
          seconds and raises the *Note Queue.Empty: 841.  exception if
          no item was available within that time.  Otherwise (block is
          `False'), return an item if one is immediately available,
          else raise the *Note Queue.Empty: 841. exception (`timeout'
          is ignored in that case).

      -- Method: get_nowait ()
          Equivalent to `get(False)'.

     *Note Queue: 1652. has a few additional methods not found in *Note
     Queue.Queue: 316.  These methods are usually unnecessary for most
     code:

      -- Method: close ()
          Indicate that no more data will be put on this queue by the
          current process.  The background thread will quit once it has
          flushed all buffered data to the pipe.  This is called
          automatically when the queue is garbage collected.

      -- Method: join_thread ()
          Join the background thread.  This can only be used after
          *Note close(): 167f. has been called.  It blocks until the
          background thread exits, ensuring that all data in the buffer
          has been flushed to the pipe.

          By default if a process is not the creator of the queue then
          on exit it will attempt to join the queue’s background
          thread.  The process can call *Note cancel_join_thread():
          1677. to make *Note join_thread(): 1680. do nothing.

      -- Method: cancel_join_thread ()
          Prevent *Note join_thread(): 1680. from blocking.  In
          particular, this prevents the background thread from being
          joined automatically when the process exits – see *Note
          join_thread(): 1680.

          A better name for this method might be
          `allow_exit_without_flush()'.  It is likely to cause enqueued
          data to lost, and you almost certainly will not need to use
          it.  It is really only there if you need the current process
          to exit immediately without waiting to flush enqueued data to
          the underlying pipe, and you don’t care about lost data.

          Note: This class’s functionality requires a functioning
          shared semaphore implementation on the host operating system.
          Without one, the functionality in this class will be
          disabled, and attempts to instantiate a *Note Queue: 141.
          will result in an *Note ImportError: 388. See issue 3770(1)
          for additional information.  The same holds true for any of
          the specialized queue types listed below.

 -- Class: multiprocessing.queues.SimpleQueue
     It is a simplified *Note Queue: 1652. type, very close to a locked
     *Note Pipe: 1653.

      -- Method: empty ()
          Return `True' if the queue is empty, `False' otherwise.

      -- Method: get ()
          Remove and return an item from the queue.

      -- Method: put (item)
          Put `item' into the queue.

 -- Class: multiprocessing.JoinableQueue ([maxsize])
     *Note JoinableQueue: 1672, a *Note Queue: 1652. subclass, is a
     queue which additionally has *Note task_done(): 1673. and *Note
     join(): 1684. methods.

      -- Method: task_done ()
          Indicate that a formerly enqueued task is complete. Used by
          queue consumer threads.  For each *Note get(): 167e. used to
          fetch a task, a subsequent call to *Note task_done(): 1673.
          tells the queue that the processing on the task is complete.

          If a *Note join(): c13. is currently blocking, it will resume
          when all items have been processed (meaning that a *Note
          task_done(): 1673. call was received for every item that had
          been *Note put(): 167c. into the queue).

          Raises a *Note ValueError: 236. if called more times than
          there were items placed in the queue.

      -- Method: join ()
          Block until all items in the queue have been gotten and
          processed.

          The count of unfinished tasks goes up whenever an item is
          added to the queue.  The count goes down whenever a consumer
          thread calls *Note task_done(): 1673. to indicate that the
          item was retrieved and all work on it is complete.  When the
          count of unfinished tasks drops to zero, *Note join(): c13.
          unblocks.

---------- Footnotes ----------

(1) https://bugs.python.org/issue3770


File: python.info,  Node: Miscellaneous<2>,  Next: Connection Objects<2>,  Prev: Pipes and Queues,  Up: Reference

5.16.6.10 Miscellaneous
.......................

 -- Function: multiprocessing.active_children ()
     Return list of all live children of the current process.

     Calling this has the side effect of “joining” any processes
     which have already finished.

 -- Function: multiprocessing.cpu_count ()
     Return the number of CPUs in the system.  May raise *Note
     NotImplementedError: 978.

 -- Function: multiprocessing.current_process ()
     Return the *Note Process: 164e. object corresponding to the
     current process.

     An analogue of *Note threading.current_thread(): 1600.

 -- Function: multiprocessing.freeze_support ()
     Add support for when a program which uses *Note multiprocessing:
     11a. has been frozen to produce a Windows executable.  (Has been
     tested with `py2exe', `PyInstaller' and `cx_Freeze'.)

     One needs to call this function straight after the `if __name__ ==
     '__main__'' line of the main module.  For example:

         from multiprocessing import Process, freeze_support

         def f():
             print 'hello world!'

         if __name__ == '__main__':
             freeze_support()
             Process(target=f).start()

     If the `freeze_support()' line is omitted then trying to run the
     frozen executable will raise *Note RuntimeError: 3b3.

     Calling `freeze_support()' has no effect when invoked on any
     operating system other than Windows.  In addition, if the module
     is being run normally by the Python interpreter on Windows (the
     program has not been frozen), then `freeze_support()' has no
     effect.

 -- Function: multiprocessing.set_executable ()
     Sets the path of the Python interpreter to use when starting a
     child process.  (By default *Note sys.executable: 168b. is used).
     Embedders will probably need to do some thing like

         set_executable(os.path.join(sys.exec_prefix, 'pythonw.exe'))

     before they can create child processes.  (Windows only)

     Note: *Note multiprocessing: 11a. contains no analogues of *Note
     threading.active_count(): 15fc, *Note threading.enumerate(): 15fe,
     *Note threading.settrace(): 160c, *Note threading.setprofile():
     160e, *Note threading.Timer: bf1, or *Note threading.local: 1572.


File: python.info,  Node: Connection Objects<2>,  Next: Synchronization primitives,  Prev: Miscellaneous<2>,  Up: Reference

5.16.6.11 Connection Objects
............................

Connection objects allow the sending and receiving of picklable objects
or strings.  They can be thought of as message oriented connected
sockets.

Connection objects are usually created using *Note Pipe(): 1653. –
see also *Note Listeners and Clients: 168d.

 -- Class: multiprocessing.Connection
      -- Method: send (obj)
          Send an object to the other end of the connection which
          should be read using *Note recv(): 1655.

          The object must be picklable.  Very large pickles
          (approximately 32 MB+, though it depends on the OS) may raise
          a *Note ValueError: 236. exception.

      -- Method: recv ()
          Return an object sent from the other end of the connection
          using *Note send(): 1654.  Blocks until there its something
          to receive.  Raises *Note EOFError: 8b3. if there is nothing
          left to receive and the other end was closed.

      -- Method: fileno ()
          Return the file descriptor or handle used by the connection.

      -- Method: close ()
          Close the connection.

          This is called automatically when the connection is garbage
          collected.

      -- Method: poll ([timeout])
          Return whether there is any data available to be read.

          If `timeout' is not specified then it will return
          immediately.  If `timeout' is a number then this specifies
          the maximum time in seconds to block.  If `timeout' is `None'
          then an infinite timeout is used.

      -- Method: send_bytes (buffer[, offset[, size]])
          Send byte data from an object supporting the buffer interface
          as a complete message.

          If `offset' is given then data is read from that position in
          `buffer'.  If `size' is given then that many bytes will be
          read from buffer.  Very large buffers (approximately 32 MB+,
          though it depends on the OS) may raise a *Note ValueError:
          236. exception

      -- Method: recv_bytes ([maxlength])
          Return a complete message of byte data sent from the other
          end of the connection as a string.  Blocks until there is
          something to receive.  Raises *Note EOFError: 8b3. if there
          is nothing left to receive and the other end has closed.

          If `maxlength' is specified and the message is longer than
          `maxlength' then *Note IOError: 1fa. is raised and the
          connection will no longer be readable.

      -- Method: recv_bytes_into (buffer[, offset])
          Read into `buffer' a complete message of byte data sent from
          the other end of the connection and return the number of
          bytes in the message.  Blocks until there is something to
          receive.  Raises *Note EOFError: 8b3. if there is nothing
          left to receive and the other end was closed.

          `buffer' must be an object satisfying the writable buffer
          interface.  If `offset' is given then the message will be
          written into the buffer from that position.  Offset must be a
          non-negative integer less than the length of `buffer' (in
          bytes).

          If the buffer is too short then a *Note BufferTooShort: 166e.
          exception is raised and the complete message is available as
          `e.args[0]' where `e' is the exception instance.

For example:

    >>> from multiprocessing import Pipe
    >>> a, b = Pipe()
    >>> a.send([1, 'hello', None])
    >>> b.recv()
    [1, 'hello', None]
    >>> b.send_bytes('thank you')
    >>> a.recv_bytes()
    'thank you'
    >>> import array
    >>> arr1 = array.array('i', range(5))
    >>> arr2 = array.array('i', [0] * 10)
    >>> a.send_bytes(arr1)
    >>> count = b.recv_bytes_into(arr2)
    >>> assert count == len(arr1) * arr1.itemsize
    >>> arr2
    array('i', [0, 1, 2, 3, 4, 0, 0, 0, 0, 0])

     Warning: The *Note Connection.recv(): 1655. method automatically
     unpickles the data it receives, which can be a security risk
     unless you can trust the process which sent the message.

     Therefore, unless the connection object was produced using *Note
     Pipe(): 1653. you should only use the *Note recv(): 1655. and
     *Note send(): 1654.  methods after performing some sort of
     authentication.  See *Note Authentication keys: 166c.

     Warning: If a process is killed while it is trying to read or
     write to a pipe then the data in the pipe is likely to become
     corrupted, because it may become impossible to be sure where the
     message boundaries lie.


File: python.info,  Node: Synchronization primitives,  Next: Shared ctypes Objects,  Prev: Connection Objects<2>,  Up: Reference

5.16.6.12 Synchronization primitives
....................................

Generally synchronization primitives are not as necessary in a
multiprocess program as they are in a multithreaded program.  See the
documentation for *Note threading: 179. module.

Note that one can also create synchronization primitives by using a
manager object – see *Note Managers: 1674.

 -- Class: multiprocessing.BoundedSemaphore ([value])
     A bounded semaphore object: a close analog of *Note
     threading.BoundedSemaphore: 1609.

     A solitary difference from its close analog exists: its `acquire'
     method’s first argument is named `block' and it supports an
     optional second argument `timeout', as is consistent with *Note
     Lock.acquire(): 1694.

          Note: On Mac OS X, this is indistinguishable from *Note
          Semaphore: 165d. because `sem_getvalue()' is not implemented
          on that platform.

 -- Class: multiprocessing.Condition ([lock])
     A condition variable: a clone of *Note threading.Condition: 1623.

     If `lock' is specified then it should be a *Note Lock: 165b. or
     *Note RLock: 165c.  object from *Note multiprocessing: 11a.

 -- Class: multiprocessing.Event
     A clone of *Note threading.Event: 26a.  This method returns the
     state of the internal semaphore on exit, so it will always return
     `True' except if a timeout is given and the operation times out.

     Changed in version 2.7: Previously, the method always returned
     `None'.


 -- Class: multiprocessing.Lock
     A non-recursive lock object: a close analog of *Note
     threading.Lock: 1604.  Once a process or thread has acquired a
     lock, subsequent attempts to acquire it from any process or thread
     will block until it is released; any process or thread may release
     it.  The concepts and behaviors of *Note threading.Lock: 1604. as
     it applies to threads are replicated here in *Note
     multiprocessing.Lock: 165b. as it applies to either processes or
     threads, except as noted.

     Note that *Note Lock: 165b. is actually a factory function which
     returns an instance of `multiprocessing.synchronize.Lock'
     initialized with a default context.

     *Note Lock: 165b. supports the *Note context manager: 1695.
     protocol and thus may be used in *Note with: 1c1. statements.

      -- Method: acquire (block=True, timeout=None)
          Acquire a lock, blocking or non-blocking.

          With the `block' argument set to `True' (the default), the
          method call will block until the lock is in an unlocked
          state, then set it to locked and return `True'.  Note that
          the name of this first argument differs from that in *Note
          threading.Lock.acquire(): 161d.

          With the `block' argument set to `False', the method call
          does not block.  If the lock is currently in a locked state,
          return `False'; otherwise set the lock to a locked state and
          return `True'.

          When invoked with a positive, floating-point value for
          `timeout', block for at most the number of seconds specified
          by `timeout' as long as the lock can not be acquired.
          Invocations with a negative value for `timeout' are
          equivalent to a `timeout' of zero.  Invocations with a
          `timeout' value of `None' (the default) set the timeout
          period to infinite.  The `timeout' argument has no practical
          implications if the `block' argument is set to `False' and is
          thus ignored.  Returns `True' if the lock has been acquired
          or `False' if the timeout period has elapsed.  Note that the
          `timeout' argument does not exist in this method’s analog,
          *Note threading.Lock.acquire(): 161d.

      -- Method: release ()
          Release a lock.  This can be called from any process or
          thread, not only the process or thread which originally
          acquired the lock.

          Behavior is the same as in *Note threading.Lock.release():
          161e. except that when invoked on an unlocked lock, a *Note
          ValueError: 236. is raised.

 -- Class: multiprocessing.RLock
     A recursive lock object: a close analog of *Note threading.RLock:
     1606.  A recursive lock must be released by the process or thread
     that acquired it.  Once a process or thread has acquired a
     recursive lock, the same process or thread may acquire it again
     without blocking; that process or thread must release it once for
     each time it has been acquired.

     Note that *Note RLock: 165c. is actually a factory function which
     returns an instance of `multiprocessing.synchronize.RLock'
     initialized with a default context.

     *Note RLock: 165c. supports the *Note context manager: 1695.
     protocol and thus may be used in *Note with: 1c1. statements.

      -- Method: acquire (block=True, timeout=None)
          Acquire a lock, blocking or non-blocking.

          When invoked with the `block' argument set to `True', block
          until the lock is in an unlocked state (not owned by any
          process or thread) unless the lock is already owned by the
          current process or thread.  The current process or thread
          then takes ownership of the lock (if it does not already have
          ownership) and the recursion level inside the lock increments
          by one, resulting in a return value of `True'.  Note that
          there are several differences in this first argument’s
          behavior compared to the implementation of *Note
          threading.RLock.acquire(): 1620, starting with the name of
          the argument itself.

          When invoked with the `block' argument set to `False', do not
          block.  If the lock has already been acquired (and thus is
          owned) by another process or thread, the current process or
          thread does not take ownership and the recursion level within
          the lock is not changed, resulting in a return value of
          `False'.  If the lock is in an unlocked state, the current
          process or thread takes ownership and the recursion level is
          incremented, resulting in a return value of `True'.

          Use and behaviors of the `timeout' argument are the same as in
          *Note Lock.acquire(): 1694.  Note that the `timeout' argument
          does not exist in this method’s analog, *Note
          threading.RLock.acquire(): 1620.

      -- Method: release ()
          Release a lock, decrementing the recursion level.  If after
          the decrement the recursion level is zero, reset the lock to
          unlocked (not owned by any process or thread) and if any
          other processes or threads are blocked waiting for the lock
          to become unlocked, allow exactly one of them to proceed.  If
          after the decrement the recursion level is still nonzero, the
          lock remains locked and owned by the calling process or
          thread.

          Only call this method when the calling process or thread owns
          the lock.  An *Note AssertionError: 834. is raised if this
          method is called by a process or thread other than the owner
          or if the lock is in an unlocked (unowned) state.  Note that
          the type of exception raised in this situation differs from
          the implemented behavior in *Note threading.RLock.release():
          1621.

 -- Class: multiprocessing.Semaphore ([value])
     A semaphore object: a close analog of *Note threading.Semaphore:
     162b.

     A solitary difference from its close analog exists: its `acquire'
     method’s first argument is named `block' and it supports an
     optional second argument `timeout', as is consistent with *Note
     Lock.acquire(): 1694.

     Note: The `acquire()' method of *Note BoundedSemaphore: 165e,
     *Note Lock: 165b, *Note RLock: 165c. and *Note Semaphore: 165d.
     has a timeout parameter not supported by the equivalents in *Note
     threading: 179.  The signature is `acquire(block=True,
     timeout=None)' with keyword parameters being acceptable.  If
     `block' is `True' and `timeout' is not `None' then it specifies a
     timeout in seconds.  If `block' is `False' then `timeout' is
     ignored.

     On Mac OS X, `sem_timedwait' is unsupported, so calling
     `acquire()' with a timeout will emulate that function’s behavior
     using a sleeping loop.

     Note: If the SIGINT signal generated by `Ctrl-C' arrives while the
     main thread is blocked by a call to `BoundedSemaphore.acquire()',
     *Note Lock.acquire(): 1694, *Note RLock.acquire(): 1697,
     `Semaphore.acquire()', `Condition.acquire()' or `Condition.wait()'
     then the call will be immediately interrupted and *Note
     KeyboardInterrupt: 251. will be raised.

     This differs from the behaviour of *Note threading: 179. where
     SIGINT will be ignored while the equivalent blocking calls are in
     progress.

     Note: Some of this package’s functionality requires a
     functioning shared semaphore implementation on the host operating
     system. Without one, the `multiprocessing.synchronize' module will
     be disabled, and attempts to import it will result in an *Note
     ImportError: 388. See issue 3770(1) for additional information.

---------- Footnotes ----------

(1) https://bugs.python.org/issue3770


File: python.info,  Node: Shared ctypes Objects,  Next: Managers,  Prev: Synchronization primitives,  Up: Reference

5.16.6.13 Shared `ctypes' Objects
.................................

It is possible to create shared objects using shared memory which can be
inherited by child processes.

 -- Function: multiprocessing.Value (typecode_or_type, *args[, lock])
     Return a *Note ctypes: 78. object allocated from shared memory.
     By default the return value is actually a synchronized wrapper for
     the object.

     `typecode_or_type' determines the type of the returned object: it
     is either a ctypes type or a one character typecode of the kind
     used by the *Note array: e.  module.  `*args' is passed on to the
     constructor for the type.

     If `lock' is `True' (the default) then a new recursive lock object
     is created to synchronize access to the value.  If `lock' is a
     *Note Lock: 165b. or *Note RLock: 165c. object then that will be
     used to synchronize access to the value.  If `lock' is `False' then
     access to the returned object will not be automatically protected
     by a lock, so it will not necessarily be “process-safe”.

     Operations like `+=' which involve a read and write are not
     atomic.  So if, for instance, you want to atomically increment a
     shared value it is insufficient to just do

         counter.value += 1

     Assuming the associated lock is recursive (which it is by default)
     you can instead do

         with counter.get_lock():
             counter.value += 1

     Note that `lock' is a keyword-only argument.

 -- Function: multiprocessing.Array (typecode_or_type,
          size_or_initializer, *, lock=True)
     Return a ctypes array allocated from shared memory.  By default
     the return value is actually a synchronized wrapper for the array.

     `typecode_or_type' determines the type of the elements of the
     returned array: it is either a ctypes type or a one character
     typecode of the kind used by the *Note array: e. module.  If
     `size_or_initializer' is an integer, then it determines the length
     of the array, and the array will be initially zeroed.  Otherwise,
     `size_or_initializer' is a sequence which is used to initialize
     the array and whose length determines the length of the array.

     If `lock' is `True' (the default) then a new lock object is
     created to synchronize access to the value.  If `lock' is a *Note
     Lock: 165b. or *Note RLock: 165c. object then that will be used to
     synchronize access to the value.  If `lock' is `False' then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be “process-safe”.

     Note that `lock' is a keyword only argument.

     Note that an array of *Note ctypes.c_char: 153a. has `value' and
     `raw' attributes which allow one to use it to store and retrieve
     strings.

* Menu:

* The multiprocessing.sharedctypes module: The multiprocessing sharedctypes module.


File: python.info,  Node: The multiprocessing sharedctypes module,  Up: Shared ctypes Objects

5.16.6.14 The `multiprocessing.sharedctypes' module
...................................................

The *Note multiprocessing.sharedctypes: 11f. module provides functions
for allocating *Note ctypes: 78. objects from shared memory which can
be inherited by child processes.

     Note: Although it is possible to store a pointer in shared memory
     remember that this will refer to a location in the address space
     of a specific process.  However, the pointer is quite likely to be
     invalid in the context of a second process and trying to
     dereference the pointer from the second process may cause a crash.

 -- Function: multiprocessing.sharedctypes.RawArray (typecode_or_type,
          size_or_initializer)
     Return a ctypes array allocated from shared memory.

     `typecode_or_type' determines the type of the elements of the
     returned array: it is either a ctypes type or a one character
     typecode of the kind used by the *Note array: e. module.  If
     `size_or_initializer' is an integer then it determines the length
     of the array, and the array will be initially zeroed.  Otherwise
     `size_or_initializer' is a sequence which is used to initialize the
     array and whose length determines the length of the array.

     Note that setting and getting an element is potentially non-atomic
     – use *Note Array(): 169c. instead to make sure that access is
     automatically synchronized using a lock.

 -- Function: multiprocessing.sharedctypes.RawValue (typecode_or_type,
          *args)
     Return a ctypes object allocated from shared memory.

     `typecode_or_type' determines the type of the returned object: it
     is either a ctypes type or a one character typecode of the kind
     used by the *Note array: e.  module.  `*args' is passed on to the
     constructor for the type.

     Note that setting and getting the value is potentially non-atomic
     – use *Note Value(): 169e. instead to make sure that access is
     automatically synchronized using a lock.

     Note that an array of *Note ctypes.c_char: 153a. has `value' and
     `raw' attributes which allow one to use it to store and retrieve
     strings – see documentation for *Note ctypes: 78.

 -- Function: multiprocessing.sharedctypes.Array (typecode_or_type,
          size_or_initializer, *args[, lock])
     The same as *Note RawArray(): 169b. except that depending on the
     value of `lock' a process-safe synchronization wrapper may be
     returned instead of a raw ctypes array.

     If `lock' is `True' (the default) then a new lock object is
     created to synchronize access to the value.  If `lock' is a *Note
     Lock: 165b. or *Note RLock: 165c. object then that will be used to
     synchronize access to the value.  If `lock' is `False' then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be “process-safe”.

     Note that `lock' is a keyword-only argument.

 -- Function: multiprocessing.sharedctypes.Value (typecode_or_type,
          *args[, lock])
     The same as *Note RawValue(): 169d. except that depending on the
     value of `lock' a process-safe synchronization wrapper may be
     returned instead of a raw ctypes object.

     If `lock' is `True' (the default) then a new lock object is
     created to synchronize access to the value.  If `lock' is a *Note
     Lock: 165b. or *Note RLock: 165c. object then that will be used to
     synchronize access to the value.  If `lock' is `False' then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be “process-safe”.

     Note that `lock' is a keyword-only argument.

 -- Function: multiprocessing.sharedctypes.copy (obj)
     Return a ctypes object allocated from shared memory which is a
     copy of the ctypes object `obj'.

 -- Function: multiprocessing.sharedctypes.synchronized (obj[, lock])
     Return a process-safe wrapper object for a ctypes object which
     uses `lock' to synchronize access.  If `lock' is `None' (the
     default) then a *Note multiprocessing.RLock: 165c. object is
     created automatically.

     A synchronized wrapper will have two methods in addition to those
     of the object it wraps: `get_obj()' returns the wrapped object and
     `get_lock()' returns the lock object used for synchronization.

     Note that accessing the ctypes object through the wrapper can be a
     lot slower than accessing the raw ctypes object.

The table below compares the syntax for creating shared ctypes objects
from shared memory with the normal ctypes syntax.  (In the table
`MyStruct' is some subclass of *Note ctypes.Structure: 155b.)

ctypes                   sharedctypes using type        sharedctypes using typecode
---------------------------------------------------------------------------------------- 
c_double(2.4)            RawValue(c_double, 2.4)        RawValue(‘d’, 2.4)
MyStruct(4, 6)           RawValue(MyStruct, 4, 6)       
(c_short * 7)()          RawArray(c_short, 7)           RawArray(‘h’, 7)
(c_int * 3)(9, 2, 8)     RawArray(c_int, (9, 2, 8))     RawArray(‘i’, (9, 2, 8))

Below is an example where a number of ctypes objects are modified by a
child process:

    from multiprocessing import Process, Lock
    from multiprocessing.sharedctypes import Value, Array
    from ctypes import Structure, c_double

    class Point(Structure):
        _fields_ = [('x', c_double), ('y', c_double)]

    def modify(n, x, s, A):
        n.value **= 2
        x.value **= 2
        s.value = s.value.upper()
        for a in A:
            a.x **= 2
            a.y **= 2

    if __name__ == '__main__':
        lock = Lock()

        n = Value('i', 7)
        x = Value(c_double, 1.0/3.0, lock=False)
        s = Array('c', 'hello world', lock=lock)
        A = Array(Point, [(1.875,-6.25), (-5.75,2.0), (2.375,9.5)], lock=lock)

        p = Process(target=modify, args=(n, x, s, A))
        p.start()
        p.join()

        print n.value
        print x.value
        print s.value
        print [(a.x, a.y) for a in A]

The results printed are

    49
    0.1111111111111111
    HELLO WORLD
    [(3.515625, 39.0625), (33.0625, 4.0), (5.640625, 90.25)]


File: python.info,  Node: Managers,  Next: Proxy Objects,  Prev: Shared ctypes Objects,  Up: Reference

5.16.6.15 Managers
..................

Managers provide a way to create data which can be shared between
different processes. A manager object controls a server process which
manages `shared objects'.  Other processes can access the shared
objects by using proxies.

 -- Function: multiprocessing.Manager ()
     Returns a started *Note SyncManager: 16a3. object which can be
     used for sharing objects between processes.  The returned manager
     object corresponds to a spawned child process and has methods
     which will create shared objects and return corresponding proxies.

Manager processes will be shutdown as soon as they are garbage
collected or their parent process exits.  The manager classes are
defined in the *Note multiprocessing.managers: 11d. module:

 -- Class: multiprocessing.managers.BaseManager ([address[, authkey]])
     Create a BaseManager object.

     Once created one should call *Note start(): 16a5. or
     `get_server().serve_forever()' to ensure that the manager object
     refers to a started manager process.

     `address' is the address on which the manager process listens for
     new connections.  If `address' is `None' then an arbitrary one is
     chosen.

     `authkey' is the authentication key which will be used to check
     the validity of incoming connections to the server process.  If
     `authkey' is `None' then `current_process().authkey'.  Otherwise
     `authkey' is used and it must be a string.

      -- Method: start ([initializer[, initargs]])
          Start a subprocess to start the manager.  If `initializer' is
          not `None' then the subprocess will call
          `initializer(*initargs)' when it starts.

      -- Method: get_server ()
          Returns a `Server' object which represents the actual server
          under the control of the Manager. The `Server' object
          supports the `serve_forever()' method:

              >>> from multiprocessing.managers import BaseManager
              >>> manager = BaseManager(address=('', 50000), authkey='abc')
              >>> server = manager.get_server()
              >>> server.serve_forever()

          `Server' additionally has an *Note address: 16a7. attribute.

      -- Method: connect ()
          Connect a local manager object to a remote manager process:

              >>> from multiprocessing.managers import BaseManager
              >>> m = BaseManager(address=('127.0.0.1', 5000), authkey='abc')
              >>> m.connect()

      -- Method: shutdown ()
          Stop the process used by the manager.  This is only available
          if *Note start(): 16a5. has been used to start the server
          process.

          This can be called multiple times.

      -- Method: register (typeid[, callable[, proxytype[, exposed[,
               method_to_typeid[, create_method]]]]])
          A classmethod which can be used for registering a type or
          callable with the manager class.

          `typeid' is a “type identifier” which is used to identify
          a particular type of shared object.  This must be a string.

          `callable' is a callable used for creating objects for this
          type identifier.  If a manager instance will be created using
          the `from_address()' classmethod or if the `create_method'
          argument is `False' then this can be left as `None'.

          `proxytype' is a subclass of *Note BaseProxy: 16ab. which is
          used to create proxies for shared objects with this `typeid'.
          If `None' then a proxy class is created automatically.

          `exposed' is used to specify a sequence of method names which
          proxies for this typeid should be allowed to access using
          *Note BaseProxy._callmethod(): 16ac.  (If `exposed' is `None'
          then `proxytype._exposed_' is used instead if it exists.)  In
          the case where no exposed list is specified, all “public
          methods” of the shared object will be accessible.  (Here a
          “public method” means any attribute which has a *Note
          __call__(): 725. method and whose name does not begin with
          `'_''.)

          `method_to_typeid' is a mapping used to specify the return
          type of those exposed methods which should return a proxy.
          It maps method names to typeid strings.  (If
          `method_to_typeid' is `None' then
          `proxytype._method_to_typeid_' is used instead if it exists.)
          If a method’s name is not a key of this mapping or if the
          mapping is `None' then the object returned by the method will
          be copied by value.

          `create_method' determines whether a method should be created
          with name `typeid' which can be used to tell the server
          process to create a new shared object and return a proxy for
          it.  By default it is `True'.

     *Note BaseManager: 16a4. instances also have one read-only
     property:

      -- Attribute: address
          The address used by the manager.

 -- Class: multiprocessing.managers.SyncManager
     A subclass of *Note BaseManager: 16a4. which can be used for the
     synchronization of processes.  Objects of this type are returned by
     `multiprocessing.Manager()'.

     It also supports creation of shared lists and dictionaries.

      -- Method: BoundedSemaphore ([value])
          Create a shared *Note threading.BoundedSemaphore: 1609.
          object and return a proxy for it.

      -- Method: Condition ([lock])
          Create a shared *Note threading.Condition: 1623. object and
          return a proxy for it.

          If `lock' is supplied then it should be a proxy for a *Note
          threading.Lock: 1604. or *Note threading.RLock: 1606. object.

      -- Method: Event ()
          Create a shared *Note threading.Event: 26a. object and return
          a proxy for it.

      -- Method: Lock ()
          Create a shared *Note threading.Lock: 1604. object and return
          a proxy for it.

      -- Method: Namespace ()
          Create a shared *Note Namespace: 165a. object and return a
          proxy for it.

      -- Method: Queue ([maxsize])
          Create a shared *Note Queue.Queue: 316. object and return a
          proxy for it.

      -- Method: RLock ()
          Create a shared *Note threading.RLock: 1606. object and
          return a proxy for it.

      -- Method: Semaphore ([value])
          Create a shared *Note threading.Semaphore: 162b. object and
          return a proxy for it.

      -- Method: Array (typecode, sequence)
          Create an array and return a proxy for it.

      -- Method: Value (typecode, value)
          Create an object with a writable `value' attribute and return
          a proxy for it.

      -- Method: dict ()
      -- Method: dict (mapping)
      -- Method: dict (sequence)
          Create a shared `dict' object and return a proxy for it.

      -- Method: list ()
      -- Method: list (sequence)
          Create a shared `list' object and return a proxy for it.

          Note: Modifications to mutable values or items in dict and
          list proxies will not be propagated through the manager,
          because the proxy has no way of knowing when its values or
          items are modified.  To modify such an item, you can
          re-assign the modified object to the container proxy:

              # create a list proxy and append a mutable object (a dictionary)
              lproxy = manager.list()
              lproxy.append({})
              # now mutate the dictionary
              d = lproxy[0]
              d['a'] = 1
              d['b'] = 2
              # at this point, the changes to d are not yet synced, but by
              # reassigning the dictionary, the proxy is notified of the change
              lproxy[0] = d

 -- Class: multiprocessing.managers.Namespace
     A type that can register with *Note SyncManager: 16a3.

     A namespace object has no public methods, but does have writable
     attributes.  Its representation shows the values of its attributes.

     However, when using a proxy for a namespace object, an attribute
     beginning with `'_'' will be an attribute of the proxy and not an
     attribute of the referent:

         >>> manager = multiprocessing.Manager()
         >>> Global = manager.Namespace()
         >>> Global.x = 10
         >>> Global.y = 'hello'
         >>> Global._z = 12.3    # this is an attribute of the proxy
         >>> print Global
         Namespace(x=10, y='hello')

* Menu:

* Customized managers::
* Using a remote manager::


File: python.info,  Node: Customized managers,  Next: Using a remote manager,  Up: Managers

5.16.6.16 Customized managers
.............................

To create one’s own manager, one creates a subclass of *Note
BaseManager: 16a4. and uses the *Note register(): 16aa. classmethod to
register new types or callables with the manager class.  For example:

    from multiprocessing.managers import BaseManager

    class MathsClass(object):
        def add(self, x, y):
            return x + y
        def mul(self, x, y):
            return x * y

    class MyManager(BaseManager):
        pass

    MyManager.register('Maths', MathsClass)

    if __name__ == '__main__':
        manager = MyManager()
        manager.start()
        maths = manager.Maths()
        print maths.add(4, 3)         # prints 7
        print maths.mul(7, 8)         # prints 56


File: python.info,  Node: Using a remote manager,  Prev: Customized managers,  Up: Managers

5.16.6.17 Using a remote manager
................................

It is possible to run a manager server on one machine and have clients
use it from other machines (assuming that the firewalls involved allow
it).

Running the following commands creates a server for a single shared
queue which remote clients can access:

    >>> from multiprocessing.managers import BaseManager
    >>> import Queue
    >>> queue = Queue.Queue()
    >>> class QueueManager(BaseManager): pass
    >>> QueueManager.register('get_queue', callable=lambda:queue)
    >>> m = QueueManager(address=('', 50000), authkey='abracadabra')
    >>> s = m.get_server()
    >>> s.serve_forever()

One client can access the server as follows:

    >>> from multiprocessing.managers import BaseManager
    >>> class QueueManager(BaseManager): pass
    >>> QueueManager.register('get_queue')
    >>> m = QueueManager(address=('foo.bar.org', 50000), authkey='abracadabra')
    >>> m.connect()
    >>> queue = m.get_queue()
    >>> queue.put('hello')

Another client can also use it:

    >>> from multiprocessing.managers import BaseManager
    >>> class QueueManager(BaseManager): pass
    >>> QueueManager.register('get_queue')
    >>> m = QueueManager(address=('foo.bar.org', 50000), authkey='abracadabra')
    >>> m.connect()
    >>> queue = m.get_queue()
    >>> queue.get()
    'hello'

Local processes can also access that queue, using the code from above
on the client to access it remotely:

    >>> from multiprocessing import Process, Queue
    >>> from multiprocessing.managers import BaseManager
    >>> class Worker(Process):
    ...     def __init__(self, q):
    ...         self.q = q
    ...         super(Worker, self).__init__()
    ...     def run(self):
    ...         self.q.put('local hello')
    ...
    >>> queue = Queue()
    >>> w = Worker(queue)
    >>> w.start()
    >>> class QueueManager(BaseManager): pass
    ...
    >>> QueueManager.register('get_queue', callable=lambda: queue)
    >>> m = QueueManager(address=('', 50000), authkey='abracadabra')
    >>> s = m.get_server()
    >>> s.serve_forever()


File: python.info,  Node: Proxy Objects,  Next: Process Pools,  Prev: Managers,  Up: Reference

5.16.6.18 Proxy Objects
.......................

A proxy is an object which `refers' to a shared object which lives
(presumably) in a different process.  The shared object is said to be
the `referent' of the proxy.  Multiple proxy objects may have the same
referent.

A proxy object has methods which invoke corresponding methods of its
referent (although not every method of the referent will necessarily be
available through the proxy).  A proxy can usually be used in most of
the same ways that its referent can:

    >>> from multiprocessing import Manager
    >>> manager = Manager()
    >>> l = manager.list([i*i for i in range(10)])
    >>> print l
    [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
    >>> print repr(l)
    <ListProxy object, typeid 'list' at 0x...>
    >>> l[4]
    16
    >>> l[2:5]
    [4, 9, 16]

Notice that applying *Note str(): 1ea. to a proxy will return the
representation of the referent, whereas applying *Note repr(): 1c6.
will return the representation of the proxy.

An important feature of proxy objects is that they are picklable so
they can be passed between processes.  Note, however, that if a proxy
is sent to the corresponding manager’s process then unpickling it
will produce the referent itself.  This means, for example, that one
shared object can contain a second:

    >>> a = manager.list()
    >>> b = manager.list()
    >>> a.append(b)         # referent of a now contains referent of b
    >>> print a, b
    [[]] []
    >>> b.append('hello')
    >>> print a, b
    [['hello']] ['hello']

     Note: The proxy types in *Note multiprocessing: 11a. do nothing to
     support comparisons by value.  So, for instance, we have:

         >>> manager.list([1,2,3]) == [1,2,3]
         False

     One should just use a copy of the referent instead when making
     comparisons.

 -- Class: multiprocessing.managers.BaseProxy
     Proxy objects are instances of subclasses of *Note BaseProxy: 16ab.

      -- Method: _callmethod (methodname[, args[, kwds]])
          Call and return the result of a method of the proxy’s
          referent.

          If `proxy' is a proxy whose referent is `obj' then the
          expression

              proxy._callmethod(methodname, args, kwds)

          will evaluate the expression

              getattr(obj, methodname)(*args, **kwds)

          in the manager’s process.

          The returned value will be a copy of the result of the call
          or a proxy to a new shared object – see documentation for
          the `method_to_typeid' argument of *Note
          BaseManager.register(): 16aa.

          If an exception is raised by the call, then is re-raised by
          *Note _callmethod(): 16ac.  If some other exception is raised
          in the manager’s process then this is converted into a
          `RemoteError' exception and is raised by *Note _callmethod():
          16ac.

          Note in particular that an exception will be raised if
          `methodname' has not been `exposed'.

          An example of the usage of *Note _callmethod(): 16ac.:

              >>> l = manager.list(range(10))
              >>> l._callmethod('__len__')
              10
              >>> l._callmethod('__getslice__', (2, 7))   # equiv to `l[2:7]`
              [2, 3, 4, 5, 6]
              >>> l._callmethod('__getitem__', (20,))     # equiv to `l[20]`
              Traceback (most recent call last):
              ...
              IndexError: list index out of range

      -- Method: _getvalue ()
          Return a copy of the referent.

          If the referent is unpicklable then this will raise an
          exception.

      -- Method: __repr__ ()
          Return a representation of the proxy object.

      -- Method: __str__ ()
          Return the representation of the referent.

* Menu:

* Cleanup: Cleanup<2>.


File: python.info,  Node: Cleanup<2>,  Up: Proxy Objects

5.16.6.19 Cleanup
.................

A proxy object uses a weakref callback so that when it gets garbage
collected it deregisters itself from the manager which owns its
referent.

A shared object gets deleted from the manager process when there are no
longer any proxies referring to it.


File: python.info,  Node: Process Pools,  Next: Listeners and Clients,  Prev: Proxy Objects,  Up: Reference

5.16.6.20 Process Pools
.......................

One can create a pool of processes which will carry out tasks submitted
to it with the `Pool' class.

 -- Class: multiprocessing.Pool ([processes[, initializer[, initargs[,
          maxtasksperchild]]]])
     A process pool object which controls a pool of worker processes to
     which jobs can be submitted.  It supports asynchronous results
     with timeouts and callbacks and has a parallel map implementation.

     `processes' is the number of worker processes to use.  If
     `processes' is `None' then the number returned by `cpu_count()' is
     used.  If `initializer' is not `None' then each worker process
     will call `initializer(*initargs)' when it starts.

     Note that the methods of the pool object should only be called by
     the process which created the pool.

     New in version 2.7: `maxtasksperchild' is the number of tasks a
     worker process can complete before it will exit and be replaced
     with a fresh worker process, to enable unused resources to be
     freed. The default `maxtasksperchild' is `None', which means
     worker processes will live as long as the pool.

          Note: Worker processes within a `Pool' typically live for the
          complete duration of the Pool’s work queue. A frequent
          pattern found in other systems (such as Apache, mod_wsgi,
          etc) to free resources held by workers is to allow a worker
          within a pool to complete only a set amount of work before
          being exiting, being cleaned up and a new process spawned to
          replace the old one. The `maxtasksperchild' argument to the
          `Pool' exposes this ability to the end user.

      -- Method: apply (func[, args[, kwds]])
          Equivalent of the *Note apply(): 317. built-in function.  It
          blocks until the result is ready, so *Note apply_async():
          16c3. is better suited for performing work in parallel.
          Additionally, `func' is only executed in one of the workers
          of the pool.

      -- Method: apply_async (func[, args[, kwds[, callback]]])
          A variant of the *Note apply(): 317. method which returns a
          result object.

          If `callback' is specified then it should be a callable which
          accepts a single argument.  When the result becomes ready
          `callback' is applied to it (unless the call failed).
          `callback' should complete immediately since otherwise the
          thread which handles the results will get blocked.

      -- Method: map (func, iterable[, chunksize])
          A parallel equivalent of the *Note map(): 318. built-in
          function (it supports only one `iterable' argument though).
          It blocks until the result is ready.

          This method chops the iterable into a number of chunks which
          it submits to the process pool as separate tasks.  The
          (approximate) size of these chunks can be specified by
          setting `chunksize' to a positive integer.

      -- Method: map_async (func, iterable[, chunksize[, callback]])
          A variant of the *Note map(): 16c4. method which returns a
          result object.

          If `callback' is specified then it should be a callable which
          accepts a single argument.  When the result becomes ready
          `callback' is applied to it (unless the call failed).
          `callback' should complete immediately since otherwise the
          thread which handles the results will get blocked.

      -- Method: imap (func, iterable[, chunksize])
          An equivalent of *Note itertools.imap(): d8d.

          The `chunksize' argument is the same as the one used by the
          *Note map(): 16c4.  method.  For very long iterables using a
          large value for `chunksize' can make the job complete `much'
          faster than using the default value of `1'.

          Also if `chunksize' is `1' then the `next()' method of the
          iterator returned by the *Note imap(): 16c6. method has an
          optional `timeout' parameter: `next(timeout)' will raise
          `multiprocessing.TimeoutError' if the result cannot be
          returned within `timeout' seconds.

      -- Method: imap_unordered (func, iterable[, chunksize])
          The same as *Note imap(): 16c6. except that the ordering of
          the results from the returned iterator should be considered
          arbitrary.  (Only when there is only one worker process is
          the order guaranteed to be “correct”.)

      -- Method: close ()
          Prevents any more tasks from being submitted to the pool.
          Once all the tasks have been completed the worker processes
          will exit.

      -- Method: terminate ()
          Stops the worker processes immediately without completing
          outstanding work.  When the pool object is garbage collected
          *Note terminate(): 16c9. will be called immediately.

      -- Method: join ()
          Wait for the worker processes to exit.  One must call *Note
          close(): 16c8. or *Note terminate(): 16c9. before using *Note
          join(): 16ca.

 -- Class: multiprocessing.pool.AsyncResult
     The class of the result returned by `Pool.apply_async()' and
     `Pool.map_async()'.

      -- Method: get ([timeout])
          Return the result when it arrives.  If `timeout' is not
          `None' and the result does not arrive within `timeout'
          seconds then `multiprocessing.TimeoutError' is raised.  If
          the remote call raised an exception then that exception will
          be reraised by *Note get(): 16cc.

      -- Method: wait ([timeout])
          Wait until the result is available or until `timeout' seconds
          pass.

      -- Method: ready ()
          Return whether the call has completed.

      -- Method: successful ()
          Return whether the call completed without raising an
          exception.  Will raise *Note AssertionError: 834. if the
          result is not ready.

The following example demonstrates the use of a pool:

    from multiprocessing import Pool
    import time

    def f(x):
        return x*x

    if __name__ == '__main__':
        pool = Pool(processes=4)              # start 4 worker processes

        result = pool.apply_async(f, (10,))   # evaluate "f(10)" asynchronously in a single process
        print result.get(timeout=1)           # prints "100" unless your computer is *very* slow

        print pool.map(f, range(10))          # prints "[0, 1, 4,..., 81]"

        it = pool.imap(f, range(10))
        print it.next()                       # prints "0"
        print it.next()                       # prints "1"
        print it.next(timeout=1)              # prints "4" unless your computer is *very* slow

        result = pool.apply_async(time.sleep, (10,))
        print result.get(timeout=1)           # raises multiprocessing.TimeoutError


File: python.info,  Node: Listeners and Clients,  Next: Authentication keys,  Prev: Process Pools,  Up: Reference

5.16.6.21 Listeners and Clients
...............................

Usually message passing between processes is done using queues or by
using *Note Connection: 1679. objects returned by *Note Pipe(): 1653.

However, the *Note multiprocessing.connection: 11b. module allows some
extra flexibility.  It basically gives a high level message oriented
API for dealing with sockets or Windows named pipes, and also has
support for `digest authentication' using the *Note hmac: e9. module.

 -- Function: multiprocessing.connection.deliver_challenge (connection,
          authkey)
     Send a randomly generated message to the other end of the
     connection and wait for a reply.

     If the reply matches the digest of the message using `authkey' as
     the key then a welcome message is sent to the other end of the
     connection.  Otherwise *Note AuthenticationError: 16d2. is raised.

 -- Function: multiprocessing.connection.answer_challenge (connection,
          authkey)
     Receive a message, calculate the digest of the message using
     `authkey' as the key, and then send the digest back.

     If a welcome message is not received, then *Note
     AuthenticationError: 16d2. is raised.

 -- Function: multiprocessing.connection.Client (address[, family[,
          authenticate[, authkey]]])
     Attempt to set up a connection to the listener which is using
     address `address', returning a *Note Connection: 1679.

     The type of the connection is determined by `family' argument, but
     this can generally be omitted since it can usually be inferred
     from the format of `address'. (See *Note Address Formats: 16d5.)

     If `authenticate' is `True' or `authkey' is a string then digest
     authentication is used.  The key used for authentication will be
     either `authkey' or `current_process().authkey)' if `authkey' is
     `None'.  If authentication fails then *Note AuthenticationError:
     16d2. is raised.  See *Note Authentication keys: 166c.

 -- Class: multiprocessing.connection.Listener ([address[, family[,
          backlog[, authenticate[, authkey]]]]])
     A wrapper for a bound socket or Windows named pipe which is
     ‘listening’ for connections.

     `address' is the address to be used by the bound socket or named
     pipe of the listener object.

          Note: If an address of ‘0.0.0.0’ is used, the address
          will not be a connectable end point on Windows. If you
          require a connectable end-point, you should use
          ‘127.0.0.1’.

     `family' is the type of socket (or named pipe) to use.  This can
     be one of the strings `'AF_INET'' (for a TCP socket), `'AF_UNIX''
     (for a Unix domain socket) or `'AF_PIPE'' (for a Windows named
     pipe).  Of these only the first is guaranteed to be available.  If
     `family' is `None' then the family is inferred from the format of
     `address'.  If `address' is also `None' then a default is chosen.
     This default is the family which is assumed to be the fastest
     available.  See *Note Address Formats: 16d5.  Note that if
     `family' is `'AF_UNIX'' and address is `None' then the socket will
     be created in a private temporary directory created using *Note
     tempfile.mkstemp(): eb1.

     If the listener object uses a socket then `backlog' (1 by default)
     is passed to the *Note listen(): 16d7. method of the socket once
     it has been bound.

     If `authenticate' is `True' (`False' by default) or `authkey' is
     not `None' then digest authentication is used.

     If `authkey' is a string then it will be used as the
     authentication key; otherwise it must be `None'.

     If `authkey' is `None' and `authenticate' is `True' then
     `current_process().authkey' is used as the authentication key.  If
     `authkey' is `None' and `authenticate' is `False' then no
     authentication is done.  If authentication fails then *Note
     AuthenticationError: 16d2. is raised.  See *Note Authentication
     keys: 166c.

      -- Method: accept ()
          Accept a connection on the bound socket or named pipe of the
          listener object and return a *Note Connection: 1679. object.
          If authentication is attempted and fails, then
          `AuthenticationError' is raised.

      -- Method: close ()
          Close the bound socket or named pipe of the listener object.
          This is called automatically when the listener is garbage
          collected.  However it is advisable to call it explicitly.

     Listener objects have the following read-only properties:

      -- Attribute: address
          The address which is being used by the Listener object.

      -- Attribute: last_accepted
          The address from which the last accepted connection came.  If
          this is unavailable then it is `None'.

The module defines two exceptions:

 -- Exception: multiprocessing.connection.AuthenticationError
     Exception raised when there is an authentication error.

`Examples'

The following server code creates a listener which uses `'secret
password'' as an authentication key.  It then waits for a connection
and sends some data to the client:

    from multiprocessing.connection import Listener
    from array import array

    address = ('localhost', 6000)     # family is deduced to be 'AF_INET'
    listener = Listener(address, authkey='secret password')

    conn = listener.accept()
    print 'connection accepted from', listener.last_accepted

    conn.send([2.25, None, 'junk', float])

    conn.send_bytes('hello')

    conn.send_bytes(array('i', [42, 1729]))

    conn.close()
    listener.close()

The following code connects to the server and receives some data from
the server:

    from multiprocessing.connection import Client
    from array import array

    address = ('localhost', 6000)
    conn = Client(address, authkey='secret password')

    print conn.recv()                 # => [2.25, None, 'junk', float]

    print conn.recv_bytes()            # => 'hello'

    arr = array('i', [0, 0, 0, 0, 0])
    print conn.recv_bytes_into(arr)     # => 8
    print arr                         # => array('i', [42, 1729, 0, 0, 0])

    conn.close()

* Menu:

* Address Formats::


File: python.info,  Node: Address Formats,  Up: Listeners and Clients

5.16.6.22 Address Formats
.........................

   * An `'AF_INET'' address is a tuple of the form `(hostname, port)'
     where `hostname' is a string and `port' is an integer.

   * An `'AF_UNIX'' address is a string representing a filename on the
     filesystem.

   *
    An `'AF_PIPE'' address is a string of the form
          `r'\\.\pipe\`PipeName'''.  To use *Note Client(): 16d4. to
          connect to a named pipe on a remote computer called
          `ServerName' one should use an address of the form
          `r'\\`ServerName'\pipe\`PipeName''' instead.

Note that any string beginning with two backslashes is assumed by
default to be an `'AF_PIPE'' address rather than an `'AF_UNIX'' address.


File: python.info,  Node: Authentication keys,  Next: Logging<2>,  Prev: Listeners and Clients,  Up: Reference

5.16.6.23 Authentication keys
.............................

When one uses *Note Connection.recv: 1655, the data received is
automatically unpickled.  Unfortunately unpickling data from an
untrusted source is a security risk.  Therefore *Note Listener: 16d6.
and *Note Client(): 16d4. use the *Note hmac: e9. module to provide
digest authentication.

An authentication key is a string which can be thought of as a
password: once a connection is established both ends will demand proof
that the other knows the authentication key.  (Demonstrating that both
ends are using the same key does `not' involve sending the key over the
connection.)

If authentication is requested but no authentication key is specified
then the return value of `current_process().authkey' is used (see *Note
Process: 164e.).  This value will be automatically inherited by any
*Note Process: 164e. object that the current process creates.  This
means that (by default) all processes of a multi-process program will
share a single authentication key which can be used when setting up
connections between themselves.

Suitable authentication keys can also be generated by using *Note
os.urandom(): 2e6.


File: python.info,  Node: Logging<2>,  Next: The multiprocessing dummy module,  Prev: Authentication keys,  Up: Reference

5.16.6.24 Logging
.................

Some support for logging is available.  Note, however, that the *Note
logging: 102.  package does not use process shared locks so it is
possible (depending on the handler type) for messages from different
processes to get mixed up.

 -- Function: multiprocessing.get_logger ()
     Returns the logger used by *Note multiprocessing: 11a.  If
     necessary, a new one will be created.

     When first created the logger has level `logging.NOTSET' and no
     default handler. Messages sent to this logger will not by default
     propagate to the root logger.

     Note that on Windows child processes will only inherit the level
     of the parent process’s logger – any other customization of
     the logger will not be inherited.

 -- Function: multiprocessing.log_to_stderr ()
     This function performs a call to *Note get_logger(): 16df. but in
     addition to returning the logger created by get_logger, it adds a
     handler which sends output to *Note sys.stderr: 672. using format
     `'[%(levelname)s/%(processName)s] %(message)s''.

Below is an example session with logging turned on:

    >>> import multiprocessing, logging
    >>> logger = multiprocessing.log_to_stderr()
    >>> logger.setLevel(logging.INFO)
    >>> logger.warning('doomed')
    [WARNING/MainProcess] doomed
    >>> m = multiprocessing.Manager()
    [INFO/SyncManager-...] child process calling self.run()
    [INFO/SyncManager-...] created temp directory /.../pymp-...
    [INFO/SyncManager-...] manager serving at '/.../listener-...'
    >>> del m
    [INFO/MainProcess] sending shutdown message to manager
    [INFO/SyncManager-...] manager exiting with exitcode 0

In addition to having these two logging functions, the multiprocessing
also exposes two additional logging level attributes. These are
`SUBWARNING' and `SUBDEBUG'. The table below illustrates where theses
fit in the normal level hierarchy.

Level                Numeric value
------------------------------------------ 
`SUBWARNING'         25
`SUBDEBUG'           5

For a full table of logging levels, see the *Note logging: 102. module.

These additional logging levels are used primarily for certain debug
messages within the multiprocessing module. Below is the same example
as above, except with `SUBDEBUG' enabled:

    >>> import multiprocessing, logging
    >>> logger = multiprocessing.log_to_stderr()
    >>> logger.setLevel(multiprocessing.SUBDEBUG)
    >>> logger.warning('doomed')
    [WARNING/MainProcess] doomed
    >>> m = multiprocessing.Manager()
    [INFO/SyncManager-...] child process calling self.run()
    [INFO/SyncManager-...] created temp directory /.../pymp-...
    [INFO/SyncManager-...] manager serving at '/.../pymp-djGBXN/listener-...'
    >>> del m
    [SUBDEBUG/MainProcess] finalizer calling ...
    [INFO/MainProcess] sending shutdown message to manager
    [DEBUG/SyncManager-...] manager received shutdown message
    [SUBDEBUG/SyncManager-...] calling <Finalize object, callback=unlink, ...
    [SUBDEBUG/SyncManager-...] finalizer calling <built-in function unlink> ...
    [SUBDEBUG/SyncManager-...] calling <Finalize object, dead>
    [SUBDEBUG/SyncManager-...] finalizer calling <function rmtree at 0x5aa730> ...
    [INFO/SyncManager-...] manager exiting with exitcode 0


File: python.info,  Node: The multiprocessing dummy module,  Prev: Logging<2>,  Up: Reference

5.16.6.25 The `multiprocessing.dummy' module
............................................

*Note multiprocessing.dummy: 11c. replicates the API of *Note
multiprocessing: 11a. but is no more than a wrapper around the *Note
threading: 179. module.


File: python.info,  Node: Programming guidelines,  Next: Examples<7>,  Prev: Reference,  Up: multiprocessing — Process-based “threading” interface

5.16.6.26 Programming guidelines
................................

There are certain guidelines and idioms which should be adhered to when
using *Note multiprocessing: 11a.

* Menu:

* All platforms::
* Windows::


File: python.info,  Node: All platforms,  Next: Windows,  Up: Programming guidelines

5.16.6.27 All platforms
.......................

Avoid shared state

     As far as possible one should try to avoid shifting large amounts
     of data between processes.

     It is probably best to stick to using queues or pipes for
     communication between processes rather than using the lower level
     synchronization primitives from the *Note threading: 179. module.

Picklability

     Ensure that the arguments to the methods of proxies are picklable.

Thread safety of proxies

     Do not use a proxy object from more than one thread unless you
     protect it with a lock.

     (There is never a problem with different processes using the
     `same' proxy.)

Joining zombie processes

     On Unix when a process finishes but has not been joined it becomes
     a zombie.  There should never be very many because each time a new
     process starts (or *Note active_children(): 1686. is called) all
     completed processes which have not yet been joined will be joined.
     Also calling a finished process’s *Note Process.is_alive: 1667.
     will join the process.  Even so it is probably good practice to
     explicitly join all the processes that you start.

Better to inherit than pickle/unpickle

     On Windows many types from *Note multiprocessing: 11a. need to be
     picklable so that child processes can use them.  However, one
     should generally avoid sending shared objects to other processes
     using pipes or queues.  Instead you should arrange the program so
     that a process which needs access to a shared resource created
     elsewhere can inherit it from an ancestor process.

Avoid terminating processes

     Using the *Note Process.terminate: 166d.  method to stop a process
     is liable to cause any shared resources (such as locks,
     semaphores, pipes and queues) currently being used by the process
     to become broken or unavailable to other processes.

     Therefore it is probably best to only consider using *Note
     Process.terminate: 166d. on processes which never use any shared
     resources.

Joining processes that use queues

     Bear in mind that a process that has put items in a queue will
     wait before terminating until all the buffered items are fed by
     the “feeder” thread to the underlying pipe.  (The child
     process can call the *Note cancel_join_thread(): 1677. method of
     the queue to avoid this behaviour.)

     This means that whenever you use a queue you need to make sure
     that all items which have been put on the queue will eventually be
     removed before the process is joined.  Otherwise you cannot be
     sure that processes which have put items on the queue will
     terminate.  Remember also that non-daemonic processes will be
     joined automatically.

     An example which will deadlock is the following:

         from multiprocessing import Process, Queue

         def f(q):
             q.put('X' * 1000000)

         if __name__ == '__main__':
             queue = Queue()
             p = Process(target=f, args=(queue,))
             p.start()
             p.join()                    # this deadlocks
             obj = queue.get()

     A fix here would be to swap the last two lines (or simply remove
     the `p.join()' line).

Explicitly pass resources to child processes

     On Unix a child process can make use of a shared resource created
     in a parent process using a global resource.  However, it is
     better to pass the object as an argument to the constructor for
     the child process.

     Apart from making the code (potentially) compatible with Windows
     this also ensures that as long as the child process is still alive
     the object will not be garbage collected in the parent process.
     This might be important if some resource is freed when the object
     is garbage collected in the parent process.

     So for instance

         from multiprocessing import Process, Lock

         def f():
             ... do something using "lock" ...

         if __name__ == '__main__':
             lock = Lock()
             for i in range(10):
                 Process(target=f).start()

     should be rewritten as

         from multiprocessing import Process, Lock

         def f(l):
             ... do something using "l" ...

         if __name__ == '__main__':
             lock = Lock()
             for i in range(10):
                 Process(target=f, args=(lock,)).start()

Beware of replacing *Note sys.stdin: 65c. with a “file like object”

     *Note multiprocessing: 11a. originally unconditionally called:

         os.close(sys.stdin.fileno())

     in the `multiprocessing.Process._bootstrap()' method — this
     resulted in issues with processes-in-processes. This has been
     changed to:

         sys.stdin.close()
         sys.stdin = open(os.devnull)

     Which solves the fundamental issue of processes colliding with
     each other resulting in a bad file descriptor error, but
     introduces a potential danger to applications which replace *Note
     sys.stdin(): 65c. with a “file-like object” with output
     buffering.  This danger is that if multiple processes call *Note
     close(): 1140. on this file-like object, it could result in the
     same data being flushed to the object multiple times, resulting in
     corruption.

     If you write a file-like object and implement your own caching,
     you can make it fork-safe by storing the pid whenever you append
     to the cache, and discarding the cache when the pid changes. For
     example:

         @property
         def cache(self):
             pid = os.getpid()
             if pid != self._pid:
                 self._pid = pid
                 self._cache = []
             return self._cache

     For more information, see issue 5155(1), issue 5313(2) and issue
     5331(3)

---------- Footnotes ----------

(1) https://bugs.python.org/issue5155

(2) https://bugs.python.org/issue5313

(3) https://bugs.python.org/issue5331


File: python.info,  Node: Windows,  Prev: All platforms,  Up: Programming guidelines

5.16.6.28 Windows
.................

Since Windows lacks *Note os.fork(): 244. it has a few extra
restrictions:

More picklability

     Ensure that all arguments to `Process.__init__()' are picklable.
     This means, in particular, that bound or unbound methods cannot be
     used directly as the `target' argument on Windows — just define
     a function and use that instead.

     Also, if you subclass *Note Process: 164e. then make sure that
     instances will be picklable when the *Note Process.start: 164f.
     method is called.

Global variables

     Bear in mind that if code run in a child process tries to access a
     global variable, then the value it sees (if any) may not be the
     same as the value in the parent process at the time that *Note
     Process.start: 164f. was called.

     However, global variables which are just module level constants
     cause no problems.

Safe importing of main module

     Make sure that the main module can be safely imported by a new
     Python interpreter without causing unintended side effects (such a
     starting a new process).

     For example, under Windows running the following module would fail
     with a *Note RuntimeError: 3b3.:

         from multiprocessing import Process

         def foo():
             print 'hello'

         p = Process(target=foo)
         p.start()

     Instead one should protect the “entry point” of the program by
     using `if __name__ == '__main__':' as follows:

         from multiprocessing import Process, freeze_support

         def foo():
             print 'hello'

         if __name__ == '__main__':
             freeze_support()
             p = Process(target=foo)
             p.start()

     (The `freeze_support()' line can be omitted if the program will be
     run normally instead of frozen.)

     This allows the newly spawned Python interpreter to safely import
     the module and then run the module’s `foo()' function.

     Similar restrictions apply if a pool or manager is created in the
     main module.


File: python.info,  Node: Examples<7>,  Prev: Programming guidelines,  Up: multiprocessing — Process-based “threading” interface

5.16.6.29 Examples
..................

Demonstration of how to create and use customized managers and proxies:

    #
    # This module shows how to use arbitrary callables with a subclass of
    # `BaseManager`.
    #
    # Copyright (c) 2006-2008, R Oudkerk
    # All rights reserved.
    #

    from multiprocessing import freeze_support
    from multiprocessing.managers import BaseManager, BaseProxy
    import operator

    ##

    class Foo(object):
        def f(self):
            print 'you called Foo.f()'
        def g(self):
            print 'you called Foo.g()'
        def _h(self):
            print 'you called Foo._h()'

    # A simple generator function
    def baz():
        for i in xrange(10):
            yield i*i

    # Proxy type for generator objects
    class GeneratorProxy(BaseProxy):
        _exposed_ = ('next', '__next__')
        def __iter__(self):
            return self
        def next(self):
            return self._callmethod('next')
        def __next__(self):
            return self._callmethod('__next__')

    # Function to return the operator module
    def get_operator_module():
        return operator

    ##

    class MyManager(BaseManager):
        pass

    # register the Foo class; make `f()` and `g()` accessible via proxy
    MyManager.register('Foo1', Foo)

    # register the Foo class; make `g()` and `_h()` accessible via proxy
    MyManager.register('Foo2', Foo, exposed=('g', '_h'))

    # register the generator function baz; use `GeneratorProxy` to make proxies
    MyManager.register('baz', baz, proxytype=GeneratorProxy)

    # register get_operator_module(); make public functions accessible via proxy
    MyManager.register('operator', get_operator_module)

    ##

    def test():
        manager = MyManager()
        manager.start()

        print '-' * 20

        f1 = manager.Foo1()
        f1.f()
        f1.g()
        assert not hasattr(f1, '_h')
        assert sorted(f1._exposed_) == sorted(['f', 'g'])

        print '-' * 20

        f2 = manager.Foo2()
        f2.g()
        f2._h()
        assert not hasattr(f2, 'f')
        assert sorted(f2._exposed_) == sorted(['g', '_h'])

        print '-' * 20

        it = manager.baz()
        for i in it:
            print '<%d>' % i,
        print

        print '-' * 20

        op = manager.operator()
        print 'op.add(23, 45) =', op.add(23, 45)
        print 'op.pow(2, 94) =', op.pow(2, 94)
        print 'op.getslice(range(10), 2, 6) =', op.getslice(range(10), 2, 6)
        print 'op.repeat(range(5), 3) =', op.repeat(range(5), 3)
        print 'op._exposed_ =', op._exposed_

    ##

    if __name__ == '__main__':
        freeze_support()
        test()

Using `Pool':

    #
    # A test of `multiprocessing.Pool` class
    #
    # Copyright (c) 2006-2008, R Oudkerk
    # All rights reserved.
    #

    import multiprocessing
    import time
    import random
    import sys

    #
    # Functions used by test code
    #

    def calculate(func, args):
        result = func(*args)
        return '%s says that %s%s = %s' % (
            multiprocessing.current_process().name,
            func.__name__, args, result
            )

    def calculatestar(args):
        return calculate(*args)

    def mul(a, b):
        time.sleep(0.5*random.random())
        return a * b

    def plus(a, b):
        time.sleep(0.5*random.random())
        return a + b

    def f(x):
        return 1.0 / (x-5.0)

    def pow3(x):
        return x**3

    def noop(x):
        pass

    #
    # Test code
    #

    def test():
        print 'cpu_count() = %d\n' % multiprocessing.cpu_count()

        #
        # Create pool
        #

        PROCESSES = 4
        print 'Creating pool with %d processes\n' % PROCESSES
        pool = multiprocessing.Pool(PROCESSES)
        print 'pool = %s' % pool
        print

        #
        # Tests
        #

        TASKS = [(mul, (i, 7)) for i in range(10)] + \
                [(plus, (i, 8)) for i in range(10)]

        results = [pool.apply_async(calculate, t) for t in TASKS]
        imap_it = pool.imap(calculatestar, TASKS)
        imap_unordered_it = pool.imap_unordered(calculatestar, TASKS)

        print 'Ordered results using pool.apply_async():'
        for r in results:
            print '\t', r.get()
        print

        print 'Ordered results using pool.imap():'
        for x in imap_it:
            print '\t', x
        print

        print 'Unordered results using pool.imap_unordered():'
        for x in imap_unordered_it:
            print '\t', x
        print

        print 'Ordered results using pool.map() --- will block till complete:'
        for x in pool.map(calculatestar, TASKS):
            print '\t', x
        print

        #
        # Simple benchmarks
        #

        N = 100000
        print 'def pow3(x): return x**3'

        t = time.time()
        A = map(pow3, xrange(N))
        print '\tmap(pow3, xrange(%d)):\n\t\t%s seconds' % \
              (N, time.time() - t)

        t = time.time()
        B = pool.map(pow3, xrange(N))
        print '\tpool.map(pow3, xrange(%d)):\n\t\t%s seconds' % \
              (N, time.time() - t)

        t = time.time()
        C = list(pool.imap(pow3, xrange(N), chunksize=N//8))
        print '\tlist(pool.imap(pow3, xrange(%d), chunksize=%d)):\n\t\t%s' \
              ' seconds' % (N, N//8, time.time() - t)

        assert A == B == C, (len(A), len(B), len(C))
        print

        L = [None] * 1000000
        print 'def noop(x): pass'
        print 'L = [None] * 1000000'

        t = time.time()
        A = map(noop, L)
        print '\tmap(noop, L):\n\t\t%s seconds' % \
              (time.time() - t)

        t = time.time()
        B = pool.map(noop, L)
        print '\tpool.map(noop, L):\n\t\t%s seconds' % \
              (time.time() - t)

        t = time.time()
        C = list(pool.imap(noop, L, chunksize=len(L)//8))
        print '\tlist(pool.imap(noop, L, chunksize=%d)):\n\t\t%s seconds' % \
              (len(L)//8, time.time() - t)

        assert A == B == C, (len(A), len(B), len(C))
        print

        del A, B, C, L

        #
        # Test error handling
        #

        print 'Testing error handling:'

        try:
            print pool.apply(f, (5,))
        except ZeroDivisionError:
            print '\tGot ZeroDivisionError as expected from pool.apply()'
        else:
            raise AssertionError('expected ZeroDivisionError')

        try:
            print pool.map(f, range(10))
        except ZeroDivisionError:
            print '\tGot ZeroDivisionError as expected from pool.map()'
        else:
            raise AssertionError('expected ZeroDivisionError')

        try:
            print list(pool.imap(f, range(10)))
        except ZeroDivisionError:
            print '\tGot ZeroDivisionError as expected from list(pool.imap())'
        else:
            raise AssertionError('expected ZeroDivisionError')

        it = pool.imap(f, range(10))
        for i in range(10):
            try:
                x = it.next()
            except ZeroDivisionError:
                if i == 5:
                    pass
            except StopIteration:
                break
            else:
                if i == 5:
                    raise AssertionError('expected ZeroDivisionError')

        assert i == 9
        print '\tGot ZeroDivisionError as expected from IMapIterator.next()'
        print

        #
        # Testing timeouts
        #

        print 'Testing ApplyResult.get() with timeout:',
        res = pool.apply_async(calculate, TASKS[0])
        while 1:
            sys.stdout.flush()
            try:
                sys.stdout.write('\n\t%s' % res.get(0.02))
                break
            except multiprocessing.TimeoutError:
                sys.stdout.write('.')
        print
        print

        print 'Testing IMapIterator.next() with timeout:',
        it = pool.imap(calculatestar, TASKS)
        while 1:
            sys.stdout.flush()
            try:
                sys.stdout.write('\n\t%s' % it.next(0.02))
            except StopIteration:
                break
            except multiprocessing.TimeoutError:
                sys.stdout.write('.')
        print
        print

        #
        # Testing callback
        #

        print 'Testing callback:'

        A = []
        B = [56, 0, 1, 8, 27, 64, 125, 216, 343, 512, 729]

        r = pool.apply_async(mul, (7, 8), callback=A.append)
        r.wait()

        r = pool.map_async(pow3, range(10), callback=A.extend)
        r.wait()

        if A == B:
            print '\tcallbacks succeeded\n'
        else:
            print '\t*** callbacks failed\n\t\t%s != %s\n' % (A, B)

        #
        # Check there are no outstanding tasks
        #

        assert not pool._cache, 'cache = %r' % pool._cache

        #
        # Check close() methods
        #

        print 'Testing close():'

        for worker in pool._pool:
            assert worker.is_alive()

        result = pool.apply_async(time.sleep, [0.5])
        pool.close()
        pool.join()

        assert result.get() is None

        for worker in pool._pool:
            assert not worker.is_alive()

        print '\tclose() succeeded\n'

        #
        # Check terminate() method
        #

        print 'Testing terminate():'

        pool = multiprocessing.Pool(2)
        DELTA = 0.1
        ignore = pool.apply(pow3, [2])
        results = [pool.apply_async(time.sleep, [DELTA]) for i in range(100)]
        pool.terminate()
        pool.join()

        for worker in pool._pool:
            assert not worker.is_alive()

        print '\tterminate() succeeded\n'

        #
        # Check garbage collection
        #

        print 'Testing garbage collection:'

        pool = multiprocessing.Pool(2)
        DELTA = 0.1
        processes = pool._pool
        ignore = pool.apply(pow3, [2])
        results = [pool.apply_async(time.sleep, [DELTA]) for i in range(100)]

        results = pool = None

        time.sleep(DELTA * 2)

        for worker in processes:
            assert not worker.is_alive()

        print '\tgarbage collection succeeded\n'


    if __name__ == '__main__':
        multiprocessing.freeze_support()

        assert len(sys.argv) in (1, 2)

        if len(sys.argv) == 1 or sys.argv[1] == 'processes':
            print ' Using processes '.center(79, '-')
        elif sys.argv[1] == 'threads':
            print ' Using threads '.center(79, '-')
            import multiprocessing.dummy as multiprocessing
        else:
            print 'Usage:\n\t%s [processes | threads]' % sys.argv[0]
            raise SystemExit(2)

        test()

Synchronization types like locks, conditions and queues:

    #
    # A test file for the `multiprocessing` package
    #
    # Copyright (c) 2006-2008, R Oudkerk
    # All rights reserved.
    #

    import time, sys, random
    from Queue import Empty

    import multiprocessing               # may get overwritten


    #### TEST_VALUE

    def value_func(running, mutex):
        random.seed()
        time.sleep(random.random()*4)

        mutex.acquire()
        print '\n\t\t\t' + str(multiprocessing.current_process()) + ' has finished'
        running.value -= 1
        mutex.release()

    def test_value():
        TASKS = 10
        running = multiprocessing.Value('i', TASKS)
        mutex = multiprocessing.Lock()

        for i in range(TASKS):
            p = multiprocessing.Process(target=value_func, args=(running, mutex))
            p.start()

        while running.value > 0:
            time.sleep(0.08)
            mutex.acquire()
            print running.value,
            sys.stdout.flush()
            mutex.release()

        print
        print 'No more running processes'


    #### TEST_QUEUE

    def queue_func(queue):
        for i in range(30):
            time.sleep(0.5 * random.random())
            queue.put(i*i)
        queue.put('STOP')

    def test_queue():
        q = multiprocessing.Queue()

        p = multiprocessing.Process(target=queue_func, args=(q,))
        p.start()

        o = None
        while o != 'STOP':
            try:
                o = q.get(timeout=0.3)
                print o,
                sys.stdout.flush()
            except Empty:
                print 'TIMEOUT'

        print


    #### TEST_CONDITION

    def condition_func(cond):
        cond.acquire()
        print '\t' + str(cond)
        time.sleep(2)
        print '\tchild is notifying'
        print '\t' + str(cond)
        cond.notify()
        cond.release()

    def test_condition():
        cond = multiprocessing.Condition()

        p = multiprocessing.Process(target=condition_func, args=(cond,))
        print cond

        cond.acquire()
        print cond
        cond.acquire()
        print cond

        p.start()

        print 'main is waiting'
        cond.wait()
        print 'main has woken up'

        print cond
        cond.release()
        print cond
        cond.release()

        p.join()
        print cond


    #### TEST_SEMAPHORE

    def semaphore_func(sema, mutex, running):
        sema.acquire()

        mutex.acquire()
        running.value += 1
        print running.value, 'tasks are running'
        mutex.release()

        random.seed()
        time.sleep(random.random()*2)

        mutex.acquire()
        running.value -= 1
        print '%s has finished' % multiprocessing.current_process()
        mutex.release()

        sema.release()

    def test_semaphore():
        sema = multiprocessing.Semaphore(3)
        mutex = multiprocessing.RLock()
        running = multiprocessing.Value('i', 0)

        processes = [
            multiprocessing.Process(target=semaphore_func,
                                    args=(sema, mutex, running))
            for i in range(10)
            ]

        for p in processes:
            p.start()

        for p in processes:
            p.join()


    #### TEST_JOIN_TIMEOUT

    def join_timeout_func():
        print '\tchild sleeping'
        time.sleep(5.5)
        print '\n\tchild terminating'

    def test_join_timeout():
        p = multiprocessing.Process(target=join_timeout_func)
        p.start()

        print 'waiting for process to finish'

        while 1:
            p.join(timeout=1)
            if not p.is_alive():
                break
            print '.',
            sys.stdout.flush()


    #### TEST_EVENT

    def event_func(event):
        print '\t%r is waiting' % multiprocessing.current_process()
        event.wait()
        print '\t%r has woken up' % multiprocessing.current_process()

    def test_event():
        event = multiprocessing.Event()

        processes = [multiprocessing.Process(target=event_func, args=(event,))
                     for i in range(5)]

        for p in processes:
            p.start()

        print 'main is sleeping'
        time.sleep(2)

        print 'main is setting event'
        event.set()

        for p in processes:
            p.join()


    #### TEST_SHAREDVALUES

    def sharedvalues_func(values, arrays, shared_values, shared_arrays):
        for i in range(len(values)):
            v = values[i][1]
            sv = shared_values[i].value
            assert v == sv

        for i in range(len(values)):
            a = arrays[i][1]
            sa = list(shared_arrays[i][:])
            assert a == sa

        print 'Tests passed'

    def test_sharedvalues():
        values = [
            ('i', 10),
            ('h', -2),
            ('d', 1.25)
            ]
        arrays = [
            ('i', range(100)),
            ('d', [0.25 * i for i in range(100)]),
            ('H', range(1000))
            ]

        shared_values = [multiprocessing.Value(id, v) for id, v in values]
        shared_arrays = [multiprocessing.Array(id, a) for id, a in arrays]

        p = multiprocessing.Process(
            target=sharedvalues_func,
            args=(values, arrays, shared_values, shared_arrays)
            )
        p.start()
        p.join()

        assert p.exitcode == 0


    ####

    def test(namespace=multiprocessing):
        global multiprocessing

        multiprocessing = namespace

        for func in [ test_value, test_queue, test_condition,
                      test_semaphore, test_join_timeout, test_event,
                      test_sharedvalues ]:

            print '\n\t######## %s\n' % func.__name__
            func()

        ignore = multiprocessing.active_children()      # cleanup any old processes
        if hasattr(multiprocessing, '_debug_info'):
            info = multiprocessing._debug_info()
            if info:
                print info
                raise ValueError('there should be no positive refcounts left')


    if __name__ == '__main__':
        multiprocessing.freeze_support()

        assert len(sys.argv) in (1, 2)

        if len(sys.argv) == 1 or sys.argv[1] == 'processes':
            print ' Using processes '.center(79, '-')
            namespace = multiprocessing
        elif sys.argv[1] == 'manager':
            print ' Using processes and a manager '.center(79, '-')
            namespace = multiprocessing.Manager()
            namespace.Process = multiprocessing.Process
            namespace.current_process = multiprocessing.current_process
            namespace.active_children = multiprocessing.active_children
        elif sys.argv[1] == 'threads':
            print ' Using threads '.center(79, '-')
            import multiprocessing.dummy as namespace
        else:
            print 'Usage:\n\t%s [processes | manager | threads]' % sys.argv[0]
            raise SystemExit(2)

        test(namespace)

An example showing how to use queues to feed tasks to a collection of
worker processes and collect the results:

    #
    # Simple example which uses a pool of workers to carry out some tasks.
    #
    # Notice that the results will probably not come out of the output
    # queue in the same in the same order as the corresponding tasks were
    # put on the input queue.  If it is important to get the results back
    # in the original order then consider using `Pool.map()` or
    # `Pool.imap()` (which will save on the amount of code needed anyway).
    #
    # Copyright (c) 2006-2008, R Oudkerk
    # All rights reserved.
    #

    import time
    import random

    from multiprocessing import Process, Queue, current_process, freeze_support

    #
    # Function run by worker processes
    #

    def worker(input, output):
        for func, args in iter(input.get, 'STOP'):
            result = calculate(func, args)
            output.put(result)

    #
    # Function used to calculate result
    #

    def calculate(func, args):
        result = func(*args)
        return '%s says that %s%s = %s' % \
            (current_process().name, func.__name__, args, result)

    #
    # Functions referenced by tasks
    #

    def mul(a, b):
        time.sleep(0.5*random.random())
        return a * b

    def plus(a, b):
        time.sleep(0.5*random.random())
        return a + b

    #
    #
    #

    def test():
        NUMBER_OF_PROCESSES = 4
        TASKS1 = [(mul, (i, 7)) for i in range(20)]
        TASKS2 = [(plus, (i, 8)) for i in range(10)]

        # Create queues
        task_queue = Queue()
        done_queue = Queue()

        # Submit tasks
        for task in TASKS1:
            task_queue.put(task)

        # Start worker processes
        for i in range(NUMBER_OF_PROCESSES):
            Process(target=worker, args=(task_queue, done_queue)).start()

        # Get and print results
        print 'Unordered results:'
        for i in range(len(TASKS1)):
            print '\t', done_queue.get()

        # Add more tasks using `put()`
        for task in TASKS2:
            task_queue.put(task)

        # Get and print some more results
        for i in range(len(TASKS2)):
            print '\t', done_queue.get()

        # Tell child processes to stop
        for i in range(NUMBER_OF_PROCESSES):
            task_queue.put('STOP')


    if __name__ == '__main__':
        freeze_support()
        test()

An example of how a pool of worker processes can each run a
`SimpleHTTPServer.HttpServer' instance while sharing a single listening
socket.

    #
    # Example where a pool of http servers share a single listening socket
    #
    # On Windows this module depends on the ability to pickle a socket
    # object so that the worker processes can inherit a copy of the server
    # object.  (We import `multiprocessing.reduction` to enable this pickling.)
    #
    # Not sure if we should synchronize access to `socket.accept()` method by
    # using a process-shared lock -- does not seem to be necessary.
    #
    # Copyright (c) 2006-2008, R Oudkerk
    # All rights reserved.
    #

    import os
    import sys

    from multiprocessing import Process, current_process, freeze_support
    from BaseHTTPServer import HTTPServer
    from SimpleHTTPServer import SimpleHTTPRequestHandler

    if sys.platform == 'win32':
        import multiprocessing.reduction    # make sockets pickable/inheritable


    def note(format, *args):
        sys.stderr.write('[%s]\t%s\n' % (current_process().name, format%args))


    class RequestHandler(SimpleHTTPRequestHandler):
        # we override log_message() to show which process is handling the request
        def log_message(self, format, *args):
            note(format, *args)

    def serve_forever(server):
        note('starting server')
        try:
            server.serve_forever()
        except KeyboardInterrupt:
            pass


    def runpool(address, number_of_processes):
        # create a single server object -- children will each inherit a copy
        server = HTTPServer(address, RequestHandler)

        # create child processes to act as workers
        for i in range(number_of_processes-1):
            Process(target=serve_forever, args=(server,)).start()

        # main process also acts as a worker
        serve_forever(server)


    def test():
        DIR = os.path.join(os.path.dirname(__file__), '..')
        ADDRESS = ('localhost', 8000)
        NUMBER_OF_PROCESSES = 4

        print 'Serving at http://%s:%d using %d worker processes' % \
              (ADDRESS[0], ADDRESS[1], NUMBER_OF_PROCESSES)
        print 'To exit press Ctrl-' + ['C', 'Break'][sys.platform=='win32']

        os.chdir(DIR)
        runpool(ADDRESS, NUMBER_OF_PROCESSES)


    if __name__ == '__main__':
        freeze_support()
        test()

Some simple benchmarks comparing *Note multiprocessing: 11a. with *Note
threading: 179.:

    #
    # Simple benchmarks for the multiprocessing package
    #
    # Copyright (c) 2006-2008, R Oudkerk
    # All rights reserved.
    #

    import time, sys, multiprocessing, threading, Queue, gc

    if sys.platform == 'win32':
        _timer = time.clock
    else:
        _timer = time.time

    delta = 1


    #### TEST_QUEUESPEED

    def queuespeed_func(q, c, iterations):
        a = '0' * 256
        c.acquire()
        c.notify()
        c.release()

        for i in xrange(iterations):
            q.put(a)

        q.put('STOP')

    def test_queuespeed(Process, q, c):
        elapsed = 0
        iterations = 1

        while elapsed < delta:
            iterations *= 2

            p = Process(target=queuespeed_func, args=(q, c, iterations))
            c.acquire()
            p.start()
            c.wait()
            c.release()

            result = None
            t = _timer()

            while result != 'STOP':
                result = q.get()

            elapsed = _timer() - t

            p.join()

        print iterations, 'objects passed through the queue in', elapsed, 'seconds'
        print 'average number/sec:', iterations/elapsed


    #### TEST_PIPESPEED

    def pipe_func(c, cond, iterations):
        a = '0' * 256
        cond.acquire()
        cond.notify()
        cond.release()

        for i in xrange(iterations):
            c.send(a)

        c.send('STOP')

    def test_pipespeed():
        c, d = multiprocessing.Pipe()
        cond = multiprocessing.Condition()
        elapsed = 0
        iterations = 1

        while elapsed < delta:
            iterations *= 2

            p = multiprocessing.Process(target=pipe_func,
                                        args=(d, cond, iterations))
            cond.acquire()
            p.start()
            cond.wait()
            cond.release()

            result = None
            t = _timer()

            while result != 'STOP':
                result = c.recv()

            elapsed = _timer() - t
            p.join()

        print iterations, 'objects passed through connection in',elapsed,'seconds'
        print 'average number/sec:', iterations/elapsed


    #### TEST_SEQSPEED

    def test_seqspeed(seq):
        elapsed = 0
        iterations = 1

        while elapsed < delta:
            iterations *= 2

            t = _timer()

            for i in xrange(iterations):
                a = seq[5]

            elapsed = _timer()-t

        print iterations, 'iterations in', elapsed, 'seconds'
        print 'average number/sec:', iterations/elapsed


    #### TEST_LOCK

    def test_lockspeed(l):
        elapsed = 0
        iterations = 1

        while elapsed < delta:
            iterations *= 2

            t = _timer()

            for i in xrange(iterations):
                l.acquire()
                l.release()

            elapsed = _timer()-t

        print iterations, 'iterations in', elapsed, 'seconds'
        print 'average number/sec:', iterations/elapsed


    #### TEST_CONDITION

    def conditionspeed_func(c, N):
        c.acquire()
        c.notify()

        for i in xrange(N):
            c.wait()
            c.notify()

        c.release()

    def test_conditionspeed(Process, c):
        elapsed = 0
        iterations = 1

        while elapsed < delta:
            iterations *= 2

            c.acquire()
            p = Process(target=conditionspeed_func, args=(c, iterations))
            p.start()

            c.wait()

            t = _timer()

            for i in xrange(iterations):
                c.notify()
                c.wait()

            elapsed = _timer()-t

            c.release()
            p.join()

        print iterations * 2, 'waits in', elapsed, 'seconds'
        print 'average number/sec:', iterations * 2 / elapsed

    ####

    def test():
        manager = multiprocessing.Manager()

        gc.disable()

        print '\n\t######## testing Queue.Queue\n'
        test_queuespeed(threading.Thread, Queue.Queue(),
                        threading.Condition())
        print '\n\t######## testing multiprocessing.Queue\n'
        test_queuespeed(multiprocessing.Process, multiprocessing.Queue(),
                        multiprocessing.Condition())
        print '\n\t######## testing Queue managed by server process\n'
        test_queuespeed(multiprocessing.Process, manager.Queue(),
                        manager.Condition())
        print '\n\t######## testing multiprocessing.Pipe\n'
        test_pipespeed()

        print

        print '\n\t######## testing list\n'
        test_seqspeed(range(10))
        print '\n\t######## testing list managed by server process\n'
        test_seqspeed(manager.list(range(10)))
        print '\n\t######## testing Array("i", ..., lock=False)\n'
        test_seqspeed(multiprocessing.Array('i', range(10), lock=False))
        print '\n\t######## testing Array("i", ..., lock=True)\n'
        test_seqspeed(multiprocessing.Array('i', range(10), lock=True))

        print

        print '\n\t######## testing threading.Lock\n'
        test_lockspeed(threading.Lock())
        print '\n\t######## testing threading.RLock\n'
        test_lockspeed(threading.RLock())
        print '\n\t######## testing multiprocessing.Lock\n'
        test_lockspeed(multiprocessing.Lock())
        print '\n\t######## testing multiprocessing.RLock\n'
        test_lockspeed(multiprocessing.RLock())
        print '\n\t######## testing lock managed by server process\n'
        test_lockspeed(manager.Lock())
        print '\n\t######## testing rlock managed by server process\n'
        test_lockspeed(manager.RLock())

        print

        print '\n\t######## testing threading.Condition\n'
        test_conditionspeed(threading.Thread, threading.Condition())
        print '\n\t######## testing multiprocessing.Condition\n'
        test_conditionspeed(multiprocessing.Process, multiprocessing.Condition())
        print '\n\t######## testing condition managed by a server process\n'
        test_conditionspeed(multiprocessing.Process, manager.Condition())

        gc.enable()

    if __name__ == '__main__':
        multiprocessing.freeze_support()
        test()


File: python.info,  Node: mmap — Memory-mapped file support,  Next: readline — GNU readline interface,  Prev: multiprocessing — Process-based “threading” interface,  Up: Optional Operating System Services

5.16.7 `mmap' — Memory-mapped file support
--------------------------------------------

Memory-mapped file objects behave like both strings and like file
objects.  Unlike normal string objects, however, these are mutable.
You can use mmap objects in most places where strings are expected; for
example, you can use the *Note re: 144. module to search through a
memory-mapped file.  Since they’re mutable, you can change a single
character by doing `obj[index] = 'a'', or change a substring by
assigning to a slice: `obj[i1:i2] = '...''.  You can also read and
write data starting at the current file position, and `seek()' through
the file to different positions.

A memory-mapped file is created by the *Note mmap: 366. constructor,
which is different on Unix and on Windows.  In either case you must
provide a file descriptor for a file opened for update. If you wish to
map an existing Python file object, use its `fileno()' method to obtain
the correct value for the `fileno' parameter.  Otherwise, you can open
the file using the *Note os.open(): 600. function, which returns a file
descriptor directly (the file still needs to be closed when done).

     Note: If you want to create a memory-mapping for a writable,
     buffered file, you should *Note flush(): 11ef. the file first.
     This is necessary to ensure that local modifications to the
     buffers are actually available to the mapping.

For both the Unix and Windows versions of the constructor, `access' may
be specified as an optional keyword parameter. `access' accepts one of
three values: `ACCESS_READ', `ACCESS_WRITE', or `ACCESS_COPY' to
specify read-only, write-through or copy-on-write memory respectively.
`access' can be used on both Unix and Windows.  If `access' is not
specified, Windows mmap returns a write-through mapping.  The initial
memory values for all three access types are taken from the specified
file.  Assignment to an `ACCESS_READ' memory map raises a *Note
TypeError: 218. exception.  Assignment to an `ACCESS_WRITE' memory map
affects both memory and the underlying file.  Assignment to an
`ACCESS_COPY' memory map affects memory but does not update the
underlying file.

Changed in version 2.5: To map anonymous memory, -1 should be passed as
the fileno along with the length.

Changed in version 2.6: mmap.mmap has formerly been a factory function
creating mmap objects. Now mmap.mmap is the class itself.

 -- Class: mmap.mmap (fileno, length[, tagname[, access[, offset]]])
     `(Windows version)' Maps `length' bytes from the file specified by
     the file handle `fileno', and creates a mmap object.  If `length'
     is larger than the current size of the file, the file is extended
     to contain `length' bytes.  If `length' is `0', the maximum length
     of the map is the current size of the file, except that if the
     file is empty Windows raises an exception (you cannot create an
     empty mapping on Windows).

     `tagname', if specified and not `None', is a string giving a tag
     name for the mapping.  Windows allows you to have many different
     mappings against the same file.  If you specify the name of an
     existing tag, that tag is opened, otherwise a new tag of this name
     is created.  If this parameter is omitted or `None', the mapping
     is created without a name.  Avoiding the use of the tag parameter
     will assist in keeping your code portable between Unix and Windows.

     `offset' may be specified as a non-negative integer offset. mmap
     references will be relative to the offset from the beginning of
     the file. `offset' defaults to 0.  `offset' must be a multiple of
     the ALLOCATIONGRANULARITY.

 -- Class: mmap.mmap (fileno, length[, flags[, prot[, access[,
          offset]]]])
     `(Unix version)' Maps `length' bytes from the file specified by
     the file descriptor `fileno', and returns a mmap object.  If
     `length' is `0', the maximum length of the map will be the current
     size of the file when *Note mmap: 366. is called.

     `flags' specifies the nature of the mapping. `MAP_PRIVATE' creates
     a private copy-on-write mapping, so changes to the contents of the
     mmap object will be private to this process, and `MAP_SHARED'
     creates a mapping that’s shared with all other processes mapping
     the same areas of the file.  The default value is `MAP_SHARED'.

     `prot', if specified, gives the desired memory protection; the two
     most useful values are `PROT_READ' and `PROT_WRITE', to specify
     that the pages may be read or written.  `prot' defaults to
     `PROT_READ | PROT_WRITE'.

     `access' may be specified in lieu of `flags' and `prot' as an
     optional keyword parameter.  It is an error to specify both
     `flags', `prot' and `access'.  See the description of `access'
     above for information on how to use this parameter.

     `offset' may be specified as a non-negative integer offset. mmap
     references will be relative to the offset from the beginning of
     the file. `offset' defaults to 0.  `offset' must be a multiple of
     the PAGESIZE or ALLOCATIONGRANULARITY.

     To ensure validity of the created memory mapping the file specified
     by the descriptor `fileno' is internally automatically synchronized
     with physical backing store on Mac OS X and OpenVMS.

     This example shows a simple way of using *Note mmap: 366.:

         import mmap

         # write a simple example file
         with open("hello.txt", "wb") as f:
             f.write("Hello Python!\n")

         with open("hello.txt", "r+b") as f:
             # memory-map the file, size 0 means whole file
             mm = mmap.mmap(f.fileno(), 0)
             # read content via standard file methods
             print mm.readline()  # prints "Hello Python!"
             # read content via slice notation
             print mm[:5]  # prints "Hello"
             # update content using slice notation;
             # note that new content must have same size
             mm[6:] = " world!\n"
             # ... and read again using standard file methods
             mm.seek(0)
             print mm.readline()  # prints "Hello  world!"
             # close the map
             mm.close()

     The next example demonstrates how to create an anonymous map and
     exchange data between the parent and child processes:

         import mmap
         import os

         mm = mmap.mmap(-1, 13)
         mm.write("Hello world!")

         pid = os.fork()

         if pid == 0:  # In a child process
             mm.seek(0)
             print mm.readline()

             mm.close()

     Memory-mapped file objects support the following methods:

      -- Method: close ()
          Closes the mmap. Subsequent calls to other methods of the
          object will result in a ValueError exception being raised.
          This will not close the open file.

      -- Method: find (string[, start[, end]])
          Returns the lowest index in the object where the substring
          `string' is found, such that `string' is contained in the
          range [`start', `end'].  Optional arguments `start' and `end'
          are interpreted as in slice notation.  Returns `-1' on
          failure.

      -- Method: flush ([offset, size])
          Flushes changes made to the in-memory copy of a file back to
          disk. Without use of this call there is no guarantee that
          changes are written back before the object is destroyed.  If
          `offset' and `size' are specified, only changes to the given
          range of bytes will be flushed to disk; otherwise, the whole
          extent of the mapping is flushed.

          `(Windows version)' A nonzero value returned indicates
          success; zero indicates failure.

          `(Unix version)' A zero value is returned to indicate
          success. An exception is raised when the call failed.

      -- Method: move (dest, src, count)
          Copy the `count' bytes starting at offset `src' to the
          destination index `dest'.  If the mmap was created with
          `ACCESS_READ', then calls to move will raise a *Note
          TypeError: 218. exception.

      -- Method: read (num)
          Return a string containing up to `num' bytes starting from
          the current file position; the file position is updated to
          point after the bytes that were returned.

      -- Method: read_byte ()
          Returns a string of length 1 containing the character at the
          current file position, and advances the file position by 1.

      -- Method: readline ()
          Returns a single line, starting at the current file position
          and up to the next newline.

      -- Method: resize (newsize)
          Resizes the map and the underlying file, if any. If the mmap
          was created with `ACCESS_READ' or `ACCESS_COPY', resizing the
          map will raise a *Note TypeError: 218. exception.

      -- Method: rfind (string[, start[, end]])
          Returns the highest index in the object where the substring
          `string' is found, such that `string' is contained in the
          range [`start', `end'].  Optional arguments `start' and `end'
          are interpreted as in slice notation.  Returns `-1' on
          failure.

      -- Method: seek (pos[, whence])
          Set the file’s current position.  `whence' argument is
          optional and defaults to `os.SEEK_SET' or `0' (absolute file
          positioning); other values are `os.SEEK_CUR' or `1' (seek
          relative to the current position) and `os.SEEK_END' or `2'
          (seek relative to the file’s end).

      -- Method: size ()
          Return the length of the file, which can be larger than the
          size of the memory-mapped area.

      -- Method: tell ()
          Returns the current position of the file pointer.

      -- Method: write (string)
          Write the bytes in `string' into memory at the current
          position of the file pointer; the file position is updated to
          point after the bytes that were written. If the mmap was
          created with `ACCESS_READ', then writing to it will raise a
          *Note TypeError: 218. exception.

      -- Method: write_byte (byte)
          Write the single-character string `byte' into memory at the
          current position of the file pointer; the file position is
          advanced by `1'. If the mmap was created with `ACCESS_READ',
          then writing to it will raise a *Note TypeError: 218.
          exception.


File: python.info,  Node: readline — GNU readline interface,  Next: rlcompleter — Completion function for GNU readline,  Prev: mmap — Memory-mapped file support,  Up: Optional Operating System Services

5.16.8 `readline' — GNU readline interface
--------------------------------------------

The *Note readline: 145. module defines a number of functions to
facilitate completion and reading/writing of history files from the
Python interpreter.  This module can be used directly, or via the *Note
rlcompleter: 149. module, which supports completion of Python
identifiers at the interactive prompt.  Settings made using  this
module affect the behaviour of both the interpreter’s interactive
prompt  and the prompts offered by the *Note raw_input(): 891. and
*Note input(): 3d9. built-in functions.

     Note: The underlying Readline library API may be implemented by
     the `libedit' library instead of GNU readline.  On MacOS X the
     *Note readline: 145. module detects which library is being used at
     run time.

     The configuration file for `libedit' is different from that of GNU
     readline. If you programmatically load configuration strings you
     can check for the text “libedit” in `readline.__doc__' to
     differentiate between GNU readline and libedit.

Readline keybindings may be configured via an initialization file,
typically `.inputrc' in your home directory.  See Readline Init File(1)
in the GNU Readline manual for information about the format and
allowable constructs of that file, and the capabilities of the Readline
library in general.

* Menu:

* Init file::
* Line buffer::
* History file::
* History list::
* Startup hooks::
* Completion::
* Example: Example<7>.

---------- Footnotes ----------

(1) https://cnswww.cns.cwru.edu/php/chet/readline/rluserman.html#SEC9


File: python.info,  Node: Init file,  Next: Line buffer,  Up: readline — GNU readline interface

5.16.8.1 Init file
..................

The following functions relate to the init file and user configuration:

 -- Function: readline.parse_and_bind (string)
     Execute the init line provided in the `string' argument. This calls
     `rl_parse_and_bind()' in the underlying library.

 -- Function: readline.read_init_file ([filename])
     Execute a readline initialization file. The default filename is
     the last filename used. This calls `rl_read_init_file()' in the
     underlying library.


File: python.info,  Node: Line buffer,  Next: History file,  Prev: Init file,  Up: readline — GNU readline interface

5.16.8.2 Line buffer
....................

The following functions operate on the line buffer:

 -- Function: readline.get_line_buffer ()
     Return the current contents of the line buffer (`rl_line_buffer'
     in the underlying library).

 -- Function: readline.insert_text (string)
     Insert text into the line buffer at the cursor position.  This
     calls `rl_insert_text()' in the underlying library, but ignores
     the return value.

 -- Function: readline.redisplay ()
     Change what’s displayed on the screen to reflect the current
     contents of the line buffer.  This calls `rl_redisplay()' in the
     underlying library.


File: python.info,  Node: History file,  Next: History list,  Prev: Line buffer,  Up: readline — GNU readline interface

5.16.8.3 History file
.....................

The following functions operate on a history file:

 -- Function: readline.read_history_file ([filename])
     Load a readline history file, and append it to the history list.
     The default filename is `~/.history'.  This calls `read_history()'
     in the underlying library.

 -- Function: readline.write_history_file ([filename])
     Save the history list to a readline history file, overwriting any
     existing file.  The default filename is `~/.history'.  This calls
     `write_history()' in the underlying library.

 -- Function: readline.get_history_length ()
 -- Function: readline.set_history_length (length)
     Set or return the desired number of lines to save in the history
     file.  The *Note write_history_file(): 1701. function uses this
     value to truncate the history file, by calling
     `history_truncate_file()' in the underlying library.  Negative
     values imply unlimited history file size.


File: python.info,  Node: History list,  Next: Startup hooks,  Prev: History file,  Up: readline — GNU readline interface

5.16.8.4 History list
.....................

The following functions operate on a global history list:

 -- Function: readline.clear_history ()
     Clear the current history.  This calls `clear_history()' in the
     underlying library.  The Python function only exists if Python was
     compiled for a version of the library that supports it.

     New in version 2.4.


 -- Function: readline.get_current_history_length ()
     Return the number of items currently in the history.  (This is
     different from *Note get_history_length(): 1702, which returns the
     maximum number of lines that will be written to a history file.)

     New in version 2.3.


 -- Function: readline.get_history_item (index)
     Return the current contents of history item at `index'.  The item
     index is one-based.  This calls `history_get()' in the underlying
     library.

     New in version 2.3.


 -- Function: readline.remove_history_item (pos)
     Remove history item specified by its position from the history.
     The position is zero-based.  This calls `remove_history()' in the
     underlying library.

     New in version 2.4.


 -- Function: readline.replace_history_item (pos, line)
     Replace history item specified by its position with `line'.  The
     position is zero-based.  This calls `replace_history_entry()' in
     the underlying library.

     New in version 2.4.


 -- Function: readline.add_history (line)
     Append `line' to the history buffer, as if it was the last line
     typed.  This calls `add_history()' in the underlying library.


File: python.info,  Node: Startup hooks,  Next: Completion,  Prev: History list,  Up: readline — GNU readline interface

5.16.8.5 Startup hooks
......................

     New in version 2.3.


 -- Function: readline.set_startup_hook ([function])
     Set or remove the function invoked by the `rl_startup_hook'
     callback of the underlying library.  If `function' is specified,
     it will be used as the new hook function; if omitted or `None',
     any function already installed is removed.  The hook is called
     with no arguments just before readline prints the first prompt.

 -- Function: readline.set_pre_input_hook ([function])
     Set or remove the function invoked by the `rl_pre_input_hook'
     callback of the underlying library.  If `function' is specified,
     it will be used as the new hook function; if omitted or `None', any
     function already installed is removed.  The hook is called with no
     arguments after the first prompt has been printed and just before
     readline starts reading input characters.  This function only
     exists if Python was compiled for a version of the library that
     supports it.


File: python.info,  Node: Completion,  Next: Example<7>,  Prev: Startup hooks,  Up: readline — GNU readline interface

5.16.8.6 Completion
...................

The following functions relate to implementing a custom word completion
function.  This is typically operated by the Tab key, and can suggest
and automatically complete a word being typed.  By default, Readline is
set up to be used by *Note rlcompleter: 149. to complete Python
identifiers for the interactive interpreter.  If the *Note readline:
145. module is to be used with a custom completer, a different set of
word delimiters should be set.

 -- Function: readline.set_completer ([function])
     Set or remove the completer function.  If `function' is specified,
     it will be used as the new completer function; if omitted or
     `None', any completer function already installed is removed.  The
     completer function is called as `function(text, state)', for
     `state' in `0', `1', `2', …, until it returns a non-string
     value.  It should return the next possible completion starting
     with `text'.

     The installed completer function is invoked by the `entry_func'
     callback passed to `rl_completion_matches()' in the underlying
     library.  The `text' string comes from the first parameter to the
     `rl_attempted_completion_function' callback of the underlying
     library.

 -- Function: readline.get_completer ()
     Get the completer function, or `None' if no completer function has
     been set.

     New in version 2.3.


 -- Function: readline.get_completion_type ()
     Get the type of completion being attempted.  This returns the
     `rl_completion_type' variable in the underlying library as an
     integer.

     New in version 2.6.


 -- Function: readline.get_begidx ()
 -- Function: readline.get_endidx ()
     Get the beginning or ending index of the completion scope.  These
     indexes are the `start' and `end' arguments passed to the
     `rl_attempted_completion_function' callback of the underlying
     library.

 -- Function: readline.set_completer_delims (string)
 -- Function: readline.get_completer_delims ()
     Set or get the word delimiters for completion.  These determine the
     start of the word to be considered for completion (the completion
     scope).  These functions access the
     `rl_completer_word_break_characters' variable in the underlying
     library.

 -- Function: readline.set_completion_display_matches_hook ([function])
     Set or remove the completion display function.  If `function' is
     specified, it will be used as the new completion display function;
     if omitted or `None', any completion display function already
     installed is removed.  This sets or clears the
     `rl_completion_display_matches_hook' callback in the underlying
     library.  The completion display function is called as
     `function(substitution, [matches], longest_match_length)' once
     each time matches need to be displayed.

     New in version 2.6.



File: python.info,  Node: Example<7>,  Prev: Completion,  Up: readline — GNU readline interface

5.16.8.7 Example
................

The following example demonstrates how to use the *Note readline: 145.
module’s history reading and writing functions to automatically load
and save a history file named `.pyhist' from the user’s home
directory.  The code below would normally be executed automatically
during interactive sessions from the user’s *Note PYTHONSTARTUP: 63b.
file.

    import os
    import readline
    histfile = os.path.join(os.path.expanduser("~"), ".pyhist")
    try:
        readline.read_history_file(histfile)
        # default history len is -1 (infinite), which may grow unruly
        readline.set_history_length(1000)
    except IOError:
        pass
    import atexit
    atexit.register(readline.write_history_file, histfile)
    del os, histfile

The following example extends the *Note code.InteractiveConsole: 1719.
class to support history save/restore.

    import code
    import readline
    import atexit
    import os

    class HistoryConsole(code.InteractiveConsole):
        def __init__(self, locals=None, filename="<console>",
                     histfile=os.path.expanduser("~/.console-history")):
            code.InteractiveConsole.__init__(self, locals, filename)
            self.init_history(histfile)

        def init_history(self, histfile):
            readline.parse_and_bind("tab: complete")
            if hasattr(readline, "read_history_file"):
                try:
                    readline.read_history_file(histfile)
                except IOError:
                    pass
                atexit.register(self.save_history, histfile)

        def save_history(self, histfile):
            readline.set_history_length(1000)
            readline.write_history_file(histfile)


File: python.info,  Node: rlcompleter — Completion function for GNU readline,  Prev: readline — GNU readline interface,  Up: Optional Operating System Services

5.16.9 `rlcompleter' — Completion function for GNU readline
-------------------------------------------------------------

`Source code:' Lib/rlcompleter.py(1)

__________________________________________________________________

The *Note rlcompleter: 149. module defines a completion function
suitable for the *Note readline: 145. module by completing valid Python
identifiers and keywords.

When this module is imported on a Unix platform with the *Note
readline: 145. module available, an instance of the `Completer' class
is automatically created and its `complete()' method is set as the
*Note readline: 145. completer.

Example:

    >>> import rlcompleter
    >>> import readline
    >>> readline.parse_and_bind("tab: complete")
    >>> readline. <TAB PRESSED>
    readline.__doc__          readline.get_line_buffer(  readline.read_init_file(
    readline.__file__         readline.insert_text(      readline.set_completer(
    readline.__name__         readline.parse_and_bind(
    >>> readline.

The *Note rlcompleter: 149. module is designed for use with Python’s
interactive mode.  A user can add the following lines to his or her
initialization file (identified by the *Note PYTHONSTARTUP: 63b.
environment variable) to get automatic `Tab' completion:

    try:
        import readline
    except ImportError:
        print "Module readline not available."
    else:
        import rlcompleter
        readline.parse_and_bind("tab: complete")

On platforms without *Note readline: 145, the `Completer' class defined
by this module can still be used for custom purposes.

* Menu:

* Completer Objects::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/rlcompleter.py


File: python.info,  Node: Completer Objects,  Up: rlcompleter — Completion function for GNU readline

5.16.9.1 Completer Objects
..........................

Completer objects have the following method:

 -- Method: Completer.complete (text, state)
     Return the `state'th completion for `text'.

     If called for `text' that doesn’t include a period character
     (`'.''), it will complete from names currently defined in *Note
     __main__: 2, *Note __builtin__: 0. and keywords (as defined by the
     *Note keyword: fe. module).

     If called for a dotted name, it will try to evaluate anything
     without obvious side-effects (functions will not be evaluated, but
     it can generate calls to *Note __getattr__(): 345.) up to the last
     part, and find matches for the rest via the *Note dir(): 34e.
     function.  Any exception raised during the evaluation of the
     expression is caught, silenced and *Note None: 3b2. is returned.


File: python.info,  Node: Interprocess Communication and Networking,  Next: Internet Data Handling,  Prev: Optional Operating System Services,  Up: The Python Standard Library

5.17 Interprocess Communication and Networking
==============================================

The modules described in this chapter provide mechanisms for different
processes to communicate.

Some modules only work for two processes that are on the same machine,
e.g.  *Note signal: 155. and *Note subprocess: 167.  Other modules
support networking protocols that two or more processes can use to
communicate across machines.

The list of modules described in this chapter is:

* Menu:

* subprocess — Subprocess management::
* socket — Low-level networking interface::
* ssl — TLS/SSL wrapper for socket objects::
* signal — Set handlers for asynchronous events::
* popen2 — Subprocesses with accessible I/O streams::
* asyncore — Asynchronous socket handler::
* asynchat — Asynchronous socket command/response handler::


File: python.info,  Node: subprocess — Subprocess management,  Next: socket — Low-level networking interface,  Up: Interprocess Communication and Networking

5.17.1 `subprocess' — Subprocess management
---------------------------------------------

New in version 2.4.

The *Note subprocess: 167. module allows you to spawn new processes,
connect to their input/output/error pipes, and obtain their return
codes.  This module intends to replace several older modules and
functions:

    os.system
    os.spawn*
    os.popen*
    popen2.*
    commands.*

Information about how this module can be used to replace the older
functions can be found in the *Note subprocess-replacements: 1135.
section.

See also
........

POSIX users (Linux, BSD, etc.) are strongly encouraged to install and
use the much more recent subprocess32(1) module instead of the version
included with python 2.7.  It is a drop in replacement with better
behavior in many situations.

PEP 324(2) – PEP proposing the subprocess module

* Menu:

* Using the subprocess Module::
* Popen Objects::
* Windows Popen Helpers::
* Replacing Older Functions with the subprocess Module::
* Notes::

---------- Footnotes ----------

(1) https://pypi.python.org/pypi/subprocess32/

(2) https://www.python.org/dev/peps/pep-0324


File: python.info,  Node: Using the subprocess Module,  Next: Popen Objects,  Up: subprocess — Subprocess management

5.17.1.1 Using the `subprocess' Module
......................................

The recommended way to launch subprocesses is to use the following
convenience functions.  For more advanced use cases when these do not
meet your needs, use the underlying *Note Popen: 1726. interface.

 -- Function: subprocess.call (args, *, stdin=None, stdout=None,
          stderr=None, shell=False)
     Run the command described by `args'.  Wait for command to
     complete, then return the `returncode' attribute.

     The arguments shown above are merely the most common ones,
     described below in *Note Frequently Used Arguments: 1728. (hence
     the slightly odd notation in the abbreviated signature). The full
     function signature is the same as that of the *Note Popen: 1726.
     constructor - this functions passes all supplied arguments
     directly through to that interface.

     Examples:

         >>> subprocess.call(["ls", "-l"])
         0

         >>> subprocess.call("exit 1", shell=True)
         1

          Warning: Using `shell=True' can be a security hazard.  See
          the warning under *Note Frequently Used Arguments: 1728. for
          details.

          Note: Do not use `stdout=PIPE' or `stderr=PIPE' with this
          function as that can deadlock based on the child process
          output volume.  Use *Note Popen: 1726. with the
          `communicate()' method when you need pipes.

 -- Function: subprocess.check_call (args, *, stdin=None, stdout=None,
          stderr=None, shell=False)
     Run command with arguments.  Wait for command to complete. If the
     return code was zero then return, otherwise raise *Note
     CalledProcessError: 263. The *Note CalledProcessError: 263. object
     will have the return code in the *Note returncode: 172a. attribute.

     The arguments shown above are merely the most common ones,
     described below in *Note Frequently Used Arguments: 1728. (hence
     the slightly odd notation in the abbreviated signature). The full
     function signature is the same as that of the *Note Popen: 1726.
     constructor - this functions passes all supplied arguments
     directly through to that interface.

     Examples:

         >>> subprocess.check_call(["ls", "-l"])
         0

         >>> subprocess.check_call("exit 1", shell=True)
         Traceback (most recent call last):
            ...
         subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

     New in version 2.5.

          Warning: Using `shell=True' can be a security hazard.  See
          the warning under *Note Frequently Used Arguments: 1728. for
          details.

          Note: Do not use `stdout=PIPE' or `stderr=PIPE' with this
          function as that can deadlock based on the child process
          output volume.  Use *Note Popen: 1726. with the
          `communicate()' method when you need pipes.

 -- Function: subprocess.check_output (args, *, stdin=None,
          stderr=None, shell=False, universal_newlines=False)
     Run command with arguments and return its output as a byte string.

     If the return code was non-zero it raises a *Note
     CalledProcessError: 263. The *Note CalledProcessError: 263. object
     will have the return code in the *Note returncode: 172a. attribute
     and any output in the *Note output: 172b. attribute.

     The arguments shown above are merely the most common ones,
     described below in *Note Frequently Used Arguments: 1728. (hence
     the slightly odd notation in the abbreviated signature). The full
     function signature is largely the same as that of the *Note Popen:
     1726. constructor, except that `stdout' is not permitted as it is
     used internally. All other supplied arguments are passed directly
     through to the *Note Popen: 1726. constructor.

     Examples:

         >>> subprocess.check_output(["echo", "Hello World!"])
         'Hello World!\n'

         >>> subprocess.check_output("exit 1", shell=True)
         Traceback (most recent call last):
            ...
         subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

     To also capture standard error in the result, use
     `stderr=subprocess.STDOUT':

         >>> subprocess.check_output(
         ...     "ls non_existent_file; exit 0",
         ...     stderr=subprocess.STDOUT,
         ...     shell=True)
         'ls: non_existent_file: No such file or directory\n'

     New in version 2.7.

          Warning: Using `shell=True' can be a security hazard.  See
          the warning under *Note Frequently Used Arguments: 1728. for
          details.

          Note: Do not use `stderr=PIPE' with this function as that can
          deadlock based on the child process error volume.  Use *Note
          Popen: 1726. with the `communicate()' method when you need a
          stderr pipe.

 -- Data: subprocess.PIPE
     Special value that can be used as the `stdin', `stdout' or
     `stderr' argument to *Note Popen: 1726. and indicates that a pipe
     to the standard stream should be opened.

 -- Data: subprocess.STDOUT
     Special value that can be used as the `stderr' argument to *Note
     Popen: 1726. and indicates that standard error should go into the
     same handle as standard output.

 -- Exception: subprocess.CalledProcessError
     Exception raised when a process run by *Note check_call(): 1729. or
     *Note check_output(): 262. returns a non-zero exit status.

      -- Attribute: returncode
          Exit status of the child process.

      -- Attribute: cmd
          Command that was used to spawn the child process.

      -- Attribute: output
          Output of the child process if this exception is raised by
          *Note check_output(): 262.  Otherwise, `None'.

* Menu:

* Frequently Used Arguments::
* Popen Constructor::
* Exceptions: Exceptions<4>.
* Security::


File: python.info,  Node: Frequently Used Arguments,  Next: Popen Constructor,  Up: Using the subprocess Module

5.17.1.2 Frequently Used Arguments
..................................

To support a wide variety of use cases, the *Note Popen: 1726.
constructor (and the convenience functions) accept a large number of
optional arguments. For most typical use cases, many of these arguments
can be safely left at their default values. The arguments that are most
commonly needed are:

     `args' is required for all calls and should be a string, or a
     sequence of program arguments. Providing a sequence of arguments
     is generally preferred, as it allows the module to take care of
     any required escaping and quoting of arguments (e.g. to permit
     spaces in file names). If passing a single string, either `shell'
     must be *Note True: 3c8. (see below) or else the string must
     simply name the program to be executed without specifying any
     arguments.

     `stdin', `stdout' and `stderr' specify the executed program’s
     standard input, standard output and standard error file handles,
     respectively.  Valid values are *Note PIPE: 172c, an existing file
     descriptor (a positive integer), an existing file object, and
     `None'.  *Note PIPE: 172c. indicates that a new pipe to the child
     should be created.  With the default settings of `None', no
     redirection will occur; the child’s file handles will be
     inherited from the parent.  Additionally, `stderr' can be *Note
     STDOUT: 172d, which indicates that the stderr data from the child
     process should be captured into the same file handle as for stdout.

     When `stdout' or `stderr' are pipes and `universal_newlines' is
     `True' then all line endings will be converted to `'\n'' as
     described for the *Note universal newlines: 329. `'U'' mode
     argument to *Note open(): 2d9.

     If `shell' is `True', the specified command will be executed
     through the shell.  This can be useful if you are using Python
     primarily for the enhanced control flow it offers over most system
     shells and still want convenient access to other shell features
     such as shell pipes, filename wildcards, environment variable
     expansion, and expansion of `~' to a user’s home directory.
     However, note that Python itself offers implementations of many
     shell-like features (in particular, *Note glob: e4, *Note fnmatch:
     d3, *Note os.walk(): 368, *Note os.path.expandvars(): 369, *Note
     os.path.expanduser(): e21, and *Note shutil: 154.).

          Warning: Executing shell commands that incorporate
          unsanitized input from an untrusted source makes a program
          vulnerable to shell injection(1), a serious security flaw
          which can result in arbitrary command execution.  For this
          reason, the use of `shell=True' is `strongly discouraged' in
          cases where the command string is constructed from external
          input:

              >>> from subprocess import call
              >>> filename = input("What file would you like to display?\n")
              What file would you like to display?
              non_existent; rm -rf / #
              >>> call("cat " + filename, shell=True) # Uh-oh. This will end badly...

          `shell=False' disables all shell based features, but does not
          suffer from this vulnerability; see the Note in the *Note
          Popen: 1726. constructor documentation for helpful hints in
          getting `shell=False' to work.

          When using `shell=True', *Note pipes.quote(): 1730. can be
          used to properly escape whitespace and shell metacharacters
          in strings that are going to be used to construct shell
          commands.

These options, along with all of the other options, are described in
more detail in the *Note Popen: 1726. constructor documentation.

---------- Footnotes ----------

(1) http://en.wikipedia.org/wiki/Shell_injection#Shell_injection


File: python.info,  Node: Popen Constructor,  Next: Exceptions<4>,  Prev: Frequently Used Arguments,  Up: Using the subprocess Module

5.17.1.3 Popen Constructor
..........................

The underlying process creation and management in this module is
handled by the *Note Popen: 1726. class. It offers a lot of flexibility
so that developers are able to handle the less common cases not covered
by the convenience functions.

 -- Class: subprocess.Popen (args, bufsize=0, executable=None,
          stdin=None, stdout=None, stderr=None, preexec_fn=None,
          close_fds=False, shell=False, cwd=None, env=None,
          universal_newlines=False, startupinfo=None, creationflags=0)
     Execute a child program in a new process.  On Unix, the class uses
     *Note os.execvp(): 1197.-like behavior to execute the child
     program.  On Windows, the class uses the Windows `CreateProcess()'
     function.  The arguments to *Note Popen: 1726. are as follows.

     `args' should be a sequence of program arguments or else a single
     string.  By default, the program to execute is the first item in
     `args' if `args' is a sequence.  If `args' is a string, the
     interpretation is platform-dependent and described below.  See the
     `shell' and `executable' arguments for additional differences from
     the default behavior.  Unless otherwise stated, it is recommended
     to pass `args' as a sequence.

     On Unix, if `args' is a string, the string is interpreted as the
     name or path of the program to execute.  However, this can only be
     done if not passing arguments to the program.

          Note: *Note shlex.split(): 1732. can be useful when
          determining the correct tokenization for `args', especially
          in complex cases:

              >>> import shlex, subprocess
              >>> command_line = raw_input()
              /bin/vikings -input eggs.txt -output "spam spam.txt" -cmd "echo '$MONEY'"
              >>> args = shlex.split(command_line)
              >>> print args
              ['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
              >>> p = subprocess.Popen(args) # Success!

          Note in particular that options (such as `-input') and
          arguments (such as `eggs.txt') that are separated by
          whitespace in the shell go in separate list elements, while
          arguments that need quoting or backslash escaping when used
          in the shell (such as filenames containing spaces or the
          `echo' command shown above) are single list elements.

     On Windows, if `args' is a sequence, it will be converted to a
     string in a manner described in *Note Converting an argument
     sequence to a string on Windows: 1733.  This is because the
     underlying `CreateProcess()' operates on strings.

     The `shell' argument (which defaults to `False') specifies whether
     to use the shell as the program to execute.  If `shell' is `True',
     it is recommended to pass `args' as a string rather than as a
     sequence.

     On Unix with `shell=True', the shell defaults to `/bin/sh'.  If
     `args' is a string, the string specifies the command to execute
     through the shell.  This means that the string must be formatted
     exactly as it would be when typed at the shell prompt.  This
     includes, for example, quoting or backslash escaping filenames
     with spaces in them.  If `args' is a sequence, the first item
     specifies the command string, and any additional items will be
     treated as additional arguments to the shell itself.  That is to
     say, *Note Popen: 1726. does the equivalent of:

         Popen(['/bin/sh', '-c', args[0], args[1], ...])

     On Windows with `shell=True', the `COMSPEC' environment variable
     specifies the default shell.  The only time you need to specify
     `shell=True' on Windows is when the command you wish to execute is
     built into the shell (e.g. `dir' or `copy').  You do not need
     `shell=True' to run a batch file or console-based executable.

          Warning: Passing `shell=True' can be a security hazard if
          combined with untrusted input.  See the warning under *Note
          Frequently Used Arguments: 1728.  for details.

     `bufsize', if given, has the same meaning as the corresponding
     argument to the built-in open() function: `0' means unbuffered,
     `1' means line buffered, any other positive value means use a
     buffer of (approximately) that size.  A negative `bufsize' means
     to use the system default, which usually means fully buffered.
     The default value for `bufsize' is `0' (unbuffered).

          Note: If you experience performance issues, it is recommended
          that you try to enable buffering by setting `bufsize' to
          either -1 or a large enough positive value (such as 4096).

     The `executable' argument specifies a replacement program to
     execute.   It is very seldom needed.  When `shell=False',
     `executable' replaces the program to execute specified by `args'.
     However, the original `args' is still passed to the program.  Most
     programs treat the program specified by `args' as the command
     name, which can then be different from the program actually
     executed.  On Unix, the `args' name becomes the display name for
     the executable in utilities such as `ps'.  If `shell=True', on
     Unix the `executable' argument specifies a replacement shell for
     the default `/bin/sh'.

     `stdin', `stdout' and `stderr' specify the executed program’s
     standard input, standard output and standard error file handles,
     respectively.  Valid values are *Note PIPE: 172c, an existing file
     descriptor (a positive integer), an existing file object, and
     `None'.  *Note PIPE: 172c. indicates that a new pipe to the child
     should be created.  With the default settings of `None', no
     redirection will occur; the child’s file handles will be
     inherited from the parent.  Additionally, `stderr' can be *Note
     STDOUT: 172d, which indicates that the stderr data from the child
     process should be captured into the same file handle as for stdout.

     If `preexec_fn' is set to a callable object, this object will be
     called in the child process just before the child is executed.
     (Unix only)

     If `close_fds' is true, all file descriptors except `0', `1' and
     `2' will be closed before the child process is executed. (Unix
     only).  Or, on Windows, if `close_fds' is true then no handles
     will be inherited by the child process.  Note that on Windows, you
     cannot set `close_fds' to true and also redirect the standard
     handles by setting `stdin', `stdout' or `stderr'.

     If `cwd' is not `None', the child’s current directory will be
     changed to `cwd' before it is executed.  Note that this directory
     is not considered when searching the executable, so you can’t
     specify the program’s path relative to `cwd'.

     If `env' is not `None', it must be a mapping that defines the
     environment variables for the new process; these are used instead
     of inheriting the current process’ environment, which is the
     default behavior.

          Note: If specified, `env' must provide any variables required
          for the program to execute.  On Windows, in order to run a
          side-by-side assembly(1) the specified `env' `must' include a
          valid `SystemRoot'.

     If `universal_newlines' is `True', the file objects `stdout' and
     `stderr' are opened as text files in *Note universal newlines:
     329. mode.  Lines may be terminated by any of `'\n'', the Unix
     end-of-line convention, `'\r'', the old Macintosh convention or
     `'\r\n'', the Windows convention. All of these external
     representations are seen as `'\n'' by the Python program.

          Note: This feature is only available if Python is built with
          universal newline support (the default).  Also, the newlines
          attribute of the file objects *Note stdout: 1734, *Note
          stdin: 1735. and *Note stderr: 1736. are not updated by the
          communicate() method.

     If given, `startupinfo' will be a *Note STARTUPINFO: 1737. object,
     which is passed to the underlying `CreateProcess' function.
     `creationflags', if given, can be *Note CREATE_NEW_CONSOLE: 1738.
     or *Note CREATE_NEW_PROCESS_GROUP: 1739. (Windows only)

---------- Footnotes ----------

(1) https://en.wikipedia.org/wiki/Side-by-Side_Assembly


File: python.info,  Node: Exceptions<4>,  Next: Security,  Prev: Popen Constructor,  Up: Using the subprocess Module

5.17.1.4 Exceptions
...................

Exceptions raised in the child process, before the new program has
started to execute, will be re-raised in the parent.  Additionally, the
exception object will have one extra attribute called
`child_traceback', which is a string containing traceback information
from the child’s point of view.

The most common exception raised is *Note OSError: 231.  This occurs,
for example, when trying to execute a non-existent file.  Applications
should prepare for *Note OSError: 231. exceptions.

A *Note ValueError: 236. will be raised if *Note Popen: 1726. is called
with invalid arguments.

*Note check_call(): 1729. and *Note check_output(): 262. will raise
*Note CalledProcessError: 263. if the called process returns a non-zero
return code.


File: python.info,  Node: Security,  Prev: Exceptions<4>,  Up: Using the subprocess Module

5.17.1.5 Security
.................

Unlike some other popen functions, this implementation will never call a
system shell implicitly.  This means that all characters, including
shell metacharacters, can safely be passed to child processes.
Obviously, if the shell is invoked explicitly, then it is the
application’s responsibility to ensure that all whitespace and
metacharacters are quoted appropriately.


File: python.info,  Node: Popen Objects,  Next: Windows Popen Helpers,  Prev: Using the subprocess Module,  Up: subprocess — Subprocess management

5.17.1.6 Popen Objects
......................

Instances of the *Note Popen: 1726. class have the following methods:

 -- Method: Popen.poll ()
     Check if child process has terminated.  Set and return *Note
     returncode: 173e. attribute.

 -- Method: Popen.wait ()
     Wait for child process to terminate.  Set and return *Note
     returncode: 173e. attribute.

          Warning: This will deadlock when using `stdout=PIPE' and/or
          `stderr=PIPE' and the child process generates enough output to
          a pipe such that it blocks waiting for the OS pipe buffer to
          accept more data.  Use *Note communicate(): 1740. to avoid
          that.

 -- Method: Popen.communicate (input=None)
     Interact with process: Send data to stdin.  Read data from stdout
     and stderr, until end-of-file is reached.  Wait for process to
     terminate. The optional `input' argument should be a string to be
     sent to the child process, or `None', if no data should be sent to
     the child.

     *Note communicate(): 1740. returns a tuple `(stdoutdata,
     stderrdata)'.

     Note that if you want to send data to the process’s stdin, you
     need to create the Popen object with `stdin=PIPE'.  Similarly, to
     get anything other than `None' in the result tuple, you need to
     give `stdout=PIPE' and/or `stderr=PIPE' too.

          Note: The data read is buffered in memory, so do not use this
          method if the data size is large or unlimited.

 -- Method: Popen.send_signal (signal)
     Sends the signal `signal' to the child.

          Note: On Windows, SIGTERM is an alias for *Note terminate():
          1742. CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to
          processes started with a `creationflags' parameter which
          includes `CREATE_NEW_PROCESS_GROUP'.

     New in version 2.6.


 -- Method: Popen.terminate ()
     Stop the child. On Posix OSs the method sends SIGTERM to the
     child. On Windows the Win32 API function `TerminateProcess()' is
     called to stop the child.

     New in version 2.6.


 -- Method: Popen.kill ()
     Kills the child. On Posix OSs the function sends SIGKILL to the
     child.  On Windows *Note kill(): 1743. is an alias for *Note
     terminate(): 1742.

     New in version 2.6.


The following attributes are also available:

     Warning: Use *Note communicate(): 1740. rather than *Note
     .stdin.write: 1735, *Note .stdout.read: 1734. or *Note
     .stderr.read: 1736. to avoid deadlocks due to any of the other OS
     pipe buffers filling up and blocking the child process.

 -- Attribute: Popen.stdin
     If the `stdin' argument was *Note PIPE: 172c, this attribute is a
     file object that provides input to the child process.  Otherwise,
     it is `None'.

 -- Attribute: Popen.stdout
     If the `stdout' argument was *Note PIPE: 172c, this attribute is a
     file object that provides output from the child process.
     Otherwise, it is `None'.

 -- Attribute: Popen.stderr
     If the `stderr' argument was *Note PIPE: 172c, this attribute is a
     file object that provides error output from the child process.
     Otherwise, it is `None'.

 -- Attribute: Popen.pid
     The process ID of the child process.

     Note that if you set the `shell' argument to `True', this is the
     process ID of the spawned shell.

 -- Attribute: Popen.returncode
     The child return code, set by *Note poll(): 173d. and *Note
     wait(): 173f. (and indirectly by *Note communicate(): 1740.).  A
     `None' value indicates that the process hasn’t terminated yet.

     A negative value `-N' indicates that the child was terminated by
     signal `N' (Unix only).


File: python.info,  Node: Windows Popen Helpers,  Next: Replacing Older Functions with the subprocess Module,  Prev: Popen Objects,  Up: subprocess — Subprocess management

5.17.1.7 Windows Popen Helpers
..............................

The *Note STARTUPINFO: 1737. class and following constants are only
available on Windows.

 -- Class: subprocess.STARTUPINFO
     Partial support of the Windows STARTUPINFO(1) structure is used
     for *Note Popen: 1726. creation.

      -- Attribute: dwFlags
          A bit field that determines whether certain *Note
          STARTUPINFO: 1737.  attributes are used when the process
          creates a window.

              si = subprocess.STARTUPINFO()
              si.dwFlags = subprocess.STARTF_USESTDHANDLES | subprocess.STARTF_USESHOWWINDOW

      -- Attribute: hStdInput
          If *Note dwFlags: 1746. specifies *Note STARTF_USESTDHANDLES:
          1748, this attribute is the standard input handle for the
          process. If *Note STARTF_USESTDHANDLES: 1748. is not
          specified, the default for standard input is the keyboard
          buffer.

      -- Attribute: hStdOutput
          If *Note dwFlags: 1746. specifies *Note STARTF_USESTDHANDLES:
          1748, this attribute is the standard output handle for the
          process. Otherwise, this attribute is ignored and the default
          for standard output is the console window’s buffer.

      -- Attribute: hStdError
          If *Note dwFlags: 1746. specifies *Note STARTF_USESTDHANDLES:
          1748, this attribute is the standard error handle for the
          process. Otherwise, this attribute is ignored and the default
          for standard error is the console window’s buffer.

      -- Attribute: wShowWindow
          If *Note dwFlags: 1746. specifies *Note STARTF_USESHOWWINDOW:
          174c, this attribute can be any of the values that can be
          specified in the `nCmdShow' parameter for the ShowWindow(2)
          function, except for `SW_SHOWDEFAULT'. Otherwise, this
          attribute is ignored.

          *Note SW_HIDE: 174d. is provided for this attribute. It is
          used when *Note Popen: 1726. is called with `shell=True'.

* Menu:

* Constants: Constants<4>.

---------- Footnotes ----------

(1) https://msdn.microsoft.com/en-us/library/ms686331(v=vs.85).aspx

(2) https://msdn.microsoft.com/en-us/library/ms633548(v=vs.85).aspx


File: python.info,  Node: Constants<4>,  Up: Windows Popen Helpers

5.17.1.8 Constants
..................

The *Note subprocess: 167. module exposes the following constants.

 -- Data: subprocess.STD_INPUT_HANDLE
     The standard input device. Initially, this is the console input
     buffer, `CONIN$'.

 -- Data: subprocess.STD_OUTPUT_HANDLE
     The standard output device. Initially, this is the active console
     screen buffer, `CONOUT$'.

 -- Data: subprocess.STD_ERROR_HANDLE
     The standard error device. Initially, this is the active console
     screen buffer, `CONOUT$'.

 -- Data: subprocess.SW_HIDE
     Hides the window. Another window will be activated.

 -- Data: subprocess.STARTF_USESTDHANDLES
     Specifies that the *Note STARTUPINFO.hStdInput: 1747, *Note
     STARTUPINFO.hStdOutput: 1749, and *Note STARTUPINFO.hStdError:
     174a. attributes contain additional information.

 -- Data: subprocess.STARTF_USESHOWWINDOW
     Specifies that the *Note STARTUPINFO.wShowWindow: 174b. attribute
     contains additional information.

 -- Data: subprocess.CREATE_NEW_CONSOLE
     The new process has a new console, instead of inheriting its
     parent’s console (the default).

     This flag is always set when *Note Popen: 1726. is created with
     `shell=True'.

 -- Data: subprocess.CREATE_NEW_PROCESS_GROUP
     A *Note Popen: 1726. `creationflags' parameter to specify that a
     new process group will be created. This flag is necessary for
     using *Note os.kill(): 2d4.  on the subprocess.

     This flag is ignored if *Note CREATE_NEW_CONSOLE: 1738. is
     specified.


File: python.info,  Node: Replacing Older Functions with the subprocess Module,  Next: Notes,  Prev: Windows Popen Helpers,  Up: subprocess — Subprocess management

5.17.1.9 Replacing Older Functions with the `subprocess' Module
...............................................................

In this section, “a becomes b” means that b can be used as a
replacement for a.

     Note: All “a” functions in this section fail (more or less)
     silently if the executed program cannot be found; the “b”
     replacements raise *Note OSError: 231.  instead.

     In addition, the replacements using *Note check_output(): 262.
     will fail with a *Note CalledProcessError: 263. if the requested
     operation produces a non-zero return code. The output is still
     available as the *Note output: 172b. attribute of the raised
     exception.

In the following examples, we assume that the relevant functions have
already been imported from the *Note subprocess: 167. module.

* Menu:

* Replacing /bin/sh shell backquote::
* Replacing shell pipeline::
* Replacing os.system(): Replacing os system.
* Replacing the os.spawn family: Replacing the os spawn family.
* Replacing os.popen(), os.popen2(), os.popen3(): Replacing os popen os popen2 os popen3.
* Replacing functions from the popen2 module::


File: python.info,  Node: Replacing /bin/sh shell backquote,  Next: Replacing shell pipeline,  Up: Replacing Older Functions with the subprocess Module

5.17.1.10 Replacing /bin/sh shell backquote
...........................................

    output=`mycmd myarg`

becomes:

    output = check_output(["mycmd", "myarg"])


File: python.info,  Node: Replacing shell pipeline,  Next: Replacing os system,  Prev: Replacing /bin/sh shell backquote,  Up: Replacing Older Functions with the subprocess Module

5.17.1.11 Replacing shell pipeline
..................................

    output=`dmesg | grep hda`

becomes:

    p1 = Popen(["dmesg"], stdout=PIPE)
    p2 = Popen(["grep", "hda"], stdin=p1.stdout, stdout=PIPE)
    p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.
    output = p2.communicate()[0]

The p1.stdout.close() call after starting the p2 is important in order
for p1 to receive a SIGPIPE if p2 exits before p1.

Alternatively, for trusted input, the shell’s own pipeline support
may still be used directly:

    output=`dmesg | grep hda`

becomes:

    output=check_output("dmesg | grep hda", shell=True)


File: python.info,  Node: Replacing os system,  Next: Replacing the os spawn family,  Prev: Replacing shell pipeline,  Up: Replacing Older Functions with the subprocess Module

5.17.1.12 Replacing `os.system()'
.................................

    status = os.system("mycmd" + " myarg")
    # becomes
    status = subprocess.call("mycmd" + " myarg", shell=True)

Notes:

   * Calling the program through the shell is usually not required.

A more realistic example would look like this:

    try:
        retcode = call("mycmd" + " myarg", shell=True)
        if retcode < 0:
            print >>sys.stderr, "Child was terminated by signal", -retcode
        else:
            print >>sys.stderr, "Child returned", retcode
    except OSError as e:
        print >>sys.stderr, "Execution failed:", e


File: python.info,  Node: Replacing the os spawn family,  Next: Replacing os popen os popen2 os popen3,  Prev: Replacing os system,  Up: Replacing Older Functions with the subprocess Module

5.17.1.13 Replacing the `os.spawn' family
.........................................

P_NOWAIT example:

    pid = os.spawnlp(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg")
    ==>
    pid = Popen(["/bin/mycmd", "myarg"]).pid

P_WAIT example:

    retcode = os.spawnlp(os.P_WAIT, "/bin/mycmd", "mycmd", "myarg")
    ==>
    retcode = call(["/bin/mycmd", "myarg"])

Vector example:

    os.spawnvp(os.P_NOWAIT, path, args)
    ==>
    Popen([path] + args[1:])

Environment example:

    os.spawnlpe(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg", env)
    ==>
    Popen(["/bin/mycmd", "myarg"], env={"PATH": "/usr/bin"})


File: python.info,  Node: Replacing os popen os popen2 os popen3,  Next: Replacing functions from the popen2 module,  Prev: Replacing the os spawn family,  Up: Replacing Older Functions with the subprocess Module

5.17.1.14 Replacing `os.popen()', `os.popen2()', `os.popen3()'
..............................................................

    pipe = os.popen("cmd", 'r', bufsize)
    ==>
    pipe = Popen("cmd", shell=True, bufsize=bufsize, stdout=PIPE).stdout

    pipe = os.popen("cmd", 'w', bufsize)
    ==>
    pipe = Popen("cmd", shell=True, bufsize=bufsize, stdin=PIPE).stdin

    (child_stdin, child_stdout) = os.popen2("cmd", mode, bufsize)
    ==>
    p = Popen("cmd", shell=True, bufsize=bufsize,
              stdin=PIPE, stdout=PIPE, close_fds=True)
    (child_stdin, child_stdout) = (p.stdin, p.stdout)

    (child_stdin,
     child_stdout,
     child_stderr) = os.popen3("cmd", mode, bufsize)
    ==>
    p = Popen("cmd", shell=True, bufsize=bufsize,
              stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)
    (child_stdin,
     child_stdout,
     child_stderr) = (p.stdin, p.stdout, p.stderr)

    (child_stdin, child_stdout_and_stderr) = os.popen4("cmd", mode,
                                                       bufsize)
    ==>
    p = Popen("cmd", shell=True, bufsize=bufsize,
              stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
    (child_stdin, child_stdout_and_stderr) = (p.stdin, p.stdout)

On Unix, os.popen2, os.popen3 and os.popen4 also accept a sequence as
the command to execute, in which case arguments will be passed directly
to the program without shell intervention.  This usage can be replaced
as follows:

    (child_stdin, child_stdout) = os.popen2(["/bin/ls", "-l"], mode,
                                            bufsize)
    ==>
    p = Popen(["/bin/ls", "-l"], bufsize=bufsize, stdin=PIPE, stdout=PIPE)
    (child_stdin, child_stdout) = (p.stdin, p.stdout)

Return code handling translates as follows:

    pipe = os.popen("cmd", 'w')
    ...
    rc = pipe.close()
    if rc is not None and rc >> 8:
        print "There were some errors"
    ==>
    process = Popen("cmd", shell=True, stdin=PIPE)
    ...
    process.stdin.close()
    if process.wait() != 0:
        print "There were some errors"


File: python.info,  Node: Replacing functions from the popen2 module,  Prev: Replacing os popen os popen2 os popen3,  Up: Replacing Older Functions with the subprocess Module

5.17.1.15 Replacing functions from the `popen2' module
......................................................

    (child_stdout, child_stdin) = popen2.popen2("somestring", bufsize, mode)
    ==>
    p = Popen("somestring", shell=True, bufsize=bufsize,
              stdin=PIPE, stdout=PIPE, close_fds=True)
    (child_stdout, child_stdin) = (p.stdout, p.stdin)

On Unix, popen2 also accepts a sequence as the command to execute, in
which case arguments will be passed directly to the program without
shell intervention.  This usage can be replaced as follows:

    (child_stdout, child_stdin) = popen2.popen2(["mycmd", "myarg"], bufsize,
                                                mode)
    ==>
    p = Popen(["mycmd", "myarg"], bufsize=bufsize,
              stdin=PIPE, stdout=PIPE, close_fds=True)
    (child_stdout, child_stdin) = (p.stdout, p.stdin)

*Note popen2.Popen3: 1759. and *Note popen2.Popen4: 175a. basically
work as *Note subprocess.Popen: 1726, except that:

   * *Note Popen: 1726. raises an exception if the execution fails.

   * the `capturestderr' argument is replaced with the `stderr'
     argument.

   * `stdin=PIPE' and `stdout=PIPE' must be specified.

   * popen2 closes all file descriptors by default, but you have to
     specify `close_fds=True' with *Note Popen: 1726.


File: python.info,  Node: Notes,  Prev: Replacing Older Functions with the subprocess Module,  Up: subprocess — Subprocess management

5.17.1.16 Notes
...............

* Menu:

* Converting an argument sequence to a string on Windows::


File: python.info,  Node: Converting an argument sequence to a string on Windows,  Up: Notes

5.17.1.17 Converting an argument sequence to a string on Windows
................................................................

On Windows, an `args' sequence is converted to a string that can be
parsed using the following rules (which correspond to the rules used by
the MS C runtime):

  1. Arguments are delimited by white space, which is either a space or
     a tab.

  2. A string surrounded by double quotation marks is interpreted as a
     single argument, regardless of white space contained within.  A
     quoted string can be embedded in an argument.

  3. A double quotation mark preceded by a backslash is interpreted as
     a literal double quotation mark.

  4. Backslashes are interpreted literally, unless they immediately
     precede a double quotation mark.

  5. If backslashes immediately precede a double quotation mark, every
     pair of backslashes is interpreted as a literal backslash.  If the
     number of backslashes is odd, the last backslash escapes the next
     double quotation mark as described in rule 3.


File: python.info,  Node: socket — Low-level networking interface,  Next: ssl — TLS/SSL wrapper for socket objects,  Prev: subprocess — Subprocess management,  Up: Interprocess Communication and Networking

5.17.2 `socket' — Low-level networking interface
--------------------------------------------------

This module provides access to the BSD `socket' interface. It is
available on all modern Unix systems, Windows, Mac OS X, BeOS, OS/2,
and probably additional platforms.

     Note: Some behavior may be platform dependent, since calls are
     made to the operating system socket APIs.

For an introduction to socket programming (in C), see the following
papers: An Introductory 4.3BSD Interprocess Communication Tutorial, by
Stuart Sechrest and An Advanced 4.3BSD Interprocess Communication
Tutorial, by Samuel J.  Leffler et al, both in the UNIX Programmer’s
Manual, Supplementary Documents 1 (sections PS1:7 and PS1:8).  The
platform-specific reference material for the various socket-related
system calls are also a valuable source of information on the details
of socket semantics.  For Unix, refer to the manual pages; for Windows,
see the WinSock (or Winsock 2) specification. For IPv6-ready APIs,
readers may want to refer to RFC 3493(1) titled Basic Socket Interface
Extensions for IPv6.

The Python interface is a straightforward transliteration of the Unix
system call and library interface for sockets to Python’s
object-oriented style: the *Note socket(): 15df. function returns a
`socket object' whose methods implement the various socket system
calls.  Parameter types are somewhat higher-level than in the C
interface: as with `read()' and `write()' operations on Python files,
buffer allocation on receive operations is automatic, and buffer length
is implicit on send operations.

Socket addresses are represented as follows: A single string is used
for the *Note AF_UNIX: 1760. address family. A pair `(host, port)' is
used for the *Note AF_INET: 1761. address family, where `host' is a
string representing either a hostname in Internet domain notation like
`'daring.cwi.nl'' or an IPv4 address like `'100.50.200.5'', and `port'
is an integer. For *Note AF_INET6: 1762. address family, a four-tuple
`(host, port, flowinfo, scopeid)' is used, where `flowinfo' and
`scopeid' represents `sin6_flowinfo' and `sin6_scope_id' member in
`struct sockaddr_in6' in C. For *Note socket: 15c. module methods,
`flowinfo' and `scopeid' can be omitted just for backward
compatibility. Note, however, omission of `scopeid' can cause problems
in manipulating scoped IPv6 addresses. Other address families are
currently not supported. The address format required by a particular
socket object is automatically selected based on the address family
specified when the socket object was created.

For IPv4 addresses, two special forms are accepted instead of a host
address: the empty string represents `INADDR_ANY', and the string
`'<broadcast>'' represents `INADDR_BROADCAST'. The behavior is not
available for IPv6 for backward compatibility, therefore, you may want
to avoid these if you intend to support IPv6 with your Python programs.

If you use a hostname in the `host' portion of IPv4/v6 socket address,
the program may show a nondeterministic behavior, as Python uses the
first address returned from the DNS resolution.  The socket address
will be resolved differently into an actual IPv4/v6 address, depending
on the results from DNS resolution and/or the host configuration.  For
deterministic behavior use a numeric address in `host' portion.

New in version 2.5: AF_NETLINK sockets are represented as  pairs `pid,
groups'.

New in version 2.6: Linux-only support for TIPC is also available using
the `AF_TIPC' address family. TIPC is an open, non-IP based networked
protocol designed for use in clustered computer environments.
Addresses are represented by a tuple, and the fields depend on the
address type. The general tuple form is `(addr_type, v1, v2, v3 [,
scope])', where:

   - `addr_type' is one of `TIPC_ADDR_NAMESEQ', `TIPC_ADDR_NAME', or
     `TIPC_ADDR_ID'.

   - `scope' is one of `TIPC_ZONE_SCOPE', `TIPC_CLUSTER_SCOPE', and
     `TIPC_NODE_SCOPE'.

   - If `addr_type' is `TIPC_ADDR_NAME', then `v1' is the server type,
     `v2' is the port identifier, and `v3' should be 0.

     If `addr_type' is `TIPC_ADDR_NAMESEQ', then `v1' is the server
     type, `v2' is the lower port number, and `v3' is the upper port
     number.

     If `addr_type' is `TIPC_ADDR_ID', then `v1' is the node, `v2' is
     the reference, and `v3' should be set to 0.

All errors raise exceptions.  The normal exceptions for invalid
argument types and out-of-memory conditions can be raised; errors
related to socket or address semantics raise the error *Note
socket.error: 399.

Non-blocking mode is supported through *Note setblocking(): 1763.  A
generalization of this based on timeouts is supported through *Note
settimeout(): 1764.

The module *Note socket: 15c. exports the following constants and
functions:

 -- Exception: socket.error
     This exception is raised for socket-related errors. The
     accompanying value is either a string telling what went wrong or a
     pair `(errno, string)' representing an error returned by a system
     call, similar to the value accompanying *Note os.error: e2a. See
     the module *Note errno: c9, which contains names for the error
     codes defined by the underlying operating system.

     Changed in version 2.6: *Note socket.error: 399. is now a child
     class of *Note IOError: 1fa.


 -- Exception: socket.herror
     This exception is raised for address-related errors, i.e. for
     functions that use `h_errno' in the C API, including *Note
     gethostbyname_ex(): 1766. and *Note gethostbyaddr(): 1767.

     The accompanying value is a pair `(h_errno, string)' representing
     an error returned by a library call. `string' represents the
     description of `h_errno', as returned by the `hstrerror()' C
     function.

 -- Exception: socket.gaierror
     This exception is raised for address-related errors, for *Note
     getaddrinfo(): 1769. and *Note getnameinfo(): 176a. The
     accompanying value is a pair `(error, string)' representing an
     error returned by a library call. `string' represents the
     description of `error', as returned by the `gai_strerror()' C
     function. The `error' value will match one of the `EAI_*'
     constants defined in this module.

 -- Exception: socket.timeout
     This exception is raised when a timeout occurs on a socket which
     has had timeouts enabled via a prior call to `settimeout()'.  The
     accompanying value is a string whose value is currently always
     “timed out”.

     New in version 2.3.


 -- Data: socket.AF_UNIX
 -- Data: socket.AF_INET
 -- Data: socket.AF_INET6
     These constants represent the address (and protocol) families,
     used for the first argument to *Note socket(): 15df.  If the *Note
     AF_UNIX: 1760. constant is not defined then this protocol is
     unsupported.

 -- Data: socket.SOCK_STREAM
 -- Data: socket.SOCK_DGRAM
 -- Data: socket.SOCK_RAW
 -- Data: socket.SOCK_RDM
 -- Data: socket.SOCK_SEQPACKET
     These constants represent the socket types, used for the second
     argument to *Note socket(): 15c. (Only *Note SOCK_STREAM: 1dc. and
     *Note SOCK_DGRAM: 1db. appear to be generally useful.)

 -- Data: SO_*
 -- Data: socket.SOMAXCONN
 -- Data: MSG_*
 -- Data: SOL_*
 -- Data: IPPROTO_*
 -- Data: IPPORT_*
 -- Data: INADDR_*
 -- Data: IP_*
 -- Data: IPV6_*
 -- Data: EAI_*
 -- Data: AI_*
 -- Data: NI_*
 -- Data: TCP_*
     Many constants of these forms, documented in the Unix
     documentation on sockets and/or the IP protocol, are also defined
     in the socket module. They are generally used in arguments to the
     `setsockopt()' and `getsockopt()' methods of socket objects.  In
     most cases, only those symbols that are defined in the Unix header
     files are defined; for a few symbols, default values are provided.

 -- Data: SIO_*
 -- Data: RCVALL_*
     Constants for Windows’ WSAIoctl(). The constants are used as
     arguments to the *Note ioctl(): 176f. method of socket objects.

     New in version 2.6.


 -- Data: TIPC_*
     TIPC related constants, matching the ones exported by the C socket
     API. See the TIPC documentation for more information.

     New in version 2.6.


 -- Data: socket.has_ipv6
     This constant contains a boolean value which indicates if IPv6 is
     supported on this platform.

     New in version 2.3.


 -- Function: socket.create_connection (address[, timeout[,
          source_address]])
     Connect to a TCP service listening on the Internet `address' (a
     2-tuple `(host, port)'), and return the socket object.  This is a
     higher-level function than *Note socket.connect(): 1771.: if
     `host' is a non-numeric hostname, it will try to resolve it for
     both *Note AF_INET: 1761. and *Note AF_INET6: 1762, and then try
     to connect to all possible addresses in turn until a connection
     succeeds.  This makes it easy to write clients that are compatible
     to both IPv4 and IPv6.

     Passing the optional `timeout' parameter will set the timeout on
     the socket instance before attempting to connect.  If no `timeout'
     is supplied, the global default timeout setting returned by *Note
     getdefaulttimeout(): 1772. is used.

     If supplied, `source_address' must be a 2-tuple `(host, port)' for
     the socket to bind to as its source address before connecting.  If
     host or port are ‘’ or 0 respectively the OS default behavior
     will be used.

     New in version 2.6.

     Changed in version 2.7: `source_address' was added.


 -- Function: socket.getaddrinfo (host, port[, family[, socktype[,
          proto[, flags]]]])
     Translate the `host'/`port' argument into a sequence of 5-tuples
     that contain all the necessary arguments for creating a socket
     connected to that service.  `host' is a domain name, a string
     representation of an IPv4/v6 address or `None'. `port' is a string
     service name such as `'http'', a numeric port number or `None'.
     By passing `None' as the value of `host' and `port', you can pass
     `NULL' to the underlying C API.

     The `family', `socktype' and `proto' arguments can be optionally
     specified in order to narrow the list of addresses returned.  By
     default, their value is `0', meaning that the full range of
     results is selected.  The `flags' argument can be one or several
     of the `AI_*' constants, and will influence how results are
     computed and returned.  Its default value is `0'.  For example,
     `AI_NUMERICHOST' will disable domain name resolution and will
     raise an error if `host' is a domain name.

     The function returns a list of 5-tuples with the following
     structure:

     `(family, socktype, proto, canonname, sockaddr)'

     In these tuples, `family', `socktype', `proto' are all integers
     and are meant to be passed to the *Note socket(): 15df. function.
     `canonname' will be a string representing the canonical name of
     the `host' if `AI_CANONNAME' is part of the `flags' argument; else
     `canonname' will be empty.  `sockaddr' is a tuple describing a
     socket address, whose format depends on the returned `family' (a
     `(address, port)' 2-tuple for *Note AF_INET: 1761, a `(address,
     port, flow info, scope id)' 4-tuple for *Note AF_INET6: 1762.),
     and is meant to be passed to the *Note socket.connect(): 1771.
     method.

     The following example fetches address information for a
     hypothetical TCP connection to `example.org' on port 80 (results
     may differ on your system if IPv6 isn’t enabled):

         >>> socket.getaddrinfo("example.org", 80, 0, 0, socket.IPPROTO_TCP)
         [(10, 1, 6, '', ('2606:2800:220:1:248:1893:25c8:1946', 80, 0, 0)),
          (2, 1, 6, '', ('93.184.216.34', 80))]

     New in version 2.2.


 -- Function: socket.getfqdn ([name])
     Return a fully qualified domain name for `name'. If `name' is
     omitted or empty, it is interpreted as the local host.  To find
     the fully qualified name, the hostname returned by *Note
     gethostbyaddr(): 1767. is checked, followed by aliases for the
     host, if available.  The first name which includes a period is
     selected.  In case no fully qualified domain name is available,
     the hostname as returned by *Note gethostname(): 1131. is returned.

     New in version 2.0.


 -- Function: socket.gethostbyname (hostname)
     Translate a host name to IPv4 address format.  The IPv4 address is
     returned as a string, such as  `'100.50.200.5''.  If the host name
     is an IPv4 address itself it is returned unchanged.  See *Note
     gethostbyname_ex(): 1766. for a more complete interface. *Note
     gethostbyname(): 1774. does not support IPv6 name resolution, and
     *Note getaddrinfo(): 1769. should be used instead for IPv4/v6 dual
     stack support.

 -- Function: socket.gethostbyname_ex (hostname)
     Translate a host name to IPv4 address format, extended interface.
     Return a triple `(hostname, aliaslist, ipaddrlist)' where
     `hostname' is the primary host name responding to the given
     `ip_address', `aliaslist' is a (possibly empty) list of
     alternative host names for the same address, and `ipaddrlist' is a
     list of IPv4 addresses for the same interface on the same host
     (often but not always a single address). *Note gethostbyname_ex():
     1766. does not support IPv6 name resolution, and *Note
     getaddrinfo(): 1769. should be used instead for IPv4/v6 dual stack
     support.

 -- Function: socket.gethostname ()
     Return a string containing the hostname of the machine where  the
     Python interpreter is currently executing.

     If you want to know the current machine’s IP address, you may
     want to use `gethostbyname(gethostname())'. This operation assumes
     that there is a valid address-to-host mapping for the host, and
     the assumption does not always hold.

     Note: *Note gethostname(): 1131. doesn’t always return the fully
     qualified domain name; use `getfqdn()' (see above).

 -- Function: socket.gethostbyaddr (ip_address)
     Return a triple `(hostname, aliaslist, ipaddrlist)' where
     `hostname' is the primary host name responding to the given
     `ip_address', `aliaslist' is a (possibly empty) list of
     alternative host names for the same address, and `ipaddrlist' is a
     list of IPv4/v6 addresses for the same interface on the same host
     (most likely containing only a single address). To find the fully
     qualified domain name, use the function *Note getfqdn(): 1773.
     *Note gethostbyaddr(): 1767. supports both IPv4 and IPv6.

 -- Function: socket.getnameinfo (sockaddr, flags)
     Translate a socket address `sockaddr' into a 2-tuple `(host,
     port)'. Depending on the settings of `flags', the result can
     contain a fully-qualified domain name or numeric address
     representation in `host'.  Similarly, `port' can contain a string
     port name or a numeric port number.

     New in version 2.2.


 -- Function: socket.getprotobyname (protocolname)
     Translate an Internet protocol name (for example, `'icmp'') to a
     constant suitable for passing as the (optional) third argument to
     the *Note socket(): 15df.  function.  This is usually only needed
     for sockets opened in “raw” mode (*Note SOCK_RAW: 176b.); for
     the normal socket modes, the correct protocol is chosen
     automatically if the protocol is omitted or zero.

 -- Function: socket.getservbyname (servicename[, protocolname])
     Translate an Internet service name and protocol name to a port
     number for that service.  The optional protocol name, if given,
     should be `'tcp'' or `'udp'', otherwise any protocol will match.

 -- Function: socket.getservbyport (port[, protocolname])
     Translate an Internet port number and protocol name to a service
     name for that service.  The optional protocol name, if given,
     should be `'tcp'' or `'udp'', otherwise any protocol will match.

 -- Function: socket.socket ([family[, type[, proto]]])
     Create a new socket using the given address family, socket type
     and protocol number.  The address family should be *Note AF_INET:
     1761. (the default), *Note AF_INET6: 1762. or *Note AF_UNIX: 1760.
     The socket type should be *Note SOCK_STREAM: 1dc. (the default),
     *Note SOCK_DGRAM: 1db. or perhaps one of the other `SOCK_'
     constants.  The protocol number is usually zero and may be omitted
     in that case.

 -- Function: socket.socketpair ([family[, type[, proto]]])
     Build a pair of connected socket objects using the given address
     family, socket type, and protocol number.  Address family, socket
     type, and protocol number are as for the *Note socket(): 15df.
     function above. The default family is *Note AF_UNIX: 1760.  if
     defined on the platform; otherwise, the default is *Note AF_INET:
     1761.  Availability: Unix.

     New in version 2.4.


 -- Function: socket.fromfd (fd, family, type[, proto])
     Duplicate the file descriptor `fd' (an integer as returned by a
     file object’s `fileno()' method) and build a socket object from
     the result.  Address family, socket type and protocol number are
     as for the *Note socket(): 15df. function above. The file
     descriptor should refer to a socket, but this is not checked —
     subsequent operations on the object may fail if the file
     descriptor is invalid.  This function is rarely needed, but can be
     used to get or set socket options on a socket passed to a program
     as standard input or output (such as a server started by the Unix
     inet daemon).  The socket is assumed to be in blocking mode.
     Availability: Unix.

 -- Function: socket.ntohl (x)
     Convert 32-bit positive integers from network to host byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 4-byte swap
     operation.

 -- Function: socket.ntohs (x)
     Convert 16-bit positive integers from network to host byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 2-byte swap
     operation.

 -- Function: socket.htonl (x)
     Convert 32-bit positive integers from host to network byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 4-byte swap
     operation.

 -- Function: socket.htons (x)
     Convert 16-bit positive integers from host to network byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 2-byte swap
     operation.

 -- Function: socket.inet_aton (ip_string)
     Convert an IPv4 address from dotted-quad string format (for
     example, ‘123.45.67.89’) to 32-bit packed binary format, as a
     string four characters in length.  This is useful when conversing
     with a program that uses the standard C library and needs objects
     of type `struct in_addr', which is the C type for the 32-bit
     packed binary this function returns.

     *Note inet_aton(): 177e. also accepts strings with less than three
     dots; see the Unix manual page `inet(3)' for details.

     If the IPv4 address string passed to this function is invalid,
     *Note socket.error: 399. will be raised. Note that exactly what is
     valid depends on the underlying C implementation of `inet_aton()'.

     *Note inet_aton(): 177e. does not support IPv6, and *Note
     inet_pton(): 177f. should be used instead for IPv4/v6 dual stack
     support.

 -- Function: socket.inet_ntoa (packed_ip)
     Convert a 32-bit packed IPv4 address (a string four characters in
     length) to its standard dotted-quad string representation (for
     example, ‘123.45.67.89’).  This is useful when conversing with
     a program that uses the standard C library and needs objects of
     type `struct in_addr', which is the C type for the 32-bit packed
     binary data this function takes as an argument.

     If the string passed to this function is not exactly 4 bytes in
     length, *Note socket.error: 399. will be raised. *Note
     inet_ntoa(): 1780. does not support IPv6, and *Note inet_ntop():
     1781. should be used instead for IPv4/v6 dual stack support.

 -- Function: socket.inet_pton (address_family, ip_string)
     Convert an IP address from its family-specific string format to a
     packed, binary format. *Note inet_pton(): 177f. is useful when a
     library or network protocol calls for an object of type `struct
     in_addr' (similar to *Note inet_aton(): 177e.) or `struct
     in6_addr'.

     Supported values for `address_family' are currently *Note AF_INET:
     1761. and *Note AF_INET6: 1762. If the IP address string
     `ip_string' is invalid, *Note socket.error: 399. will be raised.
     Note that exactly what is valid depends on both the value of
     `address_family' and the underlying implementation of
     `inet_pton()'.

     Availability: Unix (maybe not all platforms).

     New in version 2.3.


 -- Function: socket.inet_ntop (address_family, packed_ip)
     Convert a packed IP address (a string of some number of
     characters) to its standard, family-specific string representation
     (for example, `'7.10.0.5'' or `'5aef:2b::8'') *Note inet_ntop():
     1781. is useful when a library or network protocol returns an
     object of type `struct in_addr' (similar to *Note inet_ntoa():
     1780.)  or `struct in6_addr'.

     Supported values for `address_family' are currently *Note AF_INET:
     1761. and *Note AF_INET6: 1762. If the string `packed_ip' is not
     the correct length for the specified address family, *Note
     ValueError: 236. will be raised.  A *Note socket.error: 399. is
     raised for errors from the call to *Note inet_ntop(): 1781.

     Availability: Unix (maybe not all platforms).

     New in version 2.3.


 -- Function: socket.getdefaulttimeout ()
     Return the default timeout in seconds (float) for new socket
     objects. A value of `None' indicates that new socket objects have
     no timeout. When the socket module is first imported, the default
     is `None'.

     New in version 2.3.


 -- Function: socket.setdefaulttimeout (timeout)
     Set the default timeout in seconds (float) for new socket objects.
     A value of `None' indicates that new socket objects have no
     timeout. When the socket module is first imported, the default is
     `None'.

     New in version 2.3.


 -- Data: socket.SocketType
     This is a Python type object that represents the socket object
     type. It is the same as `type(socket(...))'.

See also
........

Module *Note SocketServer: 15d.
     Classes that simplify writing network servers.

Module *Note ssl: 160.
     A TLS/SSL wrapper for socket objects.

* Menu:

* Socket Objects::
* Example: Example<8>.

---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc3493.html


File: python.info,  Node: Socket Objects,  Next: Example<8>,  Up: socket — Low-level networking interface

5.17.2.1 Socket Objects
.......................

Socket objects have the following methods.  Except for `makefile()'
these correspond to Unix system calls applicable to sockets.

 -- Method: socket.accept ()
     Accept a connection. The socket must be bound to an address and
     listening for connections. The return value is a pair `(conn,
     address)' where `conn' is a `new' socket object usable to send and
     receive data on the connection, and `address' is the address bound
     to the socket on the other end of the connection.

 -- Method: socket.bind (address)
     Bind the socket to `address'.  The socket must not already be
     bound. (The format of `address' depends on the address family —
     see above.)

          Note: This method has historically accepted a pair of
          parameters for *Note AF_INET: 1761.  addresses instead of
          only a tuple.  This was never intentional and is no longer
          available in Python 2.0 and later.

 -- Method: socket.close ()
     Close the socket.  All future operations on the socket object will
     fail. The remote end will receive no more data (after queued data
     is flushed). Sockets are automatically closed when they are
     garbage-collected.

          Note: *Note close(): 1788. releases the resource associated
          with a connection but does not necessarily close the
          connection immediately.  If you want to close the connection
          in a timely fashion, call *Note shutdown(): 1789.  before
          *Note close(): 1788.

 -- Method: socket.connect (address)
     Connect to a remote socket at `address'. (The format of `address'
     depends on the address family — see above.)

          Note: This method has historically accepted a pair of
          parameters for *Note AF_INET: 1761.  addresses instead of
          only a tuple.  This was never intentional and is no longer
          available in Python 2.0 and later.

 -- Method: socket.connect_ex (address)
     Like `connect(address)', but return an error indicator instead of
     raising an exception for errors returned by the C-level
     `connect()' call (other problems, such as “host not found,”
     can still raise exceptions).  The error indicator is `0' if the
     operation succeeded, otherwise the value of the `errno' variable.
     This is useful to support, for example, asynchronous connects.

          Note: This method has historically accepted a pair of
          parameters for *Note AF_INET: 1761.  addresses instead of
          only a tuple. This was never intentional and is no longer
          available in Python 2.0 and later.

 -- Method: socket.fileno ()
     Return the socket’s file descriptor (a small integer).  This is
     useful with *Note select.select(): 15de.

     Under Windows the small integer returned by this method cannot be
     used where a file descriptor can be used (such as *Note
     os.fdopen(): 729.).  Unix does not have this limitation.

 -- Method: socket.getpeername ()
     Return the remote address to which the socket is connected.  This
     is useful to find out the port number of a remote IPv4/v6 socket,
     for instance. (The format of the address returned depends on the
     address family — see above.)  On some systems this function is
     not supported.

 -- Method: socket.getsockname ()
     Return the socket’s own address.  This is useful to find out the
     port number of an IPv4/v6 socket, for instance. (The format of the
     address returned depends on the address family — see above.)

 -- Method: socket.getsockopt (level, optname[, buflen])
     Return the value of the given socket option (see the Unix man page
     `getsockopt(2)').  The needed symbolic constants (`SO_*' etc.)
     are defined in this module.  If `buflen' is absent, an integer
     option is assumed and its integer value is returned by the
     function.  If `buflen' is present, it specifies the maximum length
     of the buffer used to receive the option in, and this buffer is
     returned as a string.  It is up to the caller to decode the
     contents of the buffer (see the optional built-in module *Note
     struct: 166. for a way to decode C structures encoded as strings).

 -- Method: socket.ioctl (control, option)
     Platform: Windows

     The *Note ioctl(): 176f. method is a limited interface to the
     WSAIoctl system interface.  Please refer to the Win32
     documentation(1) for more information.

     On other platforms, the generic *Note fcntl.fcntl(): 178f. and
     *Note fcntl.ioctl(): 43a.  functions may be used; they accept a
     socket object as their first argument.

     New in version 2.6.


 -- Method: socket.listen (backlog)
     Listen for connections made to the socket.  The `backlog' argument
     specifies the maximum number of queued connections and should be
     at least 0; the maximum value is system-dependent (usually 5), the
     minimum value is forced to 0.

 -- Method: socket.makefile ([mode[, bufsize]])
     Return a `file object' associated with the socket.  (File objects
     are described in *Note File Objects: 66e.) The file object does
     not close the socket explicitly when its *Note close(): 1788.
     method is called, but only removes its reference to the socket
     object, so that the socket will be closed if it is not referenced
     from anywhere else.

     The socket must be in blocking mode (it can not have a timeout).
     The optional `mode' and `bufsize' arguments are interpreted the
     same way as by the built-in *Note file(): 1f9. function.

          Note: On Windows, the file-like object created by *Note
          makefile(): 1790. cannot be used where a file object with a
          file descriptor is expected, such as the stream arguments of
          *Note subprocess.Popen(): 1726.

 -- Method: socket.recv (bufsize[, flags])
     Receive data from the socket.  The return value is a string
     representing the data received.  The maximum amount of data to be
     received at once is specified by `bufsize'.  See the Unix manual
     page `recv(2)' for the meaning of the optional argument `flags';
     it defaults to zero.

          Note: For best match with hardware and network realities, the
          value of  `bufsize' should be a relatively small power of 2,
          for example, 4096.

 -- Method: socket.recvfrom (bufsize[, flags])
     Receive data from the socket.  The return value is a pair
     `(string, address)' where `string' is a string representing the
     data received and `address' is the address of the socket sending
     the data.  See the Unix manual page `recv(2)' for the meaning of
     the optional argument `flags'; it defaults to zero. (The format of
     `address' depends on the address family — see above.)

 -- Method: socket.recvfrom_into (buffer[, nbytes[, flags]])
     Receive data from the socket, writing it into `buffer' instead of
     creating a new string.  The return value is a pair `(nbytes,
     address)' where `nbytes' is the number of bytes received and
     `address' is the address of the socket sending the data.  See the
     Unix manual page `recv(2)' for the meaning of the optional
     argument `flags'; it defaults to zero.  (The format of `address'
     depends on the address family — see above.)

     New in version 2.5.


 -- Method: socket.recv_into (buffer[, nbytes[, flags]])
     Receive up to `nbytes' bytes from the socket, storing the data
     into a buffer rather than creating a new string.  If `nbytes' is
     not specified (or 0), receive up to the size available in the
     given buffer.  Returns the number of bytes received.  See the Unix
     manual page `recv(2)' for the meaning of the optional argument
     `flags'; it defaults to zero.

     New in version 2.5.


 -- Method: socket.send (string[, flags])
     Send data to the socket.  The socket must be connected to a remote
     socket.  The optional `flags' argument has the same meaning as for
     *Note recv(): 1791. above.  Returns the number of bytes sent.
     Applications are responsible for checking that all data has been
     sent; if only some of the data was transmitted, the application
     needs to attempt delivery of the remaining data. For further
     information on this concept, consult the *Note Socket Programming
     HOWTO: 1794.

 -- Method: socket.sendall (string[, flags])
     Send data to the socket.  The socket must be connected to a remote
     socket.  The optional `flags' argument has the same meaning as for
     *Note recv(): 1791. above.  Unlike *Note send(): 1793, this method
     continues to send data from `string' until either all data has
     been sent or an error occurs.  `None' is returned on success.  On
     error, an exception is raised, and there is no way to determine how
     much data, if any, was successfully sent.

 -- Method: socket.sendto (string, address)
 -- Method: socket.sendto (string, flags, address)
     Send data to the socket.  The socket should not be connected to a
     remote socket, since the destination socket is specified by
     `address'.  The optional `flags' argument has the same meaning as
     for *Note recv(): 1791. above.  Return the number of bytes sent.
     (The format of `address' depends on the address family — see
     above.)

 -- Method: socket.setblocking (flag)
     Set blocking or non-blocking mode of the socket: if `flag' is 0,
     the socket is set to non-blocking, else to blocking mode.
     Initially all sockets are in blocking mode.  In non-blocking mode,
     if a *Note recv(): 1791. call doesn’t find any data, or if a
     *Note send(): 1793. call can’t immediately dispose of the data,
     an *Note error: 399. exception is raised; in blocking mode, the
     calls block until they can proceed. `s.setblocking(0)' is
     equivalent to `s.settimeout(0.0)'; `s.setblocking(1)' is
     equivalent to `s.settimeout(None)'.

 -- Method: socket.settimeout (value)
     Set a timeout on blocking socket operations.  The `value' argument
     can be a nonnegative float expressing seconds, or `None'. If a
     float is given, subsequent socket operations will raise a *Note
     timeout: 47f. exception if the timeout period `value' has elapsed
     before the operation has completed.  Setting a timeout of `None'
     disables timeouts on socket operations.  `s.settimeout(0.0)' is
     equivalent to `s.setblocking(0)'; `s.settimeout(None)' is
     equivalent to `s.setblocking(1)'.

     New in version 2.3.


 -- Method: socket.gettimeout ()
     Return the timeout in seconds (float) associated with socket
     operations, or `None' if no timeout is set.  This reflects the
     last call to *Note setblocking(): 1763. or *Note settimeout():
     1764.

     New in version 2.3.


Some notes on socket blocking and timeouts: A socket object can be in
one of three modes: blocking, non-blocking, or timeout.  Sockets are
always created in blocking mode.  In blocking mode, operations block
until complete or the system returns an error (such as connection timed
out).  In non-blocking mode, operations fail (with an error that is
unfortunately system-dependent) if they cannot be completed
immediately.  In timeout mode, operations fail if they cannot be
completed within the timeout specified for the socket or if the system
returns an error.  The *Note setblocking(): 1763.  method is simply a
shorthand for certain *Note settimeout(): 1764. calls.

Timeout mode internally sets the socket in non-blocking mode.  The
blocking and timeout modes are shared between file descriptors and
socket objects that refer to the same network endpoint.  A consequence
of this is that file objects returned by the *Note makefile(): 1790.
method must only be used when the socket is in blocking mode; in
timeout or non-blocking mode file operations that cannot be completed
immediately will fail.

Note that the *Note connect(): 1771. operation is subject to the timeout
setting, and in general it is recommended to call *Note settimeout():
1764.  before calling *Note connect(): 1771. or pass a timeout
parameter to *Note create_connection(): 252.  The system network stack
may return a connection timeout error of its own regardless of any
Python socket timeout setting.

 -- Method: socket.setsockopt (level, optname, value)
     Set the value of the given socket option (see the Unix manual page
     `setsockopt(2)').  The needed symbolic constants are defined in the
     *Note socket: 15c. module (`SO_*' etc.).  The value can be an
     integer or a string representing a buffer.  In the latter case it
     is up to the caller to ensure that the string contains the proper
     bits (see the optional built-in module *Note struct: 166. for a
     way to encode C structures as strings).

 -- Method: socket.shutdown (how)
     Shut down one or both halves of the connection.  If `how' is
     `SHUT_RD', further receives are disallowed.  If `how' is
     `SHUT_WR', further sends are disallowed.  If `how' is `SHUT_RDWR',
     further sends and receives are disallowed.  Depending on the
     platform, shutting down one half of the connection can also close
     the opposite half (e.g. on Mac OS X, `shutdown(SHUT_WR)' does not
     allow further reads on the other end of the connection).

Note that there are no methods `read()' or `write()'; use *Note recv():
1791. and *Note send(): 1793. without `flags' argument instead.

Socket objects also have these (read-only) attributes that correspond
to the values given to the *Note socket: 15df. constructor.

 -- Attribute: socket.family
     The socket family.

     New in version 2.5.


 -- Attribute: socket.type
     The socket type.

     New in version 2.5.


 -- Attribute: socket.proto
     The socket protocol.

     New in version 2.5.


---------- Footnotes ----------

(1) https://msdn.microsoft.com/en-us/library/ms741621%28VS.85%29.aspx


File: python.info,  Node: Example<8>,  Prev: Socket Objects,  Up: socket — Low-level networking interface

5.17.2.2 Example
................

Here are four minimal example programs using the TCP/IP protocol: a
server that echoes all data that it receives back (servicing only one
client), and a client using it.  Note that a server must perform the
sequence *Note socket(): 15df, *Note bind(): 1787, *Note listen():
16d7, *Note accept(): 1786. (possibly repeating the *Note accept():
1786. to service more than one client), while a client only needs the
sequence *Note socket(): 15df, *Note connect(): 1771.  Also note that
the server does not *Note sendall(): 1795./*Note recv(): 1791. on the
socket it is listening on but on the new socket returned by *Note
accept(): 1786.

The first two examples support IPv4 only.

    # Echo server program
    import socket

    HOST = ''                 # Symbolic name meaning all available interfaces
    PORT = 50007              # Arbitrary non-privileged port
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.bind((HOST, PORT))
    s.listen(1)
    conn, addr = s.accept()
    print 'Connected by', addr
    while 1:
        data = conn.recv(1024)
        if not data: break
        conn.sendall(data)
    conn.close()

    # Echo client program
    import socket

    HOST = 'daring.cwi.nl'    # The remote host
    PORT = 50007              # The same port as used by the server
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.connect((HOST, PORT))
    s.sendall('Hello, world')
    data = s.recv(1024)
    s.close()
    print 'Received', repr(data)

The next two examples are identical to the above two, but support both
IPv4 and IPv6. The server side will listen to the first address family
available (it should listen to both instead). On most of IPv6-ready
systems, IPv6 will take precedence and the server may not accept IPv4
traffic. The client side will try to connect to the all addresses
returned as a result of the name resolution, and sends traffic to the
first one connected successfully.

    # Echo server program
    import socket
    import sys

    HOST = None               # Symbolic name meaning all available interfaces
    PORT = 50007              # Arbitrary non-privileged port
    s = None
    for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC,
                                  socket.SOCK_STREAM, 0, socket.AI_PASSIVE):
        af, socktype, proto, canonname, sa = res
        try:
            s = socket.socket(af, socktype, proto)
        except socket.error as msg:
            s = None
            continue
        try:
            s.bind(sa)
            s.listen(1)
        except socket.error as msg:
            s.close()
            s = None
            continue
        break
    if s is None:
        print 'could not open socket'
        sys.exit(1)
    conn, addr = s.accept()
    print 'Connected by', addr
    while 1:
        data = conn.recv(1024)
        if not data: break
        conn.send(data)
    conn.close()

    # Echo client program
    import socket
    import sys

    HOST = 'daring.cwi.nl'    # The remote host
    PORT = 50007              # The same port as used by the server
    s = None
    for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC, socket.SOCK_STREAM):
        af, socktype, proto, canonname, sa = res
        try:
            s = socket.socket(af, socktype, proto)
        except socket.error as msg:
            s = None
            continue
        try:
            s.connect(sa)
        except socket.error as msg:
            s.close()
            s = None
            continue
        break
    if s is None:
        print 'could not open socket'
        sys.exit(1)
    s.sendall('Hello, world')
    data = s.recv(1024)
    s.close()
    print 'Received', repr(data)

The last example shows how to write a very simple network sniffer with
raw sockets on Windows. The example requires administrator privileges
to modify the interface:

    import socket

    # the public network interface
    HOST = socket.gethostbyname(socket.gethostname())

    # create a raw socket and bind it to the public interface
    s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
    s.bind((HOST, 0))

    # Include IP headers
    s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)

    # receive all packages
    s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)

    # receive a package
    print s.recvfrom(65565)

    # disabled promiscuous mode
    s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)

Running an example several times with too small delay between
executions, could lead to this error:

    socket.error: [Errno 98] Address already in use

This is because the previous execution has left the socket in a
`TIME_WAIT' state, and can’t be immediately reused.

There is a *Note socket: 15c. flag to set, in order to prevent this,
`socket.SO_REUSEADDR':

    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind((HOST, PORT))

the `SO_REUSEADDR' flag tells the kernel to reuse a local socket in
`TIME_WAIT' state, without waiting for its natural timeout to expire.


File: python.info,  Node: ssl — TLS/SSL wrapper for socket objects,  Next: signal — Set handlers for asynchronous events,  Prev: socket — Low-level networking interface,  Up: Interprocess Communication and Networking

5.17.3 `ssl' — TLS/SSL wrapper for socket objects
---------------------------------------------------

New in version 2.6.

`Source code:' Lib/ssl.py(1)

__________________________________________________________________

This module provides access to Transport Layer Security (often known as
“Secure Sockets Layer”) encryption and peer authentication
facilities for network sockets, both client-side and server-side.  This
module uses the OpenSSL library. It is available on all modern Unix
systems, Windows, Mac OS X, and probably additional platforms, as long
as OpenSSL is installed on that platform.

     Note: Some behavior may be platform dependent, since calls are
     made to the operating system socket APIs.  The installed version
     of OpenSSL may also cause variations in behavior. For example,
     TLSv1.1 and TLSv1.2 come with openssl version 1.0.1.

     Warning: Don’t use this module without reading the *Note
     Security considerations: 17a0.  Doing so may lead to a false sense
     of security, as the default settings of the ssl module are not
     necessarily appropriate for your application.

This section documents the objects and functions in the `ssl' module;
for more general information about TLS, SSL, and certificates, the
reader is referred to the documents in the “See Also” section at
the bottom.

This module provides a class, `ssl.SSLSocket', which is derived from the
*Note socket.socket: 15df. type, and provides a socket-like wrapper
that also encrypts and decrypts the data going over the socket with
SSL.  It supports additional methods such as `getpeercert()', which
retrieves the certificate of the other side of the connection, and
`cipher()',which retrieves the cipher being used for the secure
connection.

For more sophisticated applications, the *Note ssl.SSLContext: 2e5.
class helps manage settings and certificates, which can then be
inherited by SSL sockets created through the *Note
SSLContext.wrap_socket(): 17a1. method.

* Menu:

* Functions, Constants, and Exceptions: Functions Constants and Exceptions.
* SSL Sockets::
* SSL Contexts::
* Certificates::
* Examples: Examples<8>.
* Notes on non-blocking sockets::
* Security considerations::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/ssl.py


File: python.info,  Node: Functions Constants and Exceptions,  Next: SSL Sockets,  Up: ssl — TLS/SSL wrapper for socket objects

5.17.3.1 Functions, Constants, and Exceptions
.............................................

 -- Exception: ssl.SSLError
     Raised to signal an error from the underlying SSL implementation
     (currently provided by the OpenSSL library).  This signifies some
     problem in the higher-level encryption and authentication layer
     that’s superimposed on the underlying network connection.  This
     error is a subtype of *Note socket.error: 399, which in turn is a
     subtype of *Note IOError: 1fa.  The error code and message of
     *Note SSLError: 17a3. instances are provided by the OpenSSL
     library.

      -- Attribute: library
          A string mnemonic designating the OpenSSL submodule in which
          the error occurred, such as `SSL', `PEM' or `X509'.  The
          range of possible values depends on the OpenSSL version.

          New in version 2.7.9.


      -- Attribute: reason
          A string mnemonic designating the reason this error occurred,
          for example `CERTIFICATE_VERIFY_FAILED'.  The range of
          possible values depends on the OpenSSL version.

          New in version 2.7.9.


 -- Exception: ssl.SSLZeroReturnError
     A subclass of *Note SSLError: 17a3. raised when trying to read or
     write and the SSL connection has been closed cleanly.  Note that
     this doesn’t mean that the underlying transport (read TCP) has
     been closed.

     New in version 2.7.9.


 -- Exception: ssl.SSLWantReadError
     A subclass of *Note SSLError: 17a3. raised by a *Note non-blocking
     SSL socket: 17a8. when trying to read or write data, but more data
     needs to be received on the underlying TCP transport before the
     request can be fulfilled.

     New in version 2.7.9.


 -- Exception: ssl.SSLWantWriteError
     A subclass of *Note SSLError: 17a3. raised by a *Note non-blocking
     SSL socket: 17a8. when trying to read or write data, but more data
     needs to be sent on the underlying TCP transport before the
     request can be fulfilled.

     New in version 2.7.9.


 -- Exception: ssl.SSLSyscallError
     A subclass of *Note SSLError: 17a3. raised when a system error was
     encountered while trying to fulfill an operation on a SSL socket.
     Unfortunately, there is no easy way to inspect the original errno
     number.

     New in version 2.7.9.


 -- Exception: ssl.SSLEOFError
     A subclass of *Note SSLError: 17a3. raised when the SSL connection
     has been terminated abruptly.  Generally, you shouldn’t try to
     reuse the underlying transport when this error is encountered.

     New in version 2.7.9.


 -- Exception: ssl.CertificateError
     Raised to signal an error with a certificate (such as mismatching
     hostname).  Certificate errors detected by OpenSSL, though, raise
     an *Note SSLError: 17a3.

* Menu:

* Socket creation::
* Context creation::
* Random generation::
* Certificate handling::
* Constants: Constants<5>.


File: python.info,  Node: Socket creation,  Next: Context creation,  Up: Functions Constants and Exceptions

5.17.3.2 Socket creation
........................

The following function allows for standalone socket creation.  Starting
from Python 2.7.9, it can be more flexible to use *Note
SSLContext.wrap_socket(): 17a1.  instead.

 -- Function: ssl.wrap_socket (sock, keyfile=None, certfile=None,
          server_side=False, cert_reqs=CERT_NONE, ssl_version={see
          docs}, ca_certs=None, do_handshake_on_connect=True,
          suppress_ragged_eofs=True, ciphers=None)
     Takes an instance `sock' of *Note socket.socket: 15df, and returns
     an instance of `ssl.SSLSocket', a subtype of *Note socket.socket:
     15df, which wraps the underlying socket in an SSL context.  `sock'
     must be a *Note SOCK_STREAM: 1dc. socket; other socket types are
     unsupported.

     For client-side sockets, the context construction is lazy; if the
     underlying socket isn’t connected yet, the context construction
     will be performed after `connect()' is called on the socket.  For
     server-side sockets, if the socket has no remote peer, it is
     assumed to be a listening socket, and the server-side SSL wrapping
     is automatically performed on client connections accepted via the
     `accept()' method.  *Note wrap_socket(): 25a. may raise *Note
     SSLError: 17a3.

     The `keyfile' and `certfile' parameters specify optional files
     which contain a certificate to be used to identify the local side
     of the connection.  See the discussion of *Note Certificates:
     17ae. for more information on how the certificate is stored in the
     `certfile'.

     The parameter `server_side' is a boolean which identifies whether
     server-side or client-side behavior is desired from this socket.

     The parameter `cert_reqs' specifies whether a certificate is
     required from the other side of the connection, and whether it
     will be validated if provided.  It must be one of the three values
     *Note CERT_NONE: 17af.  (certificates ignored), *Note
     CERT_OPTIONAL: 17b0. (not required, but validated if provided), or
     *Note CERT_REQUIRED: 17b1. (required and validated).  If the value
     of this parameter is not *Note CERT_NONE: 17af, then the `ca_certs'
     parameter must point to a file of CA certificates.

     The `ca_certs' file contains a set of concatenated “certification
     authority” certificates, which are used to validate certificates
     passed from the other end of the connection.  See the discussion of
     *Note Certificates: 17ae. for more information about how to
     arrange the certificates in this file.

     The parameter `ssl_version' specifies which version of the SSL
     protocol to use.  Typically, the server chooses a particular
     protocol version, and the client must adapt to the server’s
     choice.  Most of the versions are not interoperable with the other
     versions.  If not specified, the default is *Note PROTOCOL_SSLv23:
     17b2.; it provides the most compatibility with other versions.

     Here’s a table showing which versions in a client (down the
     side) can connect to which versions in a server (along the top):

           `client' / `server'          `SSLv2'       `SSLv3'       `SSLv23'       `TLSv1'       `TLSv1.1'       `TLSv1.2'
          `SSLv2'                      yes           no            yes            no            no              no
          `SSLv3'                      no            yes           yes            no            no              no
          `SSLv23'                     no            yes           yes            yes           yes             yes
          `TLSv1'                      no            no            yes            yes           no              no
          `TLSv1.1'                    no            no            yes            no            yes             no
          `TLSv1.2'                    no            no            yes            no            no              yes


          Note: Which connections succeed will vary depending on the
          version of OpenSSL.  For example, before OpenSSL 1.0.0, an
          SSLv23 client would always attempt SSLv2 connections.

     The `ciphers' parameter sets the available ciphers for this SSL
     object.  It should be a string in the OpenSSL cipher list
     format(1).

     The parameter `do_handshake_on_connect' specifies whether to do
     the SSL handshake automatically after doing a `socket.connect()',
     or whether the application program will call it explicitly, by
     invoking the *Note SSLSocket.do_handshake(): 17b3. method.  Calling
     *Note SSLSocket.do_handshake(): 17b3. explicitly gives the program
     control over the blocking behavior of the socket I/O involved in
     the handshake.

     The parameter `suppress_ragged_eofs' specifies how the
     `SSLSocket.read()' method should signal unexpected EOF from the
     other end of the connection.  If specified as *Note True: 3c8.
     (the default), it returns a normal EOF (an empty bytes object) in
     response to unexpected EOF errors raised from the underlying
     socket; if *Note False: 3c9, it will raise the exceptions back to
     the caller.

     Changed in version 2.7: New optional argument `ciphers'.


---------- Footnotes ----------

(1) https://www.openssl.org/docs/apps/ciphers.html#CIPHER-LIST-FORMAT


File: python.info,  Node: Context creation,  Next: Random generation,  Prev: Socket creation,  Up: Functions Constants and Exceptions

5.17.3.3 Context creation
.........................

A convenience function helps create *Note SSLContext: 2e5. objects for
common purposes.

 -- Function: ssl.create_default_context (purpose=Purpose.SERVER_AUTH,
          cafile=None, capath=None, cadata=None)
     Return a new *Note SSLContext: 2e5. object with default settings
     for the given `purpose'.  The settings are chosen by the *Note
     ssl: 160. module, and usually represent a higher security level
     than when calling the *Note SSLContext: 2e5. constructor directly.

     `cafile', `capath', `cadata' represent optional CA certificates to
     trust for certificate verification, as in *Note
     SSLContext.load_verify_locations(): 17b6.  If all three are *Note
     None: 3b2, this function can choose to trust the system’s default
     CA certificates instead.

     The settings are: *Note PROTOCOL_SSLv23: 17b2, *Note OP_NO_SSLv2:
     17b7, and *Note OP_NO_SSLv3: 17b8. with high encryption cipher
     suites without RC4 and without unauthenticated cipher suites.
     Passing *Note SERVER_AUTH: 17b9.  as `purpose' sets *Note
     verify_mode: 17ba. to *Note CERT_REQUIRED: 17b1.  and either loads
     CA certificates (when at least one of `cafile', `capath' or
     `cadata' is given) or uses *Note SSLContext.load_default_certs():
     17bb. to load default CA certificates.

          Note: The protocol, options, cipher and other settings may
          change to more restrictive values anytime without prior
          deprecation.  The values represent a fair balance between
          compatibility and security.

          If your application needs specific settings, you should
          create a *Note SSLContext: 2e5. and apply the settings
          yourself.

          Note: If you find that when certain older clients or servers
          attempt to connect with a *Note SSLContext: 2e5. created by
          this function that they get an error stating “Protocol or
          cipher suite mismatch”, it may be that they only support
          SSL3.0 which this function excludes using the *Note
          OP_NO_SSLv3: 17b8. SSL3.0 is widely considered to be
          completely broken(1). If you still wish to continue to use
          this function but still allow SSL 3.0 connections you can
          re-enable them using:

              ctx = ssl.create_default_context(Purpose.CLIENT_AUTH)
              ctx.options &= ~ssl.OP_NO_SSLv3

     New in version 2.7.9.

     Changed in version 2.7.10: RC4 was dropped from the default cipher
     string.

     Changed in version 2.7.13: ChaCha20/Poly1305 was added to the
     default cipher string.

     3DES was dropped from the default cipher string.


 -- Function: ssl._https_verify_certificates (enable=True)
     Specifies whether or not server certificates are verified when
     creating client HTTPS connections without specifying a particular
     SSL context.

     Starting with Python 2.7.9, *Note httplib: ef. and modules which
     use it, such as *Note urllib2: 189. and *Note xmlrpclib: 1aa,
     default to verifying remote server certificates received when
     establishing client HTTPS connections. This default verification
     checks that the certificate is signed by a Certificate Authority
     in the system trust store and that the Common Name (or Subject
     Alternate Name) on the presented certificate matches the requested
     host.

     Setting `enable' to *Note True: 3c8. ensures this default
     behaviour is in effect.

     Setting `enable' to *Note False: 3c9. reverts the default HTTPS
     certificate handling to that of Python 2.7.8 and earlier, allowing
     connections to servers using self-signed certificates, servers
     using certificates signed by a Certicate Authority not present in
     the system trust store, and servers where the hostname does not
     match the presented server certificate.

     The leading underscore on this function denotes that it
     intentionally does not exist in any implementation of Python 3 and
     may not be present in all Python 2.7 implementations. The portable
     approach to bypassing certificate checks or the system trust store
     when necessary is for tools to enable that on a case-by-case basis
     by explicitly passing in a suitably configured SSL context, rather
     than reverting the default behaviour of the standard library
     client modules.

     New in version 2.7.12.

See also
........

        * CVE-2014-9365(2) – HTTPS man-in-the-middle attack against
          Python clients using default settings

        * PEP 476(3) – Enabling certificate verification by default
          for HTTPS

        * PEP 493(4) – HTTPS verification migration tools for Python
          2.7


---------- Footnotes ----------

(1) https://en.wikipedia.org/wiki/POODLE

(2) http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-9365

(3) https://www.python.org/dev/peps/pep-0476

(4) https://www.python.org/dev/peps/pep-0493


File: python.info,  Node: Random generation,  Next: Certificate handling,  Prev: Context creation,  Up: Functions Constants and Exceptions

5.17.3.4 Random generation
..........................

     Deprecated since version 2.7.13: OpenSSL has deprecated
     `ssl.RAND_pseudo_bytes()', use `ssl.RAND_bytes()' instead.


 -- Function: ssl.RAND_status ()
     Return `True' if the SSL pseudo-random number generator has been
     seeded with ‘enough’ randomness, and `False' otherwise.  You
     can use *Note ssl.RAND_egd(): 17be. and *Note ssl.RAND_add():
     17bf. to increase the randomness of the pseudo-random number
     generator.

 -- Function: ssl.RAND_egd (path)
     If you are running an entropy-gathering daemon (EGD) somewhere,
     and `path' is the pathname of a socket connection open to it, this
     will read 256 bytes of randomness from the socket, and add it to
     the SSL pseudo-random number generator to increase the security of
     generated secret keys.  This is typically only necessary on
     systems without better sources of randomness.

     See <http://egd.sourceforge.net/> or
     <http://prngd.sourceforge.net/> for sources of entropy-gathering
     daemons.

     Availability: not available with LibreSSL and OpenSSL > 1.1.0

 -- Function: ssl.RAND_add (bytes, entropy)
     Mix the given `bytes' into the SSL pseudo-random number generator.
     The parameter `entropy' (a float) is a lower bound on the entropy
     contained in string (so you can always use `0.0').  See RFC
     1750(1) for more information on sources of entropy.

---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc1750.html


File: python.info,  Node: Certificate handling,  Next: Constants<5>,  Prev: Random generation,  Up: Functions Constants and Exceptions

5.17.3.5 Certificate handling
.............................

 -- Function: ssl.match_hostname (cert, hostname)
     Verify that `cert' (in decoded format as returned by *Note
     SSLSocket.getpeercert(): 17c2.) matches the given `hostname'.  The
     rules applied are those for checking the identity of HTTPS servers
     as outlined in RFC 2818(1) and RFC 6125(2), except that IP
     addresses are not currently supported. In addition to HTTPS, this
     function should be suitable for checking the identity of servers
     in various SSL-based protocols such as FTPS, IMAPS, POPS and
     others.

     *Note CertificateError: 17ac. is raised on failure. On success,
     the function returns nothing:

         >>> cert = {'subject': ((('commonName', 'example.com'),),)}
         >>> ssl.match_hostname(cert, "example.com")
         >>> ssl.match_hostname(cert, "example.org")
         Traceback (most recent call last):
           File "<stdin>", line 1, in <module>
           File "/home/py3k/Lib/ssl.py", line 130, in match_hostname
         ssl.CertificateError: hostname 'example.org' doesn't match 'example.com'

     New in version 2.7.9.


 -- Function: ssl.cert_time_to_seconds (cert_time)
     Return the time in seconds since the Epoch, given the `cert_time'
     string representing the “notBefore” or “notAfter” date
     from a certificate in `"%b %d %H:%M:%S %Y %Z"' strptime format (C
     locale).

     Here’s an example:

         >>> import ssl
         >>> timestamp = ssl.cert_time_to_seconds("Jan  5 09:34:43 2018 GMT")
         >>> timestamp
         1515144883
         >>> from datetime import datetime
         >>> print(datetime.utcfromtimestamp(timestamp))
         2018-01-05 09:34:43

     “notBefore” or “notAfter” dates must use GMT ( RFC
     5280(3)).

     Changed in version 2.7.9: Interpret the input time as a time in
     UTC as specified by ‘GMT’ timezone in the input string. Local
     timezone was used previously. Return an integer (no fractions of a
     second in the input format)


 -- Function: ssl.get_server_certificate (addr,
          ssl_version=PROTOCOL_SSLv23, ca_certs=None)
     Given the address `addr' of an SSL-protected server, as a
     (`hostname', `port-number') pair, fetches the server’s
     certificate, and returns it as a PEM-encoded string.  If
     `ssl_version' is specified, uses that version of the SSL protocol
     to attempt to connect to the server.  If `ca_certs' is specified,
     it should be a file containing a list of root certificates, the
     same format as used for the same parameter in *Note wrap_socket():
     25a.  The call will attempt to validate the server certificate
     against that set of root certificates, and will fail if the
     validation attempt fails.

     Changed in version 2.7.9: This function is now IPv6-compatible,
     and the default `ssl_version' is changed from *Note
     PROTOCOL_SSLv3: 17c5. to *Note PROTOCOL_SSLv23: 17b2. for maximum
     compatibility with modern servers.


 -- Function: ssl.DER_cert_to_PEM_cert (DER_cert_bytes)
     Given a certificate as a DER-encoded blob of bytes, returns a
     PEM-encoded string version of the same certificate.

 -- Function: ssl.PEM_cert_to_DER_cert (PEM_cert_string)
     Given a certificate as an ASCII PEM string, returns a DER-encoded
     sequence of bytes for that same certificate.

 -- Function: ssl.get_default_verify_paths ()
     Returns a named tuple with paths to OpenSSL’s default cafile and
     capath.  The paths are the same as used by *Note
     SSLContext.set_default_verify_paths(): 17c9. The return value is a
     *Note named tuple: a4a. `DefaultVerifyPaths':

        * `cafile' - resolved path to cafile or `None' if the file
          doesn’t exist,

        * `capath' - resolved path to capath or `None' if the directory
          doesn’t exist,

        * `openssl_cafile_env' - OpenSSL’s environment key that
          points to a cafile,

        * `openssl_cafile' - hard coded path to a cafile,

        * `openssl_capath_env' - OpenSSL’s environment key that
          points to a capath,

        * `openssl_capath' - hard coded path to a capath directory

     Availability: LibreSSL ignores the environment vars
     `openssl_cafile_env' and `openssl_capath_env'

     New in version 2.7.9.


 -- Function: ssl.enum_certificates (store_name)
     Retrieve certificates from Windows’ system cert store.
     `store_name' may be one of `CA', `ROOT' or `MY'. Windows may
     provide additional cert stores, too.

     The function returns a list of (cert_bytes, encoding_type, trust)
     tuples.  The encoding_type specifies the encoding of cert_bytes.
     It is either `x509_asn' for X.509 ASN.1 data or `pkcs_7_asn' for
     PKCS#7 ASN.1 data. Trust specifies the purpose of the certificate
     as a set of OIDS or exactly `True' if the certificate is
     trustworthy for all purposes.

     Example:

         >>> ssl.enum_certificates("CA")
         [(b'data...', 'x509_asn', {'1.3.6.1.5.5.7.3.1', '1.3.6.1.5.5.7.3.2'}),
          (b'data...', 'x509_asn', True)]

     Availability: Windows.

     New in version 2.7.9.


 -- Function: ssl.enum_crls (store_name)
     Retrieve CRLs from Windows’ system cert store. `store_name' may
     be one of `CA', `ROOT' or `MY'. Windows may provide additional cert
     stores, too.

     The function returns a list of (cert_bytes, encoding_type, trust)
     tuples.  The encoding_type specifies the encoding of cert_bytes.
     It is either `x509_asn' for X.509 ASN.1 data or `pkcs_7_asn' for
     PKCS#7 ASN.1 data.

     Availability: Windows.

     New in version 2.7.9.


---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc2818.html

(2) https://tools.ietf.org/html/rfc6125.html

(3) https://tools.ietf.org/html/rfc5280.html


File: python.info,  Node: Constants<5>,  Prev: Certificate handling,  Up: Functions Constants and Exceptions

5.17.3.6 Constants
..................

 -- Data: ssl.CERT_NONE
     Possible value for *Note SSLContext.verify_mode: 17ba, or the
     `cert_reqs' parameter to *Note wrap_socket(): 25a.  In this mode
     (the default), no certificates will be required from the other
     side of the socket connection.  If a certificate is received from
     the other end, no attempt to validate it is made.

     See the discussion of *Note Security considerations: 17a0. below.

 -- Data: ssl.CERT_OPTIONAL
     Possible value for *Note SSLContext.verify_mode: 17ba, or the
     `cert_reqs' parameter to *Note wrap_socket(): 25a.  In this mode
     no certificates will be required from the other side of the socket
     connection; but if they are provided, validation will be attempted
     and an *Note SSLError: 17a3.  will be raised on failure.

     Use of this setting requires a valid set of CA certificates to be
     passed, either to *Note SSLContext.load_verify_locations(): 17b6.
     or as a value of the `ca_certs' parameter to *Note wrap_socket():
     25a.

 -- Data: ssl.CERT_REQUIRED
     Possible value for *Note SSLContext.verify_mode: 17ba, or the
     `cert_reqs' parameter to *Note wrap_socket(): 25a.  In this mode,
     certificates are required from the other side of the socket
     connection; an *Note SSLError: 17a3.  will be raised if no
     certificate is provided, or if its validation fails.

     Use of this setting requires a valid set of CA certificates to be
     passed, either to *Note SSLContext.load_verify_locations(): 17b6.
     or as a value of the `ca_certs' parameter to *Note wrap_socket():
     25a.

 -- Data: ssl.VERIFY_DEFAULT
     Possible value for *Note SSLContext.verify_flags: 17ce. In this
     mode, certificate revocation lists (CRLs) are not checked. By
     default OpenSSL does neither require nor verify CRLs.

     New in version 2.7.9.


 -- Data: ssl.VERIFY_CRL_CHECK_LEAF
     Possible value for *Note SSLContext.verify_flags: 17ce. In this
     mode, only the peer cert is check but non of the intermediate CA
     certificates. The mode requires a valid CRL that is signed by the
     peer cert’s issuer (its direct ancestor CA). If no proper has
     been loaded *Note SSLContext.load_verify_locations: 17b6,
     validation will fail.

     New in version 2.7.9.


 -- Data: ssl.VERIFY_CRL_CHECK_CHAIN
     Possible value for *Note SSLContext.verify_flags: 17ce. In this
     mode, CRLs of all certificates in the peer cert chain are checked.

     New in version 2.7.9.


 -- Data: ssl.VERIFY_X509_STRICT
     Possible value for *Note SSLContext.verify_flags: 17ce. to disable
     workarounds for broken X.509 certificates.

     New in version 2.7.9.


 -- Data: ssl.VERIFY_X509_TRUSTED_FIRST
     Possible value for *Note SSLContext.verify_flags: 17ce. It
     instructs OpenSSL to prefer trusted certificates when building the
     trust chain to validate a certificate. This flag is enabled by
     default.

     New in version 2.7.10.


 -- Data: ssl.PROTOCOL_TLS
     Selects the highest protocol version that both the client and
     server support.  Despite the name, this option can select
     “TLS” protocols as well as “SSL”.

     New in version 2.7.13.


 -- Data: ssl.PROTOCOL_SSLv23
     Alias for `PROTOCOL_TLS'.

     Deprecated since version 2.7.13: Use `PROTOCOL_TLS' instead.


 -- Data: ssl.PROTOCOL_SSLv2
     Selects SSL version 2 as the channel encryption protocol.

     This protocol is not available if OpenSSL is compiled with the
     `OPENSSL_NO_SSL2' flag.

          Warning: SSL version 2 is insecure.  Its use is highly
          discouraged.

     Deprecated since version 2.7.13: OpenSSL has removed support for
     SSLv2.


 -- Data: ssl.PROTOCOL_SSLv3
     Selects SSL version 3 as the channel encryption protocol.

     This protocol is not be available if OpenSSL is compiled with the
     `OPENSSL_NO_SSLv3' flag.

          Warning: SSL version 3 is insecure.  Its use is highly
          discouraged.

     Deprecated since version 2.7.13: OpenSSL has deprecated all
     version specific protocols. Use the default protocol with flags
     like `OP_NO_SSLv3' instead.


 -- Data: ssl.PROTOCOL_TLSv1
     Selects TLS version 1.0 as the channel encryption protocol.

     Deprecated since version 2.7.13: OpenSSL has deprecated all
     version specific protocols. Use the default protocol with flags
     like `OP_NO_SSLv3' instead.


 -- Data: ssl.PROTOCOL_TLSv1_1
     Selects TLS version 1.1 as the channel encryption protocol.
     Available only with openssl version 1.0.1+.

     New in version 2.7.9.

     Deprecated since version 2.7.13: OpenSSL has deprecated all
     version specific protocols. Use the default protocol with flags
     like `OP_NO_SSLv3' instead.


 -- Data: ssl.PROTOCOL_TLSv1_2
     Selects TLS version 1.2 as the channel encryption protocol. This
     is the most modern version, and probably the best choice for
     maximum protection, if both sides can speak it.  Available only
     with openssl version 1.0.1+.

     New in version 2.7.9.

     Deprecated since version 2.7.13: OpenSSL has deprecated all
     version specific protocols. Use the default protocol with flags
     like `OP_NO_SSLv3' instead.


 -- Data: ssl.OP_ALL
     Enables workarounds for various bugs present in other SSL
     implementations.  This option is set by default.  It does not
     necessarily set the same flags as OpenSSL’s `SSL_OP_ALL'
     constant.

     New in version 2.7.9.


 -- Data: ssl.OP_NO_SSLv2
     Prevents an SSLv2 connection.  This option is only applicable in
     conjunction with *Note PROTOCOL_SSLv23: 17b2.  It prevents the
     peers from choosing SSLv2 as the protocol version.

     New in version 2.7.9.


 -- Data: ssl.OP_NO_SSLv3
     Prevents an SSLv3 connection.  This option is only applicable in
     conjunction with *Note PROTOCOL_SSLv23: 17b2.  It prevents the
     peers from choosing SSLv3 as the protocol version.

     New in version 2.7.9.


 -- Data: ssl.OP_NO_TLSv1
     Prevents a TLSv1 connection.  This option is only applicable in
     conjunction with *Note PROTOCOL_SSLv23: 17b2.  It prevents the
     peers from choosing TLSv1 as the protocol version.

     New in version 2.7.9.


 -- Data: ssl.OP_NO_TLSv1_1
     Prevents a TLSv1.1 connection. This option is only applicable in
     conjunction with *Note PROTOCOL_SSLv23: 17b2. It prevents the
     peers from choosing TLSv1.1 as the protocol version. Available
     only with openssl version 1.0.1+.

     New in version 2.7.9.


 -- Data: ssl.OP_NO_TLSv1_2
     Prevents a TLSv1.2 connection. This option is only applicable in
     conjunction with *Note PROTOCOL_SSLv23: 17b2. It prevents the
     peers from choosing TLSv1.2 as the protocol version. Available
     only with openssl version 1.0.1+.

     New in version 2.7.9.


 -- Data: ssl.OP_CIPHER_SERVER_PREFERENCE
     Use the server’s cipher ordering preference, rather than the
     client’s.  This option has no effect on client sockets and SSLv2
     server sockets.

     New in version 2.7.9.


 -- Data: ssl.OP_SINGLE_DH_USE
     Prevents re-use of the same DH key for distinct SSL sessions.  This
     improves forward secrecy but requires more computational resources.
     This option only applies to server sockets.

     New in version 2.7.9.


 -- Data: ssl.OP_SINGLE_ECDH_USE
     Prevents re-use of the same ECDH key for distinct SSL sessions.
     This improves forward secrecy but requires more computational
     resources.  This option only applies to server sockets.

     New in version 2.7.9.


 -- Data: ssl.OP_NO_COMPRESSION
     Disable compression on the SSL channel.  This is useful if the
     application protocol supports its own compression scheme.

     This option is only available with OpenSSL 1.0.0 and later.

     New in version 2.7.9.


 -- Data: ssl.HAS_ALPN
     Whether the OpenSSL library has built-in support for the
     `Application-Layer Protocol Negotiation' TLS extension as
     described in RFC 7301(1).

     New in version 2.7.10.


 -- Data: ssl.HAS_ECDH
     Whether the OpenSSL library has built-in support for Elliptic
     Curve-based Diffie-Hellman key exchange.  This should be true
     unless the feature was explicitly disabled by the distributor.

     New in version 2.7.9.


 -- Data: ssl.HAS_SNI
     Whether the OpenSSL library has built-in support for the `Server
     Name Indication' extension (as defined in RFC 4366(2)).

     New in version 2.7.9.


 -- Data: ssl.HAS_NPN
     Whether the OpenSSL library has built-in support for `Next Protocol
     Negotiation' as described in the NPN draft specification(3). When
     true, you can use the *Note SSLContext.set_npn_protocols(): 17e4.
     method to advertise which protocols you want to support.

     New in version 2.7.9.


 -- Data: ssl.CHANNEL_BINDING_TYPES
     List of supported TLS channel binding types.  Strings in this list
     can be used as arguments to *Note SSLSocket.get_channel_binding():
     17e6.

     New in version 2.7.9.


 -- Data: ssl.OPENSSL_VERSION
     The version string of the OpenSSL library loaded by the
     interpreter:

         >>> ssl.OPENSSL_VERSION
         'OpenSSL 0.9.8k 25 Mar 2009'

     New in version 2.7.


 -- Data: ssl.OPENSSL_VERSION_INFO
     A tuple of five integers representing version information about the
     OpenSSL library:

         >>> ssl.OPENSSL_VERSION_INFO
         (0, 9, 8, 11, 15)

     New in version 2.7.


 -- Data: ssl.OPENSSL_VERSION_NUMBER
     The raw version number of the OpenSSL library, as a single integer:

         >>> ssl.OPENSSL_VERSION_NUMBER
         9470143L
         >>> hex(ssl.OPENSSL_VERSION_NUMBER)
         '0x9080bfL'

     New in version 2.7.


 -- Data: ssl.ALERT_DESCRIPTION_HANDSHAKE_FAILURE
 -- Data: ssl.ALERT_DESCRIPTION_INTERNAL_ERROR
 -- Data: ALERT_DESCRIPTION_*
     Alert Descriptions from RFC 5246(4) and others. The IANA TLS Alert
     Registry(5) contains this list and references to the RFCs where
     their meaning is defined.

     Used as the return value of the callback function in *Note
     SSLContext.set_servername_callback(): 17e9.

     New in version 2.7.9.


 -- Data: Purpose.SERVER_AUTH
     Option for *Note create_default_context(): 17b5. and *Note
     SSLContext.load_default_certs(): 17bb.  This value indicates that
     the context may be used to authenticate Web servers (therefore, it
     will be used to create client-side sockets).

     New in version 2.7.9.


 -- Data: Purpose.CLIENT_AUTH
     Option for *Note create_default_context(): 17b5. and *Note
     SSLContext.load_default_certs(): 17bb.  This value indicates that
     the context may be used to authenticate Web clients (therefore, it
     will be used to create server-side sockets).

     New in version 2.7.9.


---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc7301.html

(2) https://tools.ietf.org/html/rfc4366.html

(3) https://tools.ietf.org/html/draft-agl-tls-nextprotoneg

(4) https://tools.ietf.org/html/rfc5246.html

(5)
https://www.iana.org/assignments/tls-parameters/tls-parameters.xml#tls-parameters-6


File: python.info,  Node: SSL Sockets,  Next: SSL Contexts,  Prev: Functions Constants and Exceptions,  Up: ssl — TLS/SSL wrapper for socket objects

5.17.3.7 SSL Sockets
....................

SSL sockets provide the following methods of *Note Socket Objects:
1784.:

   - *Note accept(): 1786.

   - *Note bind(): 1787.

   - *Note close(): 1788.

   - *Note connect(): 1771.

   - *Note fileno(): 178b.

   - *Note getpeername(): 178c, *Note getsockname(): 178d.

   - *Note getsockopt(): 178e, *Note setsockopt(): 1798.

   - *Note gettimeout(): 1797, *Note settimeout(): 1764, *Note
     setblocking(): 1763.

   - *Note listen(): 16d7.

   - *Note makefile(): 1790.

   - *Note recv(): 1791, *Note recv_into(): 253.  (but passing a
     non-zero `flags' argument is not allowed)

   - *Note send(): 1793, *Note sendall(): 1795. (with the same
     limitation)

   - *Note shutdown(): 1789.

However, since the SSL (and TLS) protocol has its own framing atop of
TCP, the SSL sockets abstraction can, in certain respects, diverge from
the specification of normal, OS-level sockets.  See especially the
*Note notes on non-blocking sockets: 17a8.

SSL sockets also have the following additional methods and attributes:

 -- Method: SSLSocket.do_handshake ()
     Perform the SSL setup handshake.

     Changed in version 2.7.9: The handshake method also performs *Note
     match_hostname(): 17c1. when the *Note check_hostname: 17ec.
     attribute of the socket’s *Note context: 17ed. is true.


 -- Method: SSLSocket.getpeercert (binary_form=False)
     If there is no certificate for the peer on the other end of the
     connection, return `None'.  If the SSL handshake hasn’t been
     done yet, raise *Note ValueError: 236.

     If the `binary_form' parameter is *Note False: 3c9, and a
     certificate was received from the peer, this method returns a
     *Note dict: 319. instance.  If the certificate was not validated,
     the dict is empty.  If the certificate was validated, it returns a
     dict with several keys, amongst them `subject' (the principal for
     which the certificate was issued) and `issuer' (the principal
     issuing the certificate).  If a certificate contains an instance
     of the `Subject Alternative Name' extension (see RFC 3280(1)),
     there will also be a `subjectAltName' key in the dictionary.

     The `subject' and `issuer' fields are tuples containing the
     sequence of relative distinguished names (RDNs) given in the
     certificate’s data structure for the respective fields, and each
     RDN is a sequence of name-value pairs.  Here is a real-world
     example:

         {'issuer': ((('countryName', 'IL'),),
                     (('organizationName', 'StartCom Ltd.'),),
                     (('organizationalUnitName',
                       'Secure Digital Certificate Signing'),),
                     (('commonName',
                       'StartCom Class 2 Primary Intermediate Server CA'),)),
          'notAfter': 'Nov 22 08:15:19 2013 GMT',
          'notBefore': 'Nov 21 03:09:52 2011 GMT',
          'serialNumber': '95F0',
          'subject': ((('description', '571208-SLe257oHY9fVQ07Z'),),
                      (('countryName', 'US'),),
                      (('stateOrProvinceName', 'California'),),
                      (('localityName', 'San Francisco'),),
                      (('organizationName', 'Electronic Frontier Foundation, Inc.'),),
                      (('commonName', '*.eff.org'),),
                      (('emailAddress', 'hostmaster@eff.org'),)),
          'subjectAltName': (('DNS', '*.eff.org'), ('DNS', 'eff.org')),
          'version': 3}

          Note: To validate a certificate for a particular service, you
          can use the *Note match_hostname(): 17c1. function.

     If the `binary_form' parameter is *Note True: 3c8, and a
     certificate was provided, this method returns the DER-encoded form
     of the entire certificate as a sequence of bytes, or *Note None:
     3b2. if the peer did not provide a certificate.  Whether the peer
     provides a certificate depends on the SSL socket’s role:

        * for a client SSL socket, the server will always provide a
          certificate, regardless of whether validation was required;

        * for a server SSL socket, the client will only provide a
          certificate when requested by the server; therefore *Note
          getpeercert(): 17c2. will return *Note None: 3b2. if you used
          *Note CERT_NONE: 17af. (rather than *Note CERT_OPTIONAL:
          17b0. or *Note CERT_REQUIRED: 17b1.).

     Changed in version 2.7.9: The returned dictionary includes
     additional items such as `issuer' and `notBefore'. Additionall
     *Note ValueError: 236. is raised when the handshake isn’t done.
     The returned dictionary includes additional X509v3 extension items
     such as `crlDistributionPoints', `caIssuers' and `OCSP' URIs.


 -- Method: SSLSocket.cipher ()
     Returns a three-value tuple containing the name of the cipher
     being used, the version of the SSL protocol that defines its use,
     and the number of secret bits being used.  If no connection has
     been established, returns `None'.

 -- Method: SSLSocket.compression ()
     Return the compression algorithm being used as a string, or `None'
     if the connection isn’t compressed.

     If the higher-level protocol supports its own compression
     mechanism, you can use *Note OP_NO_COMPRESSION: 17df. to disable
     SSL-level compression.

     New in version 2.7.9.


 -- Method: SSLSocket.get_channel_binding (cb_type="tls-unique")
     Get channel binding data for current connection, as a bytes
     object.  Returns `None' if not connected or the handshake has not
     been completed.

     The `cb_type' parameter allow selection of the desired channel
     binding type. Valid channel binding types are listed in the *Note
     CHANNEL_BINDING_TYPES: 17e5. list.  Currently only the
     ‘tls-unique’ channel binding, defined by RFC 5929(2), is
     supported.  *Note ValueError: 236. will be raised if an
     unsupported channel binding type is requested.

     New in version 2.7.9.


 -- Method: SSLSocket.selected_alpn_protocol ()
     Return the protocol that was selected during the TLS handshake.  If
     *Note SSLContext.set_alpn_protocols(): 17f1. was not called, if
     the other party does not support ALPN, if this socket does not
     support any of the client’s proposed protocols, or if the
     handshake has not happened yet, `None' is returned.

     New in version 2.7.10.


 -- Method: SSLSocket.selected_npn_protocol ()
     Return the higher-level protocol that was selected during the
     TLS/SSL handshake. If *Note SSLContext.set_npn_protocols(): 17e4.
     was not called, or if the other party does not support NPN, or if
     the handshake has not yet happened, this will return `None'.

     New in version 2.7.9.


 -- Method: SSLSocket.unwrap ()
     Performs the SSL shutdown handshake, which removes the TLS layer
     from the underlying socket, and returns the underlying socket
     object.  This can be used to go from encrypted operation over a
     connection to unencrypted.  The returned socket should always be
     used for further communication with the other side of the
     connection, rather than the original socket.

 -- Method: SSLSocket.version ()
     Return the actual SSL protocol version negotiated by the connection
     as a string, or `None' is no secure connection is established.  As
     of this writing, possible return values include `"SSLv2"',
     `"SSLv3"', `"TLSv1"', `"TLSv1.1"' and `"TLSv1.2"'.  Recent OpenSSL
     versions may define more return values.

     New in version 2.7.9.


 -- Attribute: SSLSocket.context
     The *Note SSLContext: 2e5. object this SSL socket is tied to.  If
     the SSL socket was created using the top-level *Note
     wrap_socket(): 25a. function (rather than *Note
     SSLContext.wrap_socket(): 17a1.), this is a custom context object
     created for this SSL socket.

     New in version 2.7.9.


---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc3280.html

(2) https://tools.ietf.org/html/rfc5929.html

