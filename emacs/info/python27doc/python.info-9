This is python.info, produced by makeinfo version 4.8 from python.texi.

Generated by Sphinx 1.6.3.
INFO-DIR-SECTION Python
START-INFO-DIR-ENTRY
* Python: (python.info). The Python reference manual.
END-INFO-DIR-ENTRY

     Python 2.7.13, July 15, 2017

     Copyright (C) 1990-2017, Python Software Foundation


File: python.info,  Node: Subclassing Unpicklers,  Next: Example<3>,  Prev: The pickle protocol,  Up: pickle — Python object serialization

5.11.1.9 Subclassing Unpicklers
...............................

By default, unpickling will import any class that it finds in the
pickle data.  You can control exactly what gets unpickled and what gets
called by customizing your unpickler.  Unfortunately, exactly how you
do this is different depending on whether you’re using *Note pickle:
12e. or *Note cPickle: 73. (1)

In the *Note pickle: 12e. module, you need to derive a subclass from
`Unpickler', overriding the `load_global()' method.  `load_global()'
should read two lines from the pickle data stream where the first line
will the name of the module containing the class and the second line
will be the name of the instance’s class.  It then looks up the
class, possibly importing the module and digging out the attribute,
then it appends what it finds to the unpickler’s stack.  Later on,
this class will be assigned to the `__class__' attribute of an empty
class, as a way of magically creating an instance without calling its
class’s *Note __init__(): 394. Your job (should you choose to accept
it), would be to have `load_global()' push onto the unpickler’s
stack, a known safe version of any class you deem safe to unpickle.  It
is up to you to produce such a class.  Or you could raise an error if
you want to disallow all unpickling of instances.  If this sounds like
a hack, you’re right.  Refer to the source code to make this work.

Things are a little cleaner with *Note cPickle: 73, but not by much. To
control what gets unpickled, you can set the unpickler’s `find_global'
attribute to a function or `None'.  If it is `None' then any attempts to
unpickle instances will raise an `UnpicklingError'.  If it is a
function, then it should accept a module name and a class name, and
return the corresponding class object.  It is responsible for looking
up the class and performing any necessary imports, and it may raise an
error to prevent instances of the class from being unpickled.

The moral of the story is that you should be really careful about the
source of the strings your application unpickles.

---------- Footnotes ----------

(1) A word of caution: the mechanisms described here use internal
attributes and methods, which are subject to change in future versions
of Python.  We intend to someday provide a common interface for
controlling this behavior, which will work in either *Note pickle: 12e.
or *Note cPickle: 73.


File: python.info,  Node: Example<3>,  Prev: Subclassing Unpicklers,  Up: pickle — Python object serialization

5.11.1.10 Example
.................

For the simplest code, use the `dump()' and `load()' functions.  Note
that a self-referencing list is pickled and restored correctly.

    import pickle

    data1 = {'a': [1, 2.0, 3, 4+6j],
             'b': ('string', u'Unicode string'),
             'c': None}

    selfref_list = [1, 2, 3]
    selfref_list.append(selfref_list)

    output = open('data.pkl', 'wb')

    # Pickle dictionary using protocol 0.
    pickle.dump(data1, output)

    # Pickle the list using the highest protocol available.
    pickle.dump(selfref_list, output, -1)

    output.close()

The following example reads the resulting pickled data.  When reading a
pickle-containing file, you should open the file in binary mode because
you can’t be sure if the ASCII or binary format was used.

    import pprint, pickle

    pkl_file = open('data.pkl', 'rb')

    data1 = pickle.load(pkl_file)
    pprint.pprint(data1)

    data2 = pickle.load(pkl_file)
    pprint.pprint(data2)

    pkl_file.close()

Here’s a larger example that shows how to modify pickling behavior
for a class.  The `TextReader' class opens a text file, and returns the
line number and line contents each time its `readline()' method is
called. If a `TextReader' instance is pickled, all attributes `except'
the file object member are saved. When the instance is unpickled, the
file is reopened, and reading resumes from the last location. The *Note
__setstate__(): 464. and *Note __getstate__(): 463. methods are used to
implement this behavior.

    #!/usr/local/bin/python

    class TextReader:
        """Print and number lines in a text file."""
        def __init__(self, file):
            self.file = file
            self.fh = open(file)
            self.lineno = 0

        def readline(self):
            self.lineno = self.lineno + 1
            line = self.fh.readline()
            if not line:
                return None
            if line.endswith("\n"):
                line = line[:-1]
            return "%d: %s" % (self.lineno, line)

        def __getstate__(self):
            odict = self.__dict__.copy() # copy the dict since we change it
            del odict['fh']              # remove filehandle entry
            return odict

        def __setstate__(self, dict):
            fh = open(dict['file'])      # reopen file
            count = dict['lineno']       # read from file...
            while count:                 # until line count is restored
                fh.readline()
                count = count - 1
            self.__dict__.update(dict)   # update attributes
            self.fh = fh                 # save the file object

A sample usage might be something like this:

    >>> import TextReader
    >>> obj = TextReader.TextReader("TextReader.py")
    >>> obj.readline()
    '1: #!/usr/local/bin/python'
    >>> obj.readline()
    '2: '
    >>> obj.readline()
    '3: class TextReader:'
    >>> import pickle
    >>> pickle.dump(obj, open('save.p', 'wb'))

If you want to see that *Note pickle: 12e. works across Python
processes, start another Python session, before continuing.  What
follows can happen from either the same process or a new process.

    >>> import pickle
    >>> reader = pickle.load(open('save.p', 'rb'))
    >>> reader.readline()
    '4:     """Print and number lines in a text file."""'

See also
........

Module *Note copy_reg: 72.
     Pickle interface constructor registration for extension types.

Module *Note shelve: 152.
     Indexed databases of objects; uses *Note pickle: 12e.

Module *Note copy: 71.
     Shallow and deep object copying.

Module *Note marshal: 10c.
     High-performance serialization of built-in types.


File: python.info,  Node: cPickle — A faster pickle,  Next: copy_reg — Register pickle support functions,  Prev: pickle — Python object serialization,  Up: Data Persistence

5.11.2 `cPickle' — A faster `pickle'
--------------------------------------

The *Note cPickle: 73. module supports serialization and
de-serialization of Python objects, providing an interface and
functionality nearly identical to the *Note pickle: 12e. module.  There
are several differences, the most important being performance and
subclassability.

First, *Note cPickle: 73. can be up to 1000 times faster than *Note
pickle: 12e. because the former is implemented in C.  Second, in the
*Note cPickle: 73. module the callables `Pickler()' and `Unpickler()'
are functions, not classes.  This means that you cannot use them to
derive custom pickling and unpickling subclasses.  Most applications
have no need for this functionality and should benefit from the greatly
improved performance of the *Note cPickle: 73. module.

The pickle data stream produced by *Note pickle: 12e. and *Note
cPickle: 73. are identical, so it is possible to use *Note pickle: 12e.
and *Note cPickle: 73.  interchangeably with existing pickles. (1)

There are additional minor differences in API between *Note cPickle:
73. and *Note pickle: 12e, however for most applications, they are
interchangeable.  More documentation is provided in the *Note pickle:
12e. module documentation, which includes a list of the documented
differences.

---------- Footnotes ----------

(1) Since the pickle data format is actually a tiny stack-oriented
programming language, and some freedom is taken in the encodings of
certain objects, it is possible that the two modules produce different
data streams for the same input objects.  However it is guaranteed that
they will always be able to read each other’s data streams.


File: python.info,  Node: copy_reg — Register pickle support functions,  Next: shelve — Python object persistence,  Prev: cPickle — A faster pickle,  Up: Data Persistence

5.11.3 `copy_reg' — Register `pickle' support functions
---------------------------------------------------------

     Note: The *Note copy_reg: 72. module has been renamed to `copyreg'
     in Python 3.  The *Note 2to3: c05. tool will automatically adapt
     imports when converting your sources to Python 3.

The *Note copy_reg: 72. module offers a way to define functions used
while pickling specific objects.  The *Note pickle: 12e, *Note cPickle:
73, and *Note copy: 71. modules use those functions when
pickling/copying those objects.  The module provides configuration
information about object constructors which are not classes.  Such
constructors may be factory functions or class instances.

 -- Function: copy_reg.constructor (object)
     Declares `object' to be a valid constructor.  If `object' is not
     callable (and hence not valid as a constructor), raises *Note
     TypeError: 218.

 -- Function: copy_reg.pickle (type, function[, constructor])
     Declares that `function' should be used as a “reduction”
     function for objects of type `type'; `type' must not be a
     “classic” class object.  (Classic classes are handled
     differently; see the documentation for the *Note pickle: 12e.
     module for details.)  `function' should return either a string or
     a tuple containing two or three elements.

     The optional `constructor' parameter, if provided, is a callable
     object which can be used to reconstruct the object when called
     with the tuple of arguments returned by `function' at pickling
     time.  *Note TypeError: 218. will be raised if `object' is a class
     or `constructor' is not callable.

     See the *Note pickle: 12e. module for more details on the
     interface expected of `function' and `constructor'.

* Menu:

* Example: Example<4>.


File: python.info,  Node: Example<4>,  Up: copy_reg — Register pickle support functions

5.11.3.1 Example
................

The example below would like to show how to register a pickle function
and how it will be used:

    >>> import copy_reg, copy, pickle
    >>> class C(object):
    ...     def __init__(self, a):
    ...         self.a = a
    ...
    >>> def pickle_c(c):
    ...     print("pickling a C instance...")
    ...     return C, (c.a,)
    ...
    >>> copy_reg.pickle(C, pickle_c)
    >>> c = C(1)
    >>> d = copy.copy(c)
    pickling a C instance...
    >>> p = pickle.dumps(c)
    pickling a C instance...


File: python.info,  Node: shelve — Python object persistence,  Next: marshal — Internal Python object serialization,  Prev: copy_reg — Register pickle support functions,  Up: Data Persistence

5.11.4 `shelve' — Python object persistence
---------------------------------------------

`Source code:' Lib/shelve.py(1)

__________________________________________________________________

A “shelf” is a persistent, dictionary-like object.  The difference
with “dbm” databases is that the values (not the keys!) in a shelf
can be essentially arbitrary Python objects — anything that the *Note
pickle: 12e. module can handle.  This includes most class instances,
recursive data types, and objects containing lots of shared
sub-objects.  The keys are ordinary strings.

 -- Function: shelve.open (filename, flag='c', protocol=None,
          writeback=False)
     Open a persistent dictionary.  The filename specified is the base
     filename for the underlying database.  As a side-effect, an
     extension may be added to the filename and more than one file may
     be created.  By default, the underlying database file is opened
     for reading and writing.  The optional `flag' parameter has the
     same interpretation as the `flag' parameter of *Note
     anydbm.open(): f13.

     By default, version 0 pickles are used to serialize values.  The
     version of the pickle protocol can be specified with the
     `protocol' parameter.

     Changed in version 2.3: The `protocol' parameter was added.

     Because of Python semantics, a shelf cannot know when a mutable
     persistent-dictionary entry is modified.  By default modified
     objects are written `only' when assigned to the shelf (see *Note
     Example: f14.).  If the optional `writeback' parameter is set to
     `True', all entries accessed are also cached in memory, and
     written back on *Note sync(): f15. and *Note close(): f16.; this
     can make it handier to mutate mutable entries in the persistent
     dictionary, but, if many entries are accessed, it can consume vast
     amounts of memory for the cache, and it can make the close
     operation very slow since all accessed entries are written back
     (there is no way to determine which accessed entries are mutable,
     nor which ones were actually mutated).

     Like file objects, shelve objects should be closed explicitly to
     ensure that the persistent data is flushed to disk.

     Warning: Because the *Note shelve: 152. module is backed by *Note
     pickle: 12e, it is insecure to load a shelf from an untrusted
     source.  Like with pickle, loading a shelf can execute arbitrary
     code.

Shelf objects support most of the methods supported by dictionaries.
This eases the transition from dictionary based scripts to those
requiring persistent storage.

Note, the Python 3 transition methods (*Note viewkeys(): 1e4, *Note
viewvalues(): 1e5, and *Note viewitems(): 1e6.) are not supported.

Two additional methods are supported:

 -- Method: Shelf.sync ()
     Write back all entries in the cache if the shelf was opened with
     `writeback' set to *Note True: 3c8.  Also empty the cache and
     synchronize the persistent dictionary on disk, if feasible.  This
     is called automatically when the shelf is closed with *Note
     close(): f16.

 -- Method: Shelf.close ()
     Synchronize and close the persistent `dict' object.  Operations on
     a closed shelf will fail with a *Note ValueError: 236.

See also
........

Persistent dictionary recipe(2) with widely supported storage formats
and having the speed of native dictionaries.

* Menu:

* Restrictions::
* Example: Example<5>.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/shelve.py

(2) https://code.activestate.com/recipes/576642/


File: python.info,  Node: Restrictions,  Next: Example<5>,  Up: shelve — Python object persistence

5.11.4.1 Restrictions
.....................

 
   * The choice of which database package will be used (such as *Note
     dbm: 7f, *Note gdbm: dd. or *Note bsddb: 1c.) depends on which
     interface is available.  Therefore it is not safe to open the
     database directly using *Note dbm: 7f.  The database is also
     (unfortunately) subject to the limitations of *Note dbm: 7f, if it
     is used — this means that (the pickled representation of) the
     objects stored in the database should be fairly small, and in rare
     cases key collisions may cause the database to refuse updates.

   * The *Note shelve: 152. module does not support `concurrent'
     read/write access to shelved objects.  (Multiple simultaneous read
     accesses are safe.)  When a program has a shelf open for writing,
     no other program should have it open for reading or writing.  Unix
     file locking can be used to solve this, but this differs across
     Unix versions and requires knowledge about the database
     implementation used.

 -- Class: shelve.Shelf (dict, protocol=None, writeback=False)
     A subclass of *Note UserDict.DictMixin: c2a. which stores pickled
     values in the `dict' object.

     By default, version 0 pickles are used to serialize values.  The
     version of the pickle protocol can be specified with the
     `protocol' parameter. See the *Note pickle: 12e. documentation for
     a discussion of the pickle protocols.

     Changed in version 2.3: The `protocol' parameter was added.

     If the `writeback' parameter is `True', the object will hold a
     cache of all entries accessed and write them back to the `dict' at
     sync and close times.  This allows natural operations on mutable
     entries, but can consume much more memory and make sync and close
     take a long time.

 -- Class: shelve.BsdDbShelf (dict, protocol=None, writeback=False)
     A subclass of *Note Shelf: f18. which exposes `first()', `next()',
     `previous()', `last()' and `set_location()' which are available in
     the *Note bsddb: 1c. module but not in other database modules.
     The `dict' object passed to the constructor must support those
     methods.  This is generally accomplished by calling one of *Note
     bsddb.hashopen(): f1a, *Note bsddb.btopen(): f1b. or *Note
     bsddb.rnopen(): f1c.  The optional `protocol' and `writeback'
     parameters have the same interpretation as for the *Note Shelf:
     f18. class.

 -- Class: shelve.DbfilenameShelf (filename, flag='c', protocol=None,
          writeback=False)
     A subclass of *Note Shelf: f18. which accepts a `filename' instead
     of a dict-like object.  The underlying file will be opened using
     *Note anydbm.open(): f13.  By default, the file will be created
     and opened for both read and write.  The optional `flag' parameter
     has the same interpretation as for the *Note open(): f12.
     function.  The optional `protocol' and `writeback' parameters have
     the same interpretation as for the *Note Shelf: f18. class.


File: python.info,  Node: Example<5>,  Prev: Restrictions,  Up: shelve — Python object persistence

5.11.4.2 Example
................

To summarize the interface (`key' is a string, `data' is an arbitrary
object):

    import shelve

    d = shelve.open(filename) # open -- file may get suffix added by low-level
                              # library

    d[key] = data   # store data at key (overwrites old data if
                    # using an existing key)
    data = d[key]   # retrieve a COPY of data at key (raise KeyError if no
                    # such key)
    del d[key]      # delete data stored at key (raises KeyError
                    # if no such key)
    flag = d.has_key(key)   # true if the key exists
    klist = d.keys() # a list of all existing keys (slow!)

    # as d was opened WITHOUT writeback=True, beware:
    d['xx'] = range(4)  # this works as expected, but...
    d['xx'].append(5)   # *this doesn't!* -- d['xx'] is STILL range(4)!

    # having opened d without writeback=True, you need to code carefully:
    temp = d['xx']      # extracts the copy
    temp.append(5)      # mutates the copy
    d['xx'] = temp      # stores the copy right back, to persist it

    # or, d=shelve.open(filename,writeback=True) would let you just code
    # d['xx'].append(5) and have it work as expected, BUT it would also
    # consume more memory and make the d.close() operation slower.

    d.close()       # close it

See also
........

Module *Note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *Note bsddb: 1c.
     BSD `db' database interface.

Module *Note dbhash: 7e.
     Thin layer around the *Note bsddb: 1c. which provides an *Note
     open(): f1f.  function like the other database modules.

Module *Note dbm: 7f.
     Standard Unix database interface.

Module *Note dumbdbm: b7.
     Portable implementation of the `dbm' interface.

Module *Note gdbm: dd.
     GNU database interface, based on the `dbm' interface.

Module *Note pickle: 12e.
     Object serialization used by *Note shelve: 152.

Module *Note cPickle: 73.
     High-performance version of *Note pickle: 12e.


File: python.info,  Node: marshal — Internal Python object serialization,  Next: anydbm — Generic access to DBM-style databases,  Prev: shelve — Python object persistence,  Up: Data Persistence

5.11.5 `marshal' — Internal Python object serialization
---------------------------------------------------------

This module contains functions that can read and write Python values in
a binary format.  The format is specific to Python, but independent of
machine architecture issues (e.g., you can write a Python value to a
file on a PC, transport the file to a Sun, and read it back there).
Details of the format are undocumented on purpose; it may change
between Python versions (although it rarely does). (1)

This is not a general “persistence” module.  For general
persistence and transfer of Python objects through RPC calls, see the
modules *Note pickle: 12e. and *Note shelve: 152.  The *Note marshal:
10c. module exists mainly to support reading and writing the
“pseudo-compiled” code for Python modules of `.pyc' files.
Therefore, the Python maintainers reserve the right to modify the
marshal format in backward incompatible ways should the need arise.  If
you’re serializing and de-serializing Python objects, use the *Note
pickle: 12e. module instead – the performance is comparable, version
independence is guaranteed, and pickle supports a substantially wider
range of objects than marshal.

     Warning: The *Note marshal: 10c. module is not intended to be
     secure against erroneous or maliciously constructed data.  Never
     unmarshal data received from an untrusted or unauthenticated
     source.

Not all Python object types are supported; in general, only objects
whose value is independent from a particular invocation of Python can
be written and read by this module.  The following types are supported:
booleans, integers, long integers, floating point numbers, complex
numbers, strings, Unicode objects, tuples, lists, sets, frozensets,
dictionaries, and code objects, where it should be understood that
tuples, lists, sets, frozensets and dictionaries are only supported as
long as the values contained therein are themselves supported; and
recursive lists, sets and dictionaries should not be written (they will
cause infinite loops).  The singletons *Note None: 3b2, *Note Ellipsis:
8c0. and *Note StopIteration: 347. can also be marshalled and
unmarshalled.

     Warning: On machines where C’s `long int' type has more than 32
     bits (such as the DEC Alpha), it is possible to create plain
     Python integers that are longer than 32 bits. If such an integer
     is marshaled and read back in on a machine where C’s `long int'
     type has only 32 bits, a Python long integer object is returned
     instead.  While of a different type, the numeric value is the
     same.  (This behavior is new in Python 2.2.  In earlier versions,
     all but the least-significant 32 bits of the value were lost, and
     a warning message was printed.)

There are functions that read/write files as well as functions
operating on strings.

The module defines these functions:

 -- Function: marshal.dump (value, file[, version])
     Write the value on the open file.  The value must be a supported
     type.  The file must be an open file object such as `sys.stdout'
     or returned by *Note open(): 2d9. or *Note os.popen(): 728.  It
     may not be a wrapper such as TemporaryFile on Windows. It must be
     opened in binary mode (`'wb'' or `'w+b'').

     If the value has (or contains an object that has) an unsupported
     type, a *Note ValueError: 236. exception is raised — but garbage
     data will also be written to the file.  The object will not be
     properly read back by *Note load(): f23.

     New in version 2.4: The `version' argument indicates the data
     format that `dump' should use (see below).


 -- Function: marshal.load (file)
     Read one value from the open file and return it.  If no valid
     value is read (e.g. because the data has a different Python
     version’s incompatible marshal format), raise *Note EOFError:
     8b3, *Note ValueError: 236. or *Note TypeError: 218.  The file
     must be an open file object opened in binary mode (`'rb'' or
     `'r+b'').

          Note: If an object containing an unsupported type was
          marshalled with *Note dump(): f22, *Note load(): f23. will
          substitute `None' for the unmarshallable type.

 -- Function: marshal.dumps (value[, version])
     Return the string that would be written to a file by `dump(value,
     file)'.  The value must be a supported type.  Raise a *Note
     ValueError: 236. exception if value has (or contains an object
     that has) an unsupported type.

     New in version 2.4: The `version' argument indicates the data
     format that `dumps' should use (see below).


 -- Function: marshal.loads (string)
     Convert the string to a value.  If no valid value is found, raise
     *Note EOFError: 8b3, *Note ValueError: 236. or *Note TypeError:
     218.  Extra characters in the string are ignored.

In addition, the following constants are defined:

 -- Data: marshal.version
     Indicates the format that the module uses. Version 0 is the
     historical format, version 1 (added in Python 2.4) shares interned
     strings and version 2 (added in Python 2.5) uses a binary format
     for floating point numbers. The current version is 2.

     New in version 2.4.


---------- Footnotes ----------

(1) The name of this module stems from a bit of terminology used by the
designers of Modula-3 (amongst others), who use the term
“marshalling” for shipping of data around in a self-contained form.
Strictly speaking, “to marshal” means to convert some data from
internal to external form (in an RPC buffer for instance) and
“unmarshalling” for the reverse process.


File: python.info,  Node: anydbm — Generic access to DBM-style databases,  Next: whichdb — Guess which DBM module created a database,  Prev: marshal — Internal Python object serialization,  Up: Data Persistence

5.11.6 `anydbm' — Generic access to DBM-style databases
---------------------------------------------------------

     Note: The *Note anydbm: b. module has been renamed to *Note dbm:
     7f. in Python 3.  The *Note 2to3: c05. tool will automatically
     adapt imports when converting your sources to Python 3.

*Note anydbm: b. is a generic interface to variants of the DBM database
— *Note dbhash: 7e. (requires *Note bsddb: 1c.), *Note gdbm: dd, or
*Note dbm: 7f.  If none of these modules is installed, the
slow-but-simple implementation in module *Note dumbdbm: b7. will be
used.

 -- Function: anydbm.open (filename[, flag[, mode]])
     Open the database file `filename' and return a corresponding
     object.

     If the database file already exists, the *Note whichdb: 197.
     module is used to determine its type and the appropriate module is
     used; if it does not exist, the first module listed above that can
     be imported is used.

     The optional `flag' argument must be one of these values:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn’t exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     If not specified, the default value is `'r''.

     The optional `mode' argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666' (and will be modified by the prevailing umask).

 -- Exception: anydbm.error
     A tuple containing the exceptions that can be raised by each of
     the supported modules, with a unique exception also named *Note
     anydbm.error: f29. as the first item — the latter is used when
     *Note anydbm.error: f29. is raised.

The object returned by *Note open(): f13. supports most of the same
functionality as dictionaries; keys and their corresponding values can
be stored, retrieved, and deleted, and the `has_key()' and `keys()'
methods are available.  Keys and values must always be strings.

The following example records some hostnames and a corresponding title,
and then prints out the contents of the database:

    import anydbm

    # Open database, creating it if necessary.
    db = anydbm.open('cache', 'c')

    # Record some values
    db['www.python.org'] = 'Python Website'
    db['www.cnn.com'] = 'Cable News Network'

    # Loop through contents.  Other dictionary methods
    # such as .keys(), .values() also work.
    for k, v in db.iteritems():
        print k, '\t', v

    # Storing a non-string key or value will raise an exception (most
    # likely a TypeError).
    db['www.yahoo.com'] = 4

    # Close when done.
    db.close()

In addition to the dictionary-like methods, `anydbm' objects provide
the following method:

 -- Function: anydbm.close ()
     Close the `anydbm' database.

See also
........

Module *Note dbhash: 7e.
     BSD `db' database interface.

Module *Note dbm: 7f.
     Standard Unix database interface.

Module *Note dumbdbm: b7.
     Portable implementation of the `dbm' interface.

Module *Note gdbm: dd.
     GNU database interface, based on the `dbm' interface.

Module *Note shelve: 152.
     General object persistence built on top of  the Python `dbm'
     interface.

Module *Note whichdb: 197.
     Utility module used to determine the type of an existing database.


File: python.info,  Node: whichdb — Guess which DBM module created a database,  Next: dbm — Simple “database” interface,  Prev: anydbm — Generic access to DBM-style databases,  Up: Data Persistence

5.11.7 `whichdb' — Guess which DBM module created a database
--------------------------------------------------------------

     Note: The *Note whichdb: 197. module’s only function has been
     put into the *Note dbm: 7f.  module in Python 3.  The *Note 2to3:
     c05. tool will automatically adapt imports when converting your
     sources to Python 3.

The single function in this module attempts to guess which of the
several simple database modules available—*Note dbm: 7f, *Note gdbm:
dd, or *Note dbhash: 7e.—should be used to open a given file.

 -- Function: whichdb.whichdb (filename)
     Returns one of the following values: `None' if the file can’t be
     opened because it’s unreadable or doesn’t exist; the empty
     string (`''') if the file’s format can’t be guessed; or a
     string containing the required module name, such as `'dbm'' or
     `'gdbm''.


File: python.info,  Node: dbm — Simple “database” interface,  Next: gdbm — GNU’s reinterpretation of dbm,  Prev: whichdb — Guess which DBM module created a database,  Up: Data Persistence

5.11.8 `dbm' — Simple “database” interface
------------------------------------------------

     Note: The *Note dbm: 7f. module has been renamed to `dbm.ndbm' in
     Python 3.  The *Note 2to3: c05. tool will automatically adapt
     imports when converting your sources to Python 3.

The *Note dbm: 7f. module provides an interface to the Unix
“(n)dbm” library.  Dbm objects behave like mappings (dictionaries),
except that keys and values are always strings. Printing a dbm object
doesn’t print the keys and values, and the `items()' and `values()'
methods are not supported.

This module can be used with the “classic” ndbm interface, the BSD
DB compatibility interface, or the GNU GDBM compatibility interface. On
Unix, the `configure' script will attempt to locate the appropriate
header file to simplify building this module.

The module defines the following:

 -- Exception: dbm.error
     Raised on dbm-specific errors, such as I/O errors. *Note KeyError:
     205. is raised for general mapping errors like specifying an
     incorrect key.

 -- Data: dbm.library
     Name of the `ndbm' implementation library used.

 -- Function: dbm.open (filename[, flag[, mode]])
     Open a dbm database and return a dbm object.  The `filename'
     argument is the name of the database file (without the `.dir' or
     `.pag' extensions; note that the BSD DB implementation of the
     interface will append the extension `.db' and only create one
     file).

     The optional `flag' argument must be one of these values:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn’t exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     The optional `mode' argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666' (and will be modified by the prevailing umask).

     In addition to the dictionary-like methods, `dbm' objects provide
     the following method:

      -- Function: dbm.close ()
          Close the `dbm' database.

See also
........

Module *Note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *Note gdbm: dd.
     Similar interface to the GNU GDBM library.

Module *Note whichdb: 197.
     Utility module used to determine the type of an existing database.


File: python.info,  Node: gdbm — GNU’s reinterpretation of dbm,  Next: dbhash — DBM-style interface to the BSD database library,  Prev: dbm — Simple “database” interface,  Up: Data Persistence

5.11.9 `gdbm' — GNU’s reinterpretation of dbm
-------------------------------------------------

     Note: The *Note gdbm: dd. module has been renamed to `dbm.gnu' in
     Python 3.  The *Note 2to3: c05. tool will automatically adapt
     imports when converting your sources to Python 3.

This module is quite similar to the *Note dbm: 7f. module, but uses
`gdbm' instead to provide some additional functionality.  Please note
that the file formats created by `gdbm' and `dbm' are incompatible.

The *Note gdbm: dd. module provides an interface to the GNU DBM
library.  `gdbm' objects behave like mappings (dictionaries), except
that keys and values are always strings. Printing a `gdbm' object
doesn’t print the keys and values, and the `items()' and `values()'
methods are not supported.

The module defines the following constant and functions:

 -- Exception: gdbm.error
     Raised on `gdbm'-specific errors, such as I/O errors. *Note
     KeyError: 205. is raised for general mapping errors like
     specifying an incorrect key.

 -- Function: gdbm.open (filename[, flag[, mode]])
     Open a `gdbm' database and return a `gdbm' object.  The `filename'
     argument is the name of the database file.

     The optional `flag' argument can be:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn’t exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     The following additional characters may be appended to the flag to
     control how the database is opened:

     Value         Meaning
     --------------------------------------------------------------- 
     `'f''         Open the database in fast mode.  Writes to the
                   database will not be synchronized.
     `'s''         Synchronized mode. This will cause changes to
                   the database to be immediately written to the
                   file.
     `'u''         Do not lock database.

     Not all flags are valid for all versions of `gdbm'.  The module
     constant `open_flags' is a string of supported flag characters.
     The exception *Note error: f36. is raised if an invalid flag is
     specified.

     The optional `mode' argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666'.

In addition to the dictionary-like methods, `gdbm' objects have the
following methods:

 -- Function: gdbm.firstkey ()
     It’s possible to loop over every key in the database using this
     method  and the *Note nextkey(): f39. method.  The traversal is
     ordered by `gdbm'’s internal hash values, and won’t be sorted
     by the key values.  This method returns the starting key.

 -- Function: gdbm.nextkey (key)
     Returns the key that follows `key' in the traversal.  The
     following code prints every key in the database `db', without
     having to create a list in memory that contains them all:

         k = db.firstkey()
         while k != None:
             print k
             k = db.nextkey(k)

 -- Function: gdbm.reorganize ()
     If you have carried out a lot of deletions and would like to
     shrink the space used by the `gdbm' file, this routine will
     reorganize the database.  `gdbm' will not shorten the length of a
     database file except by using this reorganization; otherwise,
     deleted file space will be kept and reused as new (key, value)
     pairs are added.

 -- Function: gdbm.sync ()
     When the database has been opened in fast mode, this method forces
     any unwritten data to be written to the disk.

 -- Function: gdbm.close ()
     Close the `gdbm' database.

See also
........

Module *Note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *Note whichdb: 197.
     Utility module used to determine the type of an existing database.


File: python.info,  Node: dbhash — DBM-style interface to the BSD database library,  Next: bsddb — Interface to Berkeley DB library,  Prev: gdbm — GNU’s reinterpretation of dbm,  Up: Data Persistence

5.11.10 `dbhash' — DBM-style interface to the BSD database library
--------------------------------------------------------------------

Deprecated since version 2.6: The *Note dbhash: 7e. module has been
removed in Python 3.

The *Note dbhash: 7e. module provides a function to open databases
using the BSD `db' library.  This module mirrors the interface of the
other Python database modules that provide access to DBM-style
databases.  The *Note bsddb: 1c. module is required  to use *Note
dbhash: 7e.

This module provides an exception and a function:

 -- Exception: dbhash.error
     Exception raised on database errors other than *Note KeyError:
     205.  It is a synonym for `bsddb.error'.

 -- Function: dbhash.open (path[, flag[, mode]])
     Open a `db' database and return the database object.  The `path'
     argument is the name of the database file.

     The `flag' argument can be:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn’t exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     For platforms on which the BSD `db' library supports locking, an
     `'l'' can be appended to indicate that locking should be used.

     The optional `mode' parameter is used to indicate the Unix
     permission bits that should be set if a new database must be
     created; this will be masked by the current umask value for the
     process.

See also
........

Module *Note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *Note bsddb: 1c.
     Lower-level interface to the BSD `db' library.

Module *Note whichdb: 197.
     Utility module used to determine the type of an existing database.

* Menu:

* Database Objects::


File: python.info,  Node: Database Objects,  Up: dbhash — DBM-style interface to the BSD database library

5.11.10.1 Database Objects
..........................

The database objects returned by *Note open(): f1f. provide the methods
common to all the DBM-style databases and mapping objects.  The
following methods are available in addition to the standard methods.

 -- Method: dbhash.first ()
     It’s possible to loop over every key/value pair in the database
     using this method and the `next()' method.  The traversal is
     ordered by the databases internal hash values, and won’t be
     sorted by the key values.  This method returns the starting key.

 -- Method: dbhash.last ()
     Return the last key/value pair in a database traversal.  This may
     be used to begin a reverse-order traversal; see *Note previous():
     f44.

 -- Method: dbhash.next ()
     Returns the key next key/value pair in a database traversal.  The
     following code prints every key in the database `db', without
     having to create a list in memory that contains them all:

         print db.first()
         for i in xrange(1, len(db)):
             print db.next()

 -- Method: dbhash.previous ()
     Returns the previous key/value pair in a forward-traversal of the
     database. In conjunction with *Note last(): f43, this may be used
     to implement a reverse-order traversal.

 -- Method: dbhash.sync ()
     This method forces any unwritten data to be written to the disk.


File: python.info,  Node: bsddb — Interface to Berkeley DB library,  Next: dumbdbm — Portable DBM implementation,  Prev: dbhash — DBM-style interface to the BSD database library,  Up: Data Persistence

5.11.11 `bsddb' — Interface to Berkeley DB library
----------------------------------------------------

Deprecated since version 2.6: The *Note bsddb: 1c. module has been
removed in Python 3.

The *Note bsddb: 1c. module provides an interface to the Berkeley DB
library.  Users can create hash, btree or record based library files
using the appropriate open call. Bsddb objects behave generally like
dictionaries.  Keys and values must be strings, however, so to use
other objects as keys or to store other kinds of objects the user must
serialize them somehow, typically using *Note marshal.dumps(): f24. or
*Note pickle.dumps(): 461.

The *Note bsddb: 1c. module requires a Berkeley DB library version from
4.0 thru 4.7.

See also
........

<http://www.jcea.es/programacion/pybsddb.htm>
     The website with documentation for the `bsddb.db' Python Berkeley
     DB interface that closely mirrors the object oriented interface
     provided in Berkeley DB 4.x itself.

<http://www.oracle.com/database/berkeley-db/>
     The Berkeley DB library.

A more modern DB, DBEnv and DBSequence object interface is available in
the `bsddb.db' module which closely matches the Berkeley DB C API
documented at the above URLs.  Additional features provided by the
`bsddb.db' API include fine tuning, transactions, logging, and
multiprocess concurrent database access.

The following is a description of the legacy *Note bsddb: 1c. interface
compatible with the old Python bsddb module.  Starting in Python 2.5
this interface should be safe for multithreaded access.  The `bsddb.db'
API is recommended for threading users as it provides better control.

The *Note bsddb: 1c. module defines the following functions that create
objects that access the appropriate type of Berkeley DB file.  The
first two arguments of each function are the same.  For ease of
portability, only the first two arguments should be used in most
instances.

 -- Function: bsddb.hashopen (filename[, flag[, mode[, pgsize[,
          ffactor[, nelem[, cachesize[, lorder[, hflags]]]]]]]])
     Open the hash format file named `filename'.  Files never intended
     to be preserved on disk may be created by passing `None' as the
     `filename'.  The optional `flag' identifies the mode used to open
     the file.  It may be `'r'' (read only), `'w'' (read-write), `'c''
     (read-write - create if necessary; the default) or `'n''
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level `dbopen()'
     function.  Consult the Berkeley DB documentation for their use and
     interpretation.

 -- Function: bsddb.btopen (filename[, flag[, mode[, btflags[,
          cachesize[, maxkeypage[, minkeypage[, pgsize[, lorder]]]]]]]])
     Open the btree format file named `filename'.  Files never intended
     to be preserved on disk may be created by passing `None' as the
     `filename'.  The optional `flag' identifies the mode used to open
     the file.  It may be `'r'' (read only), `'w'' (read-write), `'c''
     (read-write - create if necessary; the default) or `'n''
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level dbopen function.
     Consult the Berkeley DB documentation for their use and
     interpretation.

 -- Function: bsddb.rnopen (filename[, flag[, mode[, rnflags[,
          cachesize[, pgsize[, lorder[, rlen[, delim[, source[,
          pad]]]]]]]]]])
     Open a DB record format file named `filename'.  Files never
     intended  to be preserved on disk may be created by passing `None'
     as the  `filename'.  The optional `flag' identifies the mode used
     to open the file.  It may be `'r'' (read only), `'w''
     (read-write), `'c'' (read-write - create if necessary; the
     default) or `'n'' (read-write - truncate to zero length).  The
     other arguments are rarely used and are just passed to the
     low-level dbopen function.  Consult the Berkeley DB documentation
     for their use and interpretation.

     Note: Beginning in 2.3 some Unix versions of Python may have a
     `bsddb185' module.  This is present `only' to allow backwards
     compatibility with systems which ship with the old Berkeley DB
     1.85 database library.  The `bsddb185' module should never be used
     directly in new code. The module has been removed in Python 3.  If
     you find you still need it look in PyPI.

See also
........

Module *Note dbhash: 7e.
     DBM-style interface to the *Note bsddb: 1c.

* Menu:

* Hash, BTree and Record Objects: Hash BTree and Record Objects.


File: python.info,  Node: Hash BTree and Record Objects,  Up: bsddb — Interface to Berkeley DB library

5.11.11.1 Hash, BTree and Record Objects
........................................

Once instantiated, hash, btree and record objects support the same
methods as dictionaries.  In addition, they support the methods listed
below.

Changed in version 2.3.1: Added dictionary methods.

 -- Method: bsddbobject.close ()
     Close the underlying file.  The object can no longer be accessed.
     Since there is no open *Note open(): 2d9. method for these
     objects, to open the file again a new *Note bsddb: 1c. module open
     function must be called.

 -- Method: bsddbobject.keys ()
     Return the list of keys contained in the DB file.  The order of
     the list is unspecified and should not be relied on.  In
     particular, the order of the list returned is different for
     different file formats.

 -- Method: bsddbobject.has_key (key)
     Return `1' if the DB file contains the argument as a key.

 -- Method: bsddbobject.set_location (key)
     Set the cursor to the item indicated by `key' and return a tuple
     containing the key and its value.  For binary tree databases
     (opened using *Note btopen(): f1b.), if `key' does not actually
     exist in the database, the cursor will point to the next item in
     sorted order and return that key and value.  For other databases,
     *Note KeyError: 205. will be raised if `key' is not found in the
     database.

 -- Method: bsddbobject.first ()
     Set the cursor to the first item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case
     of B-Tree databases. This method raises `bsddb.error' if the
     database is empty.

 -- Method: bsddbobject.next ()
     Set the cursor to the next item in the DB file and return it.  The
     order of keys in the file is unspecified, except in the case of
     B-Tree databases.

 -- Method: bsddbobject.previous ()
     Set the cursor to the previous item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case
     of B-Tree databases.  This is not supported on hashtable databases
     (those opened with *Note hashopen(): f1a.).

 -- Method: bsddbobject.last ()
     Set the cursor to the last item in the DB file and return it.  The
     order of keys in the file is unspecified.  This is not supported
     on hashtable databases (those opened with *Note hashopen(): f1a.).
     This method raises `bsddb.error' if the database is empty.

 -- Method: bsddbobject.sync ()
     Synchronize the database on disk.

Example:

    >>> import bsddb
    >>> db = bsddb.btopen('spam.db', 'c')
    >>> for i in range(10): db['%d'%i] = '%d'% (i*i)
    ...
    >>> db['3']
    '9'
    >>> db.keys()
    ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
    >>> db.first()
    ('0', '0')
    >>> db.next()
    ('1', '1')
    >>> db.last()
    ('9', '81')
    >>> db.set_location('2')
    ('2', '4')
    >>> db.previous()
    ('1', '1')
    >>> for k, v in db.iteritems():
    ...     print k, v
    0 0
    1 1
    2 4
    3 9
    4 16
    5 25
    6 36
    7 49
    8 64
    9 81
    >>> '8' in db
    True
    >>> db.sync()
    0


File: python.info,  Node: dumbdbm — Portable DBM implementation,  Next: sqlite3 — DB-API 2 0 interface for SQLite databases,  Prev: bsddb — Interface to Berkeley DB library,  Up: Data Persistence

5.11.12 `dumbdbm' — Portable DBM implementation
-------------------------------------------------

     Note: The *Note dumbdbm: b7. module has been renamed to `dbm.dumb'
     in Python 3.  The *Note 2to3: c05. tool will automatically adapt
     imports when converting your sources to Python 3.

     Note: The *Note dumbdbm: b7. module is intended as a last resort
     fallback for the *Note anydbm: b. module when no more robust
     module is available. The *Note dumbdbm: b7.  module is not written
     for speed and is not nearly as heavily used as the other database
     modules.

The *Note dumbdbm: b7. module provides a persistent dictionary-like
interface which is written entirely in Python.  Unlike other modules
such as *Note gdbm: dd. and *Note bsddb: 1c, no external library is
required.  As with other persistent mappings, the keys and values must
always be strings.

The module defines the following:

 -- Exception: dumbdbm.error
     Raised on dumbdbm-specific errors, such as I/O errors.  *Note
     KeyError: 205. is raised for general mapping errors like
     specifying an incorrect key.

 -- Function: dumbdbm.open (filename[, flag[, mode]])
     Open a dumbdbm database and return a dumbdbm object.  The
     `filename' argument is the basename of the database file (without
     any specific extensions).  When a dumbdbm database is created,
     files with `.dat' and `.dir' extensions are created.

     The optional `flag' argument is currently ignored; the database is
     always opened for update, and will be created if it does not exist.

     The optional `mode' argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666' (and will be modified by the prevailing umask).

     Changed in version 2.2: The `mode' argument was ignored in earlier
     versions.


In addition to the dictionary-like methods, `dumbdm' objects provide
the following method:

 -- Function: dumbdbm.close ()
     Close the `dumbdm' database.

See also
........

Module *Note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *Note dbm: 7f.
     Similar interface to the DBM/NDBM library.

Module *Note gdbm: dd.
     Similar interface to the GNU GDBM library.

Module *Note shelve: 152.
     Persistence module which stores non-string data.

Module *Note whichdb: 197.
     Utility module used to determine the type of an existing database.

* Menu:

* Dumbdbm Objects::


File: python.info,  Node: Dumbdbm Objects,  Up: dumbdbm — Portable DBM implementation

5.11.12.1 Dumbdbm Objects
.........................

In addition to the methods provided by the *Note UserDict.DictMixin:
c2a. class, `dumbdbm' objects provide the following methods.

 -- Method: dumbdbm.sync ()
     Synchronize the on-disk directory and data files.  This method is
     called by the *Note sync(): f5b. method of `Shelve' objects.


File: python.info,  Node: sqlite3 — DB-API 2 0 interface for SQLite databases,  Prev: dumbdbm — Portable DBM implementation,  Up: Data Persistence

5.11.13 `sqlite3' — DB-API 2.0 interface for SQLite databases
---------------------------------------------------------------

New in version 2.5.

SQLite is a C library that provides a lightweight disk-based database
that doesn’t require a separate server process and allows accessing
the database using a nonstandard variant of the SQL query language.
Some applications can use SQLite for internal data storage.  It’s
also possible to prototype an application using SQLite and then port
the code to a larger database such as PostgreSQL or Oracle.

The sqlite3 module was written by Gerhard Häring.  It provides a SQL
interface compliant with the DB-API 2.0 specification described by PEP
249(1).

To use the module, you must first create a *Note Connection: f5e.
object that represents the database.  Here the data will be stored in
the `example.db' file:

    import sqlite3
    conn = sqlite3.connect('example.db')

You can also supply the special name `:memory:' to create a database in
RAM.

Once you have a *Note Connection: f5e, you can create a *Note Cursor:
f5f.  object and call its *Note execute(): f60. method to perform SQL
commands:

    c = conn.cursor()

    # Create table
    c.execute('''CREATE TABLE stocks
                 (date text, trans text, symbol text, qty real, price real)''')

    # Insert a row of data
    c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")

    # Save (commit) the changes
    conn.commit()

    # We can also close the connection if we are done with it.
    # Just be sure any changes have been committed or they will be lost.
    conn.close()

The data you’ve saved is persistent and is available in subsequent
sessions:

    import sqlite3
    conn = sqlite3.connect('example.db')
    c = conn.cursor()

Usually your SQL operations will need to use values from Python
variables.  You shouldn’t assemble your query using Python’s string
operations because doing so is insecure; it makes your program
vulnerable to an SQL injection attack (see <https://xkcd.com/327/> for
humorous example of what can go wrong).

Instead, use the DB-API’s parameter substitution.  Put `?' as a
placeholder wherever you want to use a value, and then provide a tuple
of values as the second argument to the cursor’s *Note execute():
f60. method.  (Other database modules may use a different placeholder,
such as `%s' or `:1'.) For example:

    # Never do this -- insecure!
    symbol = 'RHAT'
    c.execute("SELECT * FROM stocks WHERE symbol = '%s'" % symbol)

    # Do this instead
    t = ('RHAT',)
    c.execute('SELECT * FROM stocks WHERE symbol=?', t)
    print c.fetchone()

    # Larger example that inserts many records at a time
    purchases = [('2006-03-28', 'BUY', 'IBM', 1000, 45.00),
                 ('2006-04-05', 'BUY', 'MSFT', 1000, 72.00),
                 ('2006-04-06', 'SELL', 'IBM', 500, 53.00),
                ]
    c.executemany('INSERT INTO stocks VALUES (?,?,?,?,?)', purchases)

To retrieve data after executing a SELECT statement, you can either
treat the cursor as an *Note iterator: 8a8, call the cursor’s *Note
fetchone(): f61. method to retrieve a single matching row, or call
*Note fetchall(): f62. to get a list of the matching rows.

This example uses the iterator form:

    >>> for row in c.execute('SELECT * FROM stocks ORDER BY price'):
            print row

    (u'2006-01-05', u'BUY', u'RHAT', 100, 35.14)
    (u'2006-03-28', u'BUY', u'IBM', 1000, 45.0)
    (u'2006-04-06', u'SELL', u'IBM', 500, 53.0)
    (u'2006-04-05', u'BUY', u'MSFT', 1000, 72.0)

See also
........

<https://github.com/ghaering/pysqlite>
     The pysqlite web page – sqlite3 is developed externally under
     the name “pysqlite”.

<https://www.sqlite.org>
     The SQLite web page; the documentation describes the syntax and the
     available data types for the supported SQL dialect.

<http://www.w3schools.com/sql/>
     Tutorial, reference and examples for learning SQL syntax.

PEP 249(2) - Database API Specification 2.0
     PEP written by Marc-André Lemburg.

* Menu:

* Module functions and constants::
* Connection Objects::
* Cursor Objects::
* Row Objects::
* SQLite and Python types::
* Controlling Transactions::
* Using sqlite3 efficiently::
* Common issues::

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-0249

(2) https://www.python.org/dev/peps/pep-0249


File: python.info,  Node: Module functions and constants,  Next: Connection Objects,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.1 Module functions and constants
........................................

 -- Data: sqlite3.version
     The version number of this module, as a string. This is not the
     version of the SQLite library.

 -- Data: sqlite3.version_info
     The version number of this module, as a tuple of integers. This is
     not the version of the SQLite library.

 -- Data: sqlite3.sqlite_version
     The version number of the run-time SQLite library, as a string.

 -- Data: sqlite3.sqlite_version_info
     The version number of the run-time SQLite library, as a tuple of
     integers.

 -- Data: sqlite3.PARSE_DECLTYPES
     This constant is meant to be used with the `detect_types'
     parameter of the *Note connect(): f6a. function.

     Setting it makes the *Note sqlite3: 15f. module parse the declared
     type for each column it returns.  It will parse out the first word
     of the declared type, i. e.  for “integer primary key”, it
     will parse out “integer”, or for “number(10)” it will
     parse out “number”. Then for that column, it will look into
     the converters dictionary and use the converter function
     registered for that type there.

 -- Data: sqlite3.PARSE_COLNAMES
     This constant is meant to be used with the `detect_types'
     parameter of the *Note connect(): f6a. function.

     Setting this makes the SQLite interface parse the column name for
     each column it returns.  It will look for a string formed [mytype]
     in there, and then decide that ‘mytype’ is the type of the
     column. It will try to find an entry of ‘mytype’ in the
     converters dictionary and then use the converter function found
     there to return the value. The column name found in *Note
     Cursor.description: f6c.  is only the first word of the column
     name, i.  e. if you use something like `'as "x [datetime]"'' in
     your SQL, then we will parse out everything until the first blank
     for the column name: the column name would simply be “x”.

 -- Function: sqlite3.connect (database[, timeout, detect_types,
          isolation_level, check_same_thread, factory,
          cached_statements])
     Opens a connection to the SQLite database file `database'. You can
     use `":memory:"' to open a database connection to a database that
     resides in RAM instead of on disk.

     When a database is accessed by multiple connections, and one of
     the processes modifies the database, the SQLite database is locked
     until that transaction is committed. The `timeout' parameter
     specifies how long the connection should wait for the lock to go
     away until raising an exception. The default for the timeout
     parameter is 5.0 (five seconds).

     For the `isolation_level' parameter, please see the *Note
     Connection.isolation_level: f6d. property of *Note Connection:
     f5e. objects.

     SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB
     and NULL. If you want to use other types you must add support for
     them yourself. The `detect_types' parameter and the using custom
     `converters' registered with the module-level *Note
     register_converter(): f6e. function allow you to easily do that.

     `detect_types' defaults to 0 (i. e. off, no type detection), you
     can set it to any combination of *Note PARSE_DECLTYPES: f69. and
     *Note PARSE_COLNAMES: f6b. to turn type detection on.

     By default, the *Note sqlite3: 15f. module uses its *Note
     Connection: f5e. class for the connect call.  You can, however,
     subclass the *Note Connection: f5e. class and make *Note
     connect(): f6a. use your class instead by providing your class for
     the `factory' parameter.

     Consult the section *Note SQLite and Python types: f6f. of this
     manual for details.

     The *Note sqlite3: 15f. module internally uses a statement cache
     to avoid SQL parsing overhead. If you want to explicitly set the
     number of statements that are cached for the connection, you can
     set the `cached_statements' parameter. The currently implemented
     default is to cache 100 statements.

 -- Function: sqlite3.register_converter (typename, callable)
     Registers a callable to convert a bytestring from the database
     into a custom Python type. The callable will be invoked for all
     database values that are of the type `typename'. Confer the
     parameter `detect_types' of the *Note connect(): f6a.  function
     for how the type detection works. Note that the case of `typename'
     and the name of the type in your query must match!

 -- Function: sqlite3.register_adapter (type, callable)
     Registers a callable to convert the custom Python type `type' into
     one of SQLite’s supported types. The callable `callable' accepts
     as single parameter the Python value, and must return a value of
     the following types: int, long, float, str (UTF-8 encoded),
     unicode or buffer.

 -- Function: sqlite3.complete_statement (sql)
     Returns *Note True: 3c8. if the string `sql' contains one or more
     complete SQL statements terminated by semicolons. It does not
     verify that the SQL is syntactically correct, only that there are
     no unclosed string literals and the statement is terminated by a
     semicolon.

     This can be used to build a shell for SQLite, as in the following
     example:

         # A minimal SQLite shell for experiments

         import sqlite3

         con = sqlite3.connect(":memory:")
         con.isolation_level = None
         cur = con.cursor()

         buffer = ""

         print "Enter your SQL commands to execute in sqlite3."
         print "Enter a blank line to exit."

         while True:
             line = raw_input()
             if line == "":
                 break
             buffer += line
             if sqlite3.complete_statement(buffer):
                 try:
                     buffer = buffer.strip()
                     cur.execute(buffer)

                     if buffer.lstrip().upper().startswith("SELECT"):
                         print cur.fetchall()
                 except sqlite3.Error as e:
                     print "An error occurred:", e.args[0]
                 buffer = ""

         con.close()

 -- Function: sqlite3.enable_callback_tracebacks (flag)
     By default you will not get any tracebacks in user-defined
     functions, aggregates, converters, authorizer callbacks etc. If
     you want to debug them, you can call this function with `flag' set
     to `True'. Afterwards, you will get tracebacks from callbacks on
     `sys.stderr'. Use *Note False: 3c9. to disable the feature again.


File: python.info,  Node: Connection Objects,  Next: Cursor Objects,  Prev: Module functions and constants,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.2 Connection Objects
............................

 -- Class: sqlite3.Connection
     A SQLite database connection has the following attributes and
     methods:

      -- Attribute: isolation_level
          Get or set the current isolation level. *Note None: 3b2. for
          autocommit mode or one of “DEFERRED”, “IMMEDIATE” or
          “EXCLUSIVE”. See section *Note Controlling Transactions:
          f75. for a more detailed explanation.

      -- Method: cursor (factory=Cursor)
          The cursor method accepts a single optional parameter
          `factory'. If supplied, this must be a callable returning an
          instance of *Note Cursor: f5f.  or its subclasses.

      -- Method: commit ()
          This method commits the current transaction. If you don’t
          call this method, anything you did since the last call to
          `commit()' is not visible from other database connections. If
          you wonder why you don’t see the data you’ve written to
          the database, please check you didn’t forget to call this
          method.

      -- Method: rollback ()
          This method rolls back any changes to the database since the
          last call to *Note commit(): f77.

      -- Method: close ()
          This closes the database connection. Note that this does not
          automatically call *Note commit(): f77. If you just close
          your database connection without calling *Note commit(): f77.
          first, your changes will be lost!

      -- Method: execute (sql[, parameters])
          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor’s *Note execute: f60. method with the parameters
          given.

      -- Method: executemany (sql[, parameters])
          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor’s *Note executemany: f7c. method with the parameters
          given.

      -- Method: executescript (sql_script)
          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor’s *Note executescript: f7e. method with the
          parameters given.

      -- Method: create_function (name, num_params, func)
          Creates a user-defined function that you can later use from
          within SQL statements under the function name `name'.
          `num_params' is the number of parameters the function
          accepts, and `func' is a Python callable that is called as
          the SQL function.

          The function can return any of the types supported by SQLite:
          unicode, str, int, long, float, buffer and `None'.

          Example:

              import sqlite3
              import md5

              def md5sum(t):
                  return md5.md5(t).hexdigest()

              con = sqlite3.connect(":memory:")
              con.create_function("md5", 1, md5sum)
              cur = con.cursor()
              cur.execute("select md5(?)", ("foo",))
              print cur.fetchone()[0]

      -- Method: create_aggregate (name, num_params, aggregate_class)
          Creates a user-defined aggregate function.

          The aggregate class must implement a `step' method, which
          accepts the number of parameters `num_params', and a
          `finalize' method which will return the final result of the
          aggregate.

          The `finalize' method can return any of the types supported
          by SQLite: unicode, str, int, long, float, buffer and `None'.

          Example:

              import sqlite3

              class MySum:
                  def __init__(self):
                      self.count = 0

                  def step(self, value):
                      self.count += value

                  def finalize(self):
                      return self.count

              con = sqlite3.connect(":memory:")
              con.create_aggregate("mysum", 1, MySum)
              cur = con.cursor()
              cur.execute("create table test(i)")
              cur.execute("insert into test(i) values (1)")
              cur.execute("insert into test(i) values (2)")
              cur.execute("select mysum(i) from test")
              print cur.fetchone()[0]

      -- Method: create_collation (name, callable)
          Creates a collation with the specified `name' and `callable'.
          The callable will be passed two string arguments. It should
          return -1 if the first is ordered lower than the second, 0 if
          they are ordered equal and 1 if the first is ordered higher
          than the second.  Note that this controls sorting (ORDER BY
          in SQL) so your comparisons don’t affect other SQL
          operations.

          Note that the callable will get its parameters as Python
          bytestrings, which will normally be encoded in UTF-8.

          The following example shows a custom collation that sorts
          “the wrong way”:

              import sqlite3

              def collate_reverse(string1, string2):
                  return -cmp(string1, string2)

              con = sqlite3.connect(":memory:")
              con.create_collation("reverse", collate_reverse)

              cur = con.cursor()
              cur.execute("create table test(x)")
              cur.executemany("insert into test(x) values (?)", [("a",), ("b",)])
              cur.execute("select x from test order by x collate reverse")
              for row in cur:
                  print row
              con.close()

          To remove a collation, call `create_collation' with `None' as
          callable:

              con.create_collation("reverse", None)

      -- Method: interrupt ()
          You can call this method from a different thread to abort any
          queries that might be executing on the connection. The query
          will then abort and the caller will get an exception.

      -- Method: set_authorizer (authorizer_callback)
          This routine registers a callback. The callback is invoked
          for each attempt to access a column of a table in the
          database. The callback should return `SQLITE_OK' if access is
          allowed, `SQLITE_DENY' if the entire SQL statement should be
          aborted with an error and `SQLITE_IGNORE' if the column
          should be treated as a NULL value. These constants are
          available in the *Note sqlite3: 15f. module.

          The first argument to the callback signifies what kind of
          operation is to be authorized. The second and third argument
          will be arguments or *Note None: 3b2.  depending on the first
          argument. The 4th argument is the name of the database
          (“main”, “temp”, etc.) if applicable. The 5th
          argument is the name of the inner-most trigger or view that
          is responsible for the access attempt or *Note None: 3b2. if
          this access attempt is directly from input SQL code.

          Please consult the SQLite documentation about the possible
          values for the first argument and the meaning of the second
          and third argument depending on the first one. All necessary
          constants are available in the *Note sqlite3: 15f. module.

      -- Method: set_progress_handler (handler, n)
          This routine registers a callback. The callback is invoked
          for every `n' instructions of the SQLite virtual machine.
          This is useful if you want to get called from SQLite during
          long-running operations, for example to update a GUI.

          If you want to clear any previously installed progress
          handler, call the method with *Note None: 3b2. for `handler'.

          New in version 2.6.


      -- Method: enable_load_extension (enabled)
          This routine allows/disallows the SQLite engine to load
          SQLite extensions from shared libraries.  SQLite extensions
          can define new functions, aggregates or whole new virtual
          table implementations.  One well-known extension is the
          fulltext-search extension distributed with SQLite.

          Loadable extensions are disabled by default. See (1).

          New in version 2.7.

              import sqlite3

              con = sqlite3.connect(":memory:")

              # enable extension loading
              con.enable_load_extension(True)

              # Load the fulltext search extension
              con.execute("select load_extension('./fts3.so')")

              # alternatively you can load the extension using an API call:
              # con.load_extension("./fts3.so")

              # disable extension laoding again
              con.enable_load_extension(False)

              # example from SQLite wiki
              con.execute("create virtual table recipe using fts3(name, ingredients)")
              con.executescript("""
                  insert into recipe (name, ingredients) values ('broccoli stew', 'broccoli peppers cheese tomatoes');
                  insert into recipe (name, ingredients) values ('pumpkin stew', 'pumpkin onions garlic celery');
                  insert into recipe (name, ingredients) values ('broccoli pie', 'broccoli cheese onions flour');
                  insert into recipe (name, ingredients) values ('pumpkin pie', 'pumpkin sugar flour butter');
                  """)
              for row in con.execute("select rowid, name, ingredients from recipe where name match 'pie'"):
                  print row

      -- Method: load_extension (path)
          This routine loads a SQLite extension from a shared library.
          You have to enable extension loading with *Note
          enable_load_extension(): f85. before you can use this routine.

          Loadable extensions are disabled by default. See (2).

          New in version 2.7.


      -- Attribute: row_factory
          You can change this attribute to a callable that accepts the
          cursor and the original row as a tuple and will return the
          real result row.  This way, you can implement more advanced
          ways of returning results, such  as returning an object that
          can also access columns by name.

          Example:

              import sqlite3

              def dict_factory(cursor, row):
                  d = {}
                  for idx, col in enumerate(cursor.description):
                      d[col[0]] = row[idx]
                  return d

              con = sqlite3.connect(":memory:")
              con.row_factory = dict_factory
              cur = con.cursor()
              cur.execute("select 1 as a")
              print cur.fetchone()["a"]

          If returning a tuple doesn’t suffice and you want
          name-based access to columns, you should consider setting
          *Note row_factory: f86. to the highly-optimized *Note
          sqlite3.Row: f87. type. *Note Row: f87. provides both
          index-based and case-insensitive name-based access to columns
          with almost no memory overhead. It will probably be better
          than your own custom dictionary-based approach or even a
          db_row based solution.


      -- Attribute: text_factory
          Using this attribute you can control what objects are
          returned for the `TEXT' data type. By default, this attribute
          is set to *Note unicode: 1f5. and the *Note sqlite3: 15f.
          module will return Unicode objects for `TEXT'. If you want to
          return bytestrings instead, you can set it to *Note str: 1ea.

          For efficiency reasons, there’s also a way to return
          Unicode objects only for non-ASCII data, and bytestrings
          otherwise. To activate it, set this attribute to
          `sqlite3.OptimizedUnicode'.

          You can also set it to any other callable that accepts a
          single bytestring parameter and returns the resulting object.

          See the following example code for illustration:

              import sqlite3

              con = sqlite3.connect(":memory:")
              cur = con.cursor()

              AUSTRIA = u"\xd6sterreich"

              # by default, rows are returned as Unicode
              cur.execute("select ?", (AUSTRIA,))
              row = cur.fetchone()
              assert row[0] == AUSTRIA

              # but we can make sqlite3 always return bytestrings ...
              con.text_factory = str
              cur.execute("select ?", (AUSTRIA,))
              row = cur.fetchone()
              assert type(row[0]) is str
              # the bytestrings will be encoded in UTF-8, unless you stored garbage in the
              # database ...
              assert row[0] == AUSTRIA.encode("utf-8")

              # we can also implement a custom text_factory ...
              # here we implement one that will ignore Unicode characters that cannot be
              # decoded from UTF-8
              con.text_factory = lambda x: unicode(x, "utf-8", "ignore")
              cur.execute("select ?", ("this is latin1 and would normally create errors" +
                                       u"\xe4\xf6\xfc".encode("latin1"),))
              row = cur.fetchone()
              assert type(row[0]) is unicode

              # sqlite3 offers a built-in optimized text_factory that will return bytestring
              # objects, if the data is in ASCII only, and otherwise return unicode objects
              con.text_factory = sqlite3.OptimizedUnicode
              cur.execute("select ?", (AUSTRIA,))
              row = cur.fetchone()
              assert type(row[0]) is unicode

              cur.execute("select ?", ("Germany",))
              row = cur.fetchone()
              assert type(row[0]) is str

      -- Attribute: total_changes
          Returns the total number of database rows that have been
          modified, inserted, or deleted since the database connection
          was opened.

      -- Attribute: iterdump
          Returns an iterator to dump the database in an SQL text
          format.  Useful when saving an in-memory database for later
          restoration.  This function provides the same capabilities as
          the `.dump' command in the `sqlite3' shell.

          New in version 2.6.

          Example:

              # Convert file existing_db.db to SQL dump file dump.sql
              import sqlite3, os

              con = sqlite3.connect('existing_db.db')
              with open('dump.sql', 'w') as f:
                  for line in con.iterdump():
                      f.write('%s\n' % line)

---------- Footnotes ----------

(1) The sqlite3 module is not built with loadable extension support by
default, because some platforms (notably Mac OS X) have SQLite libraries
which are compiled without this feature. To get loadable extension
support, you must modify setup.py and remove the line that sets
SQLITE_OMIT_LOAD_EXTENSION.

(2) The sqlite3 module is not built with loadable extension support by
default, because some platforms (notably Mac OS X) have SQLite libraries
which are compiled without this feature. To get loadable extension
support, you must modify setup.py and remove the line that sets
SQLITE_OMIT_LOAD_EXTENSION.


File: python.info,  Node: Cursor Objects,  Next: Row Objects,  Prev: Connection Objects,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.3 Cursor Objects
........................

 -- Class: sqlite3.Cursor
     A *Note Cursor: f5f. instance has the following attributes and
     methods.

      -- Method: execute (sql[, parameters])
          Executes an SQL statement. The SQL statement may be
          parameterized (i. e.  placeholders instead of SQL literals).
          The *Note sqlite3: 15f. module supports two kinds of
          placeholders: question marks (qmark style) and named
          placeholders (named style).

          Here’s an example of both styles:

              import sqlite3

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.execute("create table people (name_last, age)")

              who = "Yeltsin"
              age = 72

              # This is the qmark style:
              cur.execute("insert into people values (?, ?)", (who, age))

              # And this is the named style:
              cur.execute("select * from people where name_last=:who and age=:age", {"who": who, "age": age})

              print cur.fetchone()

          *Note execute(): f60. will only execute a single SQL
          statement. If you try to execute more than one statement with
          it, it will raise a Warning. Use *Note executescript(): f7e.
          if you want to execute multiple SQL statements with one call.

      -- Method: executemany (sql, seq_of_parameters)
          Executes an SQL command against all parameter sequences or
          mappings found in the sequence `sql'.  The *Note sqlite3:
          15f. module also allows using an *Note iterator: 8a8.
          yielding parameters instead of a sequence.

              import sqlite3

              class IterChars:
                  def __init__(self):
                      self.count = ord('a')

                  def __iter__(self):
                      return self

                  def next(self):
                      if self.count > ord('z'):
                          raise StopIteration
                      self.count += 1
                      return (chr(self.count - 1),) # this is a 1-tuple

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.execute("create table characters(c)")

              theIter = IterChars()
              cur.executemany("insert into characters(c) values (?)", theIter)

              cur.execute("select c from characters")
              print cur.fetchall()

          Here’s a shorter example using a *Note generator: 5f7.:

              import sqlite3
              import string

              def char_generator():
                  for c in string.lowercase:
                      yield (c,)

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.execute("create table characters(c)")

              cur.executemany("insert into characters(c) values (?)", char_generator())

              cur.execute("select c from characters")
              print cur.fetchall()

      -- Method: executescript (sql_script)
          This is a nonstandard convenience method for executing
          multiple SQL statements at once. It issues a `COMMIT'
          statement first, then executes the SQL script it gets as a
          parameter.

          `sql_script' can be a bytestring or a Unicode string.

          Example:

              import sqlite3

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.executescript("""
                  create table person(
                      firstname,
                      lastname,
                      age
                  );

                  create table book(
                      title,
                      author,
                      published
                  );

                  insert into book(title, author, published)
                  values (
                      'Dirk Gently''s Holistic Detective Agency',
                      'Douglas Adams',
                      1987
                  );
                  """)

      -- Method: fetchone ()
          Fetches the next row of a query result set, returning a
          single sequence, or *Note None: 3b2. when no more data is
          available.

      -- Method: fetchmany ([size=cursor.arraysize])
          Fetches the next set of rows of a query result, returning a
          list.  An empty list is returned when no more rows are
          available.

          The number of rows to fetch per call is specified by the
          `size' parameter.  If it is not given, the cursor’s
          arraysize determines the number of rows to be fetched. The
          method should try to fetch as many rows as indicated by the
          size parameter. If this is not possible due to the specified
          number of rows not being available, fewer rows may be
          returned.

          Note there are performance considerations involved with the
          `size' parameter.  For optimal performance, it is usually
          best to use the arraysize attribute.  If the `size' parameter
          is used, then it is best for it to retain the same value from
          one *Note fetchmany(): f8d. call to the next.

      -- Method: fetchall ()
          Fetches all (remaining) rows of a query result, returning a
          list.  Note that the cursor’s arraysize attribute can
          affect the performance of this operation.  An empty list is
          returned when no rows are available.

      -- Attribute: rowcount
          Although the *Note Cursor: f5f. class of the *Note sqlite3:
          15f. module implements this attribute, the database
          engine’s own support for the determination of “rows
          affected”/”rows selected” is quirky.

          For *Note executemany(): f7c. statements, the number of
          modifications are summed up into *Note rowcount: f8e.

          As required by the Python DB API Spec, the *Note rowcount:
          f8e. attribute “is -1 in case no `executeXX()' has been
          performed on the cursor or the rowcount of the last operation
          is not determinable by the interface”. This includes
          `SELECT' statements because we cannot determine the number of
          rows a query produced until all rows were fetched.

          With SQLite versions before 3.6.5, *Note rowcount: f8e. is
          set to 0 if you make a `DELETE FROM table' without any
          condition.

      -- Attribute: lastrowid
          This read-only attribute provides the rowid of the last
          modified row. It is only set if you issued an `INSERT'
          statement using the *Note execute(): f60.  method. For
          operations other than `INSERT' or when *Note executemany():
          f7c. is called, *Note lastrowid: f8f. is set to *Note None:
          3b2.

      -- Attribute: description
          This read-only attribute provides the column names of the
          last query. To remain compatible with the Python DB API, it
          returns a 7-tuple for each column where the last six items of
          each tuple are *Note None: 3b2.

          It is set for `SELECT' statements without any matching rows
          as well.

      -- Attribute: connection
          This read-only attribute provides the SQLite database *Note
          Connection: f5e.  used by the *Note Cursor: f5f. object.  A
          *Note Cursor: f5f. object created by calling *Note
          con.cursor(): f76. will have a *Note connection: f90.
          attribute that refers to `con':

              >>> con = sqlite3.connect(":memory:")
              >>> cur = con.cursor()
              >>> cur.connection == con
              True


File: python.info,  Node: Row Objects,  Next: SQLite and Python types,  Prev: Cursor Objects,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.4 Row Objects
.....................

 -- Class: sqlite3.Row
     A *Note Row: f87. instance serves as a highly optimized *Note
     row_factory: f86. for *Note Connection: f5e. objects.  It tries to
     mimic a tuple in most of its features.

     It supports mapping access by column name and index, iteration,
     representation, equality testing and *Note len(): 53c.

     If two *Note Row: f87. objects have exactly the same columns and
     their members are equal, they compare equal.

     Changed in version 2.6: Added iteration and equality (hashability).

      -- Method: keys ()
          This method returns a list of column names. Immediately after
          a query, it is the first member of each tuple in *Note
          Cursor.description: f6c.

          New in version 2.6.


Let’s assume we initialize a table as in the example given above:

    conn = sqlite3.connect(":memory:")
    c = conn.cursor()
    c.execute('''create table stocks
    (date text, trans text, symbol text,
     qty real, price real)''')
    c.execute("""insert into stocks
              values ('2006-01-05','BUY','RHAT',100,35.14)""")
    conn.commit()
    c.close()

Now we plug *Note Row: f87. in:

    >>> conn.row_factory = sqlite3.Row
    >>> c = conn.cursor()
    >>> c.execute('select * from stocks')
    <sqlite3.Cursor object at 0x7f4e7dd8fa80>
    >>> r = c.fetchone()
    >>> type(r)
    <type 'sqlite3.Row'>
    >>> r
    (u'2006-01-05', u'BUY', u'RHAT', 100.0, 35.14)
    >>> len(r)
    5
    >>> r[2]
    u'RHAT'
    >>> r.keys()
    ['date', 'trans', 'symbol', 'qty', 'price']
    >>> r['qty']
    100.0
    >>> for member in r:
    ...     print member
    ...
    2006-01-05
    BUY
    RHAT
    100.0
    35.14


File: python.info,  Node: SQLite and Python types,  Next: Controlling Transactions,  Prev: Row Objects,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.5 SQLite and Python types
.................................

* Menu:

* Introduction: Introduction<6>.
* Using adapters to store additional Python types in SQLite databases::
* Converting SQLite values to custom Python types::
* Default adapters and converters::


File: python.info,  Node: Introduction<6>,  Next: Using adapters to store additional Python types in SQLite databases,  Up: SQLite and Python types

5.11.13.6 Introduction
......................

SQLite natively supports the following types: `NULL', `INTEGER',
`REAL', `TEXT', `BLOB'.

The following Python types can thus be sent to SQLite without any
problem:

Python type                       SQLite type
---------------------------------------------------- 
*Note None: 3b2.                  `NULL'
*Note int: 1f2.                   `INTEGER'
*Note long: 1f3.                  `INTEGER'
*Note float: 1eb.                 `REAL'
*Note str: 1ea. (UTF8-encoded)    `TEXT'
*Note unicode: 1f5.               `TEXT'
*Note buffer: 32a.                `BLOB'

This is how SQLite types are converted to Python types by default:

SQLite type       Python type
--------------------------------------------------------------------- 
`NULL'            *Note None: 3b2.
`INTEGER'         *Note int: 1f2. or *Note long: 1f3, depending on
                  size
`REAL'            *Note float: 1eb.
`TEXT'            depends on *Note text_factory: f88, *Note
                  unicode: 1f5. by default
`BLOB'            *Note buffer: 32a.

The type system of the *Note sqlite3: 15f. module is extensible in two
ways: you can store additional Python types in a SQLite database via
object adaptation, and you can let the *Note sqlite3: 15f. module
convert SQLite types to different Python types via converters.


File: python.info,  Node: Using adapters to store additional Python types in SQLite databases,  Next: Converting SQLite values to custom Python types,  Prev: Introduction<6>,  Up: SQLite and Python types

5.11.13.7 Using adapters to store additional Python types in SQLite databases
.............................................................................

As described before, SQLite supports only a limited set of types
natively. To use other Python types with SQLite, you must `adapt' them
to one of the sqlite3 module’s supported types for SQLite: one of
NoneType, int, long, float, str, unicode, buffer.

There are two ways to enable the *Note sqlite3: 15f. module to adapt a
custom Python type to one of the supported ones.

* Menu:

* Letting your object adapt itself::
* Registering an adapter callable::


File: python.info,  Node: Letting your object adapt itself,  Next: Registering an adapter callable,  Up: Using adapters to store additional Python types in SQLite databases

5.11.13.8 Letting your object adapt itself
..........................................

This is a good approach if you write the class yourself. Let’s
suppose you have a class like this:

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

Now you want to store the point in a single SQLite column.  First
you’ll have to choose one of the supported types first to be used for
representing the point.  Let’s just use str and separate the
coordinates using a semicolon. Then you need to give your class a
method `__conform__(self, protocol)' which must return the converted
value. The parameter `protocol' will be `PrepareProtocol'.

    import sqlite3

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

        def __conform__(self, protocol):
            if protocol is sqlite3.PrepareProtocol:
                return "%f;%f" % (self.x, self.y)

    con = sqlite3.connect(":memory:")
    cur = con.cursor()

    p = Point(4.0, -3.2)
    cur.execute("select ?", (p,))
    print cur.fetchone()[0]


File: python.info,  Node: Registering an adapter callable,  Prev: Letting your object adapt itself,  Up: Using adapters to store additional Python types in SQLite databases

5.11.13.9 Registering an adapter callable
.........................................

The other possibility is to create a function that converts the type to
the string representation and register the function with *Note
register_adapter(): f70.

     Note: The type/class to adapt must be a *Note new-style class:
     5ec, i. e. it must have *Note object: 1f1. as one of its bases.

    import sqlite3

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

    def adapt_point(point):
        return "%f;%f" % (point.x, point.y)

    sqlite3.register_adapter(Point, adapt_point)

    con = sqlite3.connect(":memory:")
    cur = con.cursor()

    p = Point(4.0, -3.2)
    cur.execute("select ?", (p,))
    print cur.fetchone()[0]

The *Note sqlite3: 15f. module has two default adapters for Python’s
built-in *Note datetime.date: 374. and *Note datetime.datetime: 2dc.
types.  Now let’s suppose we want to store *Note datetime.datetime:
2dc. objects not in ISO representation, but as a Unix timestamp.

    import sqlite3
    import datetime, time

    def adapt_datetime(ts):
        return time.mktime(ts.timetuple())

    sqlite3.register_adapter(datetime.datetime, adapt_datetime)

    con = sqlite3.connect(":memory:")
    cur = con.cursor()

    now = datetime.datetime.now()
    cur.execute("select ?", (now,))
    print cur.fetchone()[0]


File: python.info,  Node: Converting SQLite values to custom Python types,  Next: Default adapters and converters,  Prev: Using adapters to store additional Python types in SQLite databases,  Up: SQLite and Python types

5.11.13.10 Converting SQLite values to custom Python types
..........................................................

Writing an adapter lets you send custom Python types to SQLite. But to
make it really useful we need to make the Python to SQLite to Python
roundtrip work.

Enter converters.

Let’s go back to the `Point' class. We stored the x and y coordinates
separated via semicolons as strings in SQLite.

First, we’ll define a converter function that accepts the string as a
parameter and constructs a `Point' object from it.

     Note: Converter functions `always' get called with a string, no
     matter under which data type you sent the value to SQLite.

    def convert_point(s):
        x, y = map(float, s.split(";"))
        return Point(x, y)

Now you need to make the *Note sqlite3: 15f. module know that what you
select from the database is actually a point. There are two ways of
doing this:

   * Implicitly via the declared type

   * Explicitly via the column name

Both ways are described in section *Note Module functions and
constants: f64, in the entries for the constants *Note PARSE_DECLTYPES:
f69. and *Note PARSE_COLNAMES: f6b.

The following example illustrates both approaches.

    import sqlite3

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

        def __repr__(self):
            return "(%f;%f)" % (self.x, self.y)

    def adapt_point(point):
        return "%f;%f" % (point.x, point.y)

    def convert_point(s):
        x, y = map(float, s.split(";"))
        return Point(x, y)

    # Register the adapter
    sqlite3.register_adapter(Point, adapt_point)

    # Register the converter
    sqlite3.register_converter("point", convert_point)

    p = Point(4.0, -3.2)

    #########################
    # 1) Using declared types
    con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES)
    cur = con.cursor()
    cur.execute("create table test(p point)")

    cur.execute("insert into test(p) values (?)", (p,))
    cur.execute("select p from test")
    print "with declared types:", cur.fetchone()[0]
    cur.close()
    con.close()

    #######################
    # 1) Using column names
    con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)
    cur = con.cursor()
    cur.execute("create table test(p)")

    cur.execute("insert into test(p) values (?)", (p,))
    cur.execute('select p as "p [point]" from test')
    print "with column names:", cur.fetchone()[0]
    cur.close()
    con.close()


File: python.info,  Node: Default adapters and converters,  Prev: Converting SQLite values to custom Python types,  Up: SQLite and Python types

5.11.13.11 Default adapters and converters
..........................................

There are default adapters for the date and datetime types in the
datetime module. They will be sent as ISO dates/ISO timestamps to
SQLite.

The default converters are registered under the name “date” for
*Note datetime.date: 374. and under the name “timestamp” for *Note
datetime.datetime: 2dc.

This way, you can use date/timestamps from Python without any additional
fiddling in most cases. The format of the adapters is also compatible
with the experimental SQLite date/time functions.

The following example demonstrates this.

    import sqlite3
    import datetime

    con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)
    cur = con.cursor()
    cur.execute("create table test(d date, ts timestamp)")

    today = datetime.date.today()
    now = datetime.datetime.now()

    cur.execute("insert into test(d, ts) values (?, ?)", (today, now))
    cur.execute("select d, ts from test")
    row = cur.fetchone()
    print today, "=>", row[0], type(row[0])
    print now, "=>", row[1], type(row[1])

    cur.execute('select current_date as "d [date]", current_timestamp as "ts [timestamp]"')
    row = cur.fetchone()
    print "current_date", row[0], type(row[0])
    print "current_timestamp", row[1], type(row[1])

If a timestamp stored in SQLite has a fractional part longer than 6
numbers, its value will be truncated to microsecond precision by the
timestamp converter.


File: python.info,  Node: Controlling Transactions,  Next: Using sqlite3 efficiently,  Prev: SQLite and Python types,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.12 Controlling Transactions
...................................

By default, the *Note sqlite3: 15f. module opens transactions
implicitly before a Data Modification Language (DML)  statement (i.e.
`INSERT'/`UPDATE'/`DELETE'/`REPLACE'), and commits transactions
implicitly before a non-DML, non-query statement (i. e.  anything other
than `SELECT' or the aforementioned).

So if you are within a transaction and issue a command like `CREATE
TABLE ...', `VACUUM', `PRAGMA', the *Note sqlite3: 15f. module will
commit implicitly before executing that command. There are two reasons
for doing that. The first is that some of these commands don’t work
within transactions. The other reason is that sqlite3 needs to keep
track of the transaction state (if a transaction is active or not).

You can control which kind of `BEGIN' statements sqlite3 implicitly
executes (or none at all) via the `isolation_level' parameter to the
*Note connect(): f6a.  call, or via the `isolation_level' property of
connections.

If you want `autocommit mode', then set `isolation_level' to `None'.

Otherwise leave it at its default, which will result in a plain
“BEGIN” statement, or set it to one of SQLite’s supported
isolation levels: “DEFERRED”, “IMMEDIATE” or “EXCLUSIVE”.


File: python.info,  Node: Using sqlite3 efficiently,  Next: Common issues,  Prev: Controlling Transactions,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.13 Using `sqlite3' efficiently
......................................

* Menu:

* Using shortcut methods::
* Accessing columns by name instead of by index::
* Using the connection as a context manager::


File: python.info,  Node: Using shortcut methods,  Next: Accessing columns by name instead of by index,  Up: Using sqlite3 efficiently

5.11.13.14 Using shortcut methods
.................................

Using the nonstandard `execute()', `executemany()' and
`executescript()' methods of the *Note Connection: f5e. object, your
code can be written more concisely because you don’t have to create
the (often superfluous) *Note Cursor: f5f. objects explicitly. Instead,
the *Note Cursor: f5f.  objects are created implicitly and these
shortcut methods return the cursor objects. This way, you can execute a
`SELECT' statement and iterate over it directly using only a single
call on the *Note Connection: f5e. object.

    import sqlite3

    persons = [
        ("Hugo", "Boss"),
        ("Calvin", "Klein")
        ]

    con = sqlite3.connect(":memory:")

    # Create the table
    con.execute("create table person(firstname, lastname)")

    # Fill the table
    con.executemany("insert into person(firstname, lastname) values (?, ?)", persons)

    # Print the table contents
    for row in con.execute("select firstname, lastname from person"):
        print row

    print "I just deleted", con.execute("delete from person").rowcount, "rows"


File: python.info,  Node: Accessing columns by name instead of by index,  Next: Using the connection as a context manager,  Prev: Using shortcut methods,  Up: Using sqlite3 efficiently

5.11.13.15 Accessing columns by name instead of by index
........................................................

One useful feature of the *Note sqlite3: 15f. module is the built-in
*Note sqlite3.Row: f87. class designed to be used as a row factory.

Rows wrapped with this class can be accessed both by index (like
tuples) and case-insensitively by name:

    import sqlite3

    con = sqlite3.connect(":memory:")
    con.row_factory = sqlite3.Row

    cur = con.cursor()
    cur.execute("select 'John' as name, 42 as age")
    for row in cur:
        assert row[0] == row["name"]
        assert row["name"] == row["nAmE"]
        assert row[1] == row["age"]
        assert row[1] == row["AgE"]


File: python.info,  Node: Using the connection as a context manager,  Prev: Accessing columns by name instead of by index,  Up: Using sqlite3 efficiently

5.11.13.16 Using the connection as a context manager
....................................................

New in version 2.6.

Connection objects can be used as context managers that automatically
commit or rollback transactions.  In the event of an exception, the
transaction is rolled back; otherwise, the transaction is committed:

    import sqlite3

    con = sqlite3.connect(":memory:")
    con.execute("create table person (id integer primary key, firstname varchar unique)")

    # Successful, con.commit() is called automatically afterwards
    with con:
        con.execute("insert into person(firstname) values (?)", ("Joe",))

    # con.rollback() is called after the with block finishes with an exception, the
    # exception is still raised and must be caught
    try:
        with con:
            con.execute("insert into person(firstname) values (?)", ("Joe",))
    except sqlite3.IntegrityError:
        print "couldn't add Joe twice"


File: python.info,  Node: Common issues,  Prev: Using sqlite3 efficiently,  Up: sqlite3 — DB-API 2 0 interface for SQLite databases

5.11.13.17 Common issues
........................

* Menu:

* Multithreading::


File: python.info,  Node: Multithreading,  Up: Common issues

5.11.13.18 Multithreading
.........................

Older SQLite versions had issues with sharing connections between
threads.  That’s why the Python module disallows sharing connections
and cursors between threads. If you still try to do so, you will get an
exception at runtime.

The only exception is calling the *Note interrupt(): f82. method, which
only makes sense to call from a different thread.


File: python.info,  Node: Data Compression and Archiving,  Next: File Formats,  Prev: Data Persistence,  Up: The Python Standard Library

5.12 Data Compression and Archiving
===================================

The modules described in this chapter support data compression with the
zlib, gzip, and bzip2 algorithms, and  the creation of ZIP- and
tar-format archives.  See also *Note Archiving operations: edb.
provided by the *Note shutil: 154. module.

* Menu:

* zlib — Compression compatible with gzip::
* gzip — Support for gzip files::
* bz2 — Compression compatible with bzip2::
* zipfile — Work with ZIP archives::
* tarfile — Read and write tar archive files::


File: python.info,  Node: zlib — Compression compatible with gzip,  Next: gzip — Support for gzip files,  Up: Data Compression and Archiving

5.12.1 `zlib' — Compression compatible with `gzip'
----------------------------------------------------

For applications that require data compression, the functions in this
module allow compression and decompression, using the zlib library. The
zlib library has its own home page at <http://www.zlib.net>.   There
are known incompatibilities between the Python module and versions of
the zlib library earlier than 1.1.3; 1.1.3 has a security
vulnerability, so we recommend using 1.1.4 or later.

zlib’s functions have many options and often need to be used in a
particular order.  This documentation doesn’t attempt to cover all of
the permutations; consult the zlib manual at
<http://www.zlib.net/manual.html> for authoritative information.

For reading and writing `.gz' files see the *Note gzip: e6. module.

The available exception and functions in this module are:

 -- Exception: zlib.error
     Exception raised on compression and decompression errors.

 -- Function: zlib.adler32 (data[, value])
     Computes an Adler-32 checksum of `data'.  (An Adler-32 checksum is
     almost as reliable as a CRC32 but can be computed much more
     quickly.)  If `value' is present, it is used as the starting value
     of the checksum; otherwise, a fixed default value is used.  This
     allows computing a running checksum over the concatenation of
     several inputs.  The algorithm is not cryptographically strong,
     and should not be used for authentication or digital signatures.
     Since the algorithm is designed for use as a checksum algorithm,
     it is not suitable for use as a general hash algorithm.

     This function always returns an integer object.

     Note: To generate the same numeric value across all Python
     versions and platforms use adler32(data) & 0xffffffff.  If you are
     only using the checksum in packed binary format this is not
     necessary as the return value is the correct 32bit binary
     representation regardless of sign.

Changed in version 2.6: The return value is in the range [-2**31,
2**31-1] regardless of platform.  In older versions the value is signed
on some platforms and unsigned on others.

Changed in version 3.0: The return value is unsigned and in the range
[0, 2**32-1] regardless of platform.

 -- Function: zlib.compress (string[, level])
     Compresses the data in `string', returning a string contained
     compressed data.  `level' is an integer from `0' to `9'
     controlling the level of compression; `1' is fastest and produces
     the least compression, `9' is slowest and produces the most.  `0'
     is no compression.  The default value is `6'.  Raises the *Note
     error: fa7. exception if any error occurs.

 -- Function: zlib.compressobj ([level[, method[, wbits[, memlevel[,
          strategy]]]]])
     Returns a compression object, to be used for compressing data
     streams that won’t fit into memory at once.  `level' is an
     integer from `0' to `9' or `-1', controlling the level of
     compression; `1' is fastest and produces the least compression,
     `9' is slowest and produces the most.  `0' is no compression.  The
     default value is `-1' (Z_DEFAULT_COMPRESSION).
     Z_DEFAULT_COMPRESSION represents a default compromise between
     speed and compression (currently equivalent to level 6).

     `method' is the compression algorithm. Currently, the only
     supported value is `DEFLATED'.

     The `wbits' argument controls the size of the history buffer (or
     the “window size”) used when compressing data, and whether a
     header and trailer is included in the output.  It can take several
     ranges of values.  The default is 15.

        * +9 to +15: The base-two logarithm of the window size, which
          therefore ranges between 512 and 32768.  Larger values produce
          better compression at the expense of greater memory usage.
          The resulting output will include a zlib-specific header and
          trailer.

        * −9 to −15: Uses the absolute value of `wbits' as the
          window size logarithm, while producing a raw output stream
          with no header or trailing checksum.

        * +25 to +31 = 16 + (9 to 15): Uses the low 4 bits of the value
          as the window size logarithm, while including a basic `gzip'
          header and trailing checksum in the output.

     `memlevel' controls the amount of memory used for internal
     compression state.  Valid values range from `1' to `9'. Higher
     values using more memory, but are faster and produce smaller
     output. The default is 8.

     `strategy' is used to tune the compression algorithm. Possible
     values are `Z_DEFAULT_STRATEGY', `Z_FILTERED', and
     `Z_HUFFMAN_ONLY'. The default is `Z_DEFAULT_STRATEGY'.

 -- Function: zlib.crc32 (data[, value])
     Computes a CRC (Cyclic Redundancy Check)  checksum of `data'. If
     `value' is present, it is used as the starting value of the
     checksum; otherwise, a fixed default value is used.  This allows
     computing a running checksum over the concatenation of several
     inputs.  The algorithm is not cryptographically strong, and should
     not be used for authentication or digital signatures.  Since the
     algorithm is designed for use as a checksum algorithm, it is not
     suitable for use as a general hash algorithm.

     This function always returns an integer object.

     Note: To generate the same numeric value across all Python
     versions and platforms use crc32(data) & 0xffffffff.  If you are
     only using the checksum in packed binary format this is not
     necessary as the return value is the correct 32bit binary
     representation regardless of sign.

Changed in version 2.6: The return value is in the range [-2**31,
2**31-1] regardless of platform.  In older versions the value would be
signed on some platforms and unsigned on others.

Changed in version 3.0: The return value is unsigned and in the range
[0, 2**32-1] regardless of platform.

 -- Function: zlib.decompress (string[, wbits[, bufsize]])
     Decompresses the data in `string', returning a string containing
     the uncompressed data.  The `wbits' parameter depends on the
     format of `string', and is discussed further below.  If `bufsize'
     is given, it is used as the initial size of the output buffer.
     Raises the *Note error: fa7. exception if any error occurs.

     The `wbits' parameter controls the size of the history buffer (or
     “window size”), and what header and trailer format is expected.
     It is similar to the parameter for *Note compressobj(): fa9, but
     accepts more ranges of values:

        * +8 to +15: The base-two logarithm of the window size.  The
          input must include a zlib header and trailer.

        * 0: Automatically determine the window size from the zlib
          header.  Only supported since zlib 1.2.3.5.

        * −8 to −15: Uses the absolute value of `wbits' as the
          window size logarithm.  The input must be a raw stream with
          no header or trailer.

        * +24 to +31 = 16 + (8 to 15): Uses the low 4 bits of the value
          as the window size logarithm.  The input must include a gzip
          header and trailer.

        * +40 to +47 = 32 + (8 to 15): Uses the low 4 bits of the value
          as the window size logarithm, and automatically accepts either
          the zlib or gzip format.

     When decompressing a stream, the window size must not be smaller
     than the size originally used to compress the stream; using a
     too-small value may result in an *Note error: fa7. exception. The
     default `wbits' value is 15, which corresponds to the largest
     window size and requires a zlib header and trailer to be included.

     `bufsize' is the initial size of the buffer used to hold
     decompressed data.  If more space is required, the buffer size
     will be increased as needed, so you don’t have to get this value
     exactly right; tuning it will only save a few calls to `malloc()'.
     The default size is 16384.

 -- Function: zlib.decompressobj ([wbits])
     Returns a decompression object, to be used for decompressing data
     streams that won’t fit into memory at once.

     The `wbits' parameter controls the size of the history buffer (or
     the “window size”), and what header and trailer format is
     expected.  It has the same meaning as *Note described for
     decompress(): fab.

Compression objects support the following methods:

 -- Method: Compress.compress (string)
     Compress `string', returning a string containing compressed data
     for at least part of the data in `string'.  This data should be
     concatenated to the output produced by any preceding calls to the
     *Note compress(): ac1. method.  Some input may be kept in internal
     buffers for later processing.

 -- Method: Compress.flush ([mode])
     All pending input is processed, and a string containing the
     remaining compressed output is returned.  `mode' can be selected
     from the constants `Z_SYNC_FLUSH',  `Z_FULL_FLUSH',  or
     `Z_FINISH', defaulting to `Z_FINISH'.  `Z_SYNC_FLUSH' and
     `Z_FULL_FLUSH' allow compressing further strings of data, while
     `Z_FINISH' finishes the compressed stream and  prevents
     compressing any more data.  After calling *Note flush(): fae. with
     `mode' set to `Z_FINISH', the *Note compress(): ac1. method cannot
     be called again; the only realistic action is to delete the object.

 -- Method: Compress.copy ()
     Returns a copy of the compression object.  This can be used to
     efficiently compress a set of data that share a common initial
     prefix.

     New in version 2.5.


Decompression objects support the following methods, and two attributes:

 -- Attribute: Decompress.unused_data
     A string which contains any bytes past the end of the compressed
     data. That is, this remains `""' until the last byte that contains
     compression data is available.  If the whole string turned out to
     contain compressed data, this is `""', the empty string.

     The only way to determine where a string of compressed data ends
     is by actually decompressing it.  This means that when compressed
     data is contained part of a larger file, you can only find the end
     of it by reading data and feeding it followed by some non-empty
     string into a decompression object’s *Note decompress(): ac2.
     method until the *Note unused_data: fb0. attribute is no longer
     the empty string.

 -- Attribute: Decompress.unconsumed_tail
     A string that contains any data that was not consumed by the last
     *Note decompress(): ac2. call because it exceeded the limit for
     the uncompressed data buffer.  This data has not yet been seen by
     the zlib machinery, so you must feed it (possibly with further
     data concatenated to it) back to a subsequent *Note decompress():
     ac2. method call in order to get correct output.

 -- Method: Decompress.decompress (string[, max_length])
     Decompress `string', returning a string containing the
     uncompressed data corresponding to at least part of the data in
     `string'.  This data should be concatenated to the output produced
     by any preceding calls to the *Note decompress(): ac2. method.
     Some of the input data may be preserved in internal buffers for
     later processing.

     If the optional parameter `max_length' is non-zero then the return
     value will be no longer than `max_length'. This may mean that not
     all of the compressed input can be processed; and unconsumed data
     will be stored in the attribute *Note unconsumed_tail: fb1. This
     string must be passed to a subsequent call to *Note decompress():
     ac2. if decompression is to continue.  If `max_length' is not
     supplied then the whole input is decompressed, and *Note
     unconsumed_tail: fb1. is an empty string.

 -- Method: Decompress.flush ([length])
     All pending input is processed, and a string containing the
     remaining uncompressed output is returned.  After calling *Note
     flush(): fb3, the *Note decompress(): ac2. method cannot be called
     again; the only realistic action is to delete the object.

     The optional parameter `length' sets the initial size of the
     output buffer.

 -- Method: Decompress.copy ()
     Returns a copy of the decompression object.  This can be used to
     save the state of the decompressor midway through the data stream
     in order to speed up random seeks into the stream at a future
     point.

     New in version 2.5.


See also
........

Module *Note gzip: e6.
     Reading and writing `gzip'-format files.

<http://www.zlib.net>
     The zlib library home page.

<http://www.zlib.net/manual.html>
     The zlib manual explains  the semantics and usage of the
     library’s many functions.


File: python.info,  Node: gzip — Support for gzip files,  Next: bz2 — Compression compatible with bzip2,  Prev: zlib — Compression compatible with gzip,  Up: Data Compression and Archiving

5.12.2 `gzip' — Support for `gzip' files
------------------------------------------

`Source code:' Lib/gzip.py(1)

__________________________________________________________________

This module provides a simple interface to compress and decompress
files just like the GNU programs `gzip' and `gunzip' would.

The data compression is provided by the *Note zlib: 1ad. module.

The *Note gzip: e6. module provides the *Note GzipFile: 227. class
which is modeled after Python’s File Object. The *Note GzipFile: 227.
class reads and writes `gzip'-format files, automatically compressing
or decompressing the data so that it looks like an ordinary file object.

Note that additional file formats which can be decompressed by the
`gzip' and `gunzip' programs, such  as those produced by `compress' and
`pack', are not supported by this module.

The module defines the following items:

 -- Class: gzip.GzipFile ([filename[, mode[, compresslevel[, fileobj[,
          mtime]]]]])
     Constructor for the *Note GzipFile: 227. class, which simulates
     most of the methods of a file object, with the exception of the
     `readinto()' and `truncate()' methods.  At least one of `fileobj'
     and `filename' must be given a non-trivial value.

     The new class instance is based on `fileobj', which can be a
     regular file, a *Note StringIO: 2df. object, or any other object
     which simulates a file.  It defaults to `None', in which case
     `filename' is opened to provide a file object.

     When `fileobj' is not `None', the `filename' argument is only used
     to be included in the `gzip' file header, which may include the
     original filename of the uncompressed file.  It defaults to the
     filename of `fileobj', if discernible; otherwise, it defaults to
     the empty string, and in this case the original filename is not
     included in the header.

     The `mode' argument can be any of `'r'', `'rb'', `'a'', `'ab'',
     `'w'', or `'wb'', depending on whether the file will be read or
     written.  The default is the mode of `fileobj' if discernible;
     otherwise, the default is `'rb''. If not given, the ‘b’ flag
     will be added to the mode to ensure the file is opened in binary
     mode for cross-platform portability.

     The `compresslevel' argument is an integer from `0' to `9'
     controlling the level of compression; `1' is fastest and produces
     the least compression, and `9' is slowest and produces the most
     compression. `0' is no compression. The default is `9'.

     The `mtime' argument is an optional numeric timestamp to be
     written to the stream when compressing.  All `gzip' compressed
     streams are required to contain a timestamp.  If omitted or
     `None', the current time is used.  This module ignores the
     timestamp when decompressing; however, some programs, such as
     `gunzip', make use of it.  The format of the timestamp is the same
     as that of the return value of `time.time()' and of the `st_mtime'
     attribute of the object returned by `os.stat()'.

     Calling a *Note GzipFile: 227. object’s `close()' method does
     not close `fileobj', since you might wish to append more material
     after the compressed data.  This also allows you to pass a *Note
     StringIO: 2df. object opened for writing as `fileobj', and
     retrieve the resulting memory buffer using the *Note StringIO:
     2df. object’s *Note getvalue(): a5a. method.

     *Note GzipFile: 227. supports iteration and the *Note with: 1c1.
     statement.

     Changed in version 2.7: Support for the *Note with: 1c1. statement
     was added.

     Changed in version 2.7: Support for zero-padded files was added.

     New in version 2.7: The `mtime' argument.


 -- Function: gzip.open (filename[, mode[, compresslevel]])
     This is a shorthand for `GzipFile(filename,' `mode,'
     `compresslevel)'.  The `filename' argument is required; `mode'
     defaults to `'rb'' and `compresslevel' defaults to `9'.

* Menu:

* Examples of usage::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/gzip.py


File: python.info,  Node: Examples of usage,  Up: gzip — Support for gzip files

5.12.2.1 Examples of usage
..........................

Example of how to read a compressed file:

    import gzip
    with gzip.open('file.txt.gz', 'rb') as f:
        file_content = f.read()

Example of how to create a compressed GZIP file:

    import gzip
    content = "Lots of content here"
    with gzip.open('file.txt.gz', 'wb') as f:
        f.write(content)

Example of how to GZIP compress an existing file:

    import gzip
    import shutil
    with open('file.txt', 'rb') as f_in, gzip.open('file.txt.gz', 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)

See also
........

Module *Note zlib: 1ad.
     The basic data compression module needed to support the `gzip' file
     format.


File: python.info,  Node: bz2 — Compression compatible with bzip2,  Next: zipfile — Work with ZIP archives,  Prev: gzip — Support for gzip files,  Up: Data Compression and Archiving

5.12.3 `bz2' — Compression compatible with `bzip2'
----------------------------------------------------

New in version 2.3.

This module provides a comprehensive interface for the bz2 compression
library.  It implements a complete file interface, one-shot
(de)compression functions, and types for sequential (de)compression.

Here is a summary of the features offered by the bz2 module:

   * *Note BZ2File: 204. class implements a complete file interface,
     including *Note readline(): fbc, *Note readlines(): fbd, *Note
     writelines(): fbe, *Note seek(): fbf, etc;

   * *Note BZ2File: 204. class implements emulated *Note seek(): fbf.
     support;

   * *Note BZ2File: 204. class implements universal newline support;

   * *Note BZ2File: 204. class offers an optimized line iteration using
     the readahead algorithm borrowed from file objects;

   * Sequential (de)compression supported by *Note BZ2Compressor: fc0.
     and *Note BZ2Decompressor: fc1. classes;

   * One-shot (de)compression supported by *Note compress(): ab9. and
     *Note decompress(): aba.  functions;

   * Thread safety uses individual locking mechanism.

* Menu:

* (De)compression of files: De compression of files.
* Sequential (de)compression: Sequential de compression.
* One-shot (de)compression: One-shot de compression.


File: python.info,  Node: De compression of files,  Next: Sequential de compression,  Up: bz2 — Compression compatible with bzip2

5.12.3.1 (De)compression of files
.................................

Handling of compressed files is offered by the *Note BZ2File: 204.
class.

 -- Class: bz2.BZ2File (filename[, mode[, buffering[, compresslevel]]])
     Open a bz2 file. Mode can be either `'r'' or `'w'', for reading
     (default) or writing. When opened for writing, the file will be
     created if it doesn’t exist, and truncated otherwise. If
     `buffering' is given, `0' means unbuffered, and larger numbers
     specify the buffer size; the default is `0'. If `compresslevel' is
     given, it must be a number between `1' and `9'; the default is
     `9'. Add a `'U'' to mode to open the file for input in *Note
     universal newlines: 329. mode. Any line ending in the input file
     will be seen as a `'\n'' in Python.  Also, a file so opened gains
     the attribute `newlines'; the value for this attribute is one of
     `None' (no newline read yet), `'\r'', `'\n'', `'\r\n'' or a tuple
     containing all the newline types seen. Universal newlines are
     available only when reading. Instances support iteration in the
     same way as normal *Note file: 1f9.  instances.

     *Note BZ2File: 204. supports the *Note with: 1c1. statement.

     Changed in version 2.7: Support for the *Note with: 1c1. statement
     was added.

          Note: This class does not support input files containing
          multiple streams (such as those produced by the `pbzip2'
          tool). When reading such an input file, only the first stream
          will be accessible. If you require support for multi-stream
          files, consider using the third-party `bz2file' module
          (available from PyPI(1)). This module provides a backport of
          Python 3.3’s *Note BZ2File: 204. class, which does support
          multi-stream files.

      -- Method: close ()
          Close the file. Sets data attribute `closed' to true. A
          closed file cannot be used for further I/O operations. *Note
          close(): fc3. may be called more than once without error.

      -- Method: read ([size])
          Read at most `size' uncompressed bytes, returned as a string.
          If the `size' argument is negative or omitted, read until EOF
          is reached.

      -- Method: readline ([size])
          Return the next line from the file, as a string, retaining
          newline. A non-negative `size' argument limits the maximum
          number of bytes to return (an incomplete line may be returned
          then). Return an empty string at EOF.

      -- Method: readlines ([size])
          Return a list of lines read. The optional `size' argument, if
          given, is an approximate bound on the total number of bytes
          in the lines returned.

      -- Method: xreadlines ()
          For backward compatibility. *Note BZ2File: 204. objects now
          include the performance optimizations previously implemented
          in the `xreadlines' module.

          Deprecated since version 2.3: This exists only for
          compatibility with the method by this name on *Note file:
          1f9. objects, which is deprecated.  Use `for line in file'
          instead.


      -- Method: seek (offset[, whence])
          Move to new file position. Argument `offset' is a byte count.
          Optional argument `whence' defaults to `os.SEEK_SET' or `0'
          (offset from start of file; offset should be `>= 0'); other
          values are `os.SEEK_CUR' or `1' (move relative to current
          position; offset can be positive or negative), and
          `os.SEEK_END' or `2' (move relative to end of file; offset is
          usually negative, although many platforms allow seeking beyond
          the end of a file).

          Note that seeking of bz2 files is emulated, and depending on
          the parameters the operation may be extremely slow.

      -- Method: tell ()
          Return the current file position, an integer (may be a long
          integer).

      -- Method: write (data)
          Write string `data' to file. Note that due to buffering,
          *Note close(): fc3. may be needed before the file on disk
          reflects the data written.

      -- Method: writelines (sequence_of_strings)
          Write the sequence of strings to the file. Note that newlines
          are not added. The sequence can be any iterable object
          producing strings. This is equivalent to calling write() for
          each string.

---------- Footnotes ----------

(1) https://pypi.python.org/pypi/bz2file


File: python.info,  Node: Sequential de compression,  Next: One-shot de compression,  Prev: De compression of files,  Up: bz2 — Compression compatible with bzip2

5.12.3.2 Sequential (de)compression
...................................

Sequential compression and decompression is done using the classes
*Note BZ2Compressor: fc0. and *Note BZ2Decompressor: fc1.

 -- Class: bz2.BZ2Compressor ([compresslevel])
     Create a new compressor object. This object may be used to
     compress data sequentially. If you want to compress data in one
     shot, use the *Note compress(): ab9. function instead. The
     `compresslevel' parameter, if given, must be a number between `1'
     and `9'; the default is `9'.

      -- Method: compress (data)
          Provide more data to the compressor object. It will return
          chunks of compressed data whenever possible. When you’ve
          finished providing data to compress, call the *Note flush():
          fca. method to finish the compression process, and return
          what is left in internal buffers.

      -- Method: flush ()
          Finish the compression process and return what is left in
          internal buffers. You must not use the compressor object
          after calling this method.

 -- Class: bz2.BZ2Decompressor
     Create a new decompressor object. This object may be used to
     decompress data sequentially. If you want to decompress data in
     one shot, use the *Note decompress(): aba. function instead.

      -- Method: decompress (data)
          Provide more data to the decompressor object. It will return
          chunks of decompressed data whenever possible. If you try to
          decompress data after the end of stream is found, *Note
          EOFError: 8b3. will be raised. If any data was found after
          the end of stream, it’ll be ignored and saved in
          `unused_data' attribute.


File: python.info,  Node: One-shot de compression,  Prev: Sequential de compression,  Up: bz2 — Compression compatible with bzip2

5.12.3.3 One-shot (de)compression
.................................

One-shot compression and decompression is provided through the *Note
compress(): ab9.  and *Note decompress(): aba. functions.

 -- Function: bz2.compress (data[, compresslevel])
     Compress `data' in one shot. If you want to compress data
     sequentially, use an instance of *Note BZ2Compressor: fc0.
     instead. The `compresslevel' parameter, if given, must be a number
     between `1' and `9'; the default is `9'.

 -- Function: bz2.decompress (data)
     Decompress `data' in one shot. If you want to decompress data
     sequentially, use an instance of *Note BZ2Decompressor: fc1.
     instead.


File: python.info,  Node: zipfile — Work with ZIP archives,  Next: tarfile — Read and write tar archive files,  Prev: bz2 — Compression compatible with bzip2,  Up: Data Compression and Archiving

5.12.4 `zipfile' — Work with ZIP archives
-------------------------------------------

New in version 1.6.

`Source code:' Lib/zipfile.py(1)

__________________________________________________________________

The ZIP file format is a common archive and compression standard. This
module provides tools to create, read, write, append, and list a ZIP
file.  Any advanced use of this module will require an understanding of
the format, as defined in PKZIP Application Note(2).

This module does not currently handle multi-disk ZIP files.  It can
handle ZIP files that use the ZIP64 extensions (that is ZIP files that
are more than 4 GByte in size).  It supports decryption of encrypted
files in ZIP archives, but it currently cannot create an encrypted
file.  Decryption is extremely slow as it is implemented in native
Python rather than C.

The module defines the following items:

 -- Exception: zipfile.BadZipfile
     The error raised for bad ZIP files (old name: `zipfile.error').

 -- Exception: zipfile.LargeZipFile
     The error raised when a ZIP file would require ZIP64 functionality
     but that has not been enabled.

 -- Class: zipfile.ZipFile
     The class for reading and writing ZIP files.  See section *Note
     ZipFile Objects: fd1. for constructor details.

 -- Class: zipfile.PyZipFile
     Class for creating ZIP archives containing Python libraries.

 -- Class: zipfile.ZipInfo ([filename[, date_time]])
     Class used to represent information about a member of an archive.
     Instances of this class are returned by the *Note getinfo(): fd4.
     and *Note infolist(): fd5.  methods of *Note ZipFile: 26d.
     objects.  Most users of the *Note zipfile: 1ab. module will not
     need to create these, but only use those created by this module.
     `filename' should be the full name of the archive member, and
     `date_time' should be a tuple containing six fields which describe
     the time of the last modification to the file; the fields are
     described in section *Note ZipInfo Objects: fd6.

 -- Function: zipfile.is_zipfile (filename)
     Returns `True' if `filename' is a valid ZIP file based on its
     magic number, otherwise returns `False'.  `filename' may be a file
     or file-like object too.

     Changed in version 2.7: Support for file and file-like objects.


 -- Data: zipfile.ZIP_STORED
     The numeric constant for an uncompressed archive member.

 -- Data: zipfile.ZIP_DEFLATED
     The numeric constant for the usual ZIP compression method.  This
     requires the *Note zlib: 1ad. module.  No other compression
     methods are currently supported.

See also
........

PKZIP Application Note(3)
     Documentation on the ZIP file format by Phil Katz, the creator of
     the format and algorithms used.

Info-ZIP Home Page(4)
     Information about the Info-ZIP project’s ZIP archive programs
     and development libraries.

* Menu:

* ZipFile Objects::
* PyZipFile Objects::
* ZipInfo Objects::
* Command-Line Interface::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/zipfile.py

(2) https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT

(3) https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT

(4) http://www.info-zip.org/


File: python.info,  Node: ZipFile Objects,  Next: PyZipFile Objects,  Up: zipfile — Work with ZIP archives

5.12.4.1 ZipFile Objects
........................

 -- Class: zipfile.ZipFile (file[, mode[, compression[, allowZip64]]])
     Open a ZIP file, where `file' can be either a path to a file (a
     string) or a file-like object.  The `mode' parameter should be
     `'r'' to read an existing file, `'w'' to truncate and write a new
     file, or `'a'' to append to an existing file.  If `mode' is `'a''
     and `file' refers to an existing ZIP file, then additional files
     are added to it.  If `file' does not refer to a ZIP file, then a
     new ZIP archive is appended to the file.  This is meant for adding
     a ZIP archive to another file (such as `python.exe').

     Changed in version 2.6: If `mode' is `a' and the file does not
     exist at all, it is created.

     `compression' is the ZIP compression method to use when writing
     the archive, and should be *Note ZIP_STORED: fd7. or *Note
     ZIP_DEFLATED: fd8.; unrecognized values will cause *Note
     RuntimeError: 3b3. to be raised.  If *Note ZIP_DEFLATED: fd8.  is
     specified but the *Note zlib: 1ad. module is not available, *Note
     RuntimeError: 3b3.  is also raised. The default is *Note
     ZIP_STORED: fd7.  If `allowZip64' is `True' zipfile will create
     ZIP files that use the ZIP64 extensions when the zipfile is larger
     than 2 GB. If it is  false (the default) *Note zipfile: 1ab.  will
     raise an exception when the ZIP file would require ZIP64
     extensions.  ZIP64 extensions are disabled by default because the
     default `zip' and `unzip' commands on Unix (the InfoZIP utilities)
     don’t support these extensions.

     Changed in version 2.7.1: If the file is created with mode `'a''
     or `'w'' and then *Note closed: fda. without adding any files to
     the archive, the appropriate ZIP structures for an empty archive
     will be written to the file.

     ZipFile is also a context manager and therefore supports the *Note
     with: 1c1. statement.  In the example, `myzip' is closed after the
     *Note with: 1c1. statement’s suite is finished—even if an
     exception occurs:

         with ZipFile('spam.zip', 'w') as myzip:
             myzip.write('eggs.txt')

     New in version 2.7: Added the ability to use *Note ZipFile: 26d.
     as a context manager.


 -- Method: ZipFile.close ()
     Close the archive file.  You must call *Note close(): fda. before
     exiting your program or essential records will not be written.

 -- Method: ZipFile.getinfo (name)
     Return a *Note ZipInfo: fd3. object with information about the
     archive member `name'.  Calling *Note getinfo(): fd4. for a name
     not currently contained in the archive will raise a *Note
     KeyError: 205.

 -- Method: ZipFile.infolist ()
     Return a list containing a *Note ZipInfo: fd3. object for each
     member of the archive.  The objects are in the same order as their
     entries in the actual ZIP file on disk if an existing archive was
     opened.

 -- Method: ZipFile.namelist ()
     Return a list of archive members by name.


 -- Method: ZipFile.open (name[, mode[, pwd]])
     Extract a member from the archive as a file-like object
     (ZipExtFile). `name' is the name of the file in the archive, or a
     *Note ZipInfo: fd3. object. The `mode' parameter, if included,
     must be one of the following: `'r'' (the default), `'U'', or
     `'rU''. Choosing `'U'' or  `'rU'' will enable *Note universal
     newline: 329.  support in the read-only object. `pwd' is the
     password used for encrypted files.  Calling  *Note open(): fdc. on
     a closed ZipFile will raise a  *Note RuntimeError: 3b3.

          Note: The file-like object is read-only and provides the
          following methods: *Note read(): 939, *Note readline(): 66f,
          *Note readlines(): 66d, *Note __iter__(): 335, `next()'.

          Note: If the ZipFile was created by passing in a file-like
          object as the  first argument to the constructor, then the
          object returned by *Note open(): fdc. shares the ZipFile’s
          file pointer.  Under these  circumstances, the object
          returned by *Note open(): fdc. should not  be used after any
          additional operations are performed on the  ZipFile object.
          If the ZipFile was created by passing in a string (the
          filename) as the first argument to the constructor, then
          *Note open(): fdc. will create a new file object that will be
          held by the ZipExtFile, allowing it to operate independently
          of the  ZipFile.

          Note: The *Note open(): fdc, *Note read(): 26e. and *Note
          extract(): fdd. methods can take a filename or a *Note
          ZipInfo: fd3. object.  You will appreciate this when trying
          to read a ZIP file that contains members with duplicate names.

     New in version 2.6.


 -- Method: ZipFile.extract (member[, path[, pwd]])
     Extract a member from the archive to the current working
     directory; `member' must be its full name or a *Note ZipInfo: fd3.
     object).  Its file information is extracted as accurately as
     possible.  `path' specifies a different directory to extract to.
     `member' can be a filename or a *Note ZipInfo: fd3. object.  `pwd'
     is the password used for encrypted files.

     Returns the normalized path created (a directory or new file).

     New in version 2.6.

          Note: If a member filename is an absolute path, a drive/UNC
          sharepoint and leading (back)slashes will be stripped, e.g.:
          `///foo/bar' becomes `foo/bar' on Unix, and `C:\foo\bar'
          becomes `foo\bar' on Windows.  And all `".."' components in a
          member filename will be removed, e.g.: `../../foo../../ba..r'
          becomes `foo../ba..r'.  On Windows illegal characters (`:',
          `<', `>', `|', `"', `?', and `*') replaced by underscore
          (`_').

 -- Method: ZipFile.extractall ([path[, members[, pwd]]])
     Extract all members from the archive to the current working
     directory.  `path' specifies a different directory to extract to.
     `members' is optional and must be a subset of the list returned by
     *Note namelist(): fdb.  `pwd' is the password used for encrypted
     files.

          Warning: Never extract archives from untrusted sources
          without prior inspection.  It is possible that files are
          created outside of `path', e.g. members that have absolute
          filenames starting with `"/"' or filenames with two dots
          `".."'.

     Changed in version 2.7.4: The zipfile module attempts to prevent
     that.  See *Note extract(): fdd. note.

     New in version 2.6.


 -- Method: ZipFile.printdir ()
     Print a table of contents for the archive to `sys.stdout'.

 -- Method: ZipFile.setpassword (pwd)
     Set `pwd' as default password to extract encrypted files.

     New in version 2.6.


 -- Method: ZipFile.read (name[, pwd])
     Return the bytes of the file `name' in the archive.  `name' is the
     name of the file in the archive, or a *Note ZipInfo: fd3. object.
     The archive must be open for read or append. `pwd' is the password
     used for encrypted  files and, if specified, it will override the
     default password set with *Note setpassword(): fe0.  Calling *Note
     read(): 26e. on a closed ZipFile  will raise a *Note RuntimeError:
     3b3.

     Changed in version 2.6: `pwd' was added, and `name' can now be a
     *Note ZipInfo: fd3. object.


 -- Method: ZipFile.testzip ()
     Read all the files in the archive and check their CRC’s and file
     headers.  Return the name of the first bad file, or else return
     `None'. Calling *Note testzip(): fe1. on a closed ZipFile will
     raise a *Note RuntimeError: 3b3.

 -- Method: ZipFile.write (filename[, arcname[, compress_type]])
     Write the file named `filename' to the archive, giving it the
     archive name `arcname' (by default, this will be the same as
     `filename', but without a drive letter and with leading path
     separators removed).  If given, `compress_type' overrides the
     value given for the `compression' parameter to the constructor for
     the new entry.  The archive must be open with mode `'w'' or `'a''
     – calling *Note write(): fe2. on a ZipFile created with mode
     `'r'' will raise a *Note RuntimeError: 3b3.  Calling  *Note
     write(): fe2. on a closed ZipFile will raise a *Note RuntimeError:
     3b3.

          Note: There is no official file name encoding for ZIP files.
          If you have unicode file names, you must convert them to byte
          strings in your desired encoding before passing them to *Note
          write(): fe2. WinZip interprets all file names as encoded in
          CP437, also known as DOS Latin.

          Note: Archive names should be relative to the archive root,
          that is, they should not start with a path separator.

          Note: If `arcname' (or `filename', if `arcname' is  not
          given) contains a null byte, the name of the file in the
          archive will be truncated at the null byte.

 -- Method: ZipFile.writestr (zinfo_or_arcname, bytes[, compress_type])
     Write the string `bytes' to the archive; `zinfo_or_arcname' is
     either the file name it will be given in the archive, or a *Note
     ZipInfo: fd3. instance.  If it’s an instance, at least the
     filename, date, and time must be given.  If it’s a name, the
     date and time is set to the current date and time. The archive
     must be opened with mode `'w'' or `'a'' – calling  *Note
     writestr(): 270. on a ZipFile created with mode `'r''  will raise
     a *Note RuntimeError: 3b3.  Calling *Note writestr(): 270. on a
     closed ZipFile will raise a *Note RuntimeError: 3b3.

     If given, `compress_type' overrides the value given for the
     `compression' parameter to the constructor for the new entry, or
     in the `zinfo_or_arcname' (if that is a *Note ZipInfo: fd3.
     instance).

          Note: When passing a *Note ZipInfo: fd3. instance as the
          `zinfo_or_arcname' parameter, the compression method used
          will be that specified in the `compress_type' member of the
          given *Note ZipInfo: fd3. instance.  By default, the *Note
          ZipInfo: fd3. constructor sets this member to *Note
          ZIP_STORED: fd7.

     Changed in version 2.7: The `compress_type' argument.


The following data attributes are also available:

 -- Attribute: ZipFile.debug
     The level of debug output to use.  This may be set from `0' (the
     default, no output) to `3' (the most output).  Debugging
     information is written to `sys.stdout'.

 -- Attribute: ZipFile.comment
     The comment text associated with the ZIP file.  If assigning a
     comment to a *Note ZipFile: 26d. instance created with mode
     ‘a’ or ‘w’, this should be a string no longer than 65535
     bytes.  Comments longer than this will be truncated in the written
     archive when *Note close(): fda. is called.


File: python.info,  Node: PyZipFile Objects,  Next: ZipInfo Objects,  Prev: ZipFile Objects,  Up: zipfile — Work with ZIP archives

5.12.4.2 PyZipFile Objects
..........................

The *Note PyZipFile: fd2. constructor takes the same parameters as the
*Note ZipFile: 26d. constructor.  Instances have one method in addition
to those of *Note ZipFile: 26d. objects.

 -- Method: PyZipFile.writepy (pathname[, basename])
     Search for files `*.py' and add the corresponding file to the
     archive.  The corresponding file is a `*.pyo' file if available,
     else a `*.pyc' file, compiling if necessary.  If the pathname is a
     file, the filename must end with `.py', and just the (corresponding
     `*.py[co]') file is added at the top level (no path information).
     If the pathname is a file that does not end with `.py', a *Note
     RuntimeError: 3b3.  will be raised.  If it is a directory, and the
     directory is not a package directory, then all the files
     `*.py[co]' are added at the top level.  If the directory is a
     package directory, then all `*.py[co]' are added under the package
     name as a file path, and if any subdirectories are package
     directories, all of these are added recursively.  `basename' is
     intended for internal use only.  The *Note writepy(): fe7. method
     makes archives with file names like this:

         string.pyc                                # Top level name
         test/__init__.pyc                         # Package directory
         test/test_support.pyc                          # Module test.test_support
         test/bogus/__init__.pyc                   # Subpackage directory
         test/bogus/myfile.pyc                     # Submodule test.bogus.myfile


File: python.info,  Node: ZipInfo Objects,  Next: Command-Line Interface,  Prev: PyZipFile Objects,  Up: zipfile — Work with ZIP archives

5.12.4.3 ZipInfo Objects
........................

Instances of the *Note ZipInfo: fd3. class are returned by the *Note
getinfo(): fd4. and *Note infolist(): fd5. methods of *Note ZipFile:
26d. objects.  Each object stores information about a single member of
the ZIP archive.

Instances have the following attributes:

 -- Attribute: ZipInfo.filename
     Name of the file in the archive.

 -- Attribute: ZipInfo.date_time
     The time and date of the last modification to the archive member.
     This is a tuple of six values:

     Index       Value
     ------------------------------------------- 
     `0'         Year (>= 1980)
     `1'         Month (one-based)
     `2'         Day of month (one-based)
     `3'         Hours (zero-based)
     `4'         Minutes (zero-based)
     `5'         Seconds (zero-based)

          Note: The ZIP file format does not support timestamps before
          1980.

 -- Attribute: ZipInfo.compress_type
     Type of compression for the archive member.

 -- Attribute: ZipInfo.comment
     Comment for the individual archive member.

 -- Attribute: ZipInfo.extra
     Expansion field data.  The PKZIP Application Note(1) contains some
     comments on the internal structure of the data contained in this
     string.

 -- Attribute: ZipInfo.create_system
     System which created ZIP archive.

 -- Attribute: ZipInfo.create_version
     PKZIP version which created ZIP archive.

 -- Attribute: ZipInfo.extract_version
     PKZIP version needed to extract archive.

 -- Attribute: ZipInfo.reserved
     Must be zero.

 -- Attribute: ZipInfo.flag_bits
     ZIP flag bits.

 -- Attribute: ZipInfo.volume
     Volume number of file header.

 -- Attribute: ZipInfo.internal_attr
     Internal attributes.

 -- Attribute: ZipInfo.external_attr
     External file attributes.

 -- Attribute: ZipInfo.header_offset
     Byte offset to the file header.

 -- Attribute: ZipInfo.CRC
     CRC-32 of the uncompressed file.

 -- Attribute: ZipInfo.compress_size
     Size of the compressed data.

 -- Attribute: ZipInfo.file_size
     Size of the uncompressed file.

---------- Footnotes ----------

(1) https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT


File: python.info,  Node: Command-Line Interface,  Prev: ZipInfo Objects,  Up: zipfile — Work with ZIP archives

5.12.4.4 Command-Line Interface
...............................

The *Note zipfile: 1ab. module provides a simple command-line interface
to interact with ZIP archives.

If you want to create a new ZIP archive, specify its name after the
*Note -c: ffc.  option and then list the filename(s) that should be
included:

    $ python -m zipfile -c monty.zip spam.txt eggs.txt

Passing a directory is also acceptable:

    $ python -m zipfile -c monty.zip life-of-brian_1979/

If you want to extract a ZIP archive into the specified directory, use
the *Note -e: ffd. option:

    $ python -m zipfile -e monty.zip target-dir/

For a list of the files in a ZIP archive, use the *Note -l: ffe. option:

    $ python -m zipfile -l monty.zip

* Menu:

* Command-line options::


File: python.info,  Node: Command-line options,  Up: Command-Line Interface

5.12.4.5 Command-line options
.............................

 -- Program Option: -l <zipfile>
     List files in a zipfile.

 -- Program Option: -c <zipfile> <source1> ... <sourceN>
     Create zipfile from source files.

 -- Program Option: -e <zipfile> <output_dir>
     Extract zipfile into target directory.

 -- Program Option: -t <zipfile>
     Test whether the zipfile is valid or not.


File: python.info,  Node: tarfile — Read and write tar archive files,  Prev: zipfile — Work with ZIP archives,  Up: Data Compression and Archiving

5.12.5 `tarfile' — Read and write tar archive files
-----------------------------------------------------

New in version 2.3.

`Source code:' Lib/tarfile.py(1)

__________________________________________________________________

The *Note tarfile: 171. module makes it possible to read and write tar
archives, including those using gzip or bz2 compression.  Use the *Note
zipfile: 1ab. module to read or write `.zip' files, or the higher-level
functions in *Note shutil: edb.

Some facts and figures:

   * reads and writes *Note gzip: e6. and *Note bz2: 1e. compressed
     archives if the respective modules are available.

   * read/write support for the POSIX.1-1988 (ustar) format.

   * read/write support for the GNU tar format including `longname' and
     `longlink' extensions, read-only support for the `sparse'
     extension.

   * read/write support for the POSIX.1-2001 (pax) format.

     New in version 2.6.

   * handles directories, regular files, hardlinks, symbolic links,
     fifos, character devices and block devices and is able to acquire
     and restore file information like timestamp, access permissions
     and owner.

 -- Function: tarfile.open (name=None, mode='r', fileobj=None,
          bufsize=10240, **kwargs)
     Return a *Note TarFile: 268. object for the pathname `name'. For
     detailed information on *Note TarFile: 268. objects and the
     keyword arguments that are allowed, see *Note TarFile Objects:
     1005.

     `mode' has to be a string of the form `'filemode[:compression]'',
     it defaults to `'r''. Here is a full list of mode combinations:

     mode                   action
     ------------------------------------------------------------------------- 
     `'r' or 'r:*''         Open for reading with transparent compression
                            (recommended).
     `'r:''                 Open for reading exclusively without compression.
     `'r:gz''               Open for reading with gzip compression.
     `'r:bz2''              Open for reading with bzip2 compression.
     `'a' or 'a:''          Open for appending with no compression. The file
                            is created if it does not exist.
     `'w' or 'w:''          Open for uncompressed writing.
     `'w:gz''               Open for gzip compressed writing.
     `'w:bz2''              Open for bzip2 compressed writing.

     Note that `'a:gz'' or `'a:bz2'' is not possible. If `mode' is not
     suitable to open a certain (compressed) file for reading, *Note
     ReadError: 1006. is raised. Use `mode' `'r'' to avoid this.  If a
     compression method is not supported, *Note CompressionError: 1007.
     is raised.

     If `fileobj' is specified, it is used as an alternative to a file
     object opened for `name'. It is supposed to be at position 0.

     For modes `'w:gz'', `'r:gz'', `'w:bz2'', `'r:bz2'', *Note
     tarfile.open(): 1004.  accepts the keyword argument
     `compresslevel' (default `9') to specify the compression level of
     the file.

     For special purposes, there is a second format for `mode':
     `'filemode|[compression]''.  *Note tarfile.open(): 1004. will
     return a *Note TarFile: 268.  object that processes its data as a
     stream of blocks.  No random seeking will be done on the file. If
     given, `fileobj' may be any object that has a `read()' or
     `write()' method (depending on the `mode'). `bufsize' specifies
     the blocksize and defaults to `20 * 512' bytes. Use this variant
     in combination with e.g. `sys.stdin', a socket file object or a
     tape device. However, such a *Note TarFile: 268. object is limited
     in that it does not allow random access, see *Note Examples: 1008.
     The currently possible modes:

     Mode              Action
     ------------------------------------------------------------------- 
     `'r|*''           Open a `stream' of tar blocks for reading with
                       transparent compression.
     `'r|''            Open a `stream' of uncompressed tar blocks for
                       reading.
     `'r|gz''          Open a gzip compressed `stream' for reading.
     `'r|bz2''         Open a bzip2 compressed `stream' for reading.
     `'w|''            Open an uncompressed `stream' for writing.
     `'w|gz''          Open a gzip compressed `stream' for writing.
     `'w|bz2''         Open a bzip2 compressed `stream' for writing.


 -- Class: tarfile.TarFile
     Class for reading and writing tar archives. Do not use this class
     directly, better use *Note tarfile.open(): 1004. instead. See
     *Note TarFile Objects: 1005.

 -- Function: tarfile.is_tarfile (name)
     Return *Note True: 3c8. if `name' is a tar archive file, that the
     *Note tarfile: 171.  module can read.

 -- Class: tarfile.TarFileCompat (filename, mode='r',
          compression=TAR_PLAIN)
     Class for limited access to tar archives with a *Note zipfile:
     1ab.-like interface.  Please consult the documentation of the
     *Note zipfile: 1ab. module for more details.  `compression' must
     be one of the following constants:

      -- Data: TAR_PLAIN
          Constant for an uncompressed tar archive.

      -- Data: TAR_GZIPPED
          Constant for a *Note gzip: e6. compressed tar archive.

     Deprecated since version 2.6: The *Note TarFileCompat: 100a. class
     has been removed in Python 3.


 -- Exception: tarfile.TarError
     Base class for all *Note tarfile: 171. exceptions.

 -- Exception: tarfile.ReadError
     Is raised when a tar archive is opened, that either cannot be
     handled by the *Note tarfile: 171. module or is somehow invalid.

 -- Exception: tarfile.CompressionError
     Is raised when a compression method is not supported or when the
     data cannot be decoded properly.

 -- Exception: tarfile.StreamError
     Is raised for the limitations that are typical for stream-like
     *Note TarFile: 268.  objects.

 -- Exception: tarfile.ExtractError
     Is raised for `non-fatal' errors when using *Note
     TarFile.extract(): 1010, but only if `TarFile.errorlevel'`== 2'.

The following constants are available at the module level:

 -- Data: tarfile.ENCODING
     The default character encoding: `'utf-8'' on Windows, the value
     returned by *Note sys.getfilesystemencoding(): 1012. otherwise.

 -- Exception: tarfile.HeaderError
     Is raised by *Note TarInfo.frombuf(): 1014. if the buffer it gets
     is invalid.

     New in version 2.6.


Each of the following constants defines a tar archive format that the
*Note tarfile: 171. module is able to create. See section *Note
Supported tar formats: 1015. for details.

 -- Data: tarfile.USTAR_FORMAT
     POSIX.1-1988 (ustar) format.

 -- Data: tarfile.GNU_FORMAT
     GNU tar format.

 -- Data: tarfile.PAX_FORMAT
     POSIX.1-2001 (pax) format.

 -- Data: tarfile.DEFAULT_FORMAT
     The default format for creating archives. This is currently *Note
     GNU_FORMAT: 1017.

See also
........

Module *Note zipfile: 1ab.
     Documentation of the *Note zipfile: 1ab. standard module.

*Note Archiving operations: edb.
     Documentation of the higher-level archiving facilities provided by
     the standard *Note shutil: 154. module.

GNU tar manual, Basic Tar Format(2)
     Documentation for tar archive files, including GNU tar extensions.

* Menu:

* TarFile Objects::
* TarInfo Objects::
* Examples: Examples<3>.
* Supported tar formats::
* Unicode issues::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/tarfile.py

(2) https://www.gnu.org/software/tar/manual/html_node/Standard.html


File: python.info,  Node: TarFile Objects,  Next: TarInfo Objects,  Up: tarfile — Read and write tar archive files

5.12.5.1 TarFile Objects
........................

The *Note TarFile: 268. object provides an interface to a tar archive.
A tar archive is a sequence of blocks. An archive member (a stored
file) is made up of a header block followed by data blocks. It is
possible to store a file in a tar archive several times. Each archive
member is represented by a *Note TarInfo: 266.  object, see *Note
TarInfo Objects: 101b. for details.

A *Note TarFile: 268. object can be used as a context manager in a
*Note with: 1c1.  statement. It will automatically be closed when the
block is completed. Please note that in the event of an exception an
archive opened for writing will not be finalized; only the internally
used file object will be closed. See the *Note Examples: 1008. section
for a use case.

New in version 2.7: Added support for the context management protocol.

 -- Class: tarfile.TarFile (name=None, mode='r', fileobj=None,
          format=DEFAULT_FORMAT, tarinfo=TarInfo, dereference=False,
          ignore_zeros=False, encoding=ENCODING, errors=None,
          pax_headers=None, debug=0, errorlevel=0)
     All following arguments are optional and can be accessed as
     instance attributes as well.

     `name' is the pathname of the archive. It can be omitted if
     `fileobj' is given.  In this case, the file object’s `name'
     attribute is used if it exists.

     `mode' is either `'r'' to read from an existing archive, `'a'' to
     append data to an existing file or `'w'' to create a new file
     overwriting an existing one.

     If `fileobj' is given, it is used for reading or writing data. If
     it can be determined, `mode' is overridden by `fileobj'’s mode.
     `fileobj' will be used from position 0.

          Note: `fileobj' is not closed, when *Note TarFile: 268. is
          closed.

     `format' controls the archive format. It must be one of the
     constants *Note USTAR_FORMAT: 1016, *Note GNU_FORMAT: 1017. or
     *Note PAX_FORMAT: 1018. that are defined at module level.

     New in version 2.6.

     The `tarinfo' argument can be used to replace the default *Note
     TarInfo: 266. class with a different one.

     New in version 2.6.

     If `dereference' is *Note False: 3c9, add symbolic and hard links
     to the archive. If it is *Note True: 3c8, add the content of the
     target files to the archive. This has no effect on systems that do
     not support symbolic links.

     If `ignore_zeros' is *Note False: 3c9, treat an empty block as the
     end of the archive.  If it is *Note True: 3c8, skip empty (and
     invalid) blocks and try to get as many members as possible. This
     is only useful for reading concatenated or damaged archives.

     `debug' can be set from `0' (no debug messages) up to `3' (all
     debug messages). The messages are written to `sys.stderr'.

     If `errorlevel' is `0', all errors are ignored when using *Note
     TarFile.extract(): 1010.  Nevertheless, they appear as error
     messages in the debug output, when debugging is enabled.  If `1',
     all `fatal' errors are raised as *Note OSError: 231. or *Note
     IOError: 1fa. exceptions. If `2', all `non-fatal' errors are
     raised as *Note TarError: 100d. exceptions as well.

     The `encoding' and `errors' arguments control the way strings are
     converted to unicode objects and vice versa. The default settings
     will work for most users.  See section *Note Unicode issues: 101c.
     for in-depth information.

     New in version 2.6.

     The `pax_headers' argument is an optional dictionary of unicode
     strings which will be added as a pax global header if `format' is
     *Note PAX_FORMAT: 1018.

     New in version 2.6.


 -- Class Method: TarFile.open (...)
     Alternative constructor. The *Note tarfile.open(): 1004. function
     is actually a shortcut to this classmethod.

 -- Method: TarFile.getmember (name)
     Return a *Note TarInfo: 266. object for member `name'. If `name'
     can not be found in the archive, *Note KeyError: 205. is raised.

          Note: If a member occurs more than once in the archive, its
          last occurrence is assumed to be the most up-to-date version.

 -- Method: TarFile.getmembers ()
     Return the members of the archive as a list of *Note TarInfo: 266.
     objects. The list has the same order as the members in the archive.

 -- Method: TarFile.getnames ()
     Return the members as a list of their names. It has the same order
     as the list returned by *Note getmembers(): 101f.

 -- Method: TarFile.list (verbose=True)
     Print a table of contents to `sys.stdout'. If `verbose' is *Note
     False: 3c9, only the names of the members are printed. If it is
     *Note True: 3c8, output similar to that of `ls -l' is produced.

 -- Method: TarFile.next ()
     Return the next member of the archive as a *Note TarInfo: 266.
     object, when *Note TarFile: 268. is opened for reading. Return
     *Note None: 3b2. if there is no more available.

 -- Method: TarFile.extractall (path=".", members=None)
     Extract all members from the archive to the current working
     directory or directory `path'. If optional `members' is given, it
     must be a subset of the list returned by *Note getmembers(): 101f.
     Directory information like owner, modification time and
     permissions are set after all members have been extracted.  This
     is done to work around two problems: A directory’s modification
     time is reset each time a file is created in it. And, if a
     directory’s permissions do not allow writing, extracting files
     to it will fail.

          Warning: Never extract archives from untrusted sources
          without prior inspection.  It is possible that files are
          created outside of `path', e.g. members that have absolute
          filenames starting with `"/"' or filenames with two dots
          `".."'.

     New in version 2.5.


 -- Method: TarFile.extract (member, path="")
     Extract a member from the archive to the current working
     directory, using its full name. Its file information is extracted
     as accurately as possible. `member' may be a filename or a *Note
     TarInfo: 266. object. You can specify a different directory using
     `path'.

          Note: The *Note extract(): 1010. method does not take care of
          several extraction issues.  In most cases you should consider
          using the *Note extractall(): 1023. method.

          Warning: See the warning for *Note extractall(): 1023.

 -- Method: TarFile.extractfile (member)
     Extract a member from the archive as a file object. `member' may
     be a filename or a *Note TarInfo: 266. object. If `member' is a
     regular file, a file-like object is returned. If `member' is a
     link, a file-like object is constructed from the link’s target.
     If `member' is none of the above, *Note None: 3b2. is returned.

          Note: The file-like object is read-only.  It provides the
          methods `read()', *Note readline(): 145, `readlines()',
          `seek()', `tell()', and *Note close(): 1025, and also
          supports iteration over its lines.

 -- Method: TarFile.add (name, arcname=None, recursive=True,
          exclude=None, filter=None)
     Add the file `name' to the archive. `name' may be any type of file
     (directory, fifo, symbolic link, etc.). If given, `arcname'
     specifies an alternative name for the file in the archive.
     Directories are added recursively by default. This can be avoided
     by setting `recursive' to *Note False: 3c9. If `exclude' is given
     it must be a function that takes one filename argument and returns
     a boolean value. Depending on this value the respective file is
     either excluded (*Note True: 3c8.) or added (*Note False: 3c9.).
     If `filter' is specified it must be a function that takes a *Note
     TarInfo: 266. object argument and returns the changed *Note
     TarInfo: 266. object. If it instead returns *Note None: 3b2. the
     *Note TarInfo: 266.  object will be excluded from the archive. See
     *Note Examples: 1008. for an example.

     Changed in version 2.6: Added the `exclude' parameter.

     Changed in version 2.7: Added the `filter' parameter.

     Deprecated since version 2.7: The `exclude' parameter is
     deprecated, please use the `filter' parameter instead.  For
     maximum portability, `filter' should be used as a keyword argument
     rather than as a positional argument so that code won’t be
     affected when `exclude' is ultimately removed.


 -- Method: TarFile.addfile (tarinfo, fileobj=None)
     Add the *Note TarInfo: 266. object `tarinfo' to the archive. If
     `fileobj' is given, `tarinfo.size' bytes are read from it and
     added to the archive.  You can create *Note TarInfo: 266. objects
     directly, or by using *Note gettarinfo(): 1027.

          Note: On Windows platforms, `fileobj' should always be opened
          with mode `'rb'' to avoid irritation about the file size.

 -- Method: TarFile.gettarinfo (name=None, arcname=None, fileobj=None)
     Create a *Note TarInfo: 266. object from the result of *Note
     os.stat(): 3de. or equivalent on an existing file.  The file is
     either named by `name', or specified as a file object `fileobj'
     with a file descriptor.  If given, `arcname' specifies an
     alternative name for the file in the archive, otherwise, the name
     is taken from `fileobj'’s *Note name: 942. attribute, or the
     `name' argument.

     You can modify some of the *Note TarInfo: 266.’s attributes
     before you add it using *Note addfile(): 1026.  If the file object
     is not an ordinary file object positioned at the beginning of the
     file, attributes such as *Note size: 1028. may need modifying.
     This is the case for objects such as *Note GzipFile: 227.  The
     *Note name: 1029. may also be modified, in which case `arcname'
     could be a dummy string.

 -- Method: TarFile.close ()
     Close the *Note TarFile: 268. In write mode, two finishing zero
     blocks are appended to the archive.

 -- Attribute: TarFile.posix
     Setting this to *Note True: 3c8. is equivalent to setting the
     *Note format: 1ef.  attribute to *Note USTAR_FORMAT: 1016, *Note
     False: 3c9. is equivalent to *Note GNU_FORMAT: 1017.

     Changed in version 2.4: `posix' defaults to *Note False: 3c9.

     Deprecated since version 2.6: Use the *Note format: 1ef. attribute
     instead.


 -- Attribute: TarFile.pax_headers
     A dictionary containing key-value pairs of pax global headers.

     New in version 2.6.



File: python.info,  Node: TarInfo Objects,  Next: Examples<3>,  Prev: TarFile Objects,  Up: tarfile — Read and write tar archive files

5.12.5.2 TarInfo Objects
........................

A *Note TarInfo: 266. object represents one member in a *Note TarFile:
268. Aside from storing all required attributes of a file (like file
type, size, time, permissions, owner etc.), it provides some useful
methods to determine its type.  It does `not' contain the file’s data
itself.

*Note TarInfo: 266. objects are returned by *Note TarFile: 268.’s
methods `getmember()', `getmembers()' and `gettarinfo()'.

 -- Class: tarfile.TarInfo (name="")
     Create a *Note TarInfo: 266. object.

 -- Method: TarInfo.frombuf (buf)
     Create and return a *Note TarInfo: 266. object from string buffer
     `buf'.

     New in version 2.6: Raises *Note HeaderError: 1013. if the buffer
     is invalid..


 -- Method: TarInfo.fromtarfile (tarfile)
     Read the next member from the *Note TarFile: 268. object `tarfile'
     and return it as a *Note TarInfo: 266. object.

     New in version 2.6.


 -- Method: TarInfo.tobuf (format=DEFAULT_FORMAT, encoding=ENCODING,
          errors='strict')
     Create a string buffer from a *Note TarInfo: 266. object. For
     information on the arguments see the constructor of the *Note
     TarFile: 268. class.

     Changed in version 2.6: The arguments were added.


A `TarInfo' object has the following public data attributes:

 -- Attribute: TarInfo.name
     Name of the archive member.

 -- Attribute: TarInfo.size
     Size in bytes.

 -- Attribute: TarInfo.mtime
     Time of last modification.

 -- Attribute: TarInfo.mode
     Permission bits.

 -- Attribute: TarInfo.type
     File type.  `type' is usually one of these constants: `REGTYPE',
     `AREGTYPE', `LNKTYPE', `SYMTYPE', `DIRTYPE', `FIFOTYPE',
     `CONTTYPE', `CHRTYPE', `BLKTYPE', `GNUTYPE_SPARSE'.  To determine
     the type of a *Note TarInfo: 266. object more conveniently, use
     the `is*()' methods below.

 -- Attribute: TarInfo.linkname
     Name of the target file name, which is only present in *Note
     TarInfo: 266. objects of type `LNKTYPE' and `SYMTYPE'.

 -- Attribute: TarInfo.uid
     User ID of the user who originally stored this member.

 -- Attribute: TarInfo.gid
     Group ID of the user who originally stored this member.

 -- Attribute: TarInfo.uname
     User name.

 -- Attribute: TarInfo.gname
     Group name.

 -- Attribute: TarInfo.pax_headers
     A dictionary containing key-value pairs of an associated pax
     extended header.

     New in version 2.6.


A *Note TarInfo: 266. object also provides some convenient query
methods:

 -- Method: TarInfo.isfile ()
     Return *Note True: 3c8. if the `Tarinfo' object is a regular file.

 -- Method: TarInfo.isreg ()
     Same as *Note isfile(): 1038.

 -- Method: TarInfo.isdir ()
     Return *Note True: 3c8. if it is a directory.

 -- Method: TarInfo.issym ()
     Return *Note True: 3c8. if it is a symbolic link.

 -- Method: TarInfo.islnk ()
     Return *Note True: 3c8. if it is a hard link.

 -- Method: TarInfo.ischr ()
     Return *Note True: 3c8. if it is a character device.

 -- Method: TarInfo.isblk ()
     Return *Note True: 3c8. if it is a block device.

 -- Method: TarInfo.isfifo ()
     Return *Note True: 3c8. if it is a FIFO.

 -- Method: TarInfo.isdev ()
     Return *Note True: 3c8. if it is one of character device, block
     device or FIFO.


File: python.info,  Node: Examples<3>,  Next: Supported tar formats,  Prev: TarInfo Objects,  Up: tarfile — Read and write tar archive files

5.12.5.3 Examples
.................

How to extract an entire tar archive to the current working directory:

    import tarfile
    tar = tarfile.open("sample.tar.gz")
    tar.extractall()
    tar.close()

How to extract a subset of a tar archive with *Note
TarFile.extractall(): 1023. using a generator function instead of a
list:

    import os
    import tarfile

    def py_files(members):
        for tarinfo in members:
            if os.path.splitext(tarinfo.name)[1] == ".py":
                yield tarinfo

    tar = tarfile.open("sample.tar.gz")
    tar.extractall(members=py_files(tar))
    tar.close()

How to create an uncompressed tar archive from a list of filenames:

    import tarfile
    tar = tarfile.open("sample.tar", "w")
    for name in ["foo", "bar", "quux"]:
        tar.add(name)
    tar.close()

The same example using the *Note with: 1c1. statement:

    import tarfile
    with tarfile.open("sample.tar", "w") as tar:
        for name in ["foo", "bar", "quux"]:
            tar.add(name)

How to read a gzip compressed tar archive and display some member
information:

    import tarfile
    tar = tarfile.open("sample.tar.gz", "r:gz")
    for tarinfo in tar:
        print tarinfo.name, "is", tarinfo.size, "bytes in size and is",
        if tarinfo.isreg():
            print "a regular file."
        elif tarinfo.isdir():
            print "a directory."
        else:
            print "something else."
    tar.close()

How to create an archive and reset the user information using the
`filter' parameter in *Note TarFile.add(): 267.:

    import tarfile
    def reset(tarinfo):
        tarinfo.uid = tarinfo.gid = 0
        tarinfo.uname = tarinfo.gname = "root"
        return tarinfo
    tar = tarfile.open("sample.tar.gz", "w:gz")
    tar.add("foo", filter=reset)
    tar.close()


File: python.info,  Node: Supported tar formats,  Next: Unicode issues,  Prev: Examples<3>,  Up: tarfile — Read and write tar archive files

5.12.5.4 Supported tar formats
..............................

There are three tar formats that can be created with the *Note tarfile:
171. module:

   * The POSIX.1-1988 ustar format (*Note USTAR_FORMAT: 1016.). It
     supports filenames up to a length of at best 256 characters and
     linknames up to 100 characters. The maximum file size is 8
     gigabytes. This is an old and limited but widely supported format.

   * The GNU tar format (*Note GNU_FORMAT: 1017.). It supports long
     filenames and linknames, files bigger than 8 gigabytes and sparse
     files. It is the de facto standard on GNU/Linux systems. *Note
     tarfile: 171. fully supports the GNU tar extensions for long
     names, sparse file support is read-only.

   * The POSIX.1-2001 pax format (*Note PAX_FORMAT: 1018.). It is the
     most flexible format with virtually no limits. It supports long
     filenames and linknames, large files and stores pathnames in a
     portable way. However, not all tar implementations today are able
     to handle pax archives properly.

     The `pax' format is an extension to the existing `ustar' format.
     It uses extra headers for information that cannot be stored
     otherwise. There are two flavours of pax headers: Extended headers
     only affect the subsequent file header, global headers are valid
     for the complete archive and affect all following files. All the
     data in a pax header is encoded in `UTF-8' for portability reasons.

There are some more variants of the tar format which can be read, but
not created:

   * The ancient V7 format. This is the first tar format from Unix
     Seventh Edition, storing only regular files and directories. Names
     must not be longer than 100 characters, there is no user/group
     name information. Some archives have miscalculated header
     checksums in case of fields with non-ASCII characters.

   * The SunOS tar extended format. This format is a variant of the
     POSIX.1-2001 pax format, but is not compatible.


File: python.info,  Node: Unicode issues,  Prev: Supported tar formats,  Up: tarfile — Read and write tar archive files

5.12.5.5 Unicode issues
.......................

The tar format was originally conceived to make backups on tape drives
with the main focus on preserving file system information. Nowadays tar
archives are commonly used for file distribution and exchanging
archives over networks. One problem of the original format (that all
other formats are merely variants of) is that there is no concept of
supporting different character encodings. For example, an ordinary tar
archive created on a `UTF-8' system cannot be read correctly on a
`Latin-1' system if it contains non-ASCII characters. Names (i.e.
filenames, linknames, user/group names) containing these characters
will appear damaged.  Unfortunately, there is no way to autodetect the
encoding of an archive.

The pax format was designed to solve this problem. It stores non-ASCII
names using the universal character encoding `UTF-8'. When a pax
archive is read, these `UTF-8' names are converted to the encoding of
the local file system.

The details of unicode conversion are controlled by the `encoding' and
`errors' keyword arguments of the *Note TarFile: 268. class.

The default value for `encoding' is the local character encoding. It is
deduced from *Note sys.getfilesystemencoding(): 1012. and *Note
sys.getdefaultencoding(): 1044. In read mode, `encoding' is used
exclusively to convert unicode names from a pax archive to strings in
the local character encoding. In write mode, the use of `encoding'
depends on the chosen archive format. In case of *Note PAX_FORMAT: 1018,
input names that contain non-ASCII characters need to be decoded before
being stored as `UTF-8' strings. The other formats do not make use of
`encoding' unless unicode objects are used as input names. These are
converted to 8-bit character strings before they are added to the
archive.

The `errors' argument defines how characters are treated that cannot be
converted to or from `encoding'. Possible values are listed in section
*Note Codec Base Classes: 8e7. In read mode, there is an additional
scheme `'utf-8'' which means that bad characters are replaced by their
`UTF-8' representation. This is the default scheme. In write mode the
default value for `errors' is `'strict'' to ensure that name
information is not altered unnoticed.


File: python.info,  Node: File Formats,  Next: Cryptographic Services,  Prev: Data Compression and Archiving,  Up: The Python Standard Library

5.13 File Formats
=================

The modules described in this chapter parse various miscellaneous file
formats that aren’t markup languages or are related to e-mail.

* Menu:

* csv — CSV File Reading and Writing::
* ConfigParser — Configuration file parser::
* robotparser — Parser for robots.txt: robotparser — Parser for robots txt.
* netrc — netrc file processing::
* xdrlib — Encode and decode XDR data::
* plistlib — Generate and parse Mac OS X .plist files: plistlib — Generate and parse Mac OS X plist files.


File: python.info,  Node: csv — CSV File Reading and Writing,  Next: ConfigParser — Configuration file parser,  Up: File Formats

5.13.1 `csv' — CSV File Reading and Writing
---------------------------------------------

New in version 2.3.

The so-called CSV (Comma Separated Values) format is the most common
import and export format for spreadsheets and databases.  There is no
“CSV standard”, so the format is operationally defined by the many
applications which read and write it.  The lack of a standard means
that subtle differences often exist in the data produced and consumed
by different applications.  These differences can make it annoying to
process CSV files from multiple sources.  Still, while the delimiters
and quoting characters vary, the overall format is similar enough that
it is possible to write a single module which can efficiently manipulate
such data, hiding the details of reading and writing the data from the
programmer.

The *Note csv: 77. module implements classes to read and write tabular
data in CSV format.  It allows programmers to say, “write this data
in the format preferred by Excel,” or “read data from this file
which was generated by Excel,” without knowing the precise details of
the CSV format used by Excel.  Programmers can also describe the CSV
formats understood by other applications or define their own
special-purpose CSV formats.

The *Note csv: 77. module’s *Note reader: 104a. and *Note writer:
45e. objects read and write sequences.  Programmers can also read and
write data in dictionary form using the *Note DictReader: 104b. and
*Note DictWriter: 104c. classes.

     Note: This version of the *Note csv: 77. module doesn’t support
     Unicode input.  Also, there are currently some issues regarding
     ASCII NUL characters.  Accordingly, all input should be UTF-8 or
     printable ASCII to be safe; see the examples in section *Note
     Examples: 104d.

See also
........

PEP 305(1) - CSV File API
     The Python Enhancement Proposal which proposed this addition to
     Python.

* Menu:

* Module Contents: Module Contents<2>.
* Dialects and Formatting Parameters::
* Reader Objects::
* Writer Objects::
* Examples: Examples<4>.

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-0305


File: python.info,  Node: Module Contents<2>,  Next: Dialects and Formatting Parameters,  Up: csv — CSV File Reading and Writing

5.13.1.1 Module Contents
........................

The *Note csv: 77. module defines the following functions:

 -- Function: csv.reader (csvfile, dialect='excel', **fmtparams)
     Return a reader object which will iterate over lines in the given
     `csvfile'.  `csvfile' can be any object which supports the *Note
     iterator: 8a8. protocol and returns a string each time its
     `next()' method is called — file objects and list objects are
     both suitable.   If `csvfile' is a file object, it must be opened
     with the ‘b’ flag on platforms where that makes a difference.
     An optional `dialect' parameter can be given which is used to
     define a set of parameters specific to a particular CSV dialect.
     It may be an instance of a subclass of the *Note Dialect: 1050.
     class or one of the strings returned by the *Note list_dialects():
     1051. function.  The other optional `fmtparams' keyword arguments
     can be given to override individual formatting parameters in the
     current dialect.  For full details about the dialect and
     formatting parameters, see section *Note Dialects and Formatting
     Parameters: 1052.

     Each row read from the csv file is returned as a list of strings.
     No automatic data type conversion is performed.

     A short usage example:

         >>> import csv
         >>> with open('eggs.csv', 'rb') as csvfile:
         ...     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')
         ...     for row in spamreader:
         ...         print ', '.join(row)
         Spam, Spam, Spam, Spam, Spam, Baked Beans
         Spam, Lovely Spam, Wonderful Spam

     Changed in version 2.5: The parser is now stricter with respect to
     multi-line quoted fields. Previously, if a line ended within a
     quoted field without a terminating newline character, a newline
     would be inserted into the returned field. This behavior caused
     problems when reading files which contained carriage return
     characters within fields.  The behavior was changed to return the
     field without inserting newlines. As a consequence, if newlines
     embedded within fields are important, the input should be split
     into lines in a manner which preserves the newline characters.


 -- Function: csv.writer (csvfile, dialect='excel', **fmtparams)
     Return a writer object responsible for converting the user’s
     data into delimited strings on the given file-like object.
     `csvfile' can be any object with a `write()' method.  If `csvfile'
     is a file object, it must be opened with the ‘b’ flag on
     platforms where that makes a difference.  An optional `dialect'
     parameter can be given which is used to define a set of parameters
     specific to a particular CSV dialect.  It may be an instance of a
     subclass of the *Note Dialect: 1050. class or one of the strings
     returned by the *Note list_dialects(): 1051. function.  The other
     optional `fmtparams' keyword arguments can be given to override
     individual formatting parameters in the current dialect.  For full
     details about the dialect and formatting parameters, see section
     *Note Dialects and Formatting Parameters: 1052. To make it as easy
     as possible to interface with modules which implement the DB API,
     the value *Note None: 3b2. is written as the empty string.  While
     this isn’t a reversible transformation, it makes it easier to
     dump SQL NULL data values to CSV files without preprocessing the
     data returned from a `cursor.fetch*' call.  Floats are stringified
     with *Note repr(): 1c6. before being written.  All other
     non-string data are stringified with *Note str(): 1ea. before
     being written.

     A short usage example:

         import csv
         with open('eggs.csv', 'wb') as csvfile:
             spamwriter = csv.writer(csvfile, delimiter=' ',
                                     quotechar='|', quoting=csv.QUOTE_MINIMAL)
             spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])
             spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])

 -- Function: csv.register_dialect (name[, dialect], **fmtparams)
     Associate `dialect' with `name'.  `name' must be a string or
     Unicode object. The dialect can be specified either by passing a
     sub-class of *Note Dialect: 1050, or by `fmtparams' keyword
     arguments, or both, with keyword arguments overriding parameters
     of the dialect. For full details about the dialect and formatting
     parameters, see section *Note Dialects and Formatting Parameters:
     1052.

 -- Function: csv.unregister_dialect (name)
     Delete the dialect associated with `name' from the dialect
     registry.  An *Note Error: 1055. is raised if `name' is not a
     registered dialect name.

 -- Function: csv.get_dialect (name)
     Return the dialect associated with `name'.  An *Note Error: 1055.
     is raised if `name' is not a registered dialect name.

     Changed in version 2.5: This function now returns an immutable
     *Note Dialect: 1050.  Previously an instance of the requested
     dialect was returned.  Users could modify the underlying class,
     changing the behavior of active readers and writers.


 -- Function: csv.list_dialects ()
     Return the names of all registered dialects.

 -- Function: csv.field_size_limit ([new_limit])
     Returns the current maximum field size allowed by the parser. If
     `new_limit' is given, this becomes the new limit.

     New in version 2.5.


The *Note csv: 77. module defines the following classes:

 -- Class: csv.DictReader (csvfile, fieldnames=None, restkey=None,
          restval=None, dialect='excel', *args, **kwds)
     Create an object which operates like a regular reader but maps the
     information read into a dict whose keys are given by the optional
     `fieldnames' parameter.  The `fieldnames' parameter is a *Note
     sequence: b86. whose elements are associated with the fields of
     the input data in order. These elements become the keys of the
     resulting dictionary.  If the `fieldnames' parameter is omitted,
     the values in the first row of the `csvfile' will be used as the
     fieldnames.  If the row read has more fields than the fieldnames
     sequence, the remaining data is added as a sequence keyed by the
     value of `restkey'.  If the row read has fewer fields than the
     fieldnames sequence, the remaining keys take the value of the
     optional `restval' parameter.  Any other optional or keyword
     arguments are passed to the underlying *Note reader: 104a.
     instance.

     A short usage example:

         >>> import csv
         >>> with open('names.csv') as csvfile:
         ...     reader = csv.DictReader(csvfile)
         ...     for row in reader:
         ...         print(row['first_name'], row['last_name'])
         ...
         Baked Beans
         Lovely Spam
         Wonderful Spam

 -- Class: csv.DictWriter (csvfile, fieldnames, restval='',
          extrasaction='raise', dialect='excel', *args, **kwds)
     Create an object which operates like a regular writer but maps
     dictionaries onto output rows.  The `fieldnames' parameter is a
     *Note sequence: b86. of keys that identify the order in which
     values in the dictionary passed to the `writerow()' method are
     written to the `csvfile'.  The optional `restval' parameter
     specifies the value to be written if the dictionary is missing a
     key in `fieldnames'.  If the dictionary passed to the `writerow()'
     method contains a key not found in `fieldnames', the optional
     `extrasaction' parameter indicates what action to take.  If it is
     set to `'raise'' a *Note ValueError: 236. is raised.  If it is set
     to `'ignore'', extra values in the dictionary are ignored.  Any
     other optional or keyword arguments are passed to the underlying
     *Note writer: 45e. instance.

     Note that unlike the *Note DictReader: 104b. class, the
     `fieldnames' parameter of the *Note DictWriter: 104c. is not
     optional.  Since Python’s *Note dict: 319.  objects are not
     ordered, there is not enough information available to deduce the
     order in which the row should be written to the `csvfile'.

     A short usage example:

         import csv

         with open('names.csv', 'w') as csvfile:
             fieldnames = ['first_name', 'last_name']
             writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

             writer.writeheader()
             writer.writerow({'first_name': 'Baked', 'last_name': 'Beans'})
             writer.writerow({'first_name': 'Lovely', 'last_name': 'Spam'})
             writer.writerow({'first_name': 'Wonderful', 'last_name': 'Spam'})

 -- Class: csv.Dialect
     The *Note Dialect: 1050. class is a container class relied on
     primarily for its attributes, which are used to define the
     parameters for a specific *Note reader: 104a. or *Note writer:
     45e. instance.

 -- Class: csv.excel
     The *Note excel: 1058. class defines the usual properties of an
     Excel-generated CSV file.  It is registered with the dialect name
     `'excel''.

 -- Class: csv.excel_tab
     The *Note excel_tab: 1059. class defines the usual properties of
     an Excel-generated TAB-delimited file.  It is registered with the
     dialect name `'excel-tab''.

 -- Class: csv.Sniffer
     The *Note Sniffer: 105a. class is used to deduce the format of a
     CSV file.

     The *Note Sniffer: 105a. class provides two methods:

      -- Method: sniff (sample, delimiters=None)
          Analyze the given `sample' and return a *Note Dialect: 1050.
          subclass reflecting the parameters found.  If the optional
          `delimiters' parameter is given, it is interpreted as a
          string containing possible valid delimiter characters.

      -- Method: has_header (sample)
          Analyze the sample text (presumed to be in CSV format) and
          return *Note True: 3c8. if the first row appears to be a
          series of column headers.

An example for *Note Sniffer: 105a. use:

    with open('example.csv', 'rb') as csvfile:
        dialect = csv.Sniffer().sniff(csvfile.read(1024))
        csvfile.seek(0)
        reader = csv.reader(csvfile, dialect)
        # ... process CSV file contents here ...

The *Note csv: 77. module defines the following constants:

 -- Data: csv.QUOTE_ALL
     Instructs *Note writer: 45e. objects to quote all fields.

 -- Data: csv.QUOTE_MINIMAL
     Instructs *Note writer: 45e. objects to only quote those fields
     which contain special characters such as `delimiter', `quotechar'
     or any of the characters in `lineterminator'.

 -- Data: csv.QUOTE_NONNUMERIC
     Instructs *Note writer: 45e. objects to quote all non-numeric
     fields.

     Instructs the reader to convert all non-quoted fields to type
     `float'.

 -- Data: csv.QUOTE_NONE
     Instructs *Note writer: 45e. objects to never quote fields.  When
     the current `delimiter' occurs in output data it is preceded by
     the current `escapechar' character.  If `escapechar' is not set,
     the writer will raise *Note Error: 1055. if any characters that
     require escaping are encountered.

     Instructs *Note reader: 104a. to perform no special processing of
     quote characters.

The *Note csv: 77. module defines the following exception:

 -- Exception: csv.Error
     Raised by any of the functions when an error is detected.


File: python.info,  Node: Dialects and Formatting Parameters,  Next: Reader Objects,  Prev: Module Contents<2>,  Up: csv — CSV File Reading and Writing

5.13.1.2 Dialects and Formatting Parameters
...........................................

To make it easier to specify the format of input and output records,
specific formatting parameters are grouped together into dialects.  A
dialect is a subclass of the *Note Dialect: 1050. class having a set of
specific methods and a single `validate()' method.  When creating *Note
reader: 104a. or *Note writer: 45e. objects, the programmer can specify
a string or a subclass of the *Note Dialect: 1050. class as the dialect
parameter.  In addition to, or instead of, the `dialect' parameter, the
programmer can also specify individual formatting parameters, which
have the same names as the attributes defined below for the *Note
Dialect: 1050. class.

Dialects support the following attributes:

 -- Attribute: Dialect.delimiter
     A one-character string used to separate fields.  It defaults to
     `',''.

 -- Attribute: Dialect.doublequote
     Controls how instances of `quotechar' appearing inside a field
     should themselves be quoted.  When *Note True: 3c8, the character
     is doubled. When *Note False: 3c9, the `escapechar' is used as a
     prefix to the `quotechar'.  It defaults to *Note True: 3c8.

     On output, if `doublequote' is *Note False: 3c9. and no
     `escapechar' is set, *Note Error: 1055. is raised if a `quotechar'
     is found in a field.

 -- Attribute: Dialect.escapechar
     A one-character string used by the writer to escape the
     `delimiter' if `quoting' is set to *Note QUOTE_NONE: 1060. and the
     `quotechar' if `doublequote' is *Note False: 3c9. On reading, the
     `escapechar' removes any special meaning from the following
     character. It defaults to *Note None: 3b2, which disables escaping.

 -- Attribute: Dialect.lineterminator
     The string used to terminate lines produced by the *Note writer:
     45e. It defaults to `'\r\n''.

          Note: The *Note reader: 104a. is hard-coded to recognise
          either `'\r'' or `'\n'' as end-of-line, and ignores
          `lineterminator'. This behavior may change in the future.

 -- Attribute: Dialect.quotechar
     A one-character string used to quote fields containing special
     characters, such as the `delimiter' or `quotechar', or which
     contain new-line characters.  It defaults to `'"''.

 -- Attribute: Dialect.quoting
     Controls when quotes should be generated by the writer and
     recognised by the reader.  It can take on any of the `QUOTE_*'
     constants (see section *Note Module Contents: 104f.) and defaults
     to *Note QUOTE_MINIMAL: 105e.

 -- Attribute: Dialect.skipinitialspace
     When *Note True: 3c8, whitespace immediately following the
     `delimiter' is ignored.  The default is *Note False: 3c9.

 -- Attribute: Dialect.strict
     When `True', raise exception *Note Error: 1055. on bad CSV input.
     The default is `False'.


File: python.info,  Node: Reader Objects,  Next: Writer Objects,  Prev: Dialects and Formatting Parameters,  Up: csv — CSV File Reading and Writing

5.13.1.3 Reader Objects
.......................

Reader objects (*Note DictReader: 104b. instances and objects returned
by the *Note reader(): 104a. function) have the following public
methods:

 -- Method: csvreader.next ()
     Return the next row of the reader’s iterable object as a list,
     parsed according to the current dialect.

Reader objects have the following public attributes:

 -- Attribute: csvreader.dialect
     A read-only description of the dialect in use by the parser.

 -- Attribute: csvreader.line_num
     The number of lines read from the source iterator. This is not the
     same as the number of records returned, as records can span
     multiple lines.

     New in version 2.5.


DictReader objects have the following public attribute:

 -- Attribute: csvreader.fieldnames
     If not passed as a parameter when creating the object, this
     attribute is initialized upon first access or when the first
     record is read from the file.

     Changed in version 2.6.



File: python.info,  Node: Writer Objects,  Next: Examples<4>,  Prev: Reader Objects,  Up: csv — CSV File Reading and Writing

5.13.1.4 Writer Objects
.......................

`Writer' objects (*Note DictWriter: 104c. instances and objects
returned by the *Note writer(): 45e. function) have the following
public methods.  A `row' must be a sequence of strings or numbers for
`Writer' objects and a dictionary mapping fieldnames to strings or
numbers (by passing them through *Note str(): 1ea.  first) for *Note
DictWriter: 104c. objects.  Note that complex numbers are written out
surrounded by parens. This may cause some problems for other programs
which read CSV files (assuming they support complex numbers at all).

 -- Method: csvwriter.writerow (row)
     Write the `row' parameter to the writer’s file object, formatted
     according to the current dialect.

 -- Method: csvwriter.writerows (rows)
     Write all the `rows' parameters (a list of `row' objects as
     described above) to the writer’s file object, formatted
     according to the current dialect.

Writer objects have the following public attribute:

 -- Attribute: csvwriter.dialect
     A read-only description of the dialect in use by the writer.

DictWriter objects have the following public method:

 -- Method: DictWriter.writeheader ()
     Write a row with the field names (as specified in the constructor).

     New in version 2.7.



File: python.info,  Node: Examples<4>,  Prev: Writer Objects,  Up: csv — CSV File Reading and Writing

5.13.1.5 Examples
.................

The simplest example of reading a CSV file:

    import csv
    with open('some.csv', 'rb') as f:
        reader = csv.reader(f)
        for row in reader:
            print row

Reading a file with an alternate format:

    import csv
    with open('passwd', 'rb') as f:
        reader = csv.reader(f, delimiter=':', quoting=csv.QUOTE_NONE)
        for row in reader:
            print row

The corresponding simplest possible writing example is:

    import csv
    with open('some.csv', 'wb') as f:
        writer = csv.writer(f)
        writer.writerows(someiterable)

Registering a new dialect:

    import csv
    csv.register_dialect('unixpwd', delimiter=':', quoting=csv.QUOTE_NONE)
    with open('passwd', 'rb') as f:
        reader = csv.reader(f, 'unixpwd')

A slightly more advanced use of the reader — catching and reporting
errors:

    import csv, sys
    filename = 'some.csv'
    with open(filename, 'rb') as f:
        reader = csv.reader(f)
        try:
            for row in reader:
                print row
        except csv.Error as e:
            sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))

And while the module doesn’t directly support parsing strings, it can
easily be done:

    import csv
    for row in csv.reader(['one,two,three']):
        print row

The *Note csv: 77. module doesn’t directly support reading and
writing Unicode, but it is 8-bit-clean save for some problems with
ASCII NUL characters.  So you can write functions or classes that
handle the encoding and decoding for you as long as you avoid encodings
like UTF-16 that use NULs.  UTF-8 is recommended.

`unicode_csv_reader()' below is a *Note generator: 5f7. that wraps
*Note csv.reader: 104a.  to handle Unicode CSV data (a list of Unicode
strings).  `utf_8_encoder()' is a *Note generator: 5f7. that encodes
the Unicode strings as UTF-8, one string (or row) at a time.  The
encoded strings are parsed by the CSV reader, and
`unicode_csv_reader()' decodes the UTF-8-encoded cells back into
Unicode:

    import csv

    def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):
        # csv.py doesn't do Unicode; encode temporarily as UTF-8:
        csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),
                                dialect=dialect, **kwargs)
        for row in csv_reader:
            # decode UTF-8 back to Unicode, cell by cell:
            yield [unicode(cell, 'utf-8') for cell in row]

    def utf_8_encoder(unicode_csv_data):
        for line in unicode_csv_data:
            yield line.encode('utf-8')

For all other encodings the following `UnicodeReader' and
`UnicodeWriter' classes can be used. They take an additional `encoding'
parameter in their constructor and make sure that the data passes the
real reader or writer encoded as UTF-8:

    import csv, codecs, cStringIO

    class UTF8Recoder:
        """
        Iterator that reads an encoded stream and reencodes the input to UTF-8
        """
        def __init__(self, f, encoding):
            self.reader = codecs.getreader(encoding)(f)

        def __iter__(self):
            return self

        def next(self):
            return self.reader.next().encode("utf-8")

    class UnicodeReader:
        """
        A CSV reader which will iterate over lines in the CSV file "f",
        which is encoded in the given encoding.
        """

        def __init__(self, f, dialect=csv.excel, encoding="utf-8", **kwds):
            f = UTF8Recoder(f, encoding)
            self.reader = csv.reader(f, dialect=dialect, **kwds)

        def next(self):
            row = self.reader.next()
            return [unicode(s, "utf-8") for s in row]

        def __iter__(self):
            return self

    class UnicodeWriter:
        """
        A CSV writer which will write rows to CSV file "f",
        which is encoded in the given encoding.
        """

        def __init__(self, f, dialect=csv.excel, encoding="utf-8", **kwds):
            # Redirect output to a queue
            self.queue = cStringIO.StringIO()
            self.writer = csv.writer(self.queue, dialect=dialect, **kwds)
            self.stream = f
            self.encoder = codecs.getincrementalencoder(encoding)()

        def writerow(self, row):
            self.writer.writerow([s.encode("utf-8") for s in row])
            # Fetch UTF-8 output from the queue ...
            data = self.queue.getvalue()
            data = data.decode("utf-8")
            # ... and reencode it into the target encoding
            data = self.encoder.encode(data)
            # write to the target stream
            self.stream.write(data)
            # empty queue
            self.queue.truncate(0)

        def writerows(self, rows):
            for row in rows:
                self.writerow(row)


File: python.info,  Node: ConfigParser — Configuration file parser,  Next: robotparser — Parser for robots txt,  Prev: csv — CSV File Reading and Writing,  Up: File Formats

5.13.2 `ConfigParser' — Configuration file parser
---------------------------------------------------

     Note: The *Note ConfigParser: 6d. module has been renamed to
     `configparser' in Python 3.  The *Note 2to3: c05. tool will
     automatically adapt imports when converting your sources to Python
     3.

This module defines the class *Note ConfigParser: 1077.   The *Note
ConfigParser: 1077.  class implements a basic configuration file parser
language which provides a structure similar to what you would find on
Microsoft Windows INI files.  You can use this to write Python programs
which can be customized by end users easily.

     Note: This library does `not' interpret or write the value-type
     prefixes used in the Windows Registry extended version of INI
     syntax.

See also
........

Module *Note shlex: 153.
     Support for a creating Unix shell-like mini-languages which can be
     used as an alternate format for application configuration files.

Module *Note json: fd.
     The json module implements a subset of JavaScript syntax which can
     also be used for this purpose.

The configuration file consists of sections, led by a `[section]'
header and followed by `name: value' entries, with continuations in the
style of RFC 822(1) (see section 3.1.1, “LONG HEADER FIELDS”);
`name=value' is also accepted.  Note that leading whitespace is removed
from values. The optional values can contain format strings which refer
to other values in the same section, or values in a special `DEFAULT'
section.  Additional defaults can be provided on initialization and
retrieval.  Lines beginning with `'#'' or `';'' are ignored and may be
used to provide comments.

Configuration files may include comments, prefixed by specific
characters (`#' and `;').  Comments may appear on their own in an
otherwise empty line, or may be entered in lines holding values or
section names.  In the latter case, they need to be preceded by a
whitespace character to be recognized as a comment.  (For backwards
compatibility, only `;' starts an inline comment, while `#' does not.)

On top of the core functionality, *Note SafeConfigParser: 1078. supports
interpolation.  This means values can contain format strings which
refer to other values in the same section, or values in a special
`DEFAULT' section.  Additional defaults can be provided on
initialization.

For example:

    [My Section]
    foodir: %(dir)s/whatever
    dir=frob
    long: this value continues
       in the next line

would resolve the `%(dir)s' to the value of `dir' (`frob' in this case).
All reference expansions are done on demand.

Default values can be specified by passing them into the *Note
ConfigParser: 1077.  constructor as a dictionary.  Additional defaults
may be passed into the `get()' method which will override all others.

Sections are normally stored in a built-in dictionary. An alternative
dictionary type can be passed to the *Note ConfigParser: 1077.
constructor. For example, if a dictionary type is passed that sorts its
keys, the sections will be sorted on write-back, as will be the keys
within each section.

 -- Class: ConfigParser.RawConfigParser ([defaults[, dict_type[,
          allow_no_value]]])
     The basic configuration object.  When `defaults' is given, it is
     initialized into the dictionary of intrinsic defaults.  When
     `dict_type' is given, it will be used to create the dictionary
     objects for the list of sections, for the options within a
     section, and for the default values.  When `allow_no_value' is
     true (default: `False'), options without values are accepted; the
     value presented for these is `None'.

     This class does not support the magical interpolation behavior.

     All option names are passed through the *Note optionxform(): 107a.
     method.  Its default implementation converts option names to lower
     case.

     New in version 2.3.

     Changed in version 2.6: `dict_type' was added.

     Changed in version 2.7: The default `dict_type' is *Note
     collections.OrderedDict: 1b6.  `allow_no_value' was added.


 -- Class: ConfigParser.ConfigParser ([defaults[, dict_type[,
          allow_no_value]]])
     Derived class of *Note RawConfigParser: 1079. that implements the
     magical interpolation feature and adds optional arguments to the
     *Note get(): 107b. and *Note items(): 107c. methods.  The values
     in `defaults' must be appropriate for the `%()s' string
     interpolation.  Note that `__name__' is an intrinsic default; its
     value is the section name, and will override any value provided in
     `defaults'.

     All option names used in interpolation will be passed through the
     `optionxform()' method just like any other option name reference.
     Using the default implementation of `optionxform()', the values
     `foo %(bar)s' and `foo %(BAR)s' are equivalent.

     New in version 2.3.

     Changed in version 2.6: `dict_type' was added.

     Changed in version 2.7: The default `dict_type' is *Note
     collections.OrderedDict: 1b6.  `allow_no_value' was added.


 -- Class: ConfigParser.SafeConfigParser ([defaults[, dict_type[,
          allow_no_value]]])
     Derived class of *Note ConfigParser: 1077. that implements a
     more-sane variant of the magical interpolation feature.  This
     implementation is more predictable as well. New applications
     should prefer this version if they don’t need to be compatible
     with older versions of Python.

     New in version 2.3.

     Changed in version 2.6: `dict_type' was added.

     Changed in version 2.7: The default `dict_type' is *Note
     collections.OrderedDict: 1b6.  `allow_no_value' was added.


 -- Exception: ConfigParser.Error
     Base class for all other configparser exceptions.

 -- Exception: ConfigParser.NoSectionError
     Exception raised when a specified section is not found.

 -- Exception: ConfigParser.DuplicateSectionError
     Exception raised if `add_section()' is called with the name of a
     section that is already present.

 -- Exception: ConfigParser.NoOptionError
     Exception raised when a specified option is not found in the
     specified  section.

 -- Exception: ConfigParser.InterpolationError
     Base class for exceptions raised when problems occur performing
     string interpolation.

 -- Exception: ConfigParser.InterpolationDepthError
     Exception raised when string interpolation cannot be completed
     because the number of iterations exceeds *Note
     MAX_INTERPOLATION_DEPTH: 1083. Subclass of *Note
     InterpolationError: 1081.

 -- Exception: ConfigParser.InterpolationMissingOptionError
     Exception raised when an option referenced from a value does not
     exist. Subclass of *Note InterpolationError: 1081.

     New in version 2.3.


 -- Exception: ConfigParser.InterpolationSyntaxError
     Exception raised when the source text into which substitutions are
     made does not conform to the required syntax. Subclass of *Note
     InterpolationError: 1081.

     New in version 2.3.


 -- Exception: ConfigParser.MissingSectionHeaderError
     Exception raised when attempting to parse a file which has no
     section headers.

 -- Exception: ConfigParser.ParsingError
     Exception raised when errors occur attempting to parse a file.

 -- Data: ConfigParser.MAX_INTERPOLATION_DEPTH
     The maximum depth for recursive interpolation for `get()' when the
     `raw' parameter is false.  This is relevant only for the *Note
     ConfigParser: 1077. class.

See also
........

Module *Note shlex: 153.
     Support for a creating Unix shell-like mini-languages which can be
     used as an alternate format for application configuration files.

* Menu:

* RawConfigParser Objects::
* ConfigParser Objects::
* SafeConfigParser Objects::
* Examples: Examples<5>.

---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc822.html


File: python.info,  Node: RawConfigParser Objects,  Next: ConfigParser Objects,  Up: ConfigParser — Configuration file parser

5.13.2.1 RawConfigParser Objects
................................

*Note RawConfigParser: 1079. instances have the following methods:

 -- Method: RawConfigParser.defaults ()
     Return a dictionary containing the instance-wide defaults.

 -- Method: RawConfigParser.sections ()
     Return a list of the sections available; `DEFAULT' is not included
     in the list.

 -- Method: RawConfigParser.add_section (section)
     Add a section named `section' to the instance.  If a section by
     the given name already exists, *Note DuplicateSectionError: 107f.
     is raised. If the name `DEFAULT' (or any of it’s
     case-insensitive variants) is passed, *Note ValueError: 236. is
     raised.

 -- Method: RawConfigParser.has_section (section)
     Indicates whether the named section is present in the
     configuration. The `DEFAULT' section is not acknowledged.

 -- Method: RawConfigParser.options (section)
     Returns a list of options available in the specified `section'.

 -- Method: RawConfigParser.has_option (section, option)
     If the given section exists, and contains the given option, return
     *Note True: 3c8.; otherwise return *Note False: 3c9.

     New in version 1.6.


 -- Method: RawConfigParser.read (filenames)
     Attempt to read and parse a list of filenames, returning a list of
     filenames which were successfully parsed.  If `filenames' is a
     string or Unicode string, it is treated as a single filename. If a
     file named in `filenames' cannot be opened, that file will be
     ignored.  This is designed so that you can specify a list of
     potential configuration file locations (for example, the current
     directory, the user’s home directory, and some system-wide
     directory), and all existing configuration files in the list will
     be read.  If none of the named files exist, the *Note
     ConfigParser: 1077. instance will contain an empty dataset.  An
     application which requires initial values to be loaded from a file
     should load the required file or files using *Note readfp(): 1091.
     before calling *Note read(): 1090.  for any optional files:

         import ConfigParser, os

         config = ConfigParser.ConfigParser()
         config.readfp(open('defaults.cfg'))
         config.read(['site.cfg', os.path.expanduser('~/.myapp.cfg')])

     Changed in version 2.4: Returns list of successfully parsed
     filenames.


 -- Method: RawConfigParser.readfp (fp[, filename])
     Read and parse configuration data from the file or file-like
     object in `fp' (only the *Note readline(): 145. method is used).
     If `filename' is omitted and `fp' has a `name' attribute, that is
     used for `filename'; the default is `<???>'.

 -- Method: RawConfigParser.get (section, option)
     Get an `option' value for the named `section'.

 -- Method: RawConfigParser.getint (section, option)
     A convenience method which coerces the `option' in the specified
     `section' to an integer.

 -- Method: RawConfigParser.getfloat (section, option)
     A convenience method which coerces the `option' in the specified
     `section' to a floating point number.

 -- Method: RawConfigParser.getboolean (section, option)
     A convenience method which coerces the `option' in the specified
     `section' to a Boolean value.  Note that the accepted values for
     the option are `"1"', `"yes"', `"true"', and `"on"', which cause
     this method to return `True', and `"0"', `"no"', `"false"', and
     `"off"', which cause it to return `False'.  These string values
     are checked in a case-insensitive manner.  Any other value will
     cause it to raise *Note ValueError: 236.

 -- Method: RawConfigParser.items (section)
     Return a list of `(name, value)' pairs for each option in the
     given `section'.

 -- Method: RawConfigParser.set (section, option, value)
     If the given section exists, set the given option to the specified
     value; otherwise raise *Note NoSectionError: 107e.  While it is
     possible to use *Note RawConfigParser: 1079. (or *Note
     ConfigParser: 1077. with `raw' parameters set to true) for
     `internal' storage of non-string values, full functionality
     (including interpolation and output to files) can only be achieved
     using string values.

     New in version 1.6.


 -- Method: RawConfigParser.write (fileobject)
     Write a representation of the configuration to the specified file
     object.  This representation can be parsed by a future *Note
     read(): 1090. call.

     New in version 1.6.


 -- Method: RawConfigParser.remove_option (section, option)
     Remove the specified `option' from the specified `section'. If the
     section does not exist, raise *Note NoSectionError: 107e.  If the
     option existed to be removed, return *Note True: 3c8.; otherwise
     return *Note False: 3c9.

     New in version 1.6.


 -- Method: RawConfigParser.remove_section (section)
     Remove the specified `section' from the configuration. If the
     section in fact existed, return `True'. Otherwise return `False'.

 -- Method: RawConfigParser.optionxform (option)
     Transforms the option name `option' as found in an input file or
     as passed in by client code to the form that should be used in the
     internal structures.  The default implementation returns a
     lower-case version of `option'; subclasses may override this or
     client code can set an attribute of this name on instances to
     affect this behavior.

     You don’t necessarily need to subclass a ConfigParser to use
     this method, you can also re-set it on an instance, to a function
     that takes a string argument.  Setting it to `str', for example,
     would make option names case sensitive:

         cfgparser = ConfigParser()
         ...
         cfgparser.optionxform = str

     Note that when reading configuration files, whitespace around the
     option names are stripped before *Note optionxform(): 107a. is
     called.


File: python.info,  Node: ConfigParser Objects,  Next: SafeConfigParser Objects,  Prev: RawConfigParser Objects,  Up: ConfigParser — Configuration file parser

5.13.2.2 ConfigParser Objects
.............................

The *Note ConfigParser: 1077. class extends some methods of the *Note
RawConfigParser: 1079. interface, adding some optional arguments.

 -- Method: ConfigParser.get (section, option[, raw[, vars]])
     Get an `option' value for the named `section'.  If `vars' is
     provided, it must be a dictionary.  The `option' is looked up in
     `vars' (if provided), `section', and in `defaults' in that order.

     All the `'%'' interpolations are expanded in the return values,
     unless the `raw' argument is true.  Values for interpolation keys
     are looked up in the same manner as the option.

 -- Method: ConfigParser.items (section[, raw[, vars]])
     Return a list of `(name, value)' pairs for each option in the
     given `section'.  Optional arguments have the same meaning as for
     the *Note get(): 107b. method.

     New in version 2.3.



File: python.info,  Node: SafeConfigParser Objects,  Next: Examples<5>,  Prev: ConfigParser Objects,  Up: ConfigParser — Configuration file parser

5.13.2.3 SafeConfigParser Objects
.................................

The *Note SafeConfigParser: 1078. class implements the same extended
interface as *Note ConfigParser: 1077, with the following addition:

 -- Method: SafeConfigParser.set (section, option, value)
     If the given section exists, set the given option to the specified
     value; otherwise raise *Note NoSectionError: 107e.  `value' must
     be a string (*Note str: 1ea.  or *Note unicode: 1f5.); if not,
     *Note TypeError: 218. is raised.

     New in version 2.4.



File: python.info,  Node: Examples<5>,  Prev: SafeConfigParser Objects,  Up: ConfigParser — Configuration file parser

5.13.2.4 Examples
.................

An example of writing to a configuration file:

    import ConfigParser

    config = ConfigParser.RawConfigParser()

    # When adding sections or items, add them in the reverse order of
    # how you want them to be displayed in the actual file.
    # In addition, please note that using RawConfigParser's and the raw
    # mode of ConfigParser's respective set functions, you can assign
    # non-string values to keys internally, but will receive an error
    # when attempting to write to a file or when you get it in non-raw
    # mode. SafeConfigParser does not allow such assignments to take place.
    config.add_section('Section1')
    config.set('Section1', 'an_int', '15')
    config.set('Section1', 'a_bool', 'true')
    config.set('Section1', 'a_float', '3.1415')
    config.set('Section1', 'baz', 'fun')
    config.set('Section1', 'bar', 'Python')
    config.set('Section1', 'foo', '%(bar)s is %(baz)s!')

    # Writing our configuration file to 'example.cfg'
    with open('example.cfg', 'wb') as configfile:
        config.write(configfile)

An example of reading the configuration file again:

    import ConfigParser

    config = ConfigParser.RawConfigParser()
    config.read('example.cfg')

    # getfloat() raises an exception if the value is not a float
    # getint() and getboolean() also do this for their respective types
    a_float = config.getfloat('Section1', 'a_float')
    an_int = config.getint('Section1', 'an_int')
    print a_float + an_int

    # Notice that the next output does not interpolate '%(bar)s' or '%(baz)s'.
    # This is because we are using a RawConfigParser().
    if config.getboolean('Section1', 'a_bool'):
        print config.get('Section1', 'foo')

To get interpolation, you will need to use a *Note ConfigParser: 1077.
or *Note SafeConfigParser: 1078.:

    import ConfigParser

    config = ConfigParser.ConfigParser()
    config.read('example.cfg')

    # Set the third, optional argument of get to 1 if you wish to use raw mode.
    print config.get('Section1', 'foo', 0)  # -> "Python is fun!"
    print config.get('Section1', 'foo', 1)  # -> "%(bar)s is %(baz)s!"

    # The optional fourth argument is a dict with members that will take
    # precedence in interpolation.
    print config.get('Section1', 'foo', 0, {'bar': 'Documentation',
                                            'baz': 'evil'})

Defaults are available in all three types of ConfigParsers. They are
used in interpolation if an option used is not defined elsewhere.

    import ConfigParser

    # New instance with 'bar' and 'baz' defaulting to 'Life' and 'hard' each
    config = ConfigParser.SafeConfigParser({'bar': 'Life', 'baz': 'hard'})
    config.read('example.cfg')

    print config.get('Section1', 'foo')  # -> "Python is fun!"
    config.remove_option('Section1', 'bar')
    config.remove_option('Section1', 'baz')
    print config.get('Section1', 'foo')  # -> "Life is hard!"

The function `opt_move' below can be used to move options between
sections:

    def opt_move(config, section1, section2, option):
        try:
            config.set(section2, option, config.get(section1, option, 1))
        except ConfigParser.NoSectionError:
            # Create non-existent section
            config.add_section(section2)
            opt_move(config, section1, section2, option)
        else:
            config.remove_option(section1, option)

Some configuration files are known to include settings without values,
but which otherwise conform to the syntax supported by *Note
ConfigParser: 6d.  The `allow_no_value' parameter to the constructor
can be used to indicate that such values should be accepted:

    >>> import ConfigParser
    >>> import io

    >>> sample_config = """
    ... [mysqld]
    ... user = mysql
    ... pid-file = /var/run/mysqld/mysqld.pid
    ... skip-external-locking
    ... old_passwords = 1
    ... skip-bdb
    ... skip-innodb
    ... """
    >>> config = ConfigParser.RawConfigParser(allow_no_value=True)
    >>> config.readfp(io.BytesIO(sample_config))

    >>> # Settings with values are treated as before:
    >>> config.get("mysqld", "user")
    'mysql'

    >>> # Settings without values provide None:
    >>> config.get("mysqld", "skip-bdb")

    >>> # Settings which aren't specified still raise an error:
    >>> config.get("mysqld", "does-not-exist")
    Traceback (most recent call last):
      ...
    ConfigParser.NoOptionError: No option 'does-not-exist' in section: 'mysqld'


File: python.info,  Node: robotparser — Parser for robots txt,  Next: netrc — netrc file processing,  Prev: ConfigParser — Configuration file parser,  Up: File Formats

5.13.3 `robotparser' —  Parser for robots.txt
-----------------------------------------------

     Note: The *Note robotparser: 14a. module has been renamed
     `urllib.robotparser' in Python 3.  The *Note 2to3: c05. tool will
     automatically adapt imports when converting your sources to Python
     3.

This module provides a single class, *Note RobotFileParser: 10a3, which
answers questions about whether or not a particular user agent can
fetch a URL on the Web site that published the `robots.txt' file.  For
more details on the structure of `robots.txt' files, see
<http://www.robotstxt.org/orig.html>.

 -- Class: robotparser.RobotFileParser (url='')
     This class provides methods to read, parse and answer questions
     about the `robots.txt' file at `url'.

      -- Method: set_url (url)
          Sets the URL referring to a `robots.txt' file.

      -- Method: read ()
          Reads the `robots.txt' URL and feeds it to the parser.

      -- Method: parse (lines)
          Parses the lines argument.

      -- Method: can_fetch (useragent, url)
          Returns `True' if the `useragent' is allowed to fetch the
          `url' according to the rules contained in the parsed
          `robots.txt' file.

      -- Method: mtime ()
          Returns the time the `robots.txt' file was last fetched.
          This is useful for long-running web spiders that need to
          check for new `robots.txt' files periodically.

      -- Method: modified ()
          Sets the time the `robots.txt' file was last fetched to the
          current time.

The following example demonstrates basic use of the RobotFileParser
class.

    >>> import robotparser
    >>> rp = robotparser.RobotFileParser()
    >>> rp.set_url("http://www.musi-cal.com/robots.txt")
    >>> rp.read()
    >>> rp.can_fetch("*", "http://www.musi-cal.com/cgi-bin/search?city=San+Francisco")
    False
    >>> rp.can_fetch("*", "http://www.musi-cal.com/")
    True


File: python.info,  Node: netrc — netrc file processing,  Next: xdrlib — Encode and decode XDR data,  Prev: robotparser — Parser for robots txt,  Up: File Formats

5.13.4 `netrc' — netrc file processing
----------------------------------------

New in version 1.5.2.

`Source code:' Lib/netrc.py(1)

__________________________________________________________________

The *Note netrc: 10ac. class parses and encapsulates the netrc file
format used by the Unix `ftp' program and other FTP clients.

 -- Class: netrc.netrc ([file])
     A *Note netrc: 10ac. instance or subclass instance encapsulates
     data from  a netrc file.  The initialization argument, if present,
     specifies the file to parse.  If no argument is given, the file
     `.netrc' in the user’s home directory will be read.  Parse
     errors will raise *Note NetrcParseError: 10ad. with diagnostic
     information including the file name, line number, and terminating
     token.  If no argument is specified on a POSIX system, the
     presence of passwords in the `.netrc' file will raise a *Note
     NetrcParseError: 10ad. if the file ownership or permissions are
     insecure (owned by a user other than the user running the process,
     or accessible for read or write by any other user).  This
     implements security behavior equivalent to that of ftp and other
     programs that use `.netrc'.

     Changed in version 2.7.6: Added the POSIX permissions check.


 -- Exception: netrc.NetrcParseError
     Exception raised by the *Note netrc: 10ac. class when syntactical
     errors are encountered in source text.  Instances of this
     exception provide three interesting attributes:  `msg' is a
     textual explanation of the error, `filename' is the name of the
     source file, and `lineno' gives the line number on which the error
     was found.

* Menu:

* netrc Objects::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/netrc.py


File: python.info,  Node: netrc Objects,  Up: netrc — netrc file processing

5.13.4.1 netrc Objects
......................

A *Note netrc: 10ac. instance has the following methods:

 -- Method: netrc.authenticators (host)
     Return a 3-tuple `(login, account, password)' of authenticators
     for `host'.  If the netrc file did not contain an entry for the
     given host, return the tuple associated with the ‘default’
     entry.  If neither matching host nor default entry is available,
     return `None'.

 -- Method: netrc.__repr__ ()
     Dump the class data as a string in the format of a netrc file.
     (This discards comments and may reorder the entries.)

Instances of *Note netrc: 10ac. have public instance variables:

 -- Attribute: netrc.hosts
     Dictionary mapping host names to `(login, account, password)'
     tuples.  The ‘default’ entry, if any, is represented as a
     pseudo-host by that name.

 -- Attribute: netrc.macros
     Dictionary mapping macro names to string lists.

     Note: Passwords are limited to a subset of the ASCII character
     set. Versions of this module prior to 2.3 were extremely limited.
     Starting with 2.3, all ASCII punctuation is allowed in passwords.
     However, note that whitespace and non-printable characters are not
     allowed in passwords.  This is a limitation of the way the .netrc
     file is parsed and may be removed in the future.


File: python.info,  Node: xdrlib — Encode and decode XDR data,  Next: plistlib — Generate and parse Mac OS X plist files,  Prev: netrc — netrc file processing,  Up: File Formats

5.13.5 `xdrlib' — Encode and decode XDR data
----------------------------------------------

`Source code:' Lib/xdrlib.py(1)

__________________________________________________________________

The *Note xdrlib: 19f. module supports the External Data Representation
Standard as described in RFC 1014(2), written by Sun Microsystems, Inc.
June 1987.  It supports most of the data types described in the RFC.

The *Note xdrlib: 19f. module defines two classes, one for packing
variables into XDR representation, and another for unpacking from XDR
representation.  There are also two exception classes.

 -- Class: xdrlib.Packer
     *Note Packer: 10b6. is the class for packing data into XDR
     representation. The *Note Packer: 10b6. class is instantiated with
     no arguments.

 -- Class: xdrlib.Unpacker (data)
     `Unpacker' is the complementary class which unpacks XDR data
     values from a string buffer.  The input buffer is given as `data'.

See also
........

RFC 1014(3) - XDR: External Data Representation Standard
     This RFC defined the encoding of data which was XDR at the time
     this module was originally written.  It has apparently been
     obsoleted by RFC 1832(4).

RFC 1832(5) - XDR: External Data Representation Standard
     Newer RFC that provides a revised definition of XDR.

* Menu:

* Packer Objects::
* Unpacker Objects::
* Exceptions: Exceptions<3>.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/xdrlib.py

(2) https://tools.ietf.org/html/rfc1014.html

(3) https://tools.ietf.org/html/rfc1014.html

(4) https://tools.ietf.org/html/rfc1832.html

(5) https://tools.ietf.org/html/rfc1832.html


File: python.info,  Node: Packer Objects,  Next: Unpacker Objects,  Up: xdrlib — Encode and decode XDR data

5.13.5.1 Packer Objects
.......................

*Note Packer: 10b6. instances have the following methods:

 -- Method: Packer.get_buffer ()
     Returns the current pack buffer as a string.

 -- Method: Packer.reset ()
     Resets the pack buffer to the empty string.

In general, you can pack any of the most common XDR data types by
calling the appropriate `pack_type()' method.  Each method takes a
single argument, the value to pack.  The following simple data type
packing methods are supported: `pack_uint()', `pack_int()',
`pack_enum()', `pack_bool()', `pack_uhyper()', and `pack_hyper()'.

 -- Method: Packer.pack_float (value)
     Packs the single-precision floating point number `value'.

 -- Method: Packer.pack_double (value)
     Packs the double-precision floating point number `value'.

The following methods support packing strings, bytes, and opaque data:

 -- Method: Packer.pack_fstring (n, s)
     Packs a fixed length string, `s'.  `n' is the length of the string
     but it is `not' packed into the data buffer.  The string is padded
     with null bytes if necessary to guaranteed 4 byte alignment.

 -- Method: Packer.pack_fopaque (n, data)
     Packs a fixed length opaque data stream, similarly to *Note
     pack_fstring(): 10be.

 -- Method: Packer.pack_string (s)
     Packs a variable length string, `s'.  The length of the string is
     first packed as an unsigned integer, then the string data is
     packed with *Note pack_fstring(): 10be.

 -- Method: Packer.pack_opaque (data)
     Packs a variable length opaque data string, similarly to *Note
     pack_string(): 10c0.

 -- Method: Packer.pack_bytes (bytes)
     Packs a variable length byte stream, similarly to *Note
     pack_string(): 10c0.

The following methods support packing arrays and lists:

 -- Method: Packer.pack_list (list, pack_item)
     Packs a `list' of homogeneous items.  This method is useful for
     lists with an indeterminate size; i.e. the size is not available
     until the entire list has been walked.  For each item in the list,
     an unsigned integer `1' is packed first, followed by the data
     value from the list.  `pack_item' is the function that is called
     to pack the individual item.  At the end of the list, an unsigned
     integer `0' is packed.

     For example, to pack a list of integers, the code might appear
     like this:

         import xdrlib
         p = xdrlib.Packer()
         p.pack_list([1, 2, 3], p.pack_int)

 -- Method: Packer.pack_farray (n, array, pack_item)
     Packs a fixed length list (`array') of homogeneous items.  `n' is
     the length of the list; it is `not' packed into the buffer, but a
     *Note ValueError: 236. exception is raised if `len(array)' is not
     equal to `n'.  As above, `pack_item' is the function used to pack
     each element.

 -- Method: Packer.pack_array (list, pack_item)
     Packs a variable length `list' of homogeneous items.  First, the
     length of the list is packed as an unsigned integer, then each
     element is packed as in *Note pack_farray(): 10c4. above.


File: python.info,  Node: Unpacker Objects,  Next: Exceptions<3>,  Prev: Packer Objects,  Up: xdrlib — Encode and decode XDR data

5.13.5.2 Unpacker Objects
.........................

The *Note Unpacker: 10b7. class offers the following methods:

 -- Method: Unpacker.reset (data)
     Resets the string buffer with the given `data'.

 -- Method: Unpacker.get_position ()
     Returns the current unpack position in the data buffer.

 -- Method: Unpacker.set_position (position)
     Sets the data buffer unpack position to `position'.  You should be
     careful about using *Note get_position(): 10c9. and *Note
     set_position(): 10ca.

 -- Method: Unpacker.get_buffer ()
     Returns the current unpack data buffer as a string.

 -- Method: Unpacker.done ()
     Indicates unpack completion.  Raises an *Note Error: 10cd.
     exception if all of the data has not been unpacked.

In addition, every data type that can be packed with a *Note Packer:
10b6, can be unpacked with an *Note Unpacker: 10b7.  Unpacking methods
are of the form `unpack_type()', and take no arguments.  They return
the unpacked object.

 -- Method: Unpacker.unpack_float ()
     Unpacks a single-precision floating point number.

 -- Method: Unpacker.unpack_double ()
     Unpacks a double-precision floating point number, similarly to
     *Note unpack_float(): 10ce.

In addition, the following methods unpack strings, bytes, and opaque
data:

 -- Method: Unpacker.unpack_fstring (n)
     Unpacks and returns a fixed length string.  `n' is the number of
     characters expected.  Padding with null bytes to guaranteed 4 byte
     alignment is assumed.

 -- Method: Unpacker.unpack_fopaque (n)
     Unpacks and returns a fixed length opaque data stream, similarly to
     *Note unpack_fstring(): 10d0.

 -- Method: Unpacker.unpack_string ()
     Unpacks and returns a variable length string.  The length of the
     string is first unpacked as an unsigned integer, then the string
     data is unpacked with *Note unpack_fstring(): 10d0.

 -- Method: Unpacker.unpack_opaque ()
     Unpacks and returns a variable length opaque data string,
     similarly to *Note unpack_string(): 10d2.

 -- Method: Unpacker.unpack_bytes ()
     Unpacks and returns a variable length byte stream, similarly to
     *Note unpack_string(): 10d2.

The following methods support unpacking arrays and lists:

 -- Method: Unpacker.unpack_list (unpack_item)
     Unpacks and returns a list of homogeneous items.  The list is
     unpacked one element at a time by first unpacking an unsigned
     integer flag.  If the flag is `1', then the item is unpacked and
     appended to the list.  A flag of `0' indicates the end of the
     list.  `unpack_item' is the function that is called to unpack the
     items.

 -- Method: Unpacker.unpack_farray (n, unpack_item)
     Unpacks and returns (as a list) a fixed length array of
     homogeneous items.  `n' is number of list elements to expect in
     the buffer. As above, `unpack_item' is the function used to unpack
     each element.

 -- Method: Unpacker.unpack_array (unpack_item)
     Unpacks and returns a variable length `list' of homogeneous items.
     First, the length of the list is unpacked as an unsigned integer,
     then each element is unpacked as in *Note unpack_farray(): 10d6.
     above.


File: python.info,  Node: Exceptions<3>,  Prev: Unpacker Objects,  Up: xdrlib — Encode and decode XDR data

5.13.5.3 Exceptions
...................

Exceptions in this module are coded as class instances:

 -- Exception: xdrlib.Error
     The base exception class.  *Note Error: 10cd. has a single public
     attribute `msg' containing the description of the error.

 -- Exception: xdrlib.ConversionError
     Class derived from *Note Error: 10cd.  Contains no additional
     instance variables.

Here is an example of how you would catch one of these exceptions:

    import xdrlib
    p = xdrlib.Packer()
    try:
        p.pack_double(8.01)
    except xdrlib.ConversionError as instance:
        print 'packing the double failed:', instance.msg


File: python.info,  Node: plistlib — Generate and parse Mac OS X plist files,  Prev: xdrlib — Encode and decode XDR data,  Up: File Formats

5.13.6 `plistlib' — Generate and parse Mac OS X `.plist' files
----------------------------------------------------------------

Changed in version 2.6: This module was previously only available in
the Mac-specific library, it is now available for all platforms.

`Source code:' Lib/plistlib.py(1)

__________________________________________________________________

This module provides an interface for reading and writing the
“property list” XML files used mainly by Mac OS X.

The property list (`.plist') file format is a simple XML pickle
supporting basic object types, like dictionaries, lists, numbers and
strings.  Usually the top level object is a dictionary.

Values can be strings, integers, floats, booleans, tuples, lists,
dictionaries (but only with string keys), *Note Data: 10dd. or *Note
datetime.datetime: 2dc.  objects.  String values (including dictionary
keys) may be unicode strings – they will be written out as UTF-8.

The `<data>' plist type is supported through the *Note Data: 10dd.
class.  This is a thin wrapper around a Python string.  Use *Note Data:
10dd. if your strings contain control characters.

See also
........

PList manual page(2)
     Apple’s documentation of the file format.

This module defines the following functions:

 -- Function: plistlib.readPlist (pathOrFile)
     Read a plist file. `pathOrFile' may either be a file name or a
     (readable) file object.  Return the unpacked root object (which
     usually is a dictionary).

     The XML data is parsed using the Expat parser from *Note
     xml.parsers.expat: 1a5.  – see its documentation for possible
     exceptions on ill-formed XML.  Unknown elements will simply be
     ignored by the plist parser.

 -- Function: plistlib.writePlist (rootObject, pathOrFile)
     Write `rootObject' to a plist file. `pathOrFile' may either be a
     file name or a (writable) file object.

     A *Note TypeError: 218. will be raised if the object is of an
     unsupported type or a container that contains objects of
     unsupported types.

 -- Function: plistlib.readPlistFromString (data)
     Read a plist from a string.  Return the root object.

 -- Function: plistlib.writePlistToString (rootObject)
     Return `rootObject' as a plist-formatted string.

 -- Function: plistlib.readPlistFromResource (path, restype='plst',
          resid=0)
     Read a plist from the resource with type `restype' from the
     resource fork of `path'.  Availability: Mac OS X.

          Note: In Python 3.x, this function has been removed.

 -- Function: plistlib.writePlistToResource (rootObject, path,
          restype='plst', resid=0)
     Write `rootObject' as a resource with type `restype' to the
     resource fork of `path'.  Availability: Mac OS X.

          Note: In Python 3.x, this function has been removed.

The following class is available:

 -- Class: plistlib.Data (data)
     Return a “data” wrapper object around the string `data'.  This
     is used in functions converting from/to plists to represent the
     `<data>' type available in plists.

     It has one attribute, `data', that can be used to retrieve the
     Python string stored in it.

* Menu:

* Examples: Examples<6>.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/plistlib.py

(2)
https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man5/plist.5.html


File: python.info,  Node: Examples<6>,  Up: plistlib — Generate and parse Mac OS X plist files

5.13.6.1 Examples
.................

Generating a plist:

    pl = dict(
        aString="Doodah",
        aList=["A", "B", 12, 32.1, [1, 2, 3]],
        aFloat = 0.1,
        anInt = 728,
        aDict=dict(
            anotherString="<hello & hi there!>",
            aUnicodeValue=u'M\xe4ssig, Ma\xdf',
            aTrueValue=True,
            aFalseValue=False,
        ),
        someData = Data("<binary gunk>"),
        someMoreData = Data("<lots of binary gunk>" * 10),
        aDate = datetime.datetime.fromtimestamp(time.mktime(time.gmtime())),
    )
    # unicode keys are possible, but a little awkward to use:
    pl[u'\xc5benraa'] = "That was a unicode key."
    writePlist(pl, fileName)

Parsing a plist:

    pl = readPlist(pathOrFile)
    print pl["aKey"]


File: python.info,  Node: Cryptographic Services,  Next: Generic Operating System Services,  Prev: File Formats,  Up: The Python Standard Library

5.14 Cryptographic Services
===========================

The modules described in this chapter implement various algorithms of a
cryptographic nature.  They are available at the discretion of the
installation.  Here’s an overview:

* Menu:

* hashlib — Secure hashes and message digests::
* hmac — Keyed-Hashing for Message Authentication::
* md5 — MD5 message digest algorithm::
* sha — SHA-1 message digest algorithm::


File: python.info,  Node: hashlib — Secure hashes and message digests,  Next: hmac — Keyed-Hashing for Message Authentication,  Up: Cryptographic Services

5.14.1 `hashlib' — Secure hashes and message digests
------------------------------------------------------

New in version 2.5.

`Source code:' Lib/hashlib.py(1)

__________________________________________________________________

This module implements a common interface to many different secure hash
and message digest algorithms.  Included are the FIPS secure hash
algorithms SHA1, SHA224, SHA256, SHA384, and SHA512 (defined in FIPS
180-2) as well as RSA’s MD5 algorithm (defined in Internet RFC
1321(2)). The terms secure hash and message digest are interchangeable.
Older algorithms were called message digests.  The modern term is
secure hash.

     Note: If you want the adler32 or crc32 hash functions, they are
     available in the *Note zlib: 1ad. module.

     Warning: Some algorithms have known hash collision weaknesses,
     refer to the “See also” section at the end.

There is one constructor method named for each type of `hash'.  All
return a hash object with the same simple interface. For example: use
`sha1()' to create a SHA1 hash object. You can now feed this object
with arbitrary strings using the `update()' method.  At any point you
can ask it for the `digest' of the concatenation of the strings fed to
it so far using the `digest()' or `hexdigest()' methods.

Constructors for hash algorithms that are always present in this module
are *Note md5(): 10e, `sha1()', `sha224()', `sha256()', `sha384()', and
`sha512()'.  Additional algorithms may also be available depending upon
the OpenSSL library that Python uses on your platform.

For example, to obtain the digest of the string `'Nobody inspects the
spammish repetition'':

    >>> import hashlib
    >>> m = hashlib.md5()
    >>> m.update("Nobody inspects")
    >>> m.update(" the spammish repetition")
    >>> m.digest()
    '\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'
    >>> m.digest_size
    16
    >>> m.block_size
    64

More condensed:

    >>> hashlib.sha224("Nobody inspects the spammish repetition").hexdigest()
    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'

A generic *Note new(): 123. constructor that takes the string name of
the desired algorithm as its first parameter also exists to allow
access to the above listed hashes as well as any other algorithms that
your OpenSSL library may offer.  The named constructors are much faster
than *Note new(): 123. and should be preferred.

Using *Note new(): 123. with an algorithm provided by OpenSSL:

    >>> h = hashlib.new('ripemd160')
    >>> h.update("Nobody inspects the spammish repetition")
    >>> h.hexdigest()
    'cc4a5ce1b3df48aec5d22d1f16b894a0b894eccc'

This module provides the following constant attribute:

 -- Data: hashlib.algorithms
     A tuple providing the names of the hash algorithms guaranteed to be
     supported by this module.

     New in version 2.7.


 -- Data: hashlib.algorithms_guaranteed
     A set containing the names of the hash algorithms guaranteed to be
     supported by this module on all platforms.

     New in version 2.7.9.


 -- Data: hashlib.algorithms_available
     A set containing the names of the hash algorithms that are
     available in the running Python interpreter.  These names will be
     recognized when passed to *Note new(): 123.  *Note
     algorithms_guaranteed: 2e7. will always be a subset.  The same
     algorithm may appear multiple times in this set under different
     names (thanks to OpenSSL).

     New in version 2.7.9.


The following values are provided as constant attributes of the hash
objects returned by the constructors:

 -- Data: hash.digest_size
     The size of the resulting hash in bytes.

 -- Data: hash.block_size
     The internal block size of the hash algorithm in bytes.

A hash object has the following methods:

 -- Method: hash.update (arg)
     Update the hash object with the string `arg'.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to
     `m.update(a+b)'.

     Changed in version 2.7: The Python GIL is released to allow other
     threads to run while hash updates on data larger than 2048 bytes
     is taking place when using hash algorithms supplied by OpenSSL.


 -- Method: hash.digest ()
     Return the digest of the strings passed to the *Note update():
     10ec. method so far.  This is a string of *Note digest_size: 10ea.
     bytes which may contain non-ASCII characters, including null bytes.

 -- Method: hash.hexdigest ()
     Like *Note digest(): 10ed. except the digest is returned as a
     string of double length, containing only hexadecimal digits.  This
     may  be used to exchange the value safely in email or other
     non-binary environments.

 -- Method: hash.copy ()
     Return a copy (“clone”) of the hash object.  This can be used
     to efficiently compute the digests of strings that share a common
     initial substring.

* Menu:

* Key derivation::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/hashlib.py

(2) https://tools.ietf.org/html/rfc1321.html


File: python.info,  Node: Key derivation,  Up: hashlib — Secure hashes and message digests

5.14.1.1 Key derivation
.......................

Key derivation and key stretching algorithms are designed for secure
password hashing. Naive algorithms such as `sha1(password)' are not
resistant against brute-force attacks. A good password hashing function
must be tunable, slow, and include a salt(1).

 -- Function: hashlib.pbkdf2_hmac (name, password, salt, rounds,
          dklen=None)
     The function provides PKCS#5 password-based key derivation
     function 2. It uses HMAC as pseudorandom function.

     The string `name' is the desired name of the hash digest algorithm
     for HMAC, e.g. ‘sha1’ or ‘sha256’. `password' and `salt'
     are interpreted as buffers of bytes. Applications and libraries
     should limit `password' to a sensible value (e.g. 1024). `salt'
     should be about 16 or more bytes from a proper source, e.g. *Note
     os.urandom(): 2e6.

     The number of `rounds' should be chosen based on the hash
     algorithm and computing power. As of 2013, at least 100,000 rounds
     of SHA-256 is suggested.

     `dklen' is the length of the derived key. If `dklen' is `None'
     then the digest size of the hash algorithm `name' is used, e.g. 64
     for SHA-512.

         >>> import hashlib, binascii
         >>> dk = hashlib.pbkdf2_hmac('sha256', b'password', b'salt', 100000)
         >>> binascii.hexlify(dk)
         b'0394a2ede332c9a13eb82e9b24631604c31df978b4e2f0fbd2c549944f9d79a5'

     New in version 2.7.8.

          Note: A fast implementation of `pbkdf2_hmac' is available
          with OpenSSL.  The Python implementation uses an inline
          version of *Note hmac: e9. It is about three times slower and
          doesn’t release the GIL.

See also
........

Module *Note hmac: e9.
     A module to generate message authentication codes using hashes.

Module *Note base64: 15.
     Another way to encode binary hashes for non-binary environments.

<http://csrc.nist.gov/publications/fips/fips180-2/fips180-2.pdf>
     The FIPS 180-2 publication on Secure Hash Algorithms.

<https://en.wikipedia.org/wiki/Cryptographic_hash_function#Cryptographic_hash_algorithms>
     Wikipedia article with information on which algorithms have known
     issues and what that means regarding their use.

---------- Footnotes ----------

(1) https://en.wikipedia.org/wiki/Salt_%28cryptography%29


File: python.info,  Node: hmac — Keyed-Hashing for Message Authentication,  Next: md5 — MD5 message digest algorithm,  Prev: hashlib — Secure hashes and message digests,  Up: Cryptographic Services

5.14.2 `hmac' — Keyed-Hashing for Message Authentication
----------------------------------------------------------

New in version 2.2.

`Source code:' Lib/hmac.py(1)

__________________________________________________________________

This module implements the HMAC algorithm as described by RFC 2104(2).

 -- Function: hmac.new (key[, msg[, digestmod]])
     Return a new hmac object.  If `msg' is present, the method call
     `update(msg)' is made. `digestmod' is the digest constructor or
     module for the HMAC object to use. It defaults to  the
     `hashlib.md5' constructor.

An HMAC object has the following methods:

 -- Method: HMAC.update (msg)
     Update the hmac object with the string `msg'.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to `m.update(a
     + b)'.

 -- Method: HMAC.digest ()
     Return the digest of the strings passed to the *Note update():
     10f4. method so far.  This string will be the same length as the
     `digest_size' of the digest given to the constructor.  It may
     contain non-ASCII characters, including NUL bytes.

          Warning: When comparing the output of *Note digest(): 10f5.
          to an externally-supplied digest during a verification
          routine, it is recommended to use the *Note compare_digest():
          2e3. function instead of the `==' operator to reduce the
          vulnerability to timing attacks.

 -- Method: HMAC.hexdigest ()
     Like *Note digest(): 10f5. except the digest is returned as a
     string twice the length containing only hexadecimal digits.  This
     may be used to exchange the value safely in email or other
     non-binary environments.

          Warning: When comparing the output of *Note hexdigest():
          10f6. to an externally-supplied digest during a verification
          routine, it is recommended to use the *Note compare_digest():
          2e3. function instead of the `==' operator to reduce the
          vulnerability to timing attacks.

 -- Method: HMAC.copy ()
     Return a copy (“clone”) of the hmac object.  This can be used
     to efficiently compute the digests of strings that share a common
     initial substring.

This module also provides the following helper function:

 -- Function: hmac.compare_digest (a, b)
     Return `a == b'.  This function uses an approach designed to
     prevent timing analysis by avoiding content-based short circuiting
     behaviour, making it appropriate for cryptography.  `a' and `b'
     must both be of the same type: either *Note unicode: 1f5. or a
     *Note bytes-like object: 10f8.

          Note: If `a' and `b' are of different lengths, or if an error
          occurs, a timing attack could theoretically reveal
          information about the types and lengths of `a' and `b'—but
          not their values.

     New in version 2.7.7.


See also
........

Module *Note hashlib: e7.
     The Python module providing secure hash functions.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/hmac.py

(2) https://tools.ietf.org/html/rfc2104.html


File: python.info,  Node: md5 — MD5 message digest algorithm,  Next: sha — SHA-1 message digest algorithm,  Prev: hmac — Keyed-Hashing for Message Authentication,  Up: Cryptographic Services

5.14.3 `md5' — MD5 message digest algorithm
---------------------------------------------

Deprecated since version 2.5: Use the *Note hashlib: e7. module instead.

This module implements the interface to RSA’s MD5 message digest
algorithm (see also Internet RFC 1321(1)).  Its use is quite
straightforward: use *Note new(): 123.  to create an md5 object. You
can now feed this object with arbitrary strings using the `update()'
method, and at any point you can ask it for the `digest' (a strong kind
of 128-bit checksum, a.k.a. “fingerprint”) of the concatenation of
the strings fed to it so far using the `digest()' method.

For example, to obtain the digest of the string `'Nobody inspects the
spammish repetition'':

    >>> import md5
    >>> m = md5.new()
    >>> m.update("Nobody inspects")
    >>> m.update(" the spammish repetition")
    >>> m.digest()
    '\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

More condensed:

    >>> md5.new("Nobody inspects the spammish repetition").digest()
    '\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

The following values are provided as constants in the module and as
attributes of the md5 objects returned by *Note new(): 123.:

 -- Data: md5.digest_size
     The size of the resulting digest in bytes.  This is always `16'.

The md5 module provides the following functions:

 -- Function: md5.new ([arg])
     Return a new md5 object.  If `arg' is present, the method call
     `update(arg)' is made.

 -- Function: md5.md5 ([arg])
     For backward compatibility reasons, this is an alternative name
     for the *Note new(): 123. function.

An md5 object has the following methods:

 -- Method: md5.update (arg)
     Update the md5 object with the string `arg'.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to
     `m.update(a+b)'.

 -- Method: md5.digest ()
     Return the digest of the strings passed to the *Note update():
     10fe. method so far.  This is a 16-byte string which may contain
     non-ASCII characters, including null bytes.

 -- Method: md5.hexdigest ()
     Like *Note digest(): 10ff. except the digest is returned as a
     string of length 32, containing only hexadecimal digits.  This may
     be used to exchange the value safely in email or other non-binary
     environments.

 -- Method: md5.copy ()
     Return a copy (“clone”) of the md5 object.  This can be used
     to efficiently compute the digests of strings that share a common
     initial substring.

See also
........

Module *Note sha: 151.
     Similar module implementing the Secure Hash Algorithm (SHA).  The
     SHA algorithm is considered a more secure hash.

---------- Footnotes ----------

(1) https://tools.ietf.org/html/rfc1321.html


File: python.info,  Node: sha — SHA-1 message digest algorithm,  Prev: md5 — MD5 message digest algorithm,  Up: Cryptographic Services

5.14.4 `sha' — SHA-1 message digest algorithm
-----------------------------------------------

Deprecated since version 2.5: Use the *Note hashlib: e7. module instead.

This module implements the interface to NIST’s secure hash
algorithm, known as SHA-1.  SHA-1 is an improved version of the
original SHA hash algorithm.  It is used in the same way as the *Note
md5: 10e. module: use *Note new(): 123. to create an sha object, then
feed this object with arbitrary strings using the `update()' method,
and at any point you can ask it for the `digest' of the concatenation
of the strings fed to it so far.  SHA-1 digests are 160 bits instead of
MD5’s 128 bits.

 -- Function: sha.new ([string])
     Return a new sha object.  If `string' is present, the method call
     `update(string)' is made.

The following values are provided as constants in the module and as
attributes of the sha objects returned by *Note new(): 123.:

 -- Data: sha.blocksize
     Size of the blocks fed into the hash function; this is always `1'.
     This size is used to allow an arbitrary string to be hashed.

 -- Data: sha.digest_size
     The size of the resulting digest in bytes.  This is always `20'.

An sha object has the same methods as md5 objects:

 -- Method: sha.update (arg)
     Update the sha object with the string `arg'.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to
     `m.update(a+b)'.

 -- Method: sha.digest ()
     Return the digest of the strings passed to the *Note update():
     1107. method so far.  This is a 20-byte string which may contain
     non-ASCII characters, including null bytes.

 -- Method: sha.hexdigest ()
     Like *Note digest(): 1108. except the digest is returned as a
     string of length 40, containing only hexadecimal digits.  This may
     be used to exchange the value safely in email or other non-binary
     environments.

 -- Method: sha.copy ()
     Return a copy (“clone”) of the sha object.  This can be used
     to efficiently compute the digests of strings that share a common
     initial substring.

See also
........

Secure Hash Standard(1)
     The Secure Hash Algorithm is defined by NIST document FIPS PUB
     180-2: Secure Hash Standard(2), published in August 2002.

Cryptographic Toolkit (Secure Hashing)(3)
     Links from NIST to various information on secure hashing.

---------- Footnotes ----------

(1)
http://csrc.nist.gov/publications/fips/fips180-2/fips180-2withchangenotice.pdf

(2)
http://csrc.nist.gov/publications/fips/fips180-2/fips180-2withchangenotice.pdf

(3) http://csrc.nist.gov/CryptoToolkit/tkhash.html


File: python.info,  Node: Generic Operating System Services,  Next: Optional Operating System Services,  Prev: Cryptographic Services,  Up: The Python Standard Library

5.15 Generic Operating System Services
======================================

The modules described in this chapter provide interfaces to operating
system features that are available on (almost) all operating systems,
such as files and a clock.  The interfaces are generally modeled after
the Unix or C interfaces, but they are available on most other systems
as well.  Here’s an overview:

* Menu:

* os — Miscellaneous operating system interfaces::
* io — Core tools for working with streams::
* time — Time access and conversions::
* argparse — Parser for command-line options, arguments and sub-commands: argparse — Parser for command-line options arguments and sub-commands.
* optparse — Parser for command line options::
* getopt — C-style parser for command line options::
* logging — Logging facility for Python::
* logging.config — Logging configuration: logging config — Logging configuration.
* logging.handlers — Logging handlers: logging handlers — Logging handlers.
* getpass — Portable password input::
* curses — Terminal handling for character-cell displays::
* curses.textpad — Text input widget for curses programs: curses textpad — Text input widget for curses programs.
* curses.ascii — Utilities for ASCII characters: curses ascii — Utilities for ASCII characters.
* curses.panel — A panel stack extension for curses: curses panel — A panel stack extension for curses.
* platform — Access to underlying platform’s identifying data::
* errno — Standard errno system symbols::
* ctypes — A foreign function library for Python::


File: python.info,  Node: os — Miscellaneous operating system interfaces,  Next: io — Core tools for working with streams,  Up: Generic Operating System Services

5.15.1 `os' — Miscellaneous operating system interfaces
---------------------------------------------------------

This module provides a portable way of using operating system dependent
functionality.  If you just want to read or write a file see *Note
open(): 2d9, if you want to manipulate paths, see the *Note os.path:
12a. module, and if you want to read all the lines in all the files on
the command line see the *Note fileinput: cd.  module.  For creating
temporary files and directories see the *Note tempfile: 173.  module,
and for high-level file and directory handling see the *Note shutil:
154.  module.

Notes on the availability of these functions:

   * The design of all built-in operating system dependent modules of
     Python is such that as long as the same functionality is
     available, it uses the same interface; for example, the function
     `os.stat(path)' returns stat information about `path' in the same
     format (which happens to have originated with the POSIX interface).

   * Extensions peculiar to a particular operating system are also
     available through the *Note os: 129. module, but using them is of
     course a threat to portability.

   * An “Availability: Unix” note means that this function is
     commonly found on Unix systems.  It does not make any claims about
     its existence on a specific operating system.

   * If not separately noted, all functions that claim “Availability:
     Unix” are supported on Mac OS X, which builds on a Unix core.

     Note: All functions in this module raise *Note OSError: 231. in
     the case of invalid or inaccessible file names and paths, or other
     arguments that have the correct type, but are not accepted by the
     operating system.

 -- Exception: os.error
     An alias for the built-in *Note OSError: 231. exception.

 -- Data: os.name
     The name of the operating system dependent module imported.  The
     following names have currently been registered: `'posix'', `'nt'',
     `'os2'', `'ce'', `'java'', `'riscos''.

See also
........

     *Note sys.platform: 1111. has a finer granularity.  *Note
os.uname(): 1112. gives system-dependent version information.

     The *Note platform: 133. module provides detailed checks for the
system’s identity.


* Menu:

* Process Parameters::
* File Object Creation::
* File Descriptor Operations::
* Files and Directories::
* Process Management::
* Miscellaneous System Information::
* Miscellaneous Functions::


File: python.info,  Node: Process Parameters,  Next: File Object Creation,  Up: os — Miscellaneous operating system interfaces

5.15.1.1 Process Parameters
...........................

These functions and data items provide information and operate on the
current process and user.

 -- Data: os.environ
     A *Note mapping: 921. object representing the string environment.
     For example, `environ['HOME']' is the pathname of your home
     directory (on some platforms), and is equivalent to
     `getenv("HOME")' in C.

     This mapping is captured the first time the *Note os: 129. module
     is imported, typically during Python startup as part of processing
     `site.py'.  Changes to the environment made after this time are
     not reflected in `os.environ', except for changes made by
     modifying `os.environ' directly.

     If the platform supports the *Note putenv(): 1115. function, this
     mapping may be used to modify the environment as well as query the
     environment.  *Note putenv(): 1115. will be called automatically
     when the mapping is modified.

          Note: Calling *Note putenv(): 1115. directly does not change
          `os.environ', so it’s better to modify `os.environ'.

          Note: On some platforms, including FreeBSD and Mac OS X,
          setting `environ' may cause memory leaks.  Refer to the
          system documentation for `putenv()'.

     If *Note putenv(): 1115. is not provided, a modified copy of this
     mapping  may be passed to the appropriate process-creation
     functions to cause  child processes to use a modified environment.

     If the platform supports the *Note unsetenv(): 367. function, you
     can delete items in this mapping to unset environment variables.
     *Note unsetenv(): 367. will be called automatically when an item
     is deleted from `os.environ', and when one of the `pop()' or
     `clear()' methods is called.

     Changed in version 2.6: Also unset environment variables when
     calling `os.environ.clear()' and `os.environ.pop()'.


 -- Function: os.chdir (path)
 -- Function: os.fchdir (fd)
 -- Function: os.getcwd ()
     These functions are described in *Note Files and Directories: 1116.

 -- Function: os.ctermid ()
     Return the filename corresponding to the controlling terminal of
     the process.

     Availability: Unix.

 -- Function: os.getegid ()
     Return the effective group id of the current process.  This
     corresponds to the “set id” bit on the file being executed in
     the current process.

     Availability: Unix.

 -- Function: os.geteuid ()
     Return the current process’s effective user id.

     Availability: Unix.

 -- Function: os.getgid ()
     Return the real group id of the current process.

     Availability: Unix.

 -- Function: os.getgroups ()
     Return list of supplemental group ids associated with the current
     process.

     Availability: Unix.

          Note: On Mac OS X, *Note getgroups(): 111b. behavior differs
          somewhat from other Unix platforms. If the Python interpreter
          was built with a deployment target of `10.5' or earlier,
          *Note getgroups(): 111b. returns the list of effective group
          ids associated with the current user process; this list is
          limited to a system-defined number of entries, typically 16,
          and may be modified by calls to *Note setgroups(): 111c. if
          suitably privileged.  If built with a deployment target
          greater than `10.5', *Note getgroups(): 111b. returns the
          current group access list for the user associated with the
          effective user id of the process; the group access list may
          change over the lifetime of the process, it is not affected by
          calls to *Note setgroups(): 111c, and its length is not
          limited to 16.  The deployment target value,
          `MACOSX_DEPLOYMENT_TARGET', can be obtained with *Note
          sysconfig.get_config_var(): 274.

 -- Function: os.initgroups (username, gid)
     Call the system initgroups() to initialize the group access list
     with all of the groups of which the specified username is a
     member, plus the specified group id.

     Availability: Unix.

     New in version 2.7.


 -- Function: os.getlogin ()
     Return the name of the user logged in on the controlling terminal
     of the process.  For most purposes, it is more useful to use the
     environment variable `LOGNAME' to find out who the user is, or
     `pwd.getpwuid(os.getuid())[0]' to get the login name of the
     process’s real user id.

     Availability: Unix.

 -- Function: os.getpgid (pid)
     Return the process group id of the process with process id `pid'.
     If `pid' is 0, the process group id of the current process is
     returned.

     Availability: Unix.

     New in version 2.3.


 -- Function: os.getpgrp ()
     Return the id of the current process group.

     Availability: Unix.

 -- Function: os.getpid ()
     Return the current process id.

     Availability: Unix, Windows.

 -- Function: os.getppid ()
     Return the parent’s process id.

     Availability: Unix.

 -- Function: os.getresuid ()
     Return a tuple (ruid, euid, suid) denoting the current process’s
     real, effective, and saved user ids.

     Availability: Unix.

     New in version 2.7.


 -- Function: os.getresgid ()
     Return a tuple (rgid, egid, sgid) denoting the current process’s
     real, effective, and saved group ids.

     Availability: Unix.

     New in version 2.7.


 -- Function: os.getuid ()
     Return the current process’s real user id.

     Availability: Unix.

 -- Function: os.getenv (varname[, value])
     Return the value of the environment variable `varname' if it
     exists, or `value' if it doesn’t.  `value' defaults to `None'.

     Availability: most flavors of Unix, Windows.

 -- Function: os.putenv (varname, value)
     Set the environment variable named `varname' to the string
     `value'.  Such changes to the environment affect subprocesses
     started with *Note os.system(): 413, *Note popen(): 728. or *Note
     fork(): 244. and *Note execv(): 1124.

     Availability: most flavors of Unix, Windows.

          Note: On some platforms, including FreeBSD and Mac OS X,
          setting `environ' may cause memory leaks. Refer to the system
          documentation for putenv.

     When *Note putenv(): 1115. is supported, assignments to items in
     `os.environ' are automatically translated into corresponding calls
     to *Note putenv(): 1115.; however, calls to *Note putenv(): 1115.
     don’t update `os.environ', so it is actually preferable to
     assign to items of `os.environ'.

 -- Function: os.setegid (egid)
     Set the current process’s effective group id.

     Availability: Unix.

 -- Function: os.seteuid (euid)
     Set the current process’s effective user id.

     Availability: Unix.

 -- Function: os.setgid (gid)
     Set the current process’ group id.

     Availability: Unix.

 -- Function: os.setgroups (groups)
     Set the list of supplemental group ids associated with the current
     process to `groups'. `groups' must be a sequence, and each element
     must be an integer identifying a group. This operation is
     typically available only to the superuser.

     Availability: Unix.

     New in version 2.2.

          Note: On Mac OS X, the length of `groups' may not exceed the
          system-defined maximum number of effective group ids,
          typically 16.  See the documentation for *Note getgroups():
          111b. for cases where it may not return the same group list
          set by calling setgroups().

 -- Function: os.setpgrp ()
     Call the system call `setpgrp()' or `setpgrp(0, 0)()' depending on
     which version is implemented (if any).  See the Unix manual for
     the semantics.

     Availability: Unix.

 -- Function: os.setpgid (pid, pgrp)
     Call the system call `setpgid()' to set the process group id of the
     process with id `pid' to the process group with id `pgrp'.  See
     the Unix manual for the semantics.

     Availability: Unix.

 -- Function: os.setregid (rgid, egid)
     Set the current process’s real and effective group ids.

     Availability: Unix.

 -- Function: os.setresgid (rgid, egid, sgid)
     Set the current process’s real, effective, and saved group ids.

     Availability: Unix.

     New in version 2.7.


 -- Function: os.setresuid (ruid, euid, suid)
     Set the current process’s real, effective, and saved user ids.

     Availability: Unix.

     New in version 2.7.


 -- Function: os.setreuid (ruid, euid)
     Set the current process’s real and effective user ids.

     Availability: Unix.

 -- Function: os.getsid (pid)
     Call the system call `getsid()'.  See the Unix manual for the
     semantics.

     Availability: Unix.

     New in version 2.4.


 -- Function: os.setsid ()
     Call the system call `setsid()'.  See the Unix manual for the
     semantics.

     Availability: Unix.

 -- Function: os.setuid (uid)
     Set the current process’s user id.

     Availability: Unix.

 -- Function: os.strerror (code)
     Return the error message corresponding to the error code in `code'.
     On platforms where `strerror()' returns `NULL' when given an
     unknown error number, *Note ValueError: 236. is raised.

     Availability: Unix, Windows.

 -- Function: os.umask (mask)
     Set the current numeric umask and return the previous umask.

     Availability: Unix, Windows.

 -- Function: os.uname ()
     Return a 5-tuple containing information identifying the current
     operating system.  The tuple contains 5 strings: `(sysname,
     nodename, release, version, machine)'.  Some systems truncate the
     nodename to 8 characters or to the leading component; a better way
     to get the hostname is *Note socket.gethostname(): 1131.  or even
     `socket.gethostbyaddr(socket.gethostname())'.

     Availability: recent flavors of Unix.

 -- Function: os.unsetenv (varname)
     Unset (delete) the environment variable named `varname'. Such
     changes to the environment affect subprocesses started with *Note
     os.system(): 413, *Note popen(): 728. or *Note fork(): 244. and
     *Note execv(): 1124.

     When *Note unsetenv(): 367. is supported, deletion of items in
     `os.environ' is automatically translated into a corresponding call
     to *Note unsetenv(): 367.; however, calls to *Note unsetenv():
     367. don’t update `os.environ', so it is actually preferable to
     delete items of `os.environ'.

     Availability: most flavors of Unix, Windows.


File: python.info,  Node: File Object Creation,  Next: File Descriptor Operations,  Prev: Process Parameters,  Up: os — Miscellaneous operating system interfaces

5.15.1.2 File Object Creation
.............................

These functions create new file objects. (See also *Note open(): 2d9.)

 -- Function: os.fdopen (fd[, mode[, bufsize]])
     Return an open file object connected to the file descriptor `fd'.
     The `mode' and `bufsize' arguments have the same meaning as the
     corresponding arguments to the built-in *Note open(): 2d9.
     function.  If *Note fdopen(): 729. raises an exception, it leaves
     `fd' untouched (unclosed).

     Availability: Unix, Windows.

     Changed in version 2.3: When specified, the `mode' argument must
     now start with one of the letters `'r'', `'w'', or `'a'',
     otherwise a *Note ValueError: 236. is raised.

     Changed in version 2.5: On Unix, when the `mode' argument starts
     with `'a'', the `O_APPEND' flag is set on the file descriptor
     (which the `fdopen()' implementation already does on most
     platforms).


 -- Function: os.popen (command[, mode[, bufsize]])
     Open a pipe to or from `command'.  The return value is an open
     file object connected to the pipe, which can be read or written
     depending on whether `mode' is `'r'' (default) or `'w''. The
     `bufsize' argument has the same meaning as the corresponding
     argument to the built-in *Note open(): 2d9. function.  The exit
     status of the command (encoded in the format specified for *Note
     wait(): 1134.) is available as the return value of the *Note
     close(): 931. method of the file object, except that when the exit
     status is zero (termination without errors), `None' is returned.

     Availability: Unix, Windows.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *Note subprocess: 167. module.  Check especially the *Note
     Replacing Older Functions with the subprocess Module: 1135.
     section.

     Changed in version 2.0: This function worked unreliably under
     Windows in earlier versions of Python.  This was due to the use of
     the `_popen()' function from the libraries provided with Windows.
     Newer versions of Python do not use the broken implementation from
     the Windows libraries.


 -- Function: os.tmpfile ()
     Return a new file object opened in update mode (`w+b').  The file
     has no directory entries associated with it and will be
     automatically deleted once there are no file descriptors for the
     file.

     Availability: Unix, Windows.

There are a number of different `popen*()' functions that provide
slightly different ways to create subprocesses.

Deprecated since version 2.6: All of the `popen*()' functions are
obsolete. Use the *Note subprocess: 167.  module.

For each of the `popen*()' variants, if `bufsize' is specified, it
specifies the buffer size for the I/O pipes. `mode', if provided,
should be the string `'b'' or `'t''; on Windows this is needed to
determine whether the file objects should be opened in binary or text
mode.  The default value for `mode' is `'t''.

Also, for each of these variants, on Unix, `cmd' may be a sequence, in
which case arguments will be passed directly to the program without
shell intervention (as with *Note os.spawnv(): 1137.). If `cmd' is a
string it will be passed to the shell (as with *Note os.system(): 413.).

These methods do not make it possible to retrieve the exit status from
the child processes.  The only way to control the input and output
streams and also retrieve the return codes is to use the *Note
subprocess: 167. module; these are only available on Unix.

For a discussion of possible deadlock conditions related to the use of
these functions, see *Note Flow Control Issues: 1138.

 -- Function: os.popen2 (cmd[, mode[, bufsize]])
     Execute `cmd' as a sub-process and return the file objects
     `(child_stdin, child_stdout)'.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *Note subprocess: 167. module.  Check especially the *Note
     Replacing Older Functions with the subprocess Module: 1135.
     section.

     Availability: Unix, Windows.

     New in version 2.0.


 -- Function: os.popen3 (cmd[, mode[, bufsize]])
     Execute `cmd' as a sub-process and return the file objects
     `(child_stdin, child_stdout, child_stderr)'.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *Note subprocess: 167. module.  Check especially the *Note
     Replacing Older Functions with the subprocess Module: 1135.
     section.

     Availability: Unix, Windows.

     New in version 2.0.


 -- Function: os.popen4 (cmd[, mode[, bufsize]])
     Execute `cmd' as a sub-process and return the file objects
     `(child_stdin, child_stdout_and_stderr)'.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *Note subprocess: 167. module.  Check especially the *Note
     Replacing Older Functions with the subprocess Module: 1135.
     section.

     Availability: Unix, Windows.

     New in version 2.0.


(Note that `child_stdin, child_stdout, and child_stderr' are named from
the point of view of the child process, so `child_stdin' is the
child’s standard input.)

This functionality is also available in the *Note popen2: 135. module
using functions of the same names, but the return values of those
functions have a different order.


File: python.info,  Node: File Descriptor Operations,  Next: Files and Directories,  Prev: File Object Creation,  Up: os — Miscellaneous operating system interfaces

5.15.1.3 File Descriptor Operations
...................................

These functions operate on I/O streams referenced using file
descriptors.

File descriptors are small integers corresponding to a file that has
been opened by the current process.  For example, standard input is
usually file descriptor 0, standard output is 1, and standard error is
2.  Further files opened by a process will then be assigned 3, 4, 5,
and so forth.  The name “file descriptor” is slightly deceptive; on
Unix platforms, sockets and pipes are also referenced by file
descriptors.

The *Note fileno(): 935. method can be used to obtain the file
descriptor associated with a file object when required.  Note that
using the file descriptor directly will bypass the file object methods,
ignoring aspects such as internal buffering of data.

 -- Function: os.close (fd)
     Close file descriptor `fd'.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O and must be
          applied to a file descriptor as returned by *Note os.open():
          600. or *Note pipe(): 113f.  To close a “file object”
          returned by the built-in function *Note open(): 2d9. or by
          *Note popen(): 728. or *Note fdopen(): 729, use its *Note
          close(): 1140. method.

 -- Function: os.closerange (fd_low, fd_high)
     Close all file descriptors from `fd_low' (inclusive) to `fd_high'
     (exclusive), ignoring errors. Equivalent to:

         for fd in xrange(fd_low, fd_high):
             try:
                 os.close(fd)
             except OSError:
                 pass

     Availability: Unix, Windows.

     New in version 2.6.


 -- Function: os.dup (fd)
     Return a duplicate of file descriptor `fd'.

     Availability: Unix, Windows.

 -- Function: os.dup2 (fd, fd2)
     Duplicate file descriptor `fd' to `fd2', closing the latter first
     if necessary.

     Availability: Unix, Windows.

 -- Function: os.fchmod (fd, mode)
     Change the mode of the file given by `fd' to the numeric `mode'.
     See the docs for *Note chmod(): e57. for possible values of `mode'.

     Availability: Unix.

     New in version 2.6.


 -- Function: os.fchown (fd, uid, gid)
     Change the owner and group id of the file given by `fd' to the
     numeric `uid' and `gid'.  To leave one of the ids unchanged, set
     it to -1.

     Availability: Unix.

     New in version 2.6.


 -- Function: os.fdatasync (fd)
     Force write of file with filedescriptor `fd' to disk. Does not
     force update of metadata.

     Availability: Unix.

          Note: This function is not available on MacOS.

 -- Function: os.fpathconf (fd, name)
     Return system configuration information relevant to an open file.
     `name' specifies the configuration value to retrieve; it may be a
     string which is the name of a defined system value; these names
     are specified in a number of standards (POSIX.1, Unix 95, Unix 98,
     and others).  Some platforms define additional names as well.  The
     names known to the host operating system are given in the
     `pathconf_names' dictionary.  For configuration variables not
     included in that mapping, passing an integer for `name' is also
     accepted.

     If `name' is a string and is not known, *Note ValueError: 236. is
     raised.  If a specific value for `name' is not supported by the
     host system, even if it is included in `pathconf_names', an *Note
     OSError: 231. is raised with *Note errno.EINVAL: 1148. for the
     error number.

     Availability: Unix.

 -- Function: os.fstat (fd)
     Return status for file descriptor `fd', like *Note stat(): 3de.

     Availability: Unix, Windows.

 -- Function: os.fstatvfs (fd)
     Return information about the filesystem containing the file
     associated with file descriptor `fd', like *Note statvfs(): 162.

     Availability: Unix.

 -- Function: os.fsync (fd)
     Force write of file with filedescriptor `fd' to disk.  On Unix,
     this calls the native `fsync()' function; on Windows, the MS
     `_commit()' function.

     If you’re starting with a Python file object `f', first do
     `f.flush()', and then do `os.fsync(f.fileno())', to ensure that
     all internal buffers associated with `f' are written to disk.

     Availability: Unix, and Windows starting in 2.2.3.

 -- Function: os.ftruncate (fd, length)
     Truncate the file corresponding to file descriptor `fd', so that
     it is at most `length' bytes in size.

     Availability: Unix.

 -- Function: os.isatty (fd)
     Return `True' if the file descriptor `fd' is open and connected to
     a tty(-like) device, else `False'.

 -- Function: os.lseek (fd, pos, how)
     Set the current position of file descriptor `fd' to position
     `pos', modified by `how': *Note SEEK_SET: 3df. or `0' to set the
     position relative to the beginning of the file; *Note SEEK_CUR:
     3e0. or `1' to set it relative to the current position; *Note
     SEEK_END: 3e1. or `2' to set it relative to the end of the file.
     Return the new cursor position in bytes, starting from the
     beginning.

     Availability: Unix, Windows.

 -- Data: os.SEEK_SET
 -- Data: os.SEEK_CUR
 -- Data: os.SEEK_END
     Parameters to the *Note lseek(): 3e2. function. Their values are
     0, 1, and 2, respectively.

     Availability: Windows, Unix.

     New in version 2.5.


 -- Function: os.open (file, flags[, mode])
     Open the file `file' and set various flags according to `flags'
     and possibly its mode according to `mode'. The default `mode' is
     `0777' (octal), and the current umask value is first masked out.
     Return the file descriptor for the newly opened file.

     For a description of the flag and mode values, see the C run-time
     documentation; flag constants (like *Note O_RDONLY: 114c. and
     *Note O_WRONLY: 114d.) are defined in this module too (see *Note
     open() flag constants: 114e.).  In particular, on Windows adding
     *Note O_BINARY: 114f. is needed to open files in binary mode.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O.  For
          normal usage, use the built-in function *Note open(): 2d9,
          which returns a “file object” with *Note read(): 939. and
          *Note write(): 93c. methods (and many more).  To wrap a file
          descriptor in a “file object”, use *Note fdopen(): 729.

 -- Function: os.openpty ()
     Open a new pseudo-terminal pair. Return a pair of file descriptors
     `(master, slave)' for the pty and the tty, respectively. For a
     (slightly) more portable approach, use the *Note pty: 13c. module.

     Availability: some flavors of Unix.

 -- Function: os.pipe ()
     Create a pipe.  Return a pair of file descriptors `(r, w)' usable
     for reading and writing, respectively.

     Availability: Unix, Windows.

 -- Function: os.read (fd, n)
     Read at most `n' bytes from file descriptor `fd'. Return a string
     containing the bytes read.  If the end of the file referred to by
     `fd' has been reached, an empty string is returned.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O and must be
          applied to a file descriptor as returned by *Note os.open():
          600. or *Note pipe(): 113f.  To read a “file object”
          returned by the built-in function *Note open(): 2d9. or by
          *Note popen(): 728. or *Note fdopen(): 729, or *Note
          sys.stdin: 65c, use its *Note read(): 939. or *Note
          readline(): 66f. methods.

 -- Function: os.tcgetpgrp (fd)
     Return the process group associated with the terminal given by
     `fd' (an open file descriptor as returned by *Note os.open():
     600.).

     Availability: Unix.

 -- Function: os.tcsetpgrp (fd, pg)
     Set the process group associated with the terminal given by `fd'
     (an open file descriptor as returned by *Note os.open(): 600.) to
     `pg'.

     Availability: Unix.

 -- Function: os.ttyname (fd)
     Return a string which specifies the terminal device associated with
     file descriptor `fd'.  If `fd' is not associated with a terminal
     device, an exception is raised.

     Availability: Unix.

 -- Function: os.write (fd, str)
     Write the string `str' to file descriptor `fd'. Return the number
     of bytes actually written.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O and must be
          applied to a file descriptor as returned by *Note os.open():
          600. or *Note pipe(): 113f.  To write a “file object”
          returned by the built-in function *Note open(): 2d9. or by
          *Note popen(): 728. or *Note fdopen(): 729, or *Note
          sys.stdout: 8b2. or *Note sys.stderr: 672, use its *Note
          write(): 93c. method.

* Menu:

* open() flag constants: open flag constants.


File: python.info,  Node: open flag constants,  Up: File Descriptor Operations

5.15.1.4 `open()' flag constants
................................

The following constants are options for the `flags' parameter to the
*Note open(): 600. function.  They can be combined using the bitwise OR
operator `|'.  Some of them are not available on all platforms.  For
descriptions of their availability and use, consult the `open(2)'
manual page on Unix or the MSDN(1) on Windows.

 -- Data: os.O_RDONLY
 -- Data: os.O_WRONLY
 -- Data: os.O_RDWR
 -- Data: os.O_APPEND
 -- Data: os.O_CREAT
 -- Data: os.O_EXCL
 -- Data: os.O_TRUNC
     The above constants are available on Unix and Windows.

 -- Data: os.O_DSYNC
 -- Data: os.O_RSYNC
 -- Data: os.O_SYNC
 -- Data: os.O_NDELAY
 -- Data: os.O_NONBLOCK
 -- Data: os.O_NOCTTY
     The above constants are only available on Unix.

 -- Data: os.O_BINARY
 -- Data: os.O_NOINHERIT
 -- Data: os.O_SHORT_LIVED
 -- Data: os.O_TEMPORARY
 -- Data: os.O_RANDOM
 -- Data: os.O_SEQUENTIAL
 -- Data: os.O_TEXT
     The above constants are only available on Windows.

 -- Data: os.O_ASYNC
 -- Data: os.O_DIRECT
 -- Data: os.O_DIRECTORY
 -- Data: os.O_NOFOLLOW
 -- Data: os.O_NOATIME
 -- Data: os.O_SHLOCK
 -- Data: os.O_EXLOCK
     The above constants are extensions and not present if they are not
     defined by the C library.

---------- Footnotes ----------

(1) http://msdn.microsoft.com/en-us/library/z0kc8e3z.aspx


File: python.info,  Node: Files and Directories,  Next: Process Management,  Prev: File Descriptor Operations,  Up: os — Miscellaneous operating system interfaces

5.15.1.5 Files and Directories
..............................

 -- Function: os.access (path, mode)
     Use the real uid/gid to test for access to `path'.  Note that most
     operations will use the effective uid/gid, therefore this routine
     can be used in a suid/sgid environment to test if the invoking
     user has the specified access to `path'.  `mode' should be *Note
     F_OK: 116d. to test the existence of `path', or it can be the
     inclusive OR of one or more of *Note R_OK: 116e, *Note W_OK: 116f,
     and *Note X_OK: 1170. to test permissions.  Return *Note True:
     3c8. if access is allowed, *Note False: 3c9. if not. See the Unix
     man page `access(2)' for more information.

     Availability: Unix, Windows.

          Note: Using *Note access(): 116c. to check if a user is
          authorized to e.g. open a file before actually doing so using
          *Note open(): 2d9. creates a security hole, because the user
          might exploit the short time interval between checking and
          opening the file to manipulate it. It’s preferable to use
          *Note EAFP: 1171.  techniques. For example:

              if os.access("myfile", os.R_OK):
                  with open("myfile") as fp:
                      return fp.read()
              return "some default data"

          is better written as:

              try:
                  fp = open("myfile")
              except IOError as e:
                  if e.errno == errno.EACCES:
                      return "some default data"
                  # Not a permission error.
                  raise
              else:
                  with fp:
                      return fp.read()

          Note: I/O operations may fail even when *Note access(): 116c.
          indicates that they would succeed, particularly for
          operations on network filesystems which may have permissions
          semantics beyond the usual POSIX permission-bit model.

 -- Data: os.F_OK
     Value to pass as the `mode' parameter of *Note access(): 116c. to
     test the existence of `path'.

 -- Data: os.R_OK
     Value to include in the `mode' parameter of *Note access(): 116c.
     to test the readability of `path'.

 -- Data: os.W_OK
     Value to include in the `mode' parameter of *Note access(): 116c.
     to test the writability of `path'.

 -- Data: os.X_OK
     Value to include in the `mode' parameter of *Note access(): 116c.
     to determine if `path' can be executed.

 -- Function: os.chdir (path)
     Change the current working directory to `path'.

     Availability: Unix, Windows.

 -- Function: os.fchdir (fd)
     Change the current working directory to the directory represented
     by the file descriptor `fd'.  The descriptor must refer to an
     opened directory, not an open file.

     Availability: Unix.

     New in version 2.3.


 -- Function: os.getcwd ()
     Return a string representing the current working directory.

     Availability: Unix, Windows.

 -- Function: os.getcwdu ()
     Return a Unicode object representing the current working directory.

     Availability: Unix, Windows.

     New in version 2.3.


 -- Function: os.chflags (path, flags)
     Set the flags of `path' to the numeric `flags'. `flags' may take a
     combination (bitwise OR) of the following values (as defined in
     the *Note stat: 161. module):

        * *Note stat.UF_NODUMP: e7e.

        * *Note stat.UF_IMMUTABLE: e7f.

        * *Note stat.UF_APPEND: e80.

        * *Note stat.UF_OPAQUE: e81.

        * *Note stat.UF_NOUNLINK: e82.

        * *Note stat.UF_COMPRESSED: e83.

        * *Note stat.UF_HIDDEN: e84.

        * *Note stat.SF_ARCHIVED: e85.

        * *Note stat.SF_IMMUTABLE: e86.

        * *Note stat.SF_APPEND: e87.

        * *Note stat.SF_NOUNLINK: e88.

        * *Note stat.SF_SNAPSHOT: e89.

     Availability: Unix.

     New in version 2.6.


 -- Function: os.chroot (path)
     Change the root directory of the current process to `path'.
     Availability: Unix.

     New in version 2.2.


 -- Function: os.chmod (path, mode)
     Change the mode of `path' to the numeric `mode'. `mode' may take
     one of the following values (as defined in the *Note stat: 161.
     module) or bitwise ORed combinations of them:

        * *Note stat.S_ISUID: e6a.

        * *Note stat.S_ISGID: e6b.

        * *Note stat.S_ENFMT: e6d.

        * *Note stat.S_ISVTX: e6e.

        * *Note stat.S_IREAD: e7a.

        * *Note stat.S_IWRITE: e7b.

        * *Note stat.S_IEXEC: e7c.

        * *Note stat.S_IRWXU: e6f.

        * *Note stat.S_IRUSR: e70.

        * *Note stat.S_IWUSR: e71.

        * *Note stat.S_IXUSR: e72.

        * *Note stat.S_IRWXG: e73.

        * *Note stat.S_IRGRP: e74.

        * *Note stat.S_IWGRP: e75.

        * *Note stat.S_IXGRP: e6c.

        * *Note stat.S_IRWXO: e76.

        * *Note stat.S_IROTH: e77.

        * *Note stat.S_IWOTH: e78.

        * *Note stat.S_IXOTH: e79.

     Availability: Unix, Windows.

          Note: Although Windows supports *Note chmod(): e57, you can
          only  set the file’s read-only flag with it (via the
          `stat.S_IWRITE'  and `stat.S_IREAD' constants or a
          corresponding integer value).  All other bits are ignored.

 -- Function: os.chown (path, uid, gid)
     Change the owner and group id of `path' to the numeric `uid' and
     `gid'. To leave one of the ids unchanged, set it to -1.

     Availability: Unix.

 -- Function: os.lchflags (path, flags)
     Set the flags of `path' to the numeric `flags', like *Note
     chflags(): e7d, but do not follow symbolic links.

     Availability: Unix.

     New in version 2.6.


 -- Function: os.lchmod (path, mode)
     Change the mode of `path' to the numeric `mode'. If path is a
     symlink, this affects the symlink rather than the target. See the
     docs for *Note chmod(): e57.  for possible values of `mode'.

     Availability: Unix.

     New in version 2.6.


 -- Function: os.lchown (path, uid, gid)
     Change the owner and group id of `path' to the numeric `uid' and
     `gid'. This function will not follow symbolic links.

     Availability: Unix.

     New in version 2.3.


 -- Function: os.link (source, link_name)
     Create a hard link pointing to `source' named `link_name'.

     Availability: Unix.

 -- Function: os.listdir (path)
     Return a list containing the names of the entries in the directory
     given by `path'.  The list is in arbitrary order.  It does not
     include the special entries `'.'' and `'..'' even if they are
     present in the directory.

     Availability: Unix, Windows.

     Changed in version 2.3: On Windows NT/2k/XP and Unix, if `path' is
     a Unicode object, the result will be a list of Unicode objects.
     Undecodable filenames will still be returned as string objects.


 -- Function: os.lstat (path)
     Perform the equivalent of an `lstat()' system call on the given
     path.  Similar to *Note stat(): 3de, but does not follow symbolic
     links.  On platforms that do not support symbolic links, this is
     an alias for *Note stat(): 3de.

 -- Function: os.mkfifo (path[, mode])
     Create a FIFO (a named pipe) named `path' with numeric mode
     `mode'.  The default `mode' is `0666' (octal).  The current umask
     value is first masked out from the mode.

     Availability: Unix.

     FIFOs are pipes that can be accessed like regular files.  FIFOs
     exist until they are deleted (for example with *Note os.unlink():
     117c.). Generally, FIFOs are used as rendezvous between
     “client” and “server” type processes: the server opens the
     FIFO for reading, and the client opens it for writing.  Note that
     *Note mkfifo(): 117b.  doesn’t open the FIFO — it just creates
     the rendezvous point.

 -- Function: os.mknod (filename[, mode=0600[, device=0]])
     Create a filesystem node (file, device special file or named pipe)
     named `filename'. `mode' specifies both the permissions to use and
     the type of node to be created, being combined (bitwise OR) with
     one of `stat.S_IFREG', `stat.S_IFCHR', `stat.S_IFBLK', and
     `stat.S_IFIFO' (those constants are available in *Note stat: 161.).
     For `stat.S_IFCHR' and `stat.S_IFBLK', `device' defines the newly
     created device special file (probably using *Note os.makedev():
     117e.), otherwise it is ignored.

     New in version 2.3.


 -- Function: os.major (device)
     Extract the device major number from a raw device number (usually
     the `st_dev' or `st_rdev' field from `stat').

     New in version 2.3.


 -- Function: os.minor (device)
     Extract the device minor number from a raw device number (usually
     the `st_dev' or `st_rdev' field from `stat').

     New in version 2.3.


 -- Function: os.makedev (major, minor)
     Compose a raw device number from the major and minor device
     numbers.

     New in version 2.3.


 -- Function: os.mkdir (path[, mode])
     Create a directory named `path' with numeric mode `mode'. The
     default `mode' is `0777' (octal).  If the directory already exists,
     *Note OSError: 231. is raised.

     On some systems, `mode' is ignored.  Where it is used, the current
     umask value is first masked out.  If bits other than the last 9
     (i.e. the last 3 digits of the octal representation of the `mode')
     are set, their meaning is platform-dependent.  On some platforms,
     they are ignored and you should call *Note chmod(): e57.
     explicitly to set them.

     It is also possible to create temporary directories; see the *Note
     tempfile: 173. module’s *Note tempfile.mkdtemp(): eb2. function.

     Availability: Unix, Windows.

 -- Function: os.makedirs (path[, mode])
     Recursive directory creation function.  Like *Note mkdir(): 1181,
     but makes all intermediate-level directories needed to contain the
     leaf directory.  Raises an *Note error: e2a. exception if the leaf
     directory already exists or cannot be created.  The default `mode'
     is `0777' (octal).

     The `mode' parameter is passed to *Note mkdir(): 1181.; see *Note
     the mkdir() description: 1182. for how it is interpreted.

          Note: *Note makedirs(): 1183. will become confused if the
          path elements to create include *Note os.pardir: 1184.

     New in version 1.5.2.

     Changed in version 2.3: This function now handles UNC paths
     correctly.


 -- Function: os.pathconf (path, name)
     Return system configuration information relevant to a named file.
     `name' specifies the configuration value to retrieve; it may be a
     string which is the name of a defined system value; these names
     are specified in a number of standards (POSIX.1, Unix 95, Unix 98,
     and others).  Some platforms define additional names as well.  The
     names known to the host operating system are given in the
     `pathconf_names' dictionary.  For configuration variables not
     included in that mapping, passing an integer for `name' is also
     accepted.

     If `name' is a string and is not known, *Note ValueError: 236. is
     raised.  If a specific value for `name' is not supported by the
     host system, even if it is included in `pathconf_names', an *Note
     OSError: 231. is raised with *Note errno.EINVAL: 1148. for the
     error number.

     Availability: Unix.

 -- Data: os.pathconf_names
     Dictionary mapping names accepted by *Note pathconf(): 1185. and
     *Note fpathconf(): 1147. to the integer values defined for those
     names by the host operating system.  This can be used to determine
     the set of names known to the system. Availability: Unix.

 -- Function: os.readlink (path)
     Return a string representing the path to which the symbolic link
     points.  The result may be either an absolute or relative
     pathname; if it is relative, it may be converted to an absolute
     pathname using `os.path.join(os.path.dirname(path), result)'.

     Changed in version 2.6: If the `path' is a Unicode object the
     result will also be a Unicode object.

     Availability: Unix.

 -- Function: os.remove (path)
     Remove (delete) the file `path'.  If `path' is a directory, *Note
     OSError: 231. is raised; see *Note rmdir(): ed6. below to remove a
     directory.  This is identical to the *Note unlink(): 117c.
     function documented below.  On Windows, attempting to remove a
     file that is in use causes an exception to be raised; on Unix, the
     directory entry is removed but the storage allocated to the file
     is not made available until the original file is no longer in use.

     Availability: Unix, Windows.

 -- Function: os.removedirs (path)
     Remove directories recursively.  Works like *Note rmdir(): ed6.
     except that, if the leaf directory is successfully removed, *Note
     removedirs(): 1188.  tries to successively remove every parent
     directory mentioned in  `path' until an error is raised (which is
     ignored, because it generally means that a parent directory is not
     empty). For example, `os.removedirs('foo/bar/baz')' will first
     remove the directory `'foo/bar/baz'', and then remove `'foo/bar''
     and `'foo'' if they are empty. Raises *Note OSError: 231. if the
     leaf directory could not be successfully removed.

     New in version 1.5.2.


 -- Function: os.rename (src, dst)
     Rename the file or directory `src' to `dst'.  If `dst' is a
     directory, *Note OSError: 231. will be raised.  On Unix, if `dst'
     exists and is a file, it will be replaced silently if the user has
     permission.  The operation may fail on some Unix flavors if `src'
     and `dst' are on different filesystems.  If successful, the
     renaming will be an atomic operation (this is a POSIX
     requirement).  On Windows, if `dst' already exists, *Note OSError:
     231. will be raised even if it is a file; there may be no way to
     implement an atomic rename when `dst' names an existing file.

     Availability: Unix, Windows.

 -- Function: os.renames (old, new)
     Recursive directory or file renaming function. Works like *Note
     rename(): ed8, except creation of any intermediate directories
     needed to make the new pathname good is attempted first. After the
     rename, directories corresponding to rightmost path segments of
     the old name will be pruned away using *Note removedirs(): 1188.

     New in version 1.5.2.

          Note: This function can fail with the new directory structure
          made if you lack permissions needed to remove the leaf
          directory or file.

 -- Function: os.rmdir (path)
     Remove (delete) the directory `path'.  Only works when the
     directory is empty, otherwise, *Note OSError: 231. is raised.  In
     order to remove whole directory trees, *Note shutil.rmtree(): ed4.
     can be used.

     Availability: Unix, Windows.

 -- Function: os.stat (path)
     Perform the equivalent of a `stat()' system call on the given path.
     (This function follows symlinks; to stat a symlink use *Note
     lstat(): e28.)

     The return value is an object whose attributes correspond to the
     members of the `stat' structure, namely:

        * `st_mode' - protection bits,

        * `st_ino' - inode number,

        * `st_dev' - device,

        * `st_nlink' - number of hard links,

        * `st_uid' - user id of owner,

        * `st_gid' - group id of owner,

        * `st_size' - size of file, in bytes,

        * `st_atime' - time of most recent access,

        * `st_mtime' - time of most recent content modification,

        * `st_ctime' - platform dependent; time of most recent metadata
          change on Unix, or the time of creation on Windows)

     Changed in version 2.3: If *Note stat_float_times(): 47e. returns
     `True', the time values are floats, measuring seconds. Fractions
     of a second may be reported if the system supports that.  See
     *Note stat_float_times(): 47e. for further discussion.

     On some Unix systems (such as Linux), the following attributes may
     also be available:

        * `st_blocks' - number of 512-byte blocks allocated for file

        * `st_blksize' - filesystem blocksize for efficient file system
          I/O

        * `st_rdev' - type of device if an inode device

        * `st_flags' - user defined flags for file

     On other Unix systems (such as FreeBSD), the following attributes
     may be available (but may be only filled out if root tries to use
     them):

        * `st_gen' - file generation number

        * `st_birthtime' - time of file creation

     On RISCOS systems, the following attributes are also available:

        * `st_ftype' (file type)

        * `st_attrs' (attributes)

        * `st_obtype' (object type).

          Note: The exact meaning and resolution of the `st_atime',
          `st_mtime', and `st_ctime' attributes depend on the operating
          system and the file system. For example, on Windows systems
          using the FAT or FAT32 file systems, `st_mtime' has 2-second
          resolution, and `st_atime' has only 1-day resolution.  See
          your operating system documentation for details.

     For backward compatibility, the return value of *Note stat(): 3de.
     is also accessible as a tuple of at least 10 integers giving the
     most important (and portable) members of the `stat' structure, in
     the order `st_mode', `st_ino', `st_dev', `st_nlink', `st_uid',
     `st_gid', `st_size', `st_atime', `st_mtime', `st_ctime'. More
     items may be added at the end by some implementations.

     The standard module *Note stat: 161. defines functions and
     constants that are useful for extracting information from a `stat'
     structure. (On Windows, some items are filled with dummy values.)

     Example:

         >>> import os
         >>> statinfo = os.stat('somefile.txt')
         >>> statinfo
         (33188, 422511, 769, 1, 1032, 100, 926, 1105022698,1105022732, 1105022732)
         >>> statinfo.st_size
         926

     Availability: Unix, Windows.

     Changed in version 2.2: Added access to values as attributes of
     the returned object.

     Changed in version 2.5: Added `st_gen' and `st_birthtime'.


 -- Function: os.stat_float_times ([newvalue])
     Determine whether `stat_result' represents time stamps as float
     objects.  If `newvalue' is `True', future calls to *Note stat():
     3de. return floats, if it is `False', future calls return ints. If
     `newvalue' is omitted, return the current setting.

     For compatibility with older Python versions, accessing
     `stat_result' as a tuple always returns integers.

     Changed in version 2.5: Python now returns float values by
     default. Applications which do not work correctly with floating
     point time stamps can use this function to restore the old
     behaviour.

     The resolution of the timestamps (that is the smallest possible
     fraction) depends on the system. Some systems only support second
     resolution; on these systems, the fraction will always be zero.

     It is recommended that this setting is only changed at program
     startup time in the `__main__' module; libraries should never
     change this setting. If an application uses a library that works
     incorrectly if floating point time stamps are processed, this
     application should turn the feature off until the library has been
     corrected.

 -- Function: os.statvfs (path)
     Perform a `statvfs()' system call on the given path.  The return
     value is an object whose attributes describe the filesystem on the
     given path, and correspond to the members of the `statvfs'
     structure, namely: `f_bsize', `f_frsize', `f_blocks', `f_bfree',
     `f_bavail', `f_files', `f_ffree', `f_favail', `f_flag',
     `f_namemax'.

     For backward compatibility, the return value is also accessible as
     a tuple whose values correspond to the attributes, in the order
     given above. The standard module *Note statvfs: 162. defines
     constants that are useful for extracting information from a
     `statvfs' structure when accessing it as a sequence; this remains
     useful when writing code that needs to work with versions of Python
     that don’t support accessing the fields as attributes.

     Availability: Unix.

     Changed in version 2.2: Added access to values as attributes of
     the returned object.


 -- Function: os.symlink (source, link_name)
     Create a symbolic link pointing to `source' named `link_name'.

     Availability: Unix.

 -- Function: os.tempnam ([dir[, prefix]])
     Return a unique path name that is reasonable for creating a
     temporary file.  This will be an absolute path that names a
     potential directory entry in the directory `dir' or a common
     location for temporary files if `dir' is omitted or `None'.  If
     given and not `None', `prefix' is used to provide a short prefix
     to the filename.  Applications are responsible for properly
     creating and managing files created using paths returned by *Note
     tempnam(): 118b.; no automatic cleanup is provided. On Unix, the
     environment variable `TMPDIR' overrides `dir', while on Windows `TMP'
     is used.  The specific behavior of this function depends on the C
     library implementation; some aspects are underspecified in system
     documentation.

          Warning: Use of *Note tempnam(): 118b. is vulnerable to
          symlink attacks; consider using *Note tmpfile(): 1136.
          (section *Note File Object Creation: 1133.) instead.

     Availability: Unix, Windows.

 -- Function: os.tmpnam ()
     Return a unique path name that is reasonable for creating a
     temporary file.  This will be an absolute path that names a
     potential directory entry in a common location for temporary
     files.  Applications are responsible for properly creating and
     managing files created using paths returned by *Note tmpnam():
     118c.; no automatic cleanup is provided.

          Warning: Use of *Note tmpnam(): 118c. is vulnerable to
          symlink attacks; consider using *Note tmpfile(): 1136.
          (section *Note File Object Creation: 1133.) instead.

     Availability: Unix, Windows.  This function probably shouldn’t
     be used on Windows, though: Microsoft’s implementation of *Note
     tmpnam(): 118c. always creates a name in the root directory of the
     current drive, and that’s generally a poor location for a temp
     file (depending on privileges, you may not even be able to open a
     file using this name).

 -- Data: os.TMP_MAX
     The maximum number of unique names that *Note tmpnam(): 118c. will
     generate before reusing names.

 -- Function: os.unlink (path)
     Remove (delete) the file `path'.  This is the same function as
     *Note remove(): ed5.; the *Note unlink(): 117c. name is its
     traditional Unix name.

     Availability: Unix, Windows.

 -- Function: os.utime (path, times)
     Set the access and modified times of the file specified by `path'.
     If `times' is `None', then the file’s access and modified times
     are set to the current time. (The effect is similar to running the
     Unix program `touch' on the path.)  Otherwise, `times' must be a
     2-tuple of numbers, of the form `(atime, mtime)' which is used to
     set the access and modified times, respectively. Whether a
     directory can be given for `path' depends on whether the operating
     system implements directories as files (for example, Windows does
     not).  Note that the exact times you set here may not be returned
     by a subsequent *Note stat(): 3de. call, depending on the
     resolution with which your operating system records access and
     modification times; see *Note stat(): 3de.

     Changed in version 2.0: Added support for `None' for `times'.

     Availability: Unix, Windows.

 -- Function: os.walk (top, topdown=True, onerror=None,
          followlinks=False)
     Generate the file names in a directory tree by walking the tree
     either top-down or bottom-up. For each directory in the tree
     rooted at directory `top' (including `top' itself), it yields a
     3-tuple `(dirpath, dirnames, filenames)'.

     `dirpath' is a string, the path to the directory.  `dirnames' is a
     list of the names of the subdirectories in `dirpath' (excluding
     `'.'' and `'..'').  `filenames' is a list of the names of the
     non-directory files in `dirpath'.  Note that the names in the
     lists contain no path components.  To get a full path (which
     begins with `top') to a file or directory in `dirpath', do
     `os.path.join(dirpath, name)'.

     If optional argument `topdown' is `True' or not specified, the
     triple for a directory is generated before the triples for any of
     its subdirectories (directories are generated top-down).  If
     `topdown' is `False', the triple for a directory is generated
     after the triples for all of its subdirectories (directories are
     generated bottom-up). No matter the value of `topdown', the list
     of subdirectories is retrieved before the tuples for the directory
     and its subdirectories are generated.

     When `topdown' is `True', the caller can modify the `dirnames'
     list in-place (perhaps using *Note del: 585. or slice assignment),
     and *Note walk(): 368. will only recurse into the subdirectories
     whose names remain in `dirnames'; this can be used to prune the
     search, impose a specific order of visiting, or even to inform
     *Note walk(): 368. about directories the caller creates or renames
     before it resumes *Note walk(): 368. again.  Modifying `dirnames'
     when `topdown' is `False' has no effect on the behavior of the
     walk, because in bottom-up mode the directories in `dirnames' are
     generated before `dirpath' itself is generated.

     By default, errors from the *Note listdir(): 2d5. call are
     ignored.  If optional argument `onerror' is specified, it should
     be a function; it will be called with one argument, an *Note
     OSError: 231. instance.  It can report the error to continue with
     the walk, or raise the exception to abort the walk.  Note that the
     filename is available as the `filename' attribute of the exception
     object.

     By default, *Note walk(): 368. will not walk down into symbolic
     links that resolve to directories. Set `followlinks' to `True' to
     visit directories pointed to by symlinks, on systems that support
     them.

     New in version 2.6: The `followlinks' parameter.

          Note: Be aware that setting `followlinks' to `True' can lead
          to infinite recursion if a link points to a parent directory
          of itself. *Note walk(): 368. does not keep track of the
          directories it visited already.

          Note: If you pass a relative pathname, don’t change the
          current working directory between resumptions of *Note
          walk(): 368.  *Note walk(): 368. never changes the current
          directory, and assumes that its caller doesn’t either.

     This example displays the number of bytes taken by non-directory
     files in each directory under the starting directory, except that
     it doesn’t look under any CVS subdirectory:

         import os
         from os.path import join, getsize
         for root, dirs, files in os.walk('python/Lib/email'):
             print root, "consumes",
             print sum(getsize(join(root, name)) for name in files),
             print "bytes in", len(files), "non-directory files"
             if 'CVS' in dirs:
                 dirs.remove('CVS')  # don't visit CVS directories

     In the next example, walking the tree bottom-up is essential:
     *Note rmdir(): ed6.  doesn’t allow deleting a directory before
     the directory is empty:

         # Delete everything reachable from the directory named in "top",
         # assuming there are no symbolic links.
         # CAUTION:  This is dangerous!  For example, if top == '/', it
         # could delete all your disk files.
         import os
         for root, dirs, files in os.walk(top, topdown=False):
             for name in files:
                 os.remove(os.path.join(root, name))
             for name in dirs:
                 os.rmdir(os.path.join(root, name))

     New in version 2.3.


