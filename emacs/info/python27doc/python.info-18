This is python.info, produced by makeinfo version 4.8 from python.texi.

Generated by Sphinx 1.6.3.
INFO-DIR-SECTION Python
START-INFO-DIR-ENTRY
* Python: (python.info). The Python reference manual.
END-INFO-DIR-ENTRY

     Python 2.7.13, July 15, 2017

     Copyright (C) 1990-2017, Python Software Foundation


File: python.info,  Node: lib2to3 - 2to3’s library,  Prev: Fixers,  Up: 2to3 - Automated Python 2 to 3 code translation

5.25.4.3 `lib2to3' - 2to3’s library
.....................................

     Note: The *Note lib2to3: ff. API should be considered unstable and
     may change drastically in the future.


File: python.info,  Node: test — Regression tests package for Python,  Next: test test_support — Utility functions for tests,  Prev: 2to3 - Automated Python 2 to 3 code translation,  Up: Development Tools

5.25.5 `test' — Regression tests package for Python
-----------------------------------------------------

     Note: The *Note test: 175. package is meant for internal use by
     Python only. It is documented for the benefit of the core
     developers of Python. Any use of this package outside of
     Python’s standard library is discouraged as code mentioned here
     can change or be removed without notice between releases of Python.

The *Note test: 175. package contains all regression tests for Python
as well as the modules *Note test.test_support: 176. and
`test.regrtest'.  *Note test.test_support: 176. is used to enhance your
tests while `test.regrtest' drives the testing suite.

Each module in the *Note test: 175. package whose name starts with
`test_' is a testing suite for a specific module or feature. All new
tests should be written using the *Note unittest: 187. or *Note
doctest: b5. module.  Some older tests are written using a
“traditional” testing style that compares output printed to
`sys.stdout'; this style of test is considered deprecated.

See also
........

Module *Note unittest: 187.
     Writing PyUnit regression tests.

Module *Note doctest: b5.
     Tests embedded in documentation strings.

* Menu:

* Writing Unit Tests for the test package::
* Running tests using the command-line interface::


File: python.info,  Node: Writing Unit Tests for the test package,  Next: Running tests using the command-line interface,  Up: test — Regression tests package for Python

5.25.5.1 Writing Unit Tests for the `test' package
..................................................

It is preferred that tests that use the *Note unittest: 187. module
follow a few guidelines. One is to name the test module by starting it
with `test_' and end it with the name of the module being tested. The
test methods in the test module should start with `test_' and end with
a description of what the method is testing. This is needed so that the
methods are recognized by the test driver as test methods. Also, no
documentation string for the method should be included. A comment (such
as `# Tests function returns only True or False') should be used to
provide documentation for test methods. This is done because
documentation strings get printed out if they exist and thus what test
is being run is not stated.

A basic boilerplate is often used:

    import unittest
    from test import test_support

    class MyTestCase1(unittest.TestCase):

        # Only use setUp() and tearDown() if necessary

        def setUp(self):
            ... code to execute in preparation for tests ...

        def tearDown(self):
            ... code to execute to clean up after tests ...

        def test_feature_one(self):
            # Test feature one.
            ... testing code ...

        def test_feature_two(self):
            # Test feature two.
            ... testing code ...

        ... more test methods ...

    class MyTestCase2(unittest.TestCase):
        ... same structure as MyTestCase1 ...

    ... more test classes ...

    def test_main():
        test_support.run_unittest(MyTestCase1,
                                  MyTestCase2,
                                  ... list other tests ...
                                 )

    if __name__ == '__main__':
        test_main()

This boilerplate code allows the testing suite to be run by
`test.regrtest' as well as on its own as a script.

The goal for regression testing is to try to break code. This leads to
a few guidelines to be followed:

   * The testing suite should exercise all classes, functions, and
     constants. This includes not just the external API that is to be
     presented to the outside world but also “private” code.

   * Whitebox testing (examining the code being tested when the tests
     are being written) is preferred. Blackbox testing (testing only
     the published user interface) is not complete enough to make sure
     all boundary and edge cases are tested.

   * Make sure all possible values are tested including invalid ones.
     This makes sure that not only all valid values are acceptable but
     also that improper values are handled correctly.

   * Exhaust as many code paths as possible. Test where branching
     occurs and thus tailor input to make sure as many different paths
     through the code are taken.

   * Add an explicit test for any bugs discovered for the tested code.
     This will make sure that the error does not crop up again if the
     code is changed in the future.

   * Make sure to clean up after your tests (such as close and remove
     all temporary files).

   * If a test is dependent on a specific condition of the operating
     system then verify the condition already exists before attempting
     the test.

   * Import as few modules as possible and do it as soon as possible.
     This minimizes external dependencies of tests and also minimizes
     possible anomalous behavior from side-effects of importing a
     module.

   * Try to maximize code reuse. On occasion, tests will vary by
     something as small as what type of input is used. Minimize code
     duplication by subclassing a basic test class with a class that
     specifies the input:

         class TestFuncAcceptsSequences(unittest.TestCase):

             func = mySuperWhammyFunction

             def test_func(self):
                 self.func(self.arg)

         class AcceptLists(TestFuncAcceptsSequences):
             arg = [1, 2, 3]

         class AcceptStrings(TestFuncAcceptsSequences):
             arg = 'abc'

         class AcceptTuples(TestFuncAcceptsSequences):
             arg = (1, 2, 3)

See also
........

Test Driven Development
     A book by Kent Beck on writing tests before code.


File: python.info,  Node: Running tests using the command-line interface,  Prev: Writing Unit Tests for the test package,  Up: test — Regression tests package for Python

5.25.5.2 Running tests using the command-line interface
.......................................................

The `test.regrtest' module can be run as a script to drive Python’s
regression test suite, thanks to the *Note -m: 30e. option: `python -m
test.regrtest'.  Running the script by itself automatically starts
running all regression tests in the *Note test: 175. package. It does
this by finding all modules in the package whose name starts with
`test_', importing them, and executing the function `test_main()' if
present. The names of tests to execute may also be passed to the
script. Specifying a single regression test (`python -m test.regrtest
test_spam') will minimize output and only print whether the test passed
or failed and thus minimize output.

Running `test.regrtest' directly allows what resources are available for
tests to use to be set. You do this by using the `-u' command-line
option. Specifying `all' as the value for the `-u' option enables all
possible resources: `python -m test.regrtest -uall'.  If all but one
resource is desired (a more common case), a comma-separated list of
resources that are not desired may be listed after `all'. The command
`python -m test.regrtest -uall,-audio,-largefile' will run
`test.regrtest' with all resources except the `audio' and `largefile'
resources. For a list of all resources and more command-line options,
run `python -m test.regrtest -h'.

Some other ways to execute the regression tests depend on what platform
the tests are being executed on. On Unix, you can run `make test' at the
top-level directory where Python was built. On Windows, executing
`rt.bat' from your `PCBuild' directory will run all regression tests.


File: python.info,  Node: test test_support — Utility functions for tests,  Prev: test — Regression tests package for Python,  Up: Development Tools

5.25.6 `test.test_support' — Utility functions for tests
----------------------------------------------------------

     Note: The *Note test.test_support: 176. module has been renamed to
     `test.support' in Python 3.x.

The *Note test.test_support: 176. module provides support for
Python’s regression tests.

This module defines the following exceptions:

 -- Exception: test.test_support.TestFailed
     Exception to be raised when a test fails. This is deprecated in
     favor of *Note unittest: 187.-based tests and *Note
     unittest.TestCase: 285.’s assertion methods.

 -- Exception: test.test_support.ResourceDenied
     Subclass of *Note unittest.SkipTest: 280. Raised when a resource
     (such as a network connection) is not available. Raised by the
     *Note requires(): 23a6.  function.

The *Note test.test_support: 176. module defines the following
constants:

 -- Data: test.test_support.verbose
     *Note True: 3c8. when verbose output is enabled. Should be checked
     when more detailed information is desired about a running test.
     `verbose' is set by `test.regrtest'.

 -- Data: test.test_support.have_unicode
     *Note True: 3c8. when Unicode support is available.

 -- Data: test.test_support.is_jython
     *Note True: 3c8. if the running interpreter is Jython.

 -- Data: test.test_support.TESTFN
     Set to a name that is safe to use as the name of a temporary file.
     Any temporary file that is created should be closed and unlinked
     (removed).

The *Note test.test_support: 176. module defines the following
functions:

 -- Function: test.test_support.forget (module_name)
     Remove the module named `module_name' from `sys.modules' and
     delete any byte-compiled files of the module.

 -- Function: test.test_support.is_resource_enabled (resource)
     Return *Note True: 3c8. if `resource' is enabled and available.
     The list of available resources is only set when `test.regrtest'
     is executing the tests.

 -- Function: test.test_support.requires (resource[, msg])
     Raise *Note ResourceDenied: 23a5. if `resource' is not available.
     `msg' is the argument to *Note ResourceDenied: 23a5. if it is
     raised. Always returns *Note True: 3c8. if called by a function
     whose `__name__' is `'__main__''.  Used when tests are executed by
     `test.regrtest'.

 -- Function: test.test_support.findfile (filename)
     Return the path to the file named `filename'. If no match is found
     `filename' is returned. This does not equal a failure since it
     could be the path to the file.

 -- Function: test.test_support.run_unittest (*classes)
     Execute *Note unittest.TestCase: 285. subclasses passed to the
     function. The function scans the classes for methods starting with
     the prefix `test_' and executes the tests individually.

     It is also legal to pass strings as parameters; these should be
     keys in `sys.modules'. Each associated module will be scanned by
     `unittest.TestLoader.loadTestsFromModule()'. This is usually seen
     in the following `test_main()' function:

         def test_main():
             test_support.run_unittest(__name__)

     This will run all tests defined in the named module.

 -- Function: test.test_support.check_warnings (*filters, quiet=True)
     A convenience wrapper for *Note warnings.catch_warnings(): 23b0.
     that makes it easier to test that a warning was correctly raised.
     It is approximately equivalent to calling
     `warnings.catch_warnings(record=True)' with *Note
     warnings.simplefilter(): 23b1. set to `always' and with the option
     to automatically validate the results that are recorded.

     `check_warnings' accepts 2-tuples of the form `("message regexp",
     WarningCategory)' as positional arguments. If one or more
     `filters' are provided, or if the optional keyword argument
     `quiet' is *Note False: 3c9, it checks to make sure the warnings
     are as expected:  each specified filter must match at least one of
     the warnings raised by the enclosed code or the test fails, and if
     any warnings are raised that do not match any of the specified
     filters the test fails.  To disable the first of these checks, set
     `quiet' to *Note True: 3c8.

     If no arguments are specified, it defaults to:

         check_warnings(("", Warning), quiet=True)

     In this case all warnings are caught and no errors are raised.

     On entry to the context manager, a `WarningRecorder' instance is
     returned. The underlying warnings list from *Note
     catch_warnings(): 23b0. is available via the recorder object’s
     *Note warnings: 193. attribute.  As a convenience, the attributes
     of the object representing the most recent warning can also be
     accessed directly through the recorder object (see example below).
     If no warning has been raised, then any of the attributes that
     would otherwise be expected on an object representing a warning
     will return *Note None: 3b2.

     The recorder object also has a `reset()' method, which clears the
     warnings list.

     The context manager is designed to be used like this:

         with check_warnings(("assertion is always true", SyntaxWarning),
                             ("", UserWarning)):
             exec('assert(False, "Hey!")')
             warnings.warn(UserWarning("Hide me!"))

     In this case if either warning was not raised, or some other
     warning was raised, *Note check_warnings(): 23af. would raise an
     error.

     When a test needs to look more deeply into the warnings, rather
     than just checking whether or not they occurred, code like this
     can be used:

         with check_warnings(quiet=True) as w:
             warnings.warn("foo")
             assert str(w.args[0]) == "foo"
             warnings.warn("bar")
             assert str(w.args[0]) == "bar"
             assert str(w.warnings[0].args[0]) == "foo"
             assert str(w.warnings[1].args[0]) == "bar"
             w.reset()
             assert len(w.warnings) == 0

     Here all warnings will be caught, and the test code tests the
     captured warnings directly.

     New in version 2.6.

     Changed in version 2.7: New optional arguments `filters' and
     `quiet'.


 -- Function: test.test_support.check_py3k_warnings (*filters,
          quiet=False)
     Similar to *Note check_warnings(): 23af, but for Python 3
     compatibility warnings.  If `sys.py3kwarning == 1', it checks if
     the warning is effectively raised.  If `sys.py3kwarning == 0', it
     checks that no warning is raised.  It accepts 2-tuples of the form
     `("message regexp", WarningCategory)' as positional arguments.
     When the optional keyword argument `quiet' is *Note True: 3c8, it
     does not fail if a filter catches nothing.  Without arguments, it
     defaults to:

         check_py3k_warnings(("", DeprecationWarning), quiet=False)

     New in version 2.7.


 -- Function: test.test_support.captured_stdout ()
     This is a context manager that runs the *Note with: 1c1. statement
     body using a *Note StringIO.StringIO: 2df. object as sys.stdout.
     That object can be retrieved using the `as' clause of the *Note
     with: 1c1. statement.

     Example use:

         with captured_stdout() as s:
             print "hello"
         assert s.getvalue() == "hello\n"

     New in version 2.6.


 -- Function: test.test_support.import_module (name, deprecated=False)
     This function imports and returns the named module. Unlike a normal
     import, this function raises *Note unittest.SkipTest: 280. if the
     module cannot be imported.

     Module and package deprecation messages are suppressed during this
     import if `deprecated' is *Note True: 3c8.

     New in version 2.7.


 -- Function: test.test_support.import_fresh_module (name, fresh=(),
          blocked=(), deprecated=False)
     This function imports and returns a fresh copy of the named Python
     module by removing the named module from `sys.modules' before
     doing the import.  Note that unlike *Note reload(): 595, the
     original module is not affected by this operation.

     `fresh' is an iterable of additional module names that are also
     removed from the `sys.modules' cache before doing the import.

     `blocked' is an iterable of module names that are replaced with `0'
     in the module cache during the import to ensure that attempts to
     import them raise *Note ImportError: 388.

     The named module and any modules named in the `fresh' and `blocked'
     parameters are saved before starting the import and then
     reinserted into `sys.modules' when the fresh import is complete.

     Module and package deprecation messages are suppressed during this
     import if `deprecated' is *Note True: 3c8.

     This function will raise *Note unittest.SkipTest: 280. if the
     named module cannot be imported.

     Example use:

         # Get copies of the warnings module for testing without
         # affecting the version being used by the rest of the test suite
         # One copy uses the C implementation, the other is forced to use
         # the pure Python fallback implementation
         py_warnings = import_fresh_module('warnings', blocked=['_warnings'])
         c_warnings = import_fresh_module('warnings', fresh=['_warnings'])

     New in version 2.7.


The *Note test.test_support: 176. module defines the following classes:

 -- Class: test.test_support.TransientResource (exc[, **kwargs])
     Instances are a context manager that raises *Note ResourceDenied:
     23a5. if the specified exception type is raised.  Any keyword
     arguments are treated as attribute/value pairs to be compared
     against any exception raised within the *Note with: 1c1.
     statement.  Only if all pairs match properly against attributes on
     the exception is *Note ResourceDenied: 23a5. raised.

     New in version 2.6.


 -- Class: test.test_support.EnvironmentVarGuard
     Class used to temporarily set or unset environment variables.
     Instances can be used as a context manager and have a complete
     dictionary interface for querying/modifying the underlying
     `os.environ'. After exit from the context manager all changes to
     environment variables done through this instance will be rolled
     back.

     New in version 2.6.

     Changed in version 2.7: Added dictionary interface.


 -- Method: EnvironmentVarGuard.set (envvar, value)
     Temporarily set the environment variable `envvar' to the value of
     `value'.

 -- Method: EnvironmentVarGuard.unset (envvar)
     Temporarily unset the environment variable `envvar'.

 -- Class: test.test_support.WarningsRecorder
     Class used to record warnings for unit tests. See documentation of
     *Note check_warnings(): 23af. above for more details.

     New in version 2.6.



File: python.info,  Node: Debugging and Profiling,  Next: Software Packaging and Distribution,  Prev: Development Tools,  Up: The Python Standard Library

5.26 Debugging and Profiling
============================

These libraries help you with Python development: the debugger enables
you to step through code, analyze stack frames and set breakpoints
etc., and the profilers run code and give you a detailed breakdown of
execution times, allowing you to identify bottlenecks in your programs.

* Menu:

* bdb — Debugger framework::
* pdb — The Python Debugger::
* Debugger Commands::
* The Python Profilers::
* hotshot — High performance logging profiler::
* timeit — Measure execution time of small code snippets::
* trace — Trace or track Python statement execution::


File: python.info,  Node: bdb — Debugger framework,  Next: pdb — The Python Debugger,  Up: Debugging and Profiling

5.26.1 `bdb' — Debugger framework
-----------------------------------

`Source code:' Lib/bdb.py(1)

__________________________________________________________________

The *Note bdb: 18. module handles basic debugger functions, like
setting breakpoints or managing execution via the debugger.

The following exception is defined:

 -- Exception: bdb.BdbQuit
     Exception raised by the *Note Bdb: 203. class for quitting the
     debugger.

The *Note bdb: 18. module also defines two classes:

 -- Class: bdb.Breakpoint (self, file, line, temporary=0, cond=None,
          funcname=None)
     This class implements temporary breakpoints, ignore counts,
     disabling and (re-)enabling, and conditionals.

     Breakpoints are indexed by number through a list called
     `bpbynumber' and by `(file, line)' pairs through `bplist'.  The
     former points to a single instance of class *Note Breakpoint:
     23c0.  The latter points to a list of such instances since there
     may be more than one breakpoint per line.

     When creating a breakpoint, its associated filename should be in
     canonical form.  If a `funcname' is defined, a breakpoint hit will
     be counted when the first line of that function is executed.  A
     conditional breakpoint always counts a hit.

     *Note Breakpoint: 23c0. instances have the following methods:

      -- Method: deleteMe ()
          Delete the breakpoint from the list associated to a
          file/line.  If it is the last breakpoint in that position, it
          also deletes the entry for the file/line.

      -- Method: enable ()
          Mark the breakpoint as enabled.

      -- Method: disable ()
          Mark the breakpoint as disabled.

      -- Method: pprint ([out])
          Print all the information about the breakpoint:

             * The breakpoint number.

             * If it is temporary or not.

             * Its file,line position.

             * The condition that causes a break.

             * If it must be ignored the next N times.

             * The breakpoint hit count.

 -- Class: bdb.Bdb (skip=None)
     The *Note Bdb: 203. class acts as a generic Python debugger base
     class.

     This class takes care of the details of the trace facility; a
     derived class should implement user interaction.  The standard
     debugger class (*Note pdb.Pdb: 23c5.) is an example.

     The `skip' argument, if given, must be an iterable of glob-style
     module name patterns.  The debugger will not step into frames that
     originate in a module that matches one of these patterns. Whether a
     frame is considered to originate in a certain module is determined
     by the `__name__' in the frame globals.

     New in version 2.7: The `skip' argument.

     The following methods of *Note Bdb: 203. normally don’t need to
     be overridden.

      -- Method: canonic (filename)
          Auxiliary method for getting a filename in a canonical form,
          that is, as a case-normalized (on case-insensitive
          filesystems) absolute path, stripped of surrounding angle
          brackets.

      -- Method: reset ()
          Set the `botframe', `stopframe', `returnframe' and `quitting'
          attributes with values ready to start debugging.

      -- Method: trace_dispatch (frame, event, arg)
          This function is installed as the trace function of debugged
          frames.  Its return value is the new trace function (in most
          cases, that is, itself).

          The default implementation decides how to dispatch a frame,
          depending on the type of event (passed as a string) that is
          about to be executed.  `event' can be one of the following:

             * `"line"': A new line of code is going to be executed.

             * `"call"': A function is about to be called, or another
               code block entered.

             * `"return"': A function or other code block is about to
               return.

             * `"exception"': An exception has occurred.

             * `"c_call"': A C function is about to be called.

             * `"c_return"': A C function has returned.

             * `"c_exception"': A C function has raised an exception.

          For the Python events, specialized functions (see below) are
          called.  For the C events, no action is taken.

          The `arg' parameter depends on the previous event.

          See the documentation for *Note sys.settrace(): 4bc. for more
          information on the trace function.  For more information on
          code and frame objects, refer to *Note The standard type
          hierarchy: 719.

      -- Method: dispatch_line (frame)
          If the debugger should stop on the current line, invoke the
          *Note user_line(): 23ca. method (which should be overridden
          in subclasses).  Raise a *Note BdbQuit: 23bf. exception if
          the `Bdb.quitting' flag is set (which can be set from *Note
          user_line(): 23ca.).  Return a reference to the *Note
          trace_dispatch(): 23c8. method for further tracing in that
          scope.

      -- Method: dispatch_call (frame, arg)
          If the debugger should stop on this function call, invoke the
          *Note user_call(): 23cc. method (which should be overridden
          in subclasses).  Raise a *Note BdbQuit: 23bf. exception if
          the `Bdb.quitting' flag is set (which can be set from *Note
          user_call(): 23cc.).  Return a reference to the *Note
          trace_dispatch(): 23c8. method for further tracing in that
          scope.

      -- Method: dispatch_return (frame, arg)
          If the debugger should stop on this function return, invoke
          the *Note user_return(): 23ce. method (which should be
          overridden in subclasses).  Raise a *Note BdbQuit: 23bf.
          exception if the `Bdb.quitting' flag is set (which can be set
          from *Note user_return(): 23ce.).  Return a reference to the
          *Note trace_dispatch(): 23c8. method for further tracing in
          that scope.

      -- Method: dispatch_exception (frame, arg)
          If the debugger should stop at this exception, invokes the
          *Note user_exception(): 23d0. method (which should be
          overridden in subclasses).  Raise a *Note BdbQuit: 23bf.
          exception if the `Bdb.quitting' flag is set (which can be set
          from *Note user_exception(): 23d0.).  Return a reference to
          the *Note trace_dispatch(): 23c8. method for further tracing
          in that scope.

     Normally derived classes don’t override the following methods,
     but they may if they want to redefine the definition of stopping
     and breakpoints.

      -- Method: stop_here (frame)
          This method checks if the `frame' is somewhere below
          `botframe' in the call stack.  `botframe' is the frame in
          which debugging started.

      -- Method: break_here (frame)
          This method checks if there is a breakpoint in the filename
          and line belonging to `frame' or, at least, in the current
          function.  If the breakpoint is a temporary one, this method
          deletes it.

      -- Method: break_anywhere (frame)
          This method checks if there is a breakpoint in the filename
          of the current frame.

     Derived classes should override these methods to gain control over
     debugger operation.

      -- Method: user_call (frame, argument_list)
          This method is called from *Note dispatch_call(): 23cb. when
          there is the possibility that a break might be necessary
          anywhere inside the called function.

      -- Method: user_line (frame)
          This method is called from *Note dispatch_line(): 23c9. when
          either *Note stop_here(): 23d1. or *Note break_here(): 23d2.
          yields `True'.

      -- Method: user_return (frame, return_value)
          This method is called from *Note dispatch_return(): 23cd.
          when *Note stop_here(): 23d1.  yields `True'.

      -- Method: user_exception (frame, exc_info)
          This method is called from *Note dispatch_exception(): 23cf.
          when *Note stop_here(): 23d1. yields `True'.

      -- Method: do_clear (arg)
          Handle how a breakpoint must be removed when it is a
          temporary one.

          This method must be implemented by derived classes.

     Derived classes and clients can call the following methods to
     affect the stepping state.

      -- Method: set_step ()
          Stop after one line of code.

      -- Method: set_next (frame)
          Stop on the next line in or below the given frame.

      -- Method: set_return (frame)
          Stop when returning from the given frame.

      -- Method: set_until (frame)
          Stop when the line with the line no greater than the current
          one is reached or when returning from current frame.

      -- Method: set_trace ([frame])
          Start debugging from `frame'.  If `frame' is not specified,
          debugging starts from caller’s frame.

      -- Method: set_continue ()
          Stop only at breakpoints or when finished.  If there are no
          breakpoints, set the system trace function to `None'.

      -- Method: set_quit ()
          Set the `quitting' attribute to `True'.  This raises *Note
          BdbQuit: 23bf. in the next call to one of the `dispatch_*()'
          methods.

     Derived classes and clients can call the following methods to
     manipulate breakpoints.  These methods return a string containing
     an error message if something went wrong, or `None' if all is well.

      -- Method: set_break (filename, lineno, temporary=0, cond=None,
               funcname=None)
          Set a new breakpoint.  If the `lineno' line doesn’t exist
          for the `filename' passed as argument, return an error
          message.  The `filename' should be in canonical form, as
          described in the *Note canonic(): 23c6. method.

      -- Method: clear_break (filename, lineno)
          Delete the breakpoints in `filename' and `lineno'.  If none
          were set, an error message is returned.

      -- Method: clear_bpbynumber (arg)
          Delete the breakpoint which has the index `arg' in the
          `Breakpoint.bpbynumber'.  If `arg' is not numeric or out of
          range, return an error message.

      -- Method: clear_all_file_breaks (filename)
          Delete all breakpoints in `filename'.  If none were set, an
          error message is returned.

      -- Method: clear_all_breaks ()
          Delete all existing breakpoints.

      -- Method: get_break (filename, lineno)
          Check if there is a breakpoint for `lineno' of `filename'.

      -- Method: get_breaks (filename, lineno)
          Return all breakpoints for `lineno' in `filename', or an
          empty list if none are set.

      -- Method: get_file_breaks (filename)
          Return all breakpoints in `filename', or an empty list if
          none are set.

      -- Method: get_all_breaks ()
          Return all breakpoints that are set.

     Derived classes and clients can call the following methods to get
     a data structure representing a stack trace.

      -- Method: get_stack (f, t)
          Get a list of records for a frame and all higher (calling)
          and lower frames, and the size of the higher part.

      -- Method: format_stack_entry (frame_lineno[, lprefix=': '])
          Return a string with information about a stack entry,
          identified by a `(frame, lineno)' tuple:

             * The canonical form of the filename which contains the
               frame.

             * The function name, or `"<lambda>"'.

             * The input arguments.

             * The return value.

             * The line of code (if it exists).

     The following two methods can be called by clients to use a
     debugger to debug a *Note statement: df3, given as a string.

      -- Method: run (cmd[, globals[, locals]])
          Debug a statement executed via the *Note exec: 41d.
          statement.  `globals' defaults to `__main__.__dict__',
          `locals' defaults to `globals'.

      -- Method: runeval (expr[, globals[, locals]])
          Debug an expression executed via the *Note eval(): 378.
          function.  `globals' and `locals' have the same meaning as in
          *Note run(): 23e7.

      -- Method: runctx (cmd, globals, locals)
          For backwards compatibility.  Calls the *Note run(): 23e7.
          method.

      -- Method: runcall (func, *args, **kwds)
          Debug a single function call, and return its result.

Finally, the module defines the following functions:

 -- Function: bdb.checkfuncname (b, frame)
     Check whether we should break here, depending on the way the
     breakpoint `b' was set.

     If it was set via line number, it checks if `b.line' is the same
     as the one in the frame also passed as argument.  If the
     breakpoint was set via function name, we have to check we are in
     the right frame (the right function) and if we are in its first
     executable line.

 -- Function: bdb.effective (file, line, frame)
     Determine if there is an effective (active) breakpoint at this
     line of code.  Return a tuple of the breakpoint and a boolean that
     indicates if it is ok to delete a temporary breakpoint.  Return
     `(None, None)' if there is no matching breakpoint.

 -- Function: bdb.set_trace ()
     Start debugging with a *Note Bdb: 203. instance from caller’s
     frame.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/bdb.py


File: python.info,  Node: pdb — The Python Debugger,  Next: Debugger Commands,  Prev: bdb — Debugger framework,  Up: Debugging and Profiling

5.26.2 `pdb' — The Python Debugger
------------------------------------

`Source code:' Lib/pdb.py(1)

__________________________________________________________________

The module *Note pdb: 12d. defines an interactive source code debugger
for Python programs.  It supports setting (conditional) breakpoints and
single stepping at the source line level, inspection of stack frames,
source code listing, and evaluation of arbitrary Python code in the
context of any stack frame.  It also supports post-mortem debugging and
can be called under program control.

The debugger is extensible — it is actually defined as the class
*Note Pdb: 23c5.  This is currently undocumented but easily understood
by reading the source.  The extension interface uses the modules *Note
bdb: 18. and *Note cmd: 61.

The debugger’s prompt is `(Pdb)'. Typical usage to run a program
under control of the debugger is:

    >>> import pdb
    >>> import mymodule
    >>> pdb.run('mymodule.test()')
    > <string>(0)?()
    (Pdb) continue
    > <string>(1)?()
    (Pdb) continue
    NameError: 'spam'
    > <string>(1)?()
    (Pdb)

`pdb.py' can also be invoked as a script to debug other scripts.  For
example:

    python -m pdb myscript.py

When invoked as a script, pdb will automatically enter post-mortem
debugging if the program being debugged exits abnormally. After
post-mortem debugging (or after normal exit of the program), pdb will
restart the program. Automatic restarting preserves pdb’s state (such
as breakpoints) and in most cases is more useful than quitting the
debugger upon program’s exit.

New in version 2.4: Restarting post-mortem behavior added.

The typical usage to break into the debugger from a running program is
to insert

    import pdb; pdb.set_trace()

at the location you want to break into the debugger.  You can then step
through the code following this statement, and continue running without
the debugger using the `c' command.

The typical usage to inspect a crashed program is:

    >>> import pdb
    >>> import mymodule
    >>> mymodule.test()
    Traceback (most recent call last):
      File "<stdin>", line 1, in ?
      File "./mymodule.py", line 4, in test
        test2()
      File "./mymodule.py", line 3, in test2
        print spam
    NameError: spam
    >>> pdb.pm()
    > ./mymodule.py(3)test2()
    -> print spam
    (Pdb)

The module defines the following functions; each enters the debugger in
a slightly different way:

 -- Function: pdb.run (statement[, globals[, locals]])
     Execute the `statement' (given as a string) under debugger
     control.  The debugger prompt appears before any code is executed;
     you can set breakpoints and type `continue', or you can step
     through the statement using `step' or `next' (all these commands
     are explained below).  The optional `globals' and `locals'
     arguments specify the environment in which the code is executed; by
     default the dictionary of the module *Note __main__: 2. is used.
     (See the explanation of the *Note exec: 41d. statement or the
     *Note eval(): 378. built-in function.)

 -- Function: pdb.runeval (expression[, globals[, locals]])
     Evaluate the `expression' (given as a string) under debugger
     control.  When *Note runeval(): 23f1. returns, it returns the
     value of the expression.  Otherwise this function is similar to
     *Note run(): 22f8.

 -- Function: pdb.runcall (function[, argument, ...])
     Call the `function' (a function or method object, not a string)
     with the given arguments.  When *Note runcall(): 23f2. returns, it
     returns whatever the function call returned.  The debugger prompt
     appears as soon as the function is entered.

 -- Function: pdb.set_trace ()
     Enter the debugger at the calling stack frame.  This is useful to
     hard-code a breakpoint at a given point in a program, even if the
     code is not otherwise being debugged (e.g. when an assertion
     fails).

 -- Function: pdb.post_mortem ([traceback])
     Enter post-mortem debugging of the given `traceback' object.  If no
     `traceback' is given, it uses the one of the exception that is
     currently being handled (an exception must be being handled if the
     default is to be used).

 -- Function: pdb.pm ()
     Enter post-mortem debugging of the traceback found in *Note
     sys.last_traceback: 23f4.

The `run*' functions and *Note set_trace(): 22f5. are aliases for
instantiating the *Note Pdb: 23c5. class and calling the method of the
same name.  If you want to access further features, you have to do this
yourself:

 -- Class: pdb.Pdb (completekey='tab', stdin=None, stdout=None,
          skip=None)
     *Note Pdb: 23c5. is the debugger class.

     The `completekey', `stdin' and `stdout' arguments are passed to the
     underlying *Note cmd.Cmd: 20e4. class; see the description there.

     The `skip' argument, if given, must be an iterable of glob-style
     module name patterns.  The debugger will not step into frames that
     originate in a module that matches one of these patterns. (2)

     Example call to enable tracing with `skip':

         import pdb; pdb.Pdb(skip=['django.*']).set_trace()

     New in version 2.7: The `skip' argument.

      -- Method: run (statement[, globals[, locals]])
      -- Method: runeval (expression[, globals[, locals]])
      -- Method: runcall (function[, argument, ...])
      -- Method: set_trace ()
          See the documentation for the functions explained above.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/pdb.py

(2) Whether a frame is considered to originate in a certain module is
determined by the `__name__' in the frame globals.


File: python.info,  Node: Debugger Commands,  Next: The Python Profilers,  Prev: pdb — The Python Debugger,  Up: Debugging and Profiling

5.26.3 Debugger Commands
------------------------

The debugger recognizes the following commands.  Most commands can be
abbreviated to one or two letters; e.g. `h(elp)' means that either `h'
or `help' can be used to enter the help command (but not `he' or `hel',
nor `H' or `Help' or `HELP').  Arguments to commands must be separated
by whitespace (spaces or tabs).  Optional arguments are enclosed in
square brackets (`[]') in the command syntax; the square brackets must
not be typed.  Alternatives in the command syntax are separated by a
vertical bar (`|').

Entering a blank line repeats the last command entered.  Exception: if
the last command was a `list' command, the next 11 lines are listed.

Commands that the debugger doesn’t recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point (`!').  This is a powerful way to inspect the program being
debugged; it is even possible to change a variable or call a function.
When an exception occurs in such a statement, the exception name is
printed but the debugger’s state is not changed.

Multiple commands may be entered on a single line, separated by `;;'.
(A single `;' is not used as it is the separator for multiple commands
in a line that is passed to the Python parser.) No intelligence is
applied to separating the commands; the input is split at the first
`;;' pair, even if it is in the middle of a quoted string.

The debugger supports aliases.  Aliases can have parameters which
allows one a certain level of adaptability to the context under
examination.

If a file `.pdbrc'  exists in the user’s home directory or in the
current directory, it is read in and executed as if it had been typed
at the debugger prompt. This is particularly useful for aliases.  If
both files exist, the one in the home directory is read first and
aliases defined there can be overridden by the local file.

h(elp) [`command']
     Without argument, print the list of available commands.  With a
     `command' as argument, print help about that command.  `help pdb'
     displays the full documentation file; if the environment variable `PAGER'
     is defined, the file is piped through that command instead.  Since
     the `command' argument must be an identifier, `help exec' must be
     entered to get help on the `!' command.

w(here)
     Print a stack trace, with the most recent frame at the bottom.  An
     arrow indicates the current frame, which determines the context of
     most commands.

d(own)
     Move the current frame one level down in the stack trace (to a
     newer frame).

u(p)
     Move the current frame one level up in the stack trace (to an
     older frame).

b(reak) [[`filename':]`lineno' | `function'[, `condition']]
     With a `lineno' argument, set a break there in the current file.
     With a `function' argument, set a break at the first executable
     statement within that function. The line number may be prefixed
     with a filename and a colon, to specify a breakpoint in another
     file (probably one that hasn’t been loaded yet).  The file is
     searched on `sys.path'. Note that each breakpoint is assigned a
     number to which all the other breakpoint commands refer.

     If a second argument is present, it is an expression which must
     evaluate to true before the breakpoint is honored.

     Without argument, list all breaks, including for each breakpoint,
     the number of times that breakpoint has been hit, the current
     ignore count, and the associated condition if any.

tbreak [[`filename':]`lineno' | `function'[, `condition']]
     Temporary breakpoint, which is removed automatically when it is
     first hit.  The arguments are the same as break.

cl(ear) [`filename:lineno' | `bpnumber' [`bpnumber …']]
     With a `filename:lineno' argument, clear all the breakpoints at
     this line.  With a space separated list of breakpoint numbers,
     clear those breakpoints.  Without argument, clear all breaks (but
     first ask confirmation).

disable [`bpnumber' [`bpnumber …']]
     Disables the breakpoints given as a space separated list of
     breakpoint numbers.  Disabling a breakpoint means it cannot cause
     the program to stop execution, but unlike clearing a breakpoint,
     it remains in the list of breakpoints and can be (re-)enabled.

enable [`bpnumber' [`bpnumber …']]
     Enables the breakpoints specified.

ignore `bpnumber' [`count']
     Sets the ignore count for the given breakpoint number.  If count
     is omitted, the ignore count is set to 0.  A breakpoint becomes
     active when the ignore count is zero.  When non-zero, the count is
     decremented each time the breakpoint is reached and the breakpoint
     is not disabled and any associated condition evaluates to true.

condition `bpnumber' [`condition']
     Condition is an expression which must evaluate to true before the
     breakpoint is honored.  If condition is absent, any existing
     condition is removed; i.e., the breakpoint is made unconditional.

commands [`bpnumber']
     Specify a list of commands for breakpoint number `bpnumber'.  The
     commands themselves appear on the following lines.  Type a line
     containing just ‘end’ to terminate the commands. An example:

         (Pdb) commands 1
         (com) print some_variable
         (com) end
         (Pdb)

     To remove all commands from a breakpoint, type commands and follow
     it immediately with  end; that is, give no commands.

     With no `bpnumber' argument, commands refers to the last
     breakpoint set.

     You can use breakpoint commands to start your program up again.
     Simply use the continue command, or step, or any other command
     that resumes execution.

     Specifying any command resuming execution (currently continue,
     step, next, return, jump, quit and their abbreviations) terminates
     the command list (as if that command was immediately followed by
     end). This is because any time you resume execution (even with a
     simple next or step), you may encounter another breakpoint—which
     could have its own command list, leading to ambiguities about
     which list to execute.

     If you use the ‘silent’ command in the command list, the usual
     message about stopping at a breakpoint is not printed.  This may
     be desirable for breakpoints that are to print a specific message
     and then continue.  If none of the other commands print anything,
     you see no sign that the breakpoint was reached.

     New in version 2.5.

s(tep)
     Execute the current line, stop at the first possible occasion
     (either in a function that is called or on the next line in the
     current function).

n(ext)
     Continue execution until the next line in the current function is
     reached or it returns.  (The difference between `next' and `step'
     is that `step' stops inside a called function, while `next'
     executes called functions at (nearly) full speed, only stopping at
     the next line in the current function.)

unt(il)
     Continue execution until the line with the line number greater
     than the current one is reached or when returning from current
     frame.

     New in version 2.6.

r(eturn)
     Continue execution until the current function returns.

c(ont(inue))
     Continue execution, only stop when a breakpoint is encountered.

j(ump) `lineno'
     Set the next line that will be executed.  Only available in the
     bottom-most frame.  This lets you jump back and execute code
     again, or jump forward to skip code that you don’t want to run.

     It should be noted that not all jumps are allowed — for instance
     it is not possible to jump into the middle of a *Note for: 303.
     loop or out of a *Note finally: 3ae. clause.

l(ist) [`first'[, `last']]
     List source code for the current file.  Without arguments, list 11
     lines around the current line or continue the previous listing.
     With one argument, list 11 lines around at that line.  With two
     arguments, list the given range; if the second argument is less
     than the first, it is interpreted as a count.

a(rgs)
     Print the argument list of the current function.

p `expression'
     Evaluate the `expression' in the current context and print its
     value.

          Note: `print' can also be used, but is not a debugger command
          — this executes the Python *Note print: 4fd. statement.

pp `expression'
     Like the `p' command, except the value of the expression is
     pretty-printed using the *Note pprint: 139. module.

alias [`name' [command]]
     Creates an alias called `name' that executes `command'.  The
     command must `not' be enclosed in quotes.  Replaceable parameters
     can be indicated by `%1', `%2', and so on, while `%*' is replaced
     by all the parameters.  If no command is given, the current alias
     for `name' is shown. If no arguments are given, all aliases are
     listed.

     Aliases may be nested and can contain anything that can be legally
     typed at the pdb prompt.  Note that internal pdb commands `can' be
     overridden by aliases.  Such a command is then hidden until the
     alias is removed.  Aliasing is recursively applied to the first
     word of the command line; all other words in the line are left
     alone.

     As an example, here are two useful aliases (especially when placed
     in the `.pdbrc' file):

         #Print instance variables (usage "pi classInst")
         alias pi for k in %1.__dict__.keys(): print "%1.",k,"=",%1.__dict__[k]
         #Print instance variables in self
         alias ps pi self

unalias `name'
     Deletes the specified alias.

[!]`statement'
     Execute the (one-line) `statement' in the context of the current
     stack frame.  The exclamation point can be omitted unless the
     first word of the statement resembles a debugger command. To set a
     global variable, you can prefix the assignment command with a
     `global' command on the same line, e.g.:

         (Pdb) global list_options; list_options = ['-l']
         (Pdb)

run [`args' …]
     Restart the debugged Python program. If an argument is supplied,
     it is split with “shlex” and the result is used as the new
     sys.argv. History, breakpoints, actions and debugger options are
     preserved. “restart” is an alias for “run”.

     New in version 2.6.

q(uit)
     Quit from the debugger. The program being executed is aborted.


File: python.info,  Node: The Python Profilers,  Next: hotshot — High performance logging profiler,  Prev: Debugger Commands,  Up: Debugging and Profiling

5.26.4 The Python Profilers
---------------------------

`Source code:' Lib/profile.py(1) and Lib/pstats.py(2)

__________________________________________________________________

* Menu:

* Introduction to the profilers::
* Instant User’s Manual::
* profile and cProfile Module Reference::
* The Stats Class::
* What Is Deterministic Profiling?::
* Limitations::
* Calibration::
* Using a custom timer::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/profile.py

(2) https://hg.python.org/cpython/file/2.7/Lib/pstats.py


File: python.info,  Node: Introduction to the profilers,  Next: Instant User’s Manual,  Up: The Python Profilers

5.26.4.1 Introduction to the profilers
......................................

*Note cProfile: 74. and *Note profile: 13a. provide `deterministic
profiling' of Python programs. A `profile' is a set of statistics that
describes how often and for how long various parts of the program
executed. These statistics can be formatted into reports via the *Note
pstats: 13b. module.

The Python standard library provides three different implementations of
the same profiling interface:

  1. *Note cProfile: 74. is recommended for most users; it’s a C
     extension with reasonable overhead that makes it suitable for
     profiling long-running programs.  Based on `lsprof', contributed
     by Brett Rosen and Ted Czotter.

     New in version 2.5.

  2. *Note profile: 13a, a pure Python module whose interface is
     imitated by *Note cProfile: 74, but which adds significant
     overhead to profiled programs.  If you’re trying to extend the
     profiler in some way, the task might be easier with this module.
     Originally designed and written by Jim Roskind.

     Changed in version 2.4: Now also reports the time spent in calls
     to built-in functions and methods.

  3. *Note hotshot: ea. was an experimental C module that focused on
     minimizing the overhead of profiling, at the expense of longer data
     post-processing times.  It is no longer maintained and may be
     dropped in a future version of Python.

     Changed in version 2.5: The results should be more meaningful than
     in the past: the timing core contained a critical bug.


The *Note profile: 13a. and *Note cProfile: 74. modules export the same
interface, so they are mostly interchangeable; *Note cProfile: 74. has
a much lower overhead but is newer and might not be available on all
systems.  *Note cProfile: 74. is really a compatibility layer on top of
the internal `_lsprof' module.  The *Note hotshot: ea. module is
reserved for specialized usage.

     Note: The profiler modules are designed to provide an execution
     profile for a given program, not for benchmarking purposes (for
     that, there is *Note timeit: 17b. for reasonably accurate
     results).  This particularly applies to benchmarking Python code
     against C code: the profilers introduce overhead for Python code,
     but not for C-level functions, and so the C code would seem faster
     than any Python one.


File: python.info,  Node: Instant User’s Manual,  Next: profile and cProfile Module Reference,  Prev: Introduction to the profilers,  Up: The Python Profilers

5.26.4.2 Instant User’s Manual
................................

This section is provided for users that “don’t want to read the
manual.” It provides a very brief overview, and allows a user to
rapidly perform profiling on an existing application.

To profile a function that takes a single argument, you can do:

    import cProfile
    import re
    cProfile.run('re.compile("foo|bar")')

(Use *Note profile: 13a. instead of *Note cProfile: 74. if the latter
is not available on your system.)

The above action would run *Note re.compile(): 9ea. and print profile
results like the following:

          197 function calls (192 primitive calls) in 0.002 seconds

    Ordered by: standard name

    ncalls  tottime  percall  cumtime  percall filename:lineno(function)
         1    0.000    0.000    0.001    0.001 <string>:1(<module>)
         1    0.000    0.000    0.001    0.001 re.py:212(compile)
         1    0.000    0.000    0.001    0.001 re.py:268(_compile)
         1    0.000    0.000    0.000    0.000 sre_compile.py:172(_compile_charset)
         1    0.000    0.000    0.000    0.000 sre_compile.py:201(_optimize_charset)
         4    0.000    0.000    0.000    0.000 sre_compile.py:25(_identityfunction)
       3/1    0.000    0.000    0.000    0.000 sre_compile.py:33(_compile)

The first line indicates that 197 calls were monitored.  Of those
calls, 192 were `primitive', meaning that the call was not induced via
recursion. The next line: `Ordered by: standard name', indicates that
the text string in the far right column was used to sort the output.
The column headings include:

ncalls
     for the number of calls,

tottime
     for the total time spent in the given function (and excluding time
     made in calls to sub-functions)

percall
     is the quotient of `tottime' divided by `ncalls'

cumtime
     is the cumulative time spent in this and all subfunctions (from
     invocation till exit). This figure is accurate `even' for
     recursive functions.

percall
     is the quotient of `cumtime' divided by primitive calls

filename:lineno(function)
     provides the respective data of each function

When there are two numbers in the first column (for example `3/1'), it
means that the function recursed.  The second value is the number of
primitive calls and the former is the total number of calls.  Note that
when the function does not recurse, these two values are the same, and
only the single figure is printed.

Instead of printing the output at the end of the profile run, you can
save the results to a file by specifying a filename to the `run()'
function:

    import cProfile
    import re
    cProfile.run('re.compile("foo|bar")', 'restats')

The *Note pstats.Stats: 2402. class reads profile results from a file
and formats them in various ways.

The file *Note cProfile: 74. can also be invoked as a script to profile
another script.  For example:

    python -m cProfile [-o output_file] [-s sort_order] myscript.py

`-o' writes the profile results to a file instead of to stdout

`-s' specifies one of the *Note sort_stats(): 2403. sort values to sort
the output by. This only applies when `-o' is not supplied.

The *Note pstats: 13b. module’s *Note Stats: 2402. class has a
variety of methods for manipulating and printing the data saved into a
profile results file:

    import pstats
    p = pstats.Stats('restats')
    p.strip_dirs().sort_stats(-1).print_stats()

The *Note strip_dirs(): 2404. method removed the extraneous path from
all the module names. The *Note sort_stats(): 2403. method sorted all
the entries according to the standard module/line/name string that is
printed. The *Note print_stats(): 2405. method printed out all the
statistics.  You might try the following sort calls:

    p.sort_stats('name')
    p.print_stats()

The first call will actually sort the list by function name, and the
second call will print out the statistics.  The following are some
interesting calls to experiment with:

    p.sort_stats('cumulative').print_stats(10)

This sorts the profile by cumulative time in a function, and then only
prints the ten most significant lines.  If you want to understand what
algorithms are taking time, the above line is what you would use.

If you were looking to see what functions were looping a lot, and
taking a lot of time, you would do:

    p.sort_stats('time').print_stats(10)

to sort according to time spent within each function, and then print the
statistics for the top ten functions.

You might also try:

    p.sort_stats('file').print_stats('__init__')

This will sort all the statistics by file name, and then print out
statistics for only the class init methods (since they are spelled with
`__init__' in them).  As one final example, you could try:

    p.sort_stats('time', 'cum').print_stats(.5, 'init')

This line sorts statistics with a primary key of time, and a secondary
key of cumulative time, and then prints out some of the statistics. To
be specific, the list is first culled down to 50% (re: `.5') of its
original size, then only lines containing `init' are maintained, and
that sub-sub-list is printed.

If you wondered what functions called the above functions, you could
now (`p' is still sorted according to the last criteria) do:

    p.print_callers(.5, 'init')

and you would get a list of callers for each of the listed functions.

If you want more functionality, you’re going to have to read the
manual, or guess what the following functions do:

    p.print_callees()
    p.add('restats')

Invoked as a script, the *Note pstats: 13b. module is a statistics
browser for reading and examining profile dumps.  It has a simple
line-oriented interface (implemented using *Note cmd: 61.) and
interactive help.


File: python.info,  Node: profile and cProfile Module Reference,  Next: The Stats Class,  Prev: Instant User’s Manual,  Up: The Python Profilers

5.26.4.3 `profile' and `cProfile' Module Reference
..................................................

Both the *Note profile: 13a. and *Note cProfile: 74. modules provide
the following functions:

 -- Function: profile.run (command, filename=None, sort=-1)
     This function takes a single argument that can be passed to the
     `exec()' function, and an optional file name.  In all cases this
     routine executes:

         exec(command, __main__.__dict__, __main__.__dict__)

     and gathers profiling statistics from the execution. If no file
     name is present, then this function automatically creates a *Note
     Stats: 2402.  instance and prints a simple profiling report. If
     the sort value is specified it is passed to this *Note Stats:
     2402. instance to control how the results are sorted.

 -- Function: profile.runctx (command, globals, locals, filename=None)
     This function is similar to *Note run(): 2407, with added
     arguments to supply the globals and locals dictionaries for the
     `command' string. This routine executes:

         exec(command, globals, locals)

     and gathers profiling statistics as in the *Note run(): 2407.
     function above.

 -- Class: profile.Profile (timer=None, timeunit=0.0, subcalls=True,
          builtins=True)
     This class is normally only used if more precise control over
     profiling is needed than what the `cProfile.run()' function
     provides.

     A custom timer can be supplied for measuring how long code takes
     to run via the `timer' argument. This must be a function that
     returns a single number representing the current time. If the
     number is an integer, the `timeunit' specifies a multiplier that
     specifies the duration of each unit of time. For example, if the
     timer returns times measured in thousands of seconds, the time
     unit would be `.001'.

     Directly using the *Note Profile: 2409. class allows formatting
     profile results without writing the profile data to a file:

         import cProfile, pstats, StringIO
         pr = cProfile.Profile()
         pr.enable()
         # ... do something ...
         pr.disable()
         s = StringIO.StringIO()
         sortby = 'cumulative'
         ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
         ps.print_stats()
         print s.getvalue()

      -- Method: enable ()
          Start collecting profiling data.

      -- Method: disable ()
          Stop collecting profiling data.

      -- Method: create_stats ()
          Stop collecting profiling data and record the results
          internally as the current profile.

      -- Method: print_stats (sort=-1)
          Create a *Note Stats: 2402. object based on the current
          profile and print the results to stdout.

      -- Method: dump_stats (filename)
          Write the results of the current profile to `filename'.

      -- Method: run (cmd)
          Profile the cmd via `exec()'.

      -- Method: runctx (cmd, globals, locals)
          Profile the cmd via `exec()' with the specified global and
          local environment.

      -- Method: runcall (func, *args, **kwargs)
          Profile `func(*args, **kwargs)'


File: python.info,  Node: The Stats Class,  Next: What Is Deterministic Profiling?,  Prev: profile and cProfile Module Reference,  Up: The Python Profilers

5.26.4.4 The `Stats' Class
..........................

Analysis of the profiler data is done using the *Note Stats: 2402.
class.

 -- Class: pstats.Stats (*filenames or profile, stream=sys.stdout)
     This class constructor creates an instance of a “statistics
     object” from a `filename' (or list of filenames) or from a
     `Profile' instance. Output will be printed to the stream specified
     by `stream'.

     The file selected by the above constructor must have been created
     by the corresponding version of *Note profile: 13a. or *Note
     cProfile: 74.  To be specific, there is `no' file compatibility
     guaranteed with future versions of this profiler, and there is no
     compatibility with files produced by other profilers.  If several
     files are provided, all the statistics for identical functions
     will be coalesced, so that an overall view of several processes can
     be considered in a single report.  If additional files need to be
     combined with data in an existing *Note Stats: 2402. object, the
     *Note add(): 2414. method can be used.

     Instead of reading the profile data from a file, a
     `cProfile.Profile' or *Note profile.Profile: 2409. object can be
     used as the profile data source.

     *Note Stats: 2402. objects have the following methods:

      -- Method: strip_dirs ()
          This method for the *Note Stats: 2402. class removes all
          leading path information from file names.  It is very useful
          in reducing the size of the printout to fit within (close to)
          80 columns.  This method modifies the object, and the
          stripped information is lost.  After performing a strip
          operation, the object is considered to have its entries in a
          “random” order, as it was just after object
          initialization and loading.  If *Note strip_dirs(): 2404.
          causes two function names to be indistinguishable (they are
          on the same line of the same filename, and have the same
          function name), then the statistics for these two entries are
          accumulated into a single entry.

      -- Method: add (*filenames)
          This method of the *Note Stats: 2402. class accumulates
          additional profiling information into the current profiling
          object.  Its arguments should refer to filenames created by
          the corresponding version of *Note profile.run(): 2407.  or
          `cProfile.run()'. Statistics for identically named (re: file,
          line, name) functions are automatically accumulated into
          single function statistics.

      -- Method: dump_stats (filename)
          Save the data loaded into the *Note Stats: 2402. object to a
          file named `filename'.  The file is created if it does not
          exist, and is overwritten if it already exists.  This is
          equivalent to the method of the same name on the *Note
          profile.Profile: 2409. and `cProfile.Profile' classes.

     New in version 2.3.

      -- Method: sort_stats (*keys)
          This method modifies the *Note Stats: 2402. object by sorting
          it according to the supplied criteria.  The argument is
          typically a string identifying the basis of a sort (example:
          `'time'' or `'name'').

          When more than one key is provided, then additional keys are
          used as secondary criteria when there is equality in all keys
          selected before them.  For example, `sort_stats('name',
          'file')' will sort all the entries according to their
          function name, and resolve all ties (identical function
          names) by sorting by file name.

          Abbreviations can be used for any key names, as long as the
          abbreviation is unambiguous.  The following are the keys
          currently defined:

          Valid Arg              Meaning
          -------------------------------------------------- 
          `'calls''              call count
          `'cumulative''         cumulative time
          `'cumtime''            cumulative time
          `'file''               file name
          `'filename''           file name
          `'module''             file name
          `'ncalls''             call count
          `'pcalls''             primitive call count
          `'line''               line number
          `'name''               function name
          `'nfl''                name/file/line
          `'stdname''            standard name
          `'time''               internal time
          `'tottime''            internal time

          Note that all sorts on statistics are in descending order
          (placing most time consuming items first), where as name,
          file, and line number searches are in ascending order
          (alphabetical). The subtle distinction between `'nfl'' and
          `'stdname'' is that the standard name is a sort of the name
          as printed, which means that the embedded line numbers get
          compared in an odd way.  For example, lines 3, 20, and 40
          would (if the file names were the same) appear in the string
          order 20, 3 and 40.  In contrast, `'nfl'' does a numeric
          compare of the line numbers.  In fact, `sort_stats('nfl')' is
          the same as `sort_stats('name', 'file', 'line')'.

          For backward-compatibility reasons, the numeric arguments
          `-1', `0', `1', and `2' are permitted.  They are interpreted
          as `'stdname'', `'calls'', `'time'', and `'cumulative''
          respectively.  If this old style format (numeric) is used,
          only one sort key (the numeric key) will be used, and
          additional arguments will be silently ignored.


      -- Method: reverse_order ()
          This method for the *Note Stats: 2402. class reverses the
          ordering of the basic list within the object.  Note that by
          default ascending vs descending order is properly selected
          based on the sort key of choice.


      -- Method: print_stats (*restrictions)
          This method for the *Note Stats: 2402. class prints out a
          report as described in the *Note profile.run(): 2407.
          definition.

          The order of the printing is based on the last *Note
          sort_stats(): 2403. operation done on the object (subject to
          caveats in *Note add(): 2414. and *Note strip_dirs(): 2404.).

          The arguments provided (if any) can be used to limit the list
          down to the significant entries.  Initially, the list is
          taken to be the complete set of profiled functions.  Each
          restriction is either an integer (to select a count of
          lines), or a decimal fraction between 0.0 and 1.0 inclusive
          (to select a percentage of lines), or a regular expression
          (to pattern match the standard name that is printed.  If
          several restrictions are provided, then they are applied
          sequentially.  For example:

              print_stats(.1, 'foo:')

          would first limit the printing to first 10% of list, and then
          only print functions that were part of filename `.*foo:'.  In
          contrast, the command:

              print_stats('foo:', .1)

          would limit the list to all functions having file names
          `.*foo:', and then proceed to only print the first 10% of
          them.

      -- Method: print_callers (*restrictions)
          This method for the *Note Stats: 2402. class prints a list of
          all functions that called each function in the profiled
          database.  The ordering is identical to that provided by
          *Note print_stats(): 2405, and the definition of the
          restricting argument is also identical.  Each caller is
          reported on its own line.  The format differs slightly
          depending on the profiler that produced the stats:

             * With *Note profile: 13a, a number is shown in
               parentheses after each caller to show how many times
               this specific call was made.  For convenience, a second
               non-parenthesized number repeats the cumulative time
               spent in the function at the right.

             * With *Note cProfile: 74, each caller is preceded by
               three numbers: the number of times this specific call
               was made, and the total and cumulative times spent in
               the current function while it was invoked by this
               specific caller.

      -- Method: print_callees (*restrictions)
          This method for the *Note Stats: 2402. class prints a list of
          all function that were called by the indicated function.
          Aside from this reversal of direction of calls (re: called vs
          was called by), the arguments and ordering are identical to
          the *Note print_callers(): 2417. method.


File: python.info,  Node: What Is Deterministic Profiling?,  Next: Limitations,  Prev: The Stats Class,  Up: The Python Profilers

5.26.4.5 What Is Deterministic Profiling?
.........................................

`Deterministic profiling' is meant to reflect the fact that all
`function call', `function return', and `exception' events are
monitored, and precise timings are made for the intervals between these
events (during which time the user’s code is executing).  In
contrast, `statistical profiling' (which is not done by this module)
randomly samples the effective instruction pointer, and deduces where
time is being spent.  The latter technique traditionally involves less
overhead (as the code does not need to be instrumented), but provides
only relative indications of where time is being spent.

In Python, since there is an interpreter active during execution, the
presence of instrumented code is not required to do deterministic
profiling.  Python automatically provides a `hook' (optional callback)
for each event.  In addition, the interpreted nature of Python tends to
add so much overhead to execution, that deterministic profiling tends
to only add small processing overhead in typical applications.  The
result is that deterministic profiling is not that expensive, yet
provides extensive run time statistics about the execution of a Python
program.

Call count statistics can be used to identify bugs in code (surprising
counts), and to identify possible inline-expansion points (high call
counts).  Internal time statistics can be used to identify “hot
loops” that should be carefully optimized.  Cumulative time
statistics should be used to identify high level errors in the
selection of algorithms.  Note that the unusual handling of cumulative
times in this profiler allows statistics for recursive implementations
of algorithms to be directly compared to iterative implementations.


File: python.info,  Node: Limitations,  Next: Calibration,  Prev: What Is Deterministic Profiling?,  Up: The Python Profilers

5.26.4.6 Limitations
....................

One limitation has to do with accuracy of timing information. There is a
fundamental problem with deterministic profilers involving accuracy.
The most obvious restriction is that the underlying “clock” is only
ticking at a rate (typically) of about .001 seconds.  Hence no
measurements will be more accurate than the underlying clock.  If
enough measurements are taken, then the “error” will tend to
average out. Unfortunately, removing this first error induces a second
source of error.

The second problem is that it “takes a while” from when an event is
dispatched until the profiler’s call to get the time actually `gets'
the state of the clock.  Similarly, there is a certain lag when exiting
the profiler event handler from the time that the clock’s value was
obtained (and then squirreled away), until the user’s code is once
again executing.  As a result, functions that are called many times, or
call many functions, will typically accumulate this error. The error
that accumulates in this fashion is typically less than the accuracy of
the clock (less than one clock tick), but it `can' accumulate and
become very significant.

The problem is more important with *Note profile: 13a. than with the
lower-overhead *Note cProfile: 74.  For this reason, *Note profile:
13a. provides a means of calibrating itself for a given platform so
that this error can be probabilistically (on the average) removed.
After the profiler is calibrated, it will be more accurate (in a least
square sense), but it will sometimes produce negative numbers (when
call counts are exceptionally low, and the gods of probability work
against you :-). )  Do `not' be alarmed by negative numbers in the
profile.  They should `only' appear if you have calibrated your
profiler, and the results are actually better than without calibration.


File: python.info,  Node: Calibration,  Next: Using a custom timer,  Prev: Limitations,  Up: The Python Profilers

5.26.4.7 Calibration
....................

The profiler of the *Note profile: 13a. module subtracts a constant
from each event handling time to compensate for the overhead of calling
the time function, and socking away the results.  By default, the
constant is 0. The following procedure can be used to obtain a better
constant for a given platform (see *Note Limitations: 241b.).

    import profile
    pr = profile.Profile()
    for i in range(5):
        print pr.calibrate(10000)

The method executes the number of Python calls given by the argument,
directly and again under the profiler, measuring the time for both. It
then computes the hidden overhead per profiler event, and returns that
as a float.  For example, on a 1.8Ghz Intel Core i5 running Mac OS X,
and using Python’s time.clock() as the timer, the magical number is
about 4.04e-6.

The object of this exercise is to get a fairly consistent result. If
your computer is `very' fast, or your timer function has poor
resolution, you might have to pass 100000, or even 1000000, to get
consistent results.

When you have a consistent answer, there are three ways you can use it:
(1)

    import profile

    # 1. Apply computed bias to all Profile instances created hereafter.
    profile.Profile.bias = your_computed_bias

    # 2. Apply computed bias to a specific Profile instance.
    pr = profile.Profile()
    pr.bias = your_computed_bias

    # 3. Specify computed bias in instance constructor.
    pr = profile.Profile(bias=your_computed_bias)

If you have a choice, you are better off choosing a smaller constant,
and then your results will “less often” show up as negative in
profile statistics.

---------- Footnotes ----------

(1) Prior to Python 2.2, it was necessary to edit the profiler source
code to embed the bias as a literal number.  You still can, but that
method is no longer described, because no longer needed.


File: python.info,  Node: Using a custom timer,  Prev: Calibration,  Up: The Python Profilers

5.26.4.8 Using a custom timer
.............................

If you want to change how current time is determined (for example, to
force use of wall-clock time or elapsed process time), pass the timing
function you want to the `Profile' class constructor:

    pr = profile.Profile(your_time_func)

The resulting profiler will then call `your_time_func'. Depending on
whether you are using *Note profile.Profile: 2409. or
`cProfile.Profile', `your_time_func'’s return value will be
interpreted differently:

*Note profile.Profile: 2409.
     `your_time_func' should return a single number, or a list of
     numbers whose sum is the current time (like what *Note os.times():
     11be. returns).  If the function returns a single time number, or
     the list of returned numbers has length 2, then you will get an
     especially fast version of the dispatch routine.

     Be warned that you should calibrate the profiler class for the
     timer function that you choose (see *Note Calibration: 241e.).
     For most machines, a timer that returns a lone integer value will
     provide the best results in terms of low overhead during
     profiling.  (*Note os.times(): 11be. is `pretty' bad, as it
     returns a tuple of floating point values).  If you want to
     substitute a better timer in the cleanest fashion, derive a class
     and hardwire a replacement dispatch method that best handles your
     timer call, along with the appropriate calibration constant.

`cProfile.Profile'
     `your_time_func' should return a single number.  If it returns
     integers, you can also invoke the class constructor with a second
     argument specifying the real duration of one unit of time.  For
     example, if `your_integer_time_func' returns times measured in
     thousands of seconds, you would construct the `Profile' instance
     as follows:

         pr = cProfile.Profile(your_integer_time_func, 0.001)

     As the `cProfile.Profile' class cannot be calibrated, custom timer
     functions should be used with care and should be as fast as
     possible.  For the best results with a custom timer, it might be
     necessary to hard-code it in the C source of the internal
     `_lsprof' module.


File: python.info,  Node: hotshot — High performance logging profiler,  Next: timeit — Measure execution time of small code snippets,  Prev: The Python Profilers,  Up: Debugging and Profiling

5.26.5 `hotshot' — High performance logging profiler
------------------------------------------------------

New in version 2.2.

This module provides a nicer interface to the `_hotshot' C module.
Hotshot is a replacement for the existing *Note profile: 13a. module.
As it’s written mostly in C, it should result in a much smaller
performance impact than the existing *Note profile: 13a. module.

     Note: The *Note hotshot: ea. module focuses on minimizing the
     overhead while profiling, at the expense of long data
     post-processing times. For common usage it is recommended to use
     *Note cProfile: 74. instead. *Note hotshot: ea. is not maintained
     and might be removed from the standard library in the future.

Changed in version 2.5: The results should be more meaningful than in
the past: the timing core contained a critical bug.

     Note: The *Note hotshot: ea. profiler does not yet work well with
     threads. It is useful to use an unthreaded script to run the
     profiler over the code you’re interested in measuring if at all
     possible.

 -- Class: hotshot.Profile (logfile[, lineevents[, linetimings]])
     The profiler object. The argument `logfile' is the name of a log
     file to use for logged profile data. The argument `lineevents'
     specifies whether to generate events for every source line, or
     just on function call/return. It defaults to `0' (only log
     function call/return). The argument `linetimings' specifies
     whether to record timing information. It defaults to `1' (store
     timing information).

* Menu:

* Profile Objects::
* Using hotshot data::
* Example Usage::


File: python.info,  Node: Profile Objects,  Next: Using hotshot data,  Up: hotshot — High performance logging profiler

5.26.5.1 Profile Objects
........................

Profile objects have the following methods:

 -- Method: Profile.addinfo (key, value)
     Add an arbitrary labelled value to the profile output.

 -- Method: Profile.close ()
     Close the logfile and terminate the profiler.

 -- Method: Profile.fileno ()
     Return the file descriptor of the profiler’s log file.

 -- Method: Profile.run (cmd)
     Profile an *Note exec: 41d.-compatible string in the script
     environment. The globals from the *Note __main__: 2. module are
     used as both the globals and locals for the script.

 -- Method: Profile.runcall (func, *args, **keywords)
     Profile a single call of a callable. Additional positional and
     keyword arguments may be passed along; the result of the call is
     returned, and exceptions are allowed to propagate cleanly, while
     ensuring that profiling is disabled on the way out.

 -- Method: Profile.runctx (cmd, globals, locals)
     Evaluate an *Note exec: 41d.-compatible string in a specific
     environment. The string is compiled before profiling begins.

 -- Method: Profile.start ()
     Start the profiler.

 -- Method: Profile.stop ()
     Stop the profiler.


File: python.info,  Node: Using hotshot data,  Next: Example Usage,  Prev: Profile Objects,  Up: hotshot — High performance logging profiler

5.26.5.2 Using hotshot data
...........................

New in version 2.2.

This module loads hotshot profiling data into the standard *Note
pstats: 13b. Stats objects.

 -- Function: hotshot.stats.load (filename)
     Load hotshot data from `filename'. Returns an instance of the
     *Note pstats.Stats: 2402. class.

See also
........

Module *Note profile: 13a.
     The *Note profile: 13a. module’s `Stats' class


File: python.info,  Node: Example Usage,  Prev: Using hotshot data,  Up: hotshot — High performance logging profiler

5.26.5.3 Example Usage
......................

Note that this example runs the Python “benchmark” pystones.  It
can take some time to run, and will produce large output files.

    >>> import hotshot, hotshot.stats, test.pystone
    >>> prof = hotshot.Profile("stones.prof")
    >>> benchtime, stones = prof.runcall(test.pystone.pystones)
    >>> prof.close()
    >>> stats = hotshot.stats.load("stones.prof")
    >>> stats.strip_dirs()
    >>> stats.sort_stats('time', 'calls')
    >>> stats.print_stats(20)
             850004 function calls in 10.090 CPU seconds

       Ordered by: internal time, call count

       ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            1    3.295    3.295   10.090   10.090 pystone.py:79(Proc0)
       150000    1.315    0.000    1.315    0.000 pystone.py:203(Proc7)
        50000    1.313    0.000    1.463    0.000 pystone.py:229(Func2)
     .
     .
     .


File: python.info,  Node: timeit — Measure execution time of small code snippets,  Next: trace — Trace or track Python statement execution,  Prev: hotshot — High performance logging profiler,  Up: Debugging and Profiling

5.26.6 `timeit' — Measure execution time of small code snippets
-----------------------------------------------------------------

New in version 2.3.

`Source code:' Lib/timeit.py(1)

__________________________________________________________________

This module provides a simple way to time small bits of Python code. It
has both a *Note Command-Line Interface: 2434. as well as a *Note
callable: 2435.  one.  It avoids a number of common traps for measuring
execution times.  See also Tim Peters’ introduction to the
“Algorithms” chapter in the `Python Cookbook', published by
O’Reilly.

* Menu:

* Basic Examples: Basic Examples<2>.
* Python Interface::
* Command-Line Interface: Command-Line Interface<3>.
* Examples: Examples<17>.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/timeit.py


File: python.info,  Node: Basic Examples<2>,  Next: Python Interface,  Up: timeit — Measure execution time of small code snippets

5.26.6.1 Basic Examples
.......................

The following example shows how the *Note Command-Line Interface: 2434.
can be used to compare three different expressions:

    $ python -m timeit '"-".join(str(n) for n in range(100))'
    10000 loops, best of 3: 40.3 usec per loop
    $ python -m timeit '"-".join([str(n) for n in range(100)])'
    10000 loops, best of 3: 33.4 usec per loop
    $ python -m timeit '"-".join(map(str, range(100)))'
    10000 loops, best of 3: 25.2 usec per loop

This can be achieved from the *Note Python Interface: 2435. with:

    >>> import timeit
    >>> timeit.timeit('"-".join(str(n) for n in range(100))', number=10000)
    0.8187260627746582
    >>> timeit.timeit('"-".join([str(n) for n in range(100)])', number=10000)
    0.7288308143615723
    >>> timeit.timeit('"-".join(map(str, range(100)))', number=10000)
    0.5858950614929199

Note however that *Note timeit: 17b. will automatically determine the
number of repetitions only when the command-line interface is used.  In
the *Note Examples: 2437. section you can find more advanced examples.


File: python.info,  Node: Python Interface,  Next: Command-Line Interface<3>,  Prev: Basic Examples<2>,  Up: timeit — Measure execution time of small code snippets

5.26.6.2 Python Interface
.........................

The module defines three convenience functions and a public class:

 -- Function: timeit.timeit (stmt='pass', setup='pass', timer=<default
          timer>, number=1000000)
     Create a *Note Timer: 243a. instance with the given statement,
     `setup' code and `timer' function and run its *Note timeit():
     243b. method with `number' executions.

     New in version 2.6.


 -- Function: timeit.repeat (stmt='pass', setup='pass', timer=<default
          timer>, repeat=3, number=1000000)
     Create a *Note Timer: 243a. instance with the given statement,
     `setup' code and `timer' function and run its *Note repeat():
     243d. method with the given `repeat' count and `number' executions.

     New in version 2.6.


 -- Function: timeit.default_timer ()
     Define a default timer, in a platform-specific manner.  On Windows,
     *Note time.clock(): 1228. has microsecond granularity, but *Note
     time.time(): 47d.’s granularity is 1/60th of a second.  On Unix,
     *Note time.clock(): 1228. has 1/100th of a second granularity, and
     *Note time.time(): 47d. is much more precise.  On either platform,
     *Note default_timer(): 243e. measures wall clock time, not the CPU
     time.  This means that other processes running on the same
     computer may interfere with the timing.

 -- Class: timeit.Timer (stmt='pass', setup='pass', timer=<timer
          function>)
     Class for timing execution speed of small code snippets.

     The constructor takes a statement to be timed, an additional
     statement used for setup, and a timer function.  Both statements
     default to `'pass''; the timer function is platform-dependent (see
     the module doc string).  `stmt' and `setup' may also contain
     multiple statements separated by `;' or newlines, as long as they
     don’t contain multi-line string literals.

     To measure the execution time of the first statement, use the
     *Note timeit(): 243b.  method.  The *Note repeat(): 243d. method
     is a convenience to call *Note timeit(): 243b.  multiple times and
     return a list of results.

     Changed in version 2.6: The `stmt' and `setup' parameters can now
     also take objects that are callable without arguments.  This will
     embed calls to them in a timer function that will then be executed
     by *Note timeit(): 243b.  Note that the timing overhead is a
     little larger in this case because of the extra function calls.

      -- Method: timeit (number=1000000)
          Time `number' executions of the main statement.  This
          executes the setup statement once, and then returns the time
          it takes to execute the main statement a number of times,
          measured in seconds as a float.  The argument is the number
          of times through the loop, defaulting to one million.  The
          main statement, the setup statement and the timer function to
          be used are passed to the constructor.

               Note: By default, *Note timeit(): 243b. temporarily
               turns off *Note garbage collection: 629. during the
               timing.  The advantage of this approach is that it makes
               independent timings more comparable.  This disadvantage
               is that GC may be an important component of the
               performance of the function being measured.  If so, GC
               can be re-enabled as the first statement in the `setup'
               string.  For example:

                   timeit.Timer('for i in xrange(10): oct(i)', 'gc.enable()').timeit()

      -- Method: repeat (repeat=3, number=1000000)
          Call *Note timeit(): 243b. a few times.

          This is a convenience function that calls the *Note timeit():
          243b. repeatedly, returning a list of results.  The first
          argument specifies how many times to call *Note timeit():
          243b.  The second argument specifies the `number' argument
          for *Note timeit(): 243b.

               Note: It’s tempting to calculate mean and standard
               deviation from the result vector and report these.
               However, this is not very useful.  In a typical case,
               the lowest value gives a lower bound for how fast your
               machine can run the given code snippet; higher values in
               the result vector are typically not caused by
               variability in Python’s speed, but by other processes
               interfering with your timing accuracy.  So the *Note
               min(): 224. of the result is probably the only number you
               should be interested in.  After that, you should look at
               the entire vector and apply common sense rather than
               statistics.

      -- Method: print_exc (file=None)
          Helper to print a traceback from the timed code.

          Typical use:

              t = Timer(...)       # outside the try/except
              try:
                  t.timeit(...)    # or t.repeat(...)
              except:
                  t.print_exc()

          The advantage over the standard traceback is that source
          lines in the compiled template will be displayed. The
          optional `file' argument directs where the traceback is sent;
          it defaults to *Note sys.stderr: 672.


File: python.info,  Node: Command-Line Interface<3>,  Next: Examples<17>,  Prev: Python Interface,  Up: timeit — Measure execution time of small code snippets

5.26.6.3 Command-Line Interface
...............................

When called as a program from the command line, the following form is
used:

    python -m timeit [-n N] [-r N] [-s S] [-t] [-c] [-h] [statement ...]

Where the following options are understood:

 -- Program Option: -n N, --number=N
     how many times to execute ‘statement’

 -- Program Option: -r N, --repeat=N
     how many times to repeat the timer (default 3)

 -- Program Option: -s S, --setup=S
     statement to be executed once initially (default `pass')

 -- Program Option: -t, --time
     use *Note time.time(): 47d. (default on all platforms but Windows)

 -- Program Option: -c, --clock
     use *Note time.clock(): 1228. (default on Windows)

 -- Program Option: -v, --verbose
     print raw timing results; repeat for more digits precision

 -- Program Option: -h, --help
     print a short usage message and exit

A multi-line statement may be given by specifying each line as a
separate statement argument; indented lines are possible by enclosing
an argument in quotes and using leading spaces.  Multiple *Note -s:
2443. options are treated similarly.

If *Note -n: 2441. is not given, a suitable number of loops is
calculated by trying successive powers of 10 until the total time is at
least 0.2 seconds.

*Note default_timer(): 243e. measurations can be affected by other
programs running on the same machine, so the best thing to do when
accurate timing is necessary is to repeat the timing a few times and
use the best time.  The *Note -r: 2442. option is good for this; the
default of 3 repetitions is probably enough in most cases.  On Unix,
you can use *Note time.clock(): 1228. to measure CPU time.

     Note: There is a certain baseline overhead associated with
     executing a pass statement.  The code here doesn’t try to hide
     it, but you should be aware of it.  The baseline overhead can be
     measured by invoking the program without arguments, and it might
     differ between Python versions.  Also, to fairly compare older
     Python versions to Python 2.3, you may want to use Python’s `-O'
     option (see *Note Optimizations: 665.) for the older versions to
     avoid timing `SET_LINENO' instructions.


File: python.info,  Node: Examples<17>,  Prev: Command-Line Interface<3>,  Up: timeit — Measure execution time of small code snippets

5.26.6.4 Examples
.................

It is possible to provide a setup statement that is executed only once
at the beginning:

    $ python -m timeit -s 'text = "sample string"; char = "g"'  'char in text'
    10000000 loops, best of 3: 0.0877 usec per loop
    $ python -m timeit -s 'text = "sample string"; char = "g"'  'text.find(char)'
    1000000 loops, best of 3: 0.342 usec per loop

    >>> import timeit
    >>> timeit.timeit('char in text', setup='text = "sample string"; char = "g"')
    0.41440500499993504
    >>> timeit.timeit('text.find(char)', setup='text = "sample string"; char = "g"')
    1.7246671520006203

The same can be done using the *Note Timer: 243a. class and its methods:

    >>> import timeit
    >>> t = timeit.Timer('char in text', setup='text = "sample string"; char = "g"')
    >>> t.timeit()
    0.3955516149999312
    >>> t.repeat()
    [0.40193588800002544, 0.3960157959998014, 0.39594301399984033]

The following examples show how to time expressions that contain
multiple lines.  Here we compare the cost of using *Note hasattr():
344. vs. *Note try: 3ad./*Note except: 3af.  to test for missing and
present object attributes:

    $ python -m timeit 'try:' '  str.__nonzero__' 'except AttributeError:' '  pass'
    100000 loops, best of 3: 15.7 usec per loop
    $ python -m timeit 'if hasattr(str, "__nonzero__"): pass'
    100000 loops, best of 3: 4.26 usec per loop

    $ python -m timeit 'try:' '  int.__nonzero__' 'except AttributeError:' '  pass'
    1000000 loops, best of 3: 1.43 usec per loop
    $ python -m timeit 'if hasattr(int, "__nonzero__"): pass'
    100000 loops, best of 3: 2.23 usec per loop

    >>> import timeit
    >>> # attribute is missing
    >>> s = """\
    ... try:
    ...     str.__nonzero__
    ... except AttributeError:
    ...     pass
    ... """
    >>> timeit.timeit(stmt=s, number=100000)
    0.9138244460009446
    >>> s = "if hasattr(str, '__bool__'): pass"
    >>> timeit.timeit(stmt=s, number=100000)
    0.5829014980008651
    >>>
    >>> # attribute is present
    >>> s = """\
    ... try:
    ...     int.__nonzero__
    ... except AttributeError:
    ...     pass
    ... """
    >>> timeit.timeit(stmt=s, number=100000)
    0.04215312199994514
    >>> s = "if hasattr(int, '__bool__'): pass"
    >>> timeit.timeit(stmt=s, number=100000)
    0.08588060699912603

To give the *Note timeit: 17b. module access to functions you define,
you can pass a `setup' parameter which contains an import statement:

    def test():
        """Stupid test function"""
        L = []
        for i in range(100):
            L.append(i)

    if __name__ == '__main__':
        import timeit
        print(timeit.timeit("test()", setup="from __main__ import test"))


File: python.info,  Node: trace — Trace or track Python statement execution,  Prev: timeit — Measure execution time of small code snippets,  Up: Debugging and Profiling

5.26.7 `trace' — Trace or track Python statement execution
------------------------------------------------------------

`Source code:' Lib/trace.py(1)

__________________________________________________________________

The *Note trace: 180. module allows you to trace program execution,
generate annotated statement coverage listings, print caller/callee
relationships and list functions executed during a program run.  It can
be used in another program or from the command line.

* Menu:

* Command-Line Usage::
* Programmatic Interface::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/trace.py


File: python.info,  Node: Command-Line Usage,  Next: Programmatic Interface,  Up: trace — Trace or track Python statement execution

5.26.7.1 Command-Line Usage
...........................

The *Note trace: 180. module can be invoked from the command line.  It
can be as simple as

    python -m trace --count -C . somefile.py ...

The above will execute `somefile.py' and generate annotated listings of
all Python modules imported during the execution into the current
directory.

 -- Program Option: --help
     Display usage and exit.

 -- Program Option: --version
     Display the version of the module and exit.

* Menu:

* Main options::
* Modifiers::
* Filters::


File: python.info,  Node: Main options,  Next: Modifiers,  Up: Command-Line Usage

5.26.7.2 Main options
.....................

At least one of the following options must be specified when invoking
*Note trace: 180.  The *Note -listfuncs: 2450. option is mutually
exclusive with the *Note -trace: 2451. and *Note -count: 2452. options.
When *Note -listfuncs: 2450. is provided, neither *Note -count: 2452.
nor *Note -trace: 2451. are accepted, and vice versa.

 -- Program Option: -c, --count
     Produce a set of annotated listing files upon program completion
     that shows how many times each statement was executed.  See also
     *Note -coverdir: 2453, *Note -file: 2454. and *Note -no-report:
     2455. below.

 -- Program Option: -t, --trace
     Display lines as they are executed.

 -- Program Option: -l, --listfuncs
     Display the functions executed by running the program.

 -- Program Option: -r, --report
     Produce an annotated list from an earlier program run that used the
     *Note -count: 2452. and *Note -file: 2454. option.  This does not
     execute any code.

 -- Program Option: -T, --trackcalls
     Display the calling relationships exposed by running the program.


File: python.info,  Node: Modifiers,  Next: Filters,  Prev: Main options,  Up: Command-Line Usage

5.26.7.3 Modifiers
..................

 -- Program Option: -f, --file=<file>
     Name of a file to accumulate counts over several tracing runs.
     Should be used with the *Note -count: 2452. option.

 -- Program Option: -C, --coverdir=<dir>
     Directory where the report files go.  The coverage report for
     `package.module' is written to file
     ``dir'/`package'/`module'.cover'.

 -- Program Option: -m, --missing
     When generating annotated listings, mark lines which were not
     executed with `>>>>>>'.

 -- Program Option: -s, --summary
     When using *Note -count: 2452. or *Note -report: 2456, write a
     brief summary to stdout for each file processed.

 -- Program Option: -R, --no-report
     Do not generate annotated listings.  This is useful if you intend
     to make several runs with *Note -count: 2452, and then produce a
     single set of annotated listings at the end.

 -- Program Option: -g, --timing
     Prefix each line with the time since the program started.  Only
     used while tracing.


File: python.info,  Node: Filters,  Prev: Modifiers,  Up: Command-Line Usage

5.26.7.4 Filters
................

These options may be repeated multiple times.

 -- Program Option: --ignore-module=<mod>
     Ignore each of the given module names and its submodules (if it is
     a package).  The argument can be a list of names separated by a
     comma.

 -- Program Option: --ignore-dir=<dir>
     Ignore all modules and packages in the named directory and
     subdirectories.  The argument can be a list of directories
     separated by *Note os.pathsep: 678.


File: python.info,  Node: Programmatic Interface,  Prev: Command-Line Usage,  Up: trace — Trace or track Python statement execution

5.26.7.5 Programmatic Interface
...............................

 -- Class: trace.Trace ([count=1[, trace=1[, countfuncs=0[,
          countcallers=0[, ignoremods=()[, ignoredirs=()[,
          infile=None[, outfile=None[, timing=False]]]]]]]]])
     Create an object to trace execution of a single statement or
     expression.  All parameters are optional.  `count' enables
     counting of line numbers.  `trace' enables line execution tracing.
     `countfuncs' enables listing of the functions called during the
     run.  `countcallers' enables call relationship tracking.
     `ignoremods' is a list of modules or packages to ignore.
     `ignoredirs' is a list of directories whose modules or packages
     should be ignored.  `infile' is the name of the file from which to
     read stored count information.  `outfile' is the name of the file
     in which to write updated count information.  `timing' enables a
     timestamp relative to when tracing was started to be displayed.

           -- Method: run (cmd)
               Execute the command and gather statistics from the
               execution with the current tracing parameters.  `cmd'
               must be a string or code object, suitable for passing
               into `exec()'.

           -- Method: runctx (cmd, globals=None, locals=None)
               Execute the command and gather statistics from the
               execution with the current tracing parameters, in the
               defined global and local environments.  If not defined,
               `globals' and `locals' default to empty dictionaries.

           -- Method: runfunc (func, *args, **kwds)
               Call `func' with the given arguments under control of
               the *Note Trace: 2461.  object with the current tracing
               parameters.

           -- Method: results ()
               Return a *Note CoverageResults: 2466. object that
               contains the cumulative results of all previous calls to
               `run', `runctx' and `runfunc' for the given *Note Trace:
               2461. instance.  Does not reset the accumulated trace
               results.

 -- Class: trace.CoverageResults
     A container for coverage results, created by *Note
     Trace.results(): 2465.  Should not be created directly by the user.

           -- Method: update (other)
               Merge in data from another *Note CoverageResults: 2466.
               object.

           -- Method: write_results ([show_missing=True[,
                    summary=False[, coverdir=None]]])
               Write coverage results.  Set `show_missing' to show
               lines that had no hits.  Set `summary' to include in the
               output the coverage summary per module.  `coverdir'
               specifies the directory into which the coverage result
               files will be output.  If `None', the results for each
               source file are placed in its directory.

A simple example demonstrating the use of the programmatic interface:

    import sys
    import trace

    # create a Trace object, telling it what to ignore, and whether to
    # do tracing or line-counting or both.
    tracer = trace.Trace(
        ignoredirs=[sys.prefix, sys.exec_prefix],
        trace=0,
        count=1)

    # run the new command using the given tracer
    tracer.run('main()')

    # make a report, placing output in the current directory
    r = tracer.results()
    r.write_results(show_missing=True, coverdir=".")


File: python.info,  Node: Software Packaging and Distribution,  Next: Python Runtime Services,  Prev: Debugging and Profiling,  Up: The Python Standard Library

5.27 Software Packaging and Distribution
========================================

These libraries help you with publishing and installing Python software.
While these modules are designed to work in conjunction with the Python
Package Index(1), they can also be used with a local index server, or
without any index server at all.

* Menu:

* distutils — Building and installing Python modules::
* ensurepip — Bootstrapping the pip installer::

---------- Footnotes ----------

(1) https://pypi.python.org


File: python.info,  Node: distutils — Building and installing Python modules,  Next: ensurepip — Bootstrapping the pip installer,  Up: Software Packaging and Distribution

5.27.1 `distutils' — Building and installing Python modules
-------------------------------------------------------------

The *Note distutils: 85. package provides support for building and
installing additional modules into a Python installation.  The new
modules may be either 100%-pure Python, or may be extension modules
written in C, or may be collections of Python packages which include
modules coded in both Python and C.

Most Python users will `not' want to use this module directly, but
instead use the cross-version tools maintained by the Python Packaging
Authority. In particular, setuptools(1) is an enhanced alternative to
*Note distutils: 85. that provides:

   * support for declaring project dependencies

   * additional mechanisms for configuring which files to include in
     source releases (including plugins for integration with version
     control systems)

   * the ability to declare project “entry points”, which can be
     used as the basis for application plugin systems

   * the ability to automatically generate Windows command line
     executables at installation time rather than needing to prebuild
     them

   * consistent behaviour across all supported Python versions

The recommended pip(2) installer runs all `setup.py' scripts with
`setuptools', even if the script itself only imports `distutils'. Refer
to the Python Packaging User Guide(3) for more information.

For the benefits of packaging tool authors and users seeking a deeper
understanding of the details of the current packaging and distribution
system, the legacy *Note distutils: 85. based user documentation and API
reference remain available:

   * *Note Installing Python Modules (Legacy version): 2f0.

   * *Note Distributing Python Modules (Legacy version): 2f1.

---------- Footnotes ----------

(1) https://setuptools.readthedocs.io/en/latest/

(2) https://pip.pypa.io/

(3) https://packaging.python.org


File: python.info,  Node: ensurepip — Bootstrapping the pip installer,  Prev: distutils — Building and installing Python modules,  Up: Software Packaging and Distribution

5.27.2 `ensurepip' — Bootstrapping the `pip' installer
--------------------------------------------------------

New in version 2.7.9.

The *Note ensurepip: c8. package provides support for bootstrapping the
`pip' installer into an existing Python installation or virtual
environment. This bootstrapping approach reflects the fact that `pip'
is an independent project with its own release cycle, and the latest
available stable version is bundled with maintenance and feature
releases of the CPython reference interpreter.

In most cases, end users of Python shouldn’t need to invoke this
module directly (as `pip' should be bootstrapped by default), but it
may be needed if installing `pip' was skipped when installing Python (or
when creating a virtual environment) or after explicitly uninstalling
`pip'.

     Note: This module `does not' access the internet. All of the
     components needed to bootstrap `pip' are included as internal
     parts of the package.

See also
........

*Note Installing Python Modules: 2ee.
     The end user guide for installing Python packages

PEP 453(1): Explicit bootstrapping of pip in Python installations
     The original rationale and specification for this module.

PEP 477(2): Backport ensurepip (PEP 453) to Python 2.7
     The rationale and specification for backporting PEP 453 to Python
     2.7.

* Menu:

* Command line interface::
* Module API::

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-0453

(2) https://www.python.org/dev/peps/pep-0477


File: python.info,  Node: Command line interface,  Next: Module API,  Up: ensurepip — Bootstrapping the pip installer

5.27.2.1 Command line interface
...............................

The command line interface is invoked using the interpreter’s `-m'
switch.

The simplest possible invocation is:

    python -m ensurepip

This invocation will install `pip' if it is not already installed, but
otherwise does nothing. To ensure the installed version of `pip' is at
least as recent as the one bundled with `ensurepip', pass the
`--upgrade' option:

    python -m ensurepip --upgrade

By default, `pip' is installed into the current virtual environment (if
one is active) or into the system site packages (if there is no active
virtual environment). The installation location can be controlled
through two additional command line options:

   * `--root <dir>': Installs `pip' relative to the given root directory
     rather than the root of the currently active virtual environment
     (if any) or the default root for the current Python installation.

   * `--user': Installs `pip' into the user site packages directory
     rather than globally for the current Python installation (this
     option is not permitted inside an active virtual environment).

By default, the scripts `pip', `pipX', and `pipX.Y' will be installed
(where X.Y stands for the version of Python used to invoke
`ensurepip'). The scripts installed can be controlled through two
additional command line options:

   * `--altinstall': if an alternate installation is requested, the
     `pip' and `pipX' script will `not' be installed.

   * `--no-default-pip': if a non-default installation is request, the
     `pip' script will `not' be installed.


File: python.info,  Node: Module API,  Prev: Command line interface,  Up: ensurepip — Bootstrapping the pip installer

5.27.2.2 Module API
...................

*Note ensurepip: c8. exposes two functions for programmatic use:

 -- Function: ensurepip.version ()
     Returns a string specifying the bundled version of pip that will be
     installed when bootstrapping an environment.

 -- Function: ensurepip.bootstrap (root=None, upgrade=False,
          user=False, altinstall=False, default_pip=True, verbosity=0)
     Bootstraps `pip' into the current or designated environment.

     `root' specifies an alternative root directory to install relative
     to.  If `root' is `None', then installation uses the default
     install location for the current environment.

     `upgrade' indicates whether or not to upgrade an existing
     installation of an earlier version of `pip' to the bundled version.

     `user' indicates whether to use the user scheme rather than
     installing globally.

     By default, the scripts `pip', `pipX', and `pipX.Y' will be
     installed (where X.Y stands for the current version of Python).

     If `altinstall' is set, then `pip' and `pipX' will `not' be
     installed.

     If `default_pip' is set to `False', then `pip' will `not' be
     installed.

     Setting both `altinstall' and `default_pip' will trigger *Note
     ValueError: 236.

     `verbosity' controls the level of output to *Note sys.stdout: 8b2.
     from the bootstrapping operation.

          Note: The bootstrapping process has side effects on both
          `sys.path' and `os.environ'. Invoking the command line
          interface in a subprocess instead allows these side effects
          to be avoided.

          Note: The bootstrapping process may install additional
          modules required by `pip', but other software should not
          assume those dependencies will always be present by default
          (as the dependencies may be removed in a future version of
          `pip').


File: python.info,  Node: Python Runtime Services,  Next: Custom Python Interpreters,  Prev: Software Packaging and Distribution,  Up: The Python Standard Library

5.28 Python Runtime Services
============================

The modules described in this chapter provide a wide range of services
related to the Python interpreter and its interaction with its
environment.  Here’s an overview:

* Menu:

* sys — System-specific parameters and functions::
* sysconfig — Provide access to Python’s configuration information::
* __builtin__ — Built-in objects::
* future_builtins — Python 3 builtins::
* __main__ — Top-level script environment::
* warnings — Warning control::
* contextlib — Utilities for with-statement contexts::
* abc — Abstract Base Classes::
* atexit — Exit handlers::
* traceback — Print or retrieve a stack traceback::
* __future__ — Future statement definitions::
* gc — Garbage Collector interface::
* inspect — Inspect live objects::
* site — Site-specific configuration hook::
* user — User-specific configuration hook::
* fpectl — Floating point exception control::


File: python.info,  Node: sys — System-specific parameters and functions,  Next: sysconfig — Provide access to Python’s configuration information,  Up: Python Runtime Services

5.28.1 `sys' — System-specific parameters and functions
---------------------------------------------------------

This module provides access to some variables used or maintained by the
interpreter and to functions that interact strongly with the
interpreter. It is always available.

 -- Data: sys.argv
     The list of command line arguments passed to a Python script.
     `argv[0]' is the script name (it is operating system dependent
     whether this is a full pathname or not).  If the command was
     executed using the *Note -c: 523. command line option to the
     interpreter, `argv[0]' is set to the string `'-c''.  If no script
     name was passed to the Python interpreter, `argv[0]' is the empty
     string.

     To loop over the standard input, or the list of files given on the
     command line, see the *Note fileinput: cd. module.

 -- Data: sys.byteorder
     An indicator of the native byte order.  This will have the value
     `'big'' on big-endian (most-significant byte first) platforms, and
     `'little'' on little-endian (least-significant byte first)
     platforms.

     New in version 2.0.


 -- Data: sys.builtin_module_names
     A tuple of strings giving the names of all modules that are
     compiled into this Python interpreter.  (This information is not
     available in any other way — `modules.keys()' only lists the
     imported modules.)

 -- Function: sys.call_tracing (func, args)
     Call `func(*args)', while tracing is enabled.  The tracing state
     is saved, and restored afterwards.  This is intended to be called
     from a debugger from a checkpoint, to recursively debug some other
     code.

 -- Data: sys.copyright
     A string containing the copyright pertaining to the Python
     interpreter.

 -- Function: sys._clear_type_cache ()
     Clear the internal type cache. The type cache is used to speed up
     attribute and method lookups. Use the function `only' to drop
     unnecessary references during reference leak debugging.

     This function should be used for internal and specialized purposes
     only.

     New in version 2.6.


 -- Function: sys._current_frames ()
     Return a dictionary mapping each thread’s identifier to the
     topmost stack frame currently active in that thread at the time
     the function is called. Note that functions in the *Note
     traceback: 181. module can build the call stack given such a frame.

     This is most useful for debugging deadlock:  this function does
     not require the deadlocked threads’ cooperation, and such
     threads’ call stacks are frozen for as long as they remain
     deadlocked.  The frame returned for a non-deadlocked thread may
     bear no relationship to that thread’s current activity by the
     time calling code examines the frame.

     This function should be used for internal and specialized purposes
     only.

     New in version 2.5.


 -- Data: sys.dllhandle
     Integer specifying the handle of the Python DLL. Availability:
     Windows.

 -- Function: sys.displayhook (value)
     If `value' is not `None', this function prints it to `sys.stdout',
     and saves it in `__builtin__._'.

     `sys.displayhook' is called on the result of evaluating an *Note
     expression: 247d.  entered in an interactive Python session.  The
     display of these values can be customized by assigning another
     one-argument function to `sys.displayhook'.

 -- Data: sys.dont_write_bytecode
     If this is true, Python won’t try to write `.pyc' or `.pyo'
     files on the import of source modules.  This value is initially
     set to `True' or `False' depending on the *Note -B: 357. command
     line option and the *Note PYTHONDONTWRITEBYTECODE: 358.
     environment variable, but you can set it yourself to control
     bytecode file generation.

     New in version 2.6.


 -- Function: sys.excepthook (type, value, traceback)
     This function prints out a given traceback and exception to
     `sys.stderr'.

     When an exception is raised and uncaught, the interpreter calls
     `sys.excepthook' with three arguments, the exception class,
     exception instance, and a traceback object.  In an interactive
     session this happens just before control is returned to the
     prompt; in a Python program this happens just before the program
     exits.  The handling of such top-level exceptions can be
     customized by assigning another three-argument function to
     `sys.excepthook'.

 -- Data: sys.__displayhook__
 -- Data: sys.__excepthook__
     These objects contain the original values of `displayhook' and
     `excepthook' at the start of the program.  They are saved so that
     `displayhook' and `excepthook' can be restored in case they happen
     to get replaced with broken objects.

 -- Function: sys.exc_info ()
     This function returns a tuple of three values that give
     information about the exception that is currently being handled.
     The information returned is specific both to the current thread
     and to the current stack frame.  If the current stack frame is not
     handling an exception, the information is taken from the calling
     stack frame, or its caller, and so on until a stack frame is found
     that is handling an exception.  Here, “handling an exception”
     is defined as “executing or having executed an except clause.”
     For any stack frame, only information about the most recently
     handled exception is accessible.

     If no exception is being handled anywhere on the stack, a tuple
     containing three `None' values is returned.  Otherwise, the values
     returned are `(type, value, traceback)'.  Their meaning is: `type'
     gets the exception type of the exception being handled (a class
     object); `value' gets the exception parameter (its `associated
     value' or the second argument to *Note raise: 5cc, which is always
     a class instance if the exception type is a class object);
     `traceback' gets a traceback object (see the Reference Manual)
     which encapsulates the call stack at the point where the exception
     originally occurred.

     If *Note exc_clear(): 480. is called, this function will return
     three `None' values until either another exception is raised in
     the current thread or the execution stack returns to a frame where
     another exception is being handled.

          Warning: Assigning the `traceback' return value to a local
          variable in a function that is handling an exception will
          cause a circular reference.  This will prevent anything
          referenced by a local variable in the same function or by the
          traceback from being garbage collected.  Since most functions
          don’t need access to the traceback, the best solution is to
          use something like `exctype, value = sys.exc_info()[:2]' to
          extract only the exception type and value.  If you do need
          the traceback, make sure to delete it after use (best done
          with a *Note try: 3ad. … *Note finally: 3ae. statement) or
          to call *Note exc_info(): 306. in a function that does not
          itself handle an exception.

          Note: Beginning with Python 2.2, such cycles are
          automatically reclaimed when garbage collection is enabled
          and they become unreachable, but it remains more efficient to
          avoid creating cycles.

 -- Function: sys.exc_clear ()
     This function clears all information relating to the current or
     last exception that occurred in the current thread.  After calling
     this function, *Note exc_info(): 306. will return three `None'
     values until another exception is raised in the current thread or
     the execution stack returns to a frame where another exception is
     being handled.

     This function is only needed in only a few obscure situations.
     These include logging and error handling systems that report
     information on the last or current exception.  This function can
     also be used to try to free resources and trigger object
     finalization, though no guarantee is made as to what objects will
     be freed, if any.

     New in version 2.3.


 -- Data: sys.exc_type
 -- Data: sys.exc_value
 -- Data: sys.exc_traceback
     Deprecated since version 1.5: Use *Note exc_info(): 306. instead.

     Since they are global variables, they are not specific to the
     current thread, so their use is not safe in a multi-threaded
     program.  When no exception is being handled, `exc_type' is set to
     `None' and the other two are undefined.

 -- Data: sys.exec_prefix
     A string giving the site-specific directory prefix where the
     platform-dependent Python files are installed; by default, this is
     also `'/usr/local''.  This can be set at build time with the
     `--exec-prefix' argument to the `configure' script.  Specifically,
     all configuration files (e.g. the `pyconfig.h' header file) are
     installed in the directory ``exec_prefix'/lib/python`X.Y'/config',
     and shared library modules are installed in
     ``exec_prefix'/lib/python`X.Y'/lib-dynload', where `X.Y' is the
     version number of Python, for example `2.7'.

 -- Data: sys.executable
     A string giving the absolute path of the executable binary for the
     Python interpreter, on systems where this makes sense. If Python
     is unable to retrieve the real path to its executable, *Note
     sys.executable: 168b. will be an empty string or `None'.

 -- Function: sys.exit ([arg])
     Exit from Python.  This is implemented by raising the *Note
     SystemExit: 346.  exception, so cleanup actions specified by
     finally clauses of *Note try: 3ad.  statements are honored, and it
     is possible to intercept the exit attempt at an outer level.

     The optional argument `arg' can be an integer giving the exit
     status (defaulting to zero), or another type of object.  If it is
     an integer, zero is considered “successful termination” and
     any nonzero value is considered “abnormal termination” by
     shells and the like.  Most systems require it to be in the range
     0–127, and produce undefined results otherwise.  Some systems
     have a convention for assigning specific meanings to specific exit
     codes, but these are generally underdeveloped; Unix programs
     generally use 2 for command line syntax errors and 1 for all other
     kind of errors.  If another type of object is passed, `None' is
     equivalent to passing zero, and any other object is printed to
     *Note stderr: 672. and results in an exit code of 1.  In
     particular, `sys.exit("some error message")' is a quick way to
     exit a program when an error occurs.

     Since *Note exit(): 8c3. ultimately “only” raises an
     exception, it will only exit the process when called from the main
     thread, and the exception is not intercepted.

 -- Data: sys.exitfunc
     This value is not actually defined by the module, but can be set
     by the user (or by a program) to specify a clean-up action at
     program exit.  When set, it should be a parameterless function.
     This function will be called when the interpreter exits.  Only one
     function may be installed in this way; to allow multiple functions
     which will be called at termination, use the *Note atexit: 12.
     module.

          Note: The exit function is not called when the program is
          killed by a signal, when a Python fatal internal error is
          detected, or when `os._exit()' is called.

     Deprecated since version 2.4: Use *Note atexit: 12. instead.


 -- Data: sys.flags
     The struct sequence `flags' exposes the status of command line
     flags. The attributes are read only.

     attribute                         flag
     -------------------------------------------------------------------------- 
     `debug'                           *Note -d: 661.
     `py3k_warning'                    *Note -3: 1cc.
     `division_warning'                *Note -Q: 1cd.
     `division_new'                    *Note -Qnew: 1cd.
     *Note inspect: f9.                *Note -i: 492.
     `interactive'                     *Note -i: 492.
     `optimize'                        *Note -O: 46c. or *Note -OO: 59f.
     *Note dont_write_bytecode: 247e.  *Note -B: 357.
     `no_user_site'                    *Note -s: 312.
     `no_site'                         *Note -S: 66a.
     `ignore_environment'              *Note -E: 663.
     `tabcheck'                        *Note -t: 66b. or *Note -tt: 66b.
     `verbose'                         *Note -v: 3cb.
     *Note unicode: 1f5.               *Note -U: 675.
     `bytes_warning'                   `-b'
     `hash_randomization'              *Note -R: 667.

     New in version 2.6.

     New in version 2.7.3: The `hash_randomization' attribute.


 -- Data: sys.float_info
     A structseq holding information about the float type. It contains
     low level information about the precision and internal
     representation.  The values correspond to the various
     floating-point constants defined in the standard header file
     `float.h' for the ‘C’ programming language; see section
     5.2.4.2.2 of the 1999 ISO/IEC C standard *Note [C99]: 2483,
     ‘Characteristics of floating types’, for details.

     attribute                 float.h macro        explanation
     ------------------------------------------------------------------------------------------------------ 
     `epsilon'                 DBL_EPSILON          difference between 1 and the least value greater than
                                                    1 that is representable as a float
     `dig'                     DBL_DIG              maximum number of decimal digits that can be
                                                    faithfully represented in a float;  see below
     `mant_dig'                DBL_MANT_DIG         float precision: the number of base-`radix' digits in
                                                    the significand of a float
     *Note max: 225.           DBL_MAX              maximum representable finite float
     `max_exp'                 DBL_MAX_EXP          maximum integer e such that `radix**(e-1)' is a
                                                    representable finite float
     `max_10_exp'              DBL_MAX_10_EXP       maximum integer e such that `10**e' is in the range
                                                    of representable finite floats
     *Note min: 224.           DBL_MIN              minimum positive normalized float
     `min_exp'                 DBL_MIN_EXP          minimum integer e such that `radix**(e-1)' is a
                                                    normalized float
     `min_10_exp'              DBL_MIN_10_EXP       minimum integer e such that `10**e' is a normalized
                                                    float
     `radix'                   FLT_RADIX            radix of exponent representation
     `rounds'                  FLT_ROUNDS           integer constant representing the rounding mode used
                                                    for arithmetic operations.  This reflects the value
                                                    of the system FLT_ROUNDS macro at interpreter startup
                                                    time.  See section 5.2.4.2.2 of the C99 standard for
                                                    an explanation of the possible values and their
                                                    meanings.

     The attribute `sys.float_info.dig' needs further explanation.  If
     `s' is any string representing a decimal number with at most
     `sys.float_info.dig' significant digits, then converting `s' to a
     float and back again will recover a string representing the same
     decimal value:

         >>> import sys
         >>> sys.float_info.dig
         15
         >>> s = '3.14159265358979'    # decimal string with 15 significant digits
         >>> format(float(s), '.15g')  # convert to float and back -> same value
         '3.14159265358979'

     But for strings with more than `sys.float_info.dig' significant
     digits, this isn’t always true:

         >>> s = '9876543211234567'    # 16 significant digits is too many!
         >>> format(float(s), '.16g')  # conversion changes value
         '9876543211234568'

     New in version 2.6.


 -- Data: sys.float_repr_style
     A string indicating how the *Note repr(): 1c6. function behaves for
     floats.  If the string has value `'short'' then for a finite float
     `x', `repr(x)' aims to produce a short string with the property
     that `float(repr(x)) == x'.  This is the usual behaviour in Python
     2.7 and later.  Otherwise, `float_repr_style' has value `'legacy''
     and `repr(x)' behaves in the same way as it did in versions of
     Python prior to 2.7.

     New in version 2.7.


 -- Function: sys.getcheckinterval ()
     Return the interpreter’s “check interval”; see *Note
     setcheckinterval(): 2484.

     New in version 2.3.


 -- Function: sys.getdefaultencoding ()
     Return the name of the current default string encoding used by the
     Unicode implementation.

     New in version 2.0.


 -- Function: sys.getdlopenflags ()
     Return the current value of the flags that are used for `dlopen()'
     calls.  The flag constants are defined in the *Note dl: b4. and
     `DLFCN' modules.  Availability: Unix.

     New in version 2.2.


 -- Function: sys.getfilesystemencoding ()
     Return the name of the encoding used to convert Unicode filenames
     into system file names, or `None' if the system default encoding
     is used. The result value depends on the operating system:

        * On Mac OS X, the encoding is `'utf-8''.

        * On Unix, the encoding is the user’s preference according to
          the result of nl_langinfo(CODESET), or `None' if the
          `nl_langinfo(CODESET)' failed.

        * On Windows NT+, file names are Unicode natively, so no
          conversion is performed. *Note getfilesystemencoding(): 1012.
          still returns `'mbcs'', as this is the encoding that
          applications should use when they explicitly want to convert
          Unicode strings to byte strings that are equivalent when used
          as file names.

        * On Windows 9x, the encoding is `'mbcs''.

     New in version 2.3.


 -- Function: sys.getrefcount (object)
     Return the reference count of the `object'.  The count returned is
     generally one higher than you might expect, because it includes
     the (temporary) reference as an argument to *Note getrefcount():
     2485.

 -- Function: sys.getrecursionlimit ()
     Return the current value of the recursion limit, the maximum depth
     of the Python interpreter stack.  This limit prevents infinite
     recursion from causing an overflow of the C stack and crashing
     Python.  It can be set by *Note setrecursionlimit(): 504.

 -- Function: sys.getsizeof (object[, default])
     Return the size of an object in bytes. The object can be any type
     of object. All built-in objects will return correct results, but
     this does not have to hold true for third-party extensions as it
     is implementation specific.

     If given, `default' will be returned if the object does not
     provide means to retrieve the size.  Otherwise a *Note TypeError:
     218. will be raised.

     *Note getsizeof(): 2486. calls the object’s `__sizeof__' method
     and adds an additional garbage collector overhead if the object is
     managed by the garbage collector.

     New in version 2.6.


 -- Function: sys._getframe ([depth])
     Return a frame object from the call stack.  If optional integer
     `depth' is given, return the frame object that many calls below
     the top of the stack.  If that is deeper than the call stack,
     *Note ValueError: 236. is raised.  The default for `depth' is
     zero, returning the frame at the top of the call stack.

     `CPython implementation detail:' This function should be used for
     internal and specialized purposes only.  It is not guaranteed to
     exist in all implementations of Python.

 -- Function: sys.getprofile ()
     Get the profiler function as set by *Note setprofile(): 4bb.

     New in version 2.6.


 -- Function: sys.gettrace ()
     Get the trace function as set by *Note settrace(): 4bc.

     `CPython implementation detail:' The *Note gettrace(): 36d.
     function is intended only for implementing debuggers, profilers,
     coverage tools and the like.  Its behavior is part of the
     implementation platform, rather than part of the language
     definition, and thus may not be available in all Python
     implementations.

     New in version 2.6.


 -- Function: sys.getwindowsversion ()
     Return a named tuple describing the Windows version currently
     running.  The named elements are `major', `minor', `build',
     `platform', `service_pack', `service_pack_minor',
     `service_pack_major', `suite_mask', and `product_type'.
     `service_pack' contains a string while all other values are
     integers. The components can also be accessed by name, so
     `sys.getwindowsversion()[0]' is equivalent to
     `sys.getwindowsversion().major'. For compatibility with prior
     versions, only the first 5 elements are retrievable by indexing.

     `platform' may be one of the following values:

     Constant                                      Platform
     ---------------------------------------------------------------------------- 
     `0 (VER_PLATFORM_WIN32s)'                     Win32s on Windows 3.1
     `1 (VER_PLATFORM_WIN32_WINDOWS)'              Windows 95/98/ME
     `2 (VER_PLATFORM_WIN32_NT)'                   Windows NT/2000/XP/x64
     `3 (VER_PLATFORM_WIN32_CE)'                   Windows CE

     `product_type' may be one of the following values:

     Constant                                    Meaning
     ---------------------------------------------------------------------------------- 
     `1 (VER_NT_WORKSTATION)'                    The system is a workstation.
     `2 (VER_NT_DOMAIN_CONTROLLER)'              The system is a domain controller.
     `3 (VER_NT_SERVER)'                         The system is a server, but not a
                                                 domain controller.

     This function wraps the Win32 `GetVersionEx()' function; see the
     Microsoft documentation on `OSVERSIONINFOEX()' for more information
     about these fields.

     Availability: Windows.

     New in version 2.3.

     Changed in version 2.7: Changed to a named tuple and added
     `service_pack_minor', `service_pack_major', `suite_mask', and
     `product_type'.


 -- Data: sys.hexversion
     The version number encoded as a single integer.  This is
     guaranteed to increase with each version, including proper support
     for non-production releases.  For example, to test that the Python
     interpreter is at least version 1.5.2, use:

         if sys.hexversion >= 0x010502F0:
             # use some advanced feature
             ...
         else:
             # use an alternative implementation or warn the user
             ...

     This is called `hexversion' since it only really looks meaningful
     when viewed as the result of passing it to the built-in *Note
     hex(): 348. function.  The `version_info' value may be used for a
     more human-friendly encoding of the same information.

     The `hexversion' is a 32-bit number with the following layout:

     Bits (big endian order)       Meaning
     ----------------------------------------------------------------------------------- 
     `1-8'                         `PY_MAJOR_VERSION'  (the `2' in `2.1.0a3')
     `9-16'                        `PY_MINOR_VERSION'  (the `1' in `2.1.0a3')
     `17-24'                       `PY_MICRO_VERSION'  (the `0' in `2.1.0a3')
     `25-28'                       `PY_RELEASE_LEVEL'  (`0xA' for alpha, `0xB' for
                                   beta, `0xC' for release candidate and `0xF' for
                                   final)
     `29-32'                       `PY_RELEASE_SERIAL'  (the `3' in `2.1.0a3', zero
                                   for final releases)

     Thus `2.1.0a3' is hexversion `0x020100a3'.

     New in version 1.5.2.


 -- Data: sys.long_info
     A struct sequence that holds information about Python’s internal
     representation of integers.  The attributes are read only.

     Attribute                     Explanation
     --------------------------------------------------------------------------------- 
     `bits_per_digit'              number of bits held in each digit.  Python
                                   integers are stored internally in base
                                   `2**long_info.bits_per_digit'
     `sizeof_digit'                size in bytes of the C type used to represent a
                                   digit

     New in version 2.7.


 -- Data: sys.last_type
 -- Data: sys.last_value
 -- Data: sys.last_traceback
     These three variables are not always defined; they are set when an
     exception is not handled and the interpreter prints an error
     message and a stack traceback.  Their intended use is to allow an
     interactive user to import a debugger module and engage in
     post-mortem debugging without having to re-execute the command
     that caused the error.  (Typical use is `import pdb; pdb.pm()' to
     enter the post-mortem debugger; see chapter *Note pdb — The
     Python Debugger: 23f0. for more information.)

     The meaning of the variables is the same as that of the return
     values from *Note exc_info(): 306. above.  (Since there is only
     one interactive thread, thread-safety is not a concern for these
     variables, unlike for `exc_type' etc.)

 -- Data: sys.maxint
     The largest positive integer supported by Python’s regular
     integer type.  This is at least 2**31-1.  The largest negative
     integer is `-maxint-1' — the asymmetry results from the use of
     2’s complement binary arithmetic.

 -- Data: sys.maxsize
     The largest positive integer supported by the platform’s
     Py_ssize_t type, and thus the maximum size lists, strings, dicts,
     and many other containers can have.

 -- Data: sys.maxunicode
     An integer giving the largest supported code point for a Unicode
     character.  The value of this depends on the configuration option
     that specifies whether Unicode characters are stored as UCS-2 or
     UCS-4.

 -- Data: sys.meta_path
     A list of *Note finder: 84e. objects that have their
     `find_module()' methods called to see if one of the objects can
     find the module to be imported. The `find_module()' method is
     called at least with the absolute name of the module being
     imported. If the module to be imported is contained in package
     then the parent package’s `__path__' attribute is passed in as a
     second argument. The method returns `None' if the module cannot be
     found, else returns a *Note loader: 84f.

     *Note sys.meta_path: 84d. is searched before any implicit default
     finders or *Note sys.path: 59a.

     See PEP 302(1) for the original specification.

 -- Data: sys.modules
     This is a dictionary that maps module names to modules which have
     already been loaded.  This can be manipulated to force reloading
     of modules and other tricks.  Note that removing a module from
     this dictionary is `not' the same as calling *Note reload(): 595.
     on the corresponding module object.

 -- Data: sys.path
     A list of strings that specifies the search path for modules.
     Initialized from the environment variable *Note PYTHONPATH: 59b,
     plus an installation-dependent default.

     As initialized upon program startup, the first item of this list,
     `path[0]', is the directory containing the script that was used to
     invoke the Python interpreter.  If the script directory is not
     available (e.g.  if the interpreter is invoked interactively or if
     the script is read from standard input), `path[0]' is the empty
     string, which directs Python to search modules in the current
     directory first.  Notice that the script directory is inserted
     `before' the entries inserted as a result of *Note PYTHONPATH: 59b.

     A program is free to modify this list for its own purposes.

     Changed in version 2.3: Unicode strings are no longer ignored.

See also
........

     Module *Note site: 158. This describes how to use .pth files to
extend *Note sys.path: 59a.


 -- Data: sys.path_hooks
     A list of callables that take a path argument to try to create a
     *Note finder: 84e. for the path. If a finder can be created, it is
     to be returned by the callable, else raise *Note ImportError: 388.

     Originally specified in PEP 302(2).

 -- Data: sys.path_importer_cache
     A dictionary acting as a cache for *Note finder: 84e. objects. The
     keys are paths that have been passed to *Note sys.path_hooks: 850.
     and the values are the finders that are found. If a path is a
     valid file system path but no explicit finder is found on *Note
     sys.path_hooks: 850. then `None' is stored to represent the
     implicit default finder should be used. If the path is not an
     existing path then *Note imp.NullImporter: 248b. is set.

     Originally specified in PEP 302(3).

 -- Data: sys.platform
     This string contains a platform identifier that can be used to
     append platform-specific components to *Note sys.path: 59a, for
     instance.

     For most Unix systems, this is the lowercased OS name as returned
     by `uname -s' with the first part of the version as returned by
     `uname -r' appended, e.g. `'sunos5'', `at the time when Python was
     built'.  Unless you want to test for a specific system version, it
     is therefore recommended to use the following idiom:

         if sys.platform.startswith('freebsd'):
             # FreeBSD-specific code here...
         elif sys.platform.startswith('linux'):
             # Linux-specific code here...

     Changed in version 2.7.3: Since lots of code check for
     `sys.platform == 'linux2'', and there is no essential change
     between Linux 2.x and 3.x, `sys.platform' is always set to
     `'linux2'', even on Linux 3.x.  In Python 3.3 and later, the value
     will always be set to `'linux'', so it is recommended to always
     use the `startswith' idiom presented above.

     For other systems, the values are:

     System                    *Note platform: 133. value
     ---------------------------------------------------------- 
     Linux (2.x `and' 3.x)     `'linux2''
     Windows                   `'win32''
     Windows/Cygwin            `'cygwin''
     Mac OS X                  `'darwin''
     OS/2                      `'os2''
     OS/2 EMX                  `'os2emx''
     RiscOS                    `'riscos''
     AtheOS                    `'atheos''

See also
........

     *Note os.name: 1110. has a coarser granularity.  *Note os.uname():
1112. gives system-dependent version information.

     The *Note platform: 133. module provides detailed checks for the
system’s identity.


 -- Data: sys.prefix
     A string giving the site-specific directory prefix where the
     platform independent Python files are installed; by default, this
     is the string `'/usr/local''.  This can be set at build time with
     the `--prefix' argument to the `configure' script.  The main
     collection of Python library modules is installed in the directory
     ``prefix'/lib/python`X.Y'' while the platform independent header
     files (all except `pyconfig.h') are stored in
     ``prefix'/include/python`X.Y'', where `X.Y' is the version number
     of Python, for example `2.7'.

 -- Data: sys.ps1
 -- Data: sys.ps2
     Strings specifying the primary and secondary prompt of the
     interpreter.  These are only defined if the interpreter is in
     interactive mode.  Their initial values in this case are `'>>> ''
     and `'... ''.  If a non-string object is assigned to either
     variable, its *Note str(): 1ea. is re-evaluated each time the
     interpreter prepares to read a new interactive command; this can
     be used to implement a dynamic prompt.

 -- Data: sys.py3kwarning
     Bool containing the status of the Python 3 warning flag. It’s
     `True' when Python is started with the -3 option.  (This should be
     considered read-only; setting it to a different value doesn’t
     have an effect on Python 3 warnings.)

     New in version 2.6.


 -- Function: sys.setcheckinterval (interval)
     Set the interpreter’s “check interval”.  This integer value
     determines how often the interpreter checks for periodic things
     such as thread switches and signal handlers.  The default is
     `100', meaning the check is performed every 100 Python virtual
     instructions. Setting it to a larger value may increase
     performance for programs using threads.  Setting it to a value
     `<=' 0 checks every virtual instruction, maximizing responsiveness
     as well as overhead.

 -- Function: sys.setdefaultencoding (name)
     Set the current default string encoding used by the Unicode
     implementation.  If `name' does not match any available encoding,
     *Note LookupError: 8b9. is raised.  This function is only intended
     to be used by the *Note site: 158. module implementation and,
     where needed, by `sitecustomize'.  Once used by the *Note site:
     158. module, it is removed from the *Note sys: 16d. module’s
     namespace.

     New in version 2.0.


 -- Function: sys.setdlopenflags (n)
     Set the flags used by the interpreter for `dlopen()' calls, such
     as when the interpreter loads extension modules.  Among other
     things, this will enable a lazy resolving of symbols when
     importing a module, if called as `sys.setdlopenflags(0)'.  To
     share symbols across extension modules, call as
     `sys.setdlopenflags(dl.RTLD_NOW | dl.RTLD_GLOBAL)'.  Symbolic
     names for the flag modules can be either found in the *Note dl:
     b4. module, or in the `DLFCN' module. If `DLFCN' is not available,
     it can be generated from `/usr/include/dlfcn.h' using the `h2py'
     script. Availability: Unix.

     New in version 2.2.


 -- Function: sys.setprofile (profilefunc)
     Set the system’s profile function, which allows you to implement
     a Python source code profiler in Python.  See chapter *Note The
     Python Profilers: 23fb. for more information on the Python
     profiler.  The system’s profile function is called similarly to
     the system’s trace function (see *Note settrace(): 4bc.), but it
     isn’t called for each executed line of code (only on call and
     return, but the return event is reported even when an exception
     has been set).  The function is thread-specific, but there is no
     way for the profiler to know about context switches between
     threads, so it does not make sense to use this in the presence of
     multiple threads. Also, its return value is not used, so it can
     simply return `None'.

 -- Function: sys.setrecursionlimit (limit)
     Set the maximum depth of the Python interpreter stack to `limit'.
     This limit prevents infinite recursion from causing an overflow of
     the C stack and crashing Python.

     The highest possible limit is platform-dependent.  A user may need
     to set the limit higher when she has a program that requires deep
     recursion and a platform that supports a higher limit.  This
     should be done with care, because a too-high limit can lead to a
     crash.

 -- Function: sys.settrace (tracefunc)
     Set the system’s trace function, which allows you to implement a
     Python source code debugger in Python.  The function is
     thread-specific; for a debugger to support multiple threads, it
     must be registered using *Note settrace(): 4bc. for each thread
     being debugged.

     Trace functions should have three arguments: `frame', `event', and
     `arg'. `frame' is the current stack frame.  `event' is a string:
     `'call'', `'line'', `'return'', `'exception'', `'c_call'',
     `'c_return'', or `'c_exception''. `arg' depends on the event type.

     The trace function is invoked (with `event' set to `'call'')
     whenever a new local scope is entered; it should return a
     reference to a local trace function to be used that scope, or
     `None' if the scope shouldn’t be traced.

     The local trace function should return a reference to itself (or
     to another function for further tracing in that scope), or `None'
     to turn off tracing in that scope.

     The events have the following meaning:

    `'call''
          A function is called (or some other code block entered).  The
          global trace function is called; `arg' is `None'; the return
          value specifies the local trace function.

    `'line''
          The interpreter is about to execute a new line of code or
          re-execute the condition of a loop.  The local trace function
          is called; `arg' is `None'; the return value specifies the
          new local trace function.  See `Objects/lnotab_notes.txt' for
          a detailed explanation of how this works.

    `'return''
          A function (or other code block) is about to return.  The
          local trace function is called; `arg' is the value that will
          be returned, or `None' if the event is caused by an exception
          being raised.  The trace function’s return value is ignored.

    `'exception''
          An exception has occurred.  The local trace function is
          called; `arg' is a tuple `(exception, value, traceback)'; the
          return value specifies the new local trace function.

    `'c_call''
          A C function is about to be called.  This may be an extension
          function or a built-in.  `arg' is the C function object.

    `'c_return''
          A C function has returned. `arg' is the C function object.

    `'c_exception''
          A C function has raised an exception.  `arg' is the C
          function object.

     Note that as an exception is propagated down the chain of callers,
     an `'exception'' event is generated at each level.

     For more information on code and frame objects, refer to *Note The
     standard type hierarchy: 719.

     `CPython implementation detail:' The *Note settrace(): 4bc.
     function is intended only for implementing debuggers, profilers,
     coverage tools and the like.  Its behavior is part of the
     implementation platform, rather than part of the language
     definition, and thus may not be available in all Python
     implementations.

 -- Function: sys.settscdump (on_flag)
     Activate dumping of VM measurements using the Pentium timestamp
     counter, if `on_flag' is true. Deactivate these dumps if `on_flag'
     is off. The function is available only if Python was compiled with
     `--with-tsc'. To understand the output of this dump, read
     `Python/ceval.c' in the Python sources.

     New in version 2.4.

     `CPython implementation detail:' This function is intimately bound
     to CPython implementation details and thus not likely to be
     implemented elsewhere.

 -- Data: sys.stdin
 -- Data: sys.stdout
 -- Data: sys.stderr
     File objects corresponding to the interpreter’s standard input,
     output and error streams.  `stdin' is used for all interpreter
     input except for scripts but including calls to *Note input():
     3d9. and *Note raw_input(): 891.  `stdout' is used for the output
     of *Note print: 4fd. and *Note expression: 247d. statements and
     for the prompts of *Note input(): 3d9. and *Note raw_input(): 891.
     The interpreter’s own prompts and (almost all of) its error
     messages go to `stderr'.  `stdout' and `stderr' needn’t be
     built-in file objects: any object is acceptable as long as it has
     a `write()' method that takes a string argument.  (Changing these
     objects doesn’t affect the standard I/O streams of processes
     executed by *Note os.popen(): 728, *Note os.system(): 413. or the
     `exec*()' family of functions in the *Note os: 129. module.)

 -- Data: sys.__stdin__
 -- Data: sys.__stdout__
 -- Data: sys.__stderr__
     These objects contain the original values of `stdin', `stderr' and
     `stdout' at the start of the program.  They are used during
     finalization, and could be useful to print to the actual standard
     stream no matter if the `sys.std*' object has been redirected.

     It can also be used to restore the actual files to known working
     file objects in case they have been overwritten with a broken
     object.  However, the preferred way to do this is to explicitly
     save the previous stream before replacing it, and restore the
     saved object.

 -- Data: sys.subversion
     A triple (repo, branch, version) representing the Subversion
     information of the Python interpreter. `repo' is the name of the
     repository, `'CPython''.  `branch' is a string of one of the forms
     `'trunk'', `'branches/name'' or `'tags/name''. `version' is the
     output of `svnversion', if the interpreter was built from a
     Subversion checkout; it contains the revision number (range) and
     possibly a trailing ‘M’ if there were local modifications. If
     the tree was exported (or svnversion was not available), it is the
     revision of `Include/patchlevel.h' if the branch is a tag.
     Otherwise, it is `None'.

     New in version 2.5.

          Note: Python is now developed(4) using Mercurial.  In recent
          Python 2.7 bugfix releases, *Note subversion: 2492.
          therefore contains placeholder information.  It is removed in
          Python 3.3.

 -- Data: sys.tracebacklimit
     When this variable is set to an integer value, it determines the
     maximum number of levels of traceback information printed when an
     unhandled exception occurs.  The default is `1000'.  When set to
     `0' or less, all traceback information is suppressed and only the
     exception type and value are printed.

 -- Data: sys.version
     A string containing the version number of the Python interpreter
     plus additional information on the build number and compiler used.
     This string is displayed when the interactive interpreter is
     started.  Do not extract version information out of it, rather,
     use *Note version_info: 2495. and the functions provided by the
     *Note platform: 133. module.

 -- Data: sys.api_version
     The C API version for this interpreter.  Programmers may find this
     useful when debugging version conflicts between Python and
     extension modules.

     New in version 2.3.


 -- Data: sys.version_info
     A tuple containing the five components of the version number:
     `major', `minor', `micro', `releaselevel', and `serial'.  All
     values except `releaselevel' are integers; the release level is
     `'alpha'', `'beta'', `'candidate'', or `'final''.  The
     `version_info' value corresponding to the Python version 2.0 is
     `(2, 0, 0, 'final', 0)'.  The components can also be accessed by
     name, so `sys.version_info[0]' is equivalent to
     `sys.version_info.major' and so on.

     New in version 2.0.

     Changed in version 2.7: Added named component attributes


 -- Data: sys.warnoptions
     This is an implementation detail of the warnings framework; do not
     modify this value.  Refer to the *Note warnings: 193. module for
     more information on the warnings framework.

 -- Data: sys.winver
     The version number used to form registry keys on Windows
     platforms. This is stored as string resource 1000 in the Python
     DLL.  The value is normally the first three characters of *Note
     version: 2494.  It is provided in the *Note sys: 16d.  module for
     informational purposes; modifying this value has no effect on the
     registry keys used by Python. Availability: Windows.

Citations
.........

(C99) ISO/IEC 9899:1999.  “Programming languages – C.”  A public
draft of this standard is available at
<http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf>.

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-0302

(2) https://www.python.org/dev/peps/pep-0302

(3) https://www.python.org/dev/peps/pep-0302

(4) https://docs.python.org/devguide/


File: python.info,  Node: sysconfig — Provide access to Python’s configuration information,  Next: __builtin__ — Built-in objects,  Prev: sys — System-specific parameters and functions,  Up: Python Runtime Services

5.28.2 `sysconfig' — Provide access to Python’s configuration information
-----------------------------------------------------------------------------

New in version 2.7.

`Source code:' Lib/sysconfig.py(1)

__________________________________________________________________

The *Note sysconfig: 16e. module provides access to Python’s
configuration information like the list of installation paths and the
configuration variables relevant for the current platform.

* Menu:

* Configuration variables::
* Installation paths::
* Other functions::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/sysconfig.py


File: python.info,  Node: Configuration variables,  Next: Installation paths,  Up: sysconfig — Provide access to Python’s configuration information

5.28.2.1 Configuration variables
................................

A Python distribution contains a `Makefile' and a `pyconfig.h' header
file that are necessary to build both the Python binary itself and
third-party C extensions compiled using *Note distutils: 85.

*Note sysconfig: 16e. puts all variables found in these files in a
dictionary that can be accessed using *Note get_config_vars(): 275. or
*Note get_config_var(): 274.

Notice that on Windows, it’s a much smaller set.

 -- Function: sysconfig.get_config_vars (*args)
     With no arguments, return a dictionary of all configuration
     variables relevant for the current platform.

     With arguments, return a list of values that result from looking
     up each argument in the configuration variable dictionary.

     For each argument, if the value is not found, return `None'.

 -- Function: sysconfig.get_config_var (name)
     Return the value of a single variable `name'. Equivalent to
     `get_config_vars().get(name)'.

     If `name' is not found, return `None'.

Example of usage:

    >>> import sysconfig
    >>> sysconfig.get_config_var('Py_ENABLE_SHARED')
    0
    >>> sysconfig.get_config_var('LIBDIR')
    '/usr/local/lib'
    >>> sysconfig.get_config_vars('AR', 'CXX')
    ['ar', 'g++']


File: python.info,  Node: Installation paths,  Next: Other functions,  Prev: Configuration variables,  Up: sysconfig — Provide access to Python’s configuration information

5.28.2.2 Installation paths
...........................

Python uses an installation scheme that differs depending on the
platform and on the installation options.  These schemes are stored in
*Note sysconfig: 16e. under unique identifiers based on the value
returned by *Note os.name: 1110.

Every new component that is installed using *Note distutils: 85. or a
Distutils-based system will follow the same scheme to copy its file in
the right places.

Python currently supports seven schemes:

   - `posix_prefix': scheme for Posix platforms like Linux or Mac OS X.
     This is the default scheme used when Python or a component is
     installed.

   - `posix_home': scheme for Posix platforms used when a `home' option
     is used upon installation.  This scheme is used when a component
     is installed through Distutils with a specific home prefix.

   - `posix_user': scheme for Posix platforms used when a component is
     installed through Distutils and the `user' option is used.  This
     scheme defines paths located under the user home directory.

   - `nt': scheme for NT platforms like Windows.

   - `nt_user': scheme for NT platforms, when the `user' option is used.

   - `os2': scheme for OS/2 platforms.

   - `os2_home': scheme for OS/2 patforms, when the `user' option is
     used.

Each scheme is itself composed of a series of paths and each path has a
unique identifier.  Python currently uses eight paths:

   - `stdlib': directory containing the standard Python library files
     that are not platform-specific.

   - `platstdlib': directory containing the standard Python library
     files that are platform-specific.

   - `platlib': directory for site-specific, platform-specific files.

   - `purelib': directory for site-specific, non-platform-specific
     files.

   - `include': directory for non-platform-specific header files.

   - `platinclude': directory for platform-specific header files.

   - `scripts': directory for script files.

   - `data': directory for data files.

*Note sysconfig: 16e. provides some functions to determine these paths.

 -- Function: sysconfig.get_scheme_names ()
     Return a tuple containing all schemes currently supported in *Note
     sysconfig: 16e.

 -- Function: sysconfig.get_path_names ()
     Return a tuple containing all path names currently supported in
     *Note sysconfig: 16e.

 -- Function: sysconfig.get_path (name[, scheme[, vars[, expand]]])
     Return an installation path corresponding to the path `name', from
     the install scheme named `scheme'.

     `name' has to be a value from the list returned by *Note
     get_path_names(): 249e.

     *Note sysconfig: 16e. stores installation paths corresponding to
     each path name, for each platform, with variables to be expanded.
     For instance the `stdlib' path for the `nt' scheme is:
     `{base}/Lib'.

     *Note get_path(): 276. will use the variables returned by *Note
     get_config_vars(): 275.  to expand the path.  All variables have
     default values for each platform so one may call this function and
     get the default value.

     If `scheme' is provided, it must be a value from the list returned
     by *Note get_scheme_names(): 249d.  Otherwise, the default scheme
     for the current platform is used.

     If `vars' is provided, it must be a dictionary of variables that
     will update the dictionary return by *Note get_config_vars(): 275.

     If `expand' is set to `False', the path will not be expanded using
     the variables.

     If `name' is not found, return `None'.

 -- Function: sysconfig.get_paths ([scheme[, vars[, expand]]])
     Return a dictionary containing all installation paths
     corresponding to an installation scheme. See *Note get_path():
     276. for more information.

     If `scheme' is not provided, will use the default scheme for the
     current platform.

     If `vars' is provided, it must be a dictionary of variables that
     will update the dictionary used to expand the paths.

     If `expand' is set to false, the paths will not be expanded.

     If `scheme' is not an existing scheme, *Note get_paths(): 249f.
     will raise a *Note KeyError: 205.


File: python.info,  Node: Other functions,  Prev: Installation paths,  Up: sysconfig — Provide access to Python’s configuration information

5.28.2.3 Other functions
........................

 -- Function: sysconfig.get_python_version ()
     Return the `MAJOR.MINOR' Python version number as a string.
     Similar to `sys.version[:3]'.

 -- Function: sysconfig.get_platform ()
     Return a string that identifies the current platform.

     This is used mainly to distinguish platform-specific build
     directories and platform-specific built distributions.  Typically
     includes the OS name and version and the architecture (as supplied
     by *Note os.uname(): 1112.), although the exact information
     included depends on the OS; e.g. for IRIX the architecture isn’t
     particularly important (IRIX only runs on SGI hardware), but for
     Linux the kernel version isn’t particularly important.

     Examples of returned values:

        - linux-i586

        - linux-alpha (?)

        - solaris-2.6-sun4u

        - irix-5.3

        - irix64-6.2

     Windows will return one of:

        - win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64,
          EM64T, etc)

        - win-ia64 (64bit Windows on Itanium)

        - win32 (all others - specifically, sys.platform is returned)

     Mac OS X can return:

        - macosx-10.6-ppc

        - macosx-10.4-ppc64

        - macosx-10.3-i386

        - macosx-10.4-fat

     For other non-POSIX platforms, currently just returns *Note
     sys.platform: 1111.

 -- Function: sysconfig.is_python_build ()
     Return `True' if the current Python installation was built from
     source.

 -- Function: sysconfig.parse_config_h (fp[, vars])
     Parse a `config.h'-style file.

     `fp' is a file-like object pointing to the `config.h'-like file.

     A dictionary containing name/value pairs is returned.  If an
     optional dictionary is passed in as the second argument, it is
     used instead of a new dictionary, and updated with the values read
     in the file.

 -- Function: sysconfig.get_config_h_filename ()
     Return the path of `pyconfig.h'.

 -- Function: sysconfig.get_makefile_filename ()
     Return the path of `Makefile'.


File: python.info,  Node: __builtin__ — Built-in objects,  Next: future_builtins — Python 3 builtins,  Prev: sysconfig — Provide access to Python’s configuration information,  Up: Python Runtime Services

5.28.3 `__builtin__' — Built-in objects
-----------------------------------------

This module provides direct access to all ‘built-in’ identifiers of
Python; for example, `__builtin__.open' is the full name for the
built-in function *Note open(): 2d9.  See *Note Built-in Functions:
7f0. and *Note Built-in Constants: 8bc. for documentation.

This module is not normally accessed explicitly by most applications,
but can be useful in modules that provide objects with the same name as
a built-in value, but in which the built-in of that name is also
needed.  For example, in a module that wants to implement an *Note
open(): 2d9. function that wraps the built-in *Note open(): 2d9, this
module can be used directly:

    import __builtin__

    def open(path):
        f = __builtin__.open(path, 'r')
        return UpperCaser(f)

    class UpperCaser:
        '''Wrapper around a file that converts output to upper-case.'''

        def __init__(self, f):
            self._f = f

        def read(self, count=-1):
            return self._f.read(count).upper()

        # ...

`CPython implementation detail:' Most modules have the name
`__builtins__' (note the `'s'') made available as part of their
globals.  The value of `__builtins__' is normally either this module or
the value of this modules’s *Note __dict__: 4a0. attribute.  Since
this is an implementation detail, it may not be used by alternate
implementations of Python.


File: python.info,  Node: future_builtins — Python 3 builtins,  Next: __main__ — Top-level script environment,  Prev: __builtin__ — Built-in objects,  Up: Python Runtime Services

5.28.4 `future_builtins' — Python 3 builtins
----------------------------------------------

New in version 2.6.

This module provides functions that exist in 2.x, but have different
behavior in Python 3, so they cannot be put into the 2.x builtins
namespace.

Instead, if you want to write code compatible with Python 3 builtins,
import them from this module, like this:

    from future_builtins import map, filter

    ... code using Python 3-style map and filter ...

The *Note 2to3: c05. tool that ports Python 2 code to Python 3 will
recognize this usage and leave the new builtins alone.

     Note: The Python 3 *Note print(): 31f. function is already in the
     builtins, but cannot be accessed from Python 2 code unless you use
     the appropriate future statement:

         from __future__ import print_function

Available builtins are:

 -- Function: future_builtins.ascii (object)
     Returns the same as *Note repr(): 1c6.  In Python 3, *Note repr():
     1c6. will return printable Unicode characters unescaped, while
     *Note ascii(): 24aa. will always backslash-escape them.  Using
     *Note future_builtins.ascii(): 24aa. instead of *Note repr(): 1c6.
     in 2.6 code makes it clear that you need a pure ASCII return value.

 -- Function: future_builtins.filter (function, iterable)
     Works like *Note itertools.ifilter(): 8aa.

 -- Function: future_builtins.hex (object)
     Works like the built-in *Note hex(): 348, but instead of *Note
     __hex__(): 37a. it will use the *Note __index__(): 260. method on
     its argument to get an integer that is then converted to
     hexadecimal.

 -- Function: future_builtins.map (function, iterable, ...)
     Works like *Note itertools.imap(): d8d.

          Note: In Python 3, *Note map(): 318. does not accept `None'
          for the function argument.

 -- Function: future_builtins.oct (object)
     Works like the built-in *Note oct(): 339, but instead of *Note
     __oct__(): 37b. it will use the *Note __index__(): 260. method on
     its argument to get an integer that is then converted to octal.

 -- Function: future_builtins.zip (*iterables)
     Works like *Note itertools.izip(): 41f.


File: python.info,  Node: __main__ — Top-level script environment,  Next: warnings — Warning control,  Prev: future_builtins — Python 3 builtins,  Up: Python Runtime Services

5.28.5 `__main__' — Top-level script environment
--------------------------------------------------

This module represents the (otherwise anonymous) scope in which the
interpreter’s main program executes — commands read either from
standard input, from a script file, or from an interactive prompt.  It
is this environment in which the idiomatic “conditional script”
stanza causes a script to run:

    if __name__ == "__main__":
        main()


File: python.info,  Node: warnings — Warning control,  Next: contextlib — Utilities for with-statement contexts,  Prev: __main__ — Top-level script environment,  Up: Python Runtime Services

5.28.6 `warnings' — Warning control
-------------------------------------

New in version 2.1.

`Source code:' Lib/warnings.py(1)

__________________________________________________________________

Warning messages are typically issued in situations where it is useful
to alert the user of some condition in a program, where that condition
(normally) doesn’t warrant raising an exception and terminating the
program.  For example, one might want to issue a warning when a program
uses an obsolete module.

Python programmers issue warnings by calling the *Note warn(): 4dc.
function defined in this module.  (C programmers use *Note
PyErr_WarnEx(): 400.; see *Note Exception Handling: 24b4. for details).

Warning messages are normally written to `sys.stderr', but their
disposition can be changed flexibly, from ignoring all warnings to
turning them into exceptions.  The disposition of warnings can vary
based on the warning category (see below), the text of the warning
message, and the source location where it is issued.  Repetitions of a
particular warning for the same source location are typically
suppressed.

There are two stages in warning control: first, each time a warning is
issued, a determination is made whether a message should be issued or
not; next, if a message is to be issued, it is formatted and printed
using a user-settable hook.

The determination whether to issue a warning message is controlled by
the warning filter, which is a sequence of matching rules and actions.
Rules can be added to the filter by calling *Note filterwarnings():
46d. and reset to its default state by calling *Note resetwarnings():
24b5.

The printing of warning messages is done by calling *Note
showwarning(): 24b6, which may be overridden; the default
implementation of this function formats the message by calling *Note
formatwarning(): 1347, which is also available for use by custom
implementations.

See also
........

*Note logging.captureWarnings(): 1346. allows you to handle all
warnings with the standard logging infrastructure.

* Menu:

* Warning Categories::
* The Warnings Filter::
* Temporarily Suppressing Warnings::
* Testing Warnings::
* Updating Code For New Versions of Python::
* Available Functions::
* Available Context Managers::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/warnings.py


File: python.info,  Node: Warning Categories,  Next: The Warnings Filter,  Up: warnings — Warning control

5.28.6.1 Warning Categories
...........................

There are a number of built-in exceptions that represent warning
categories.  This categorization is useful to be able to filter out
groups of warnings.  The following warnings category classes are
currently defined:

Class                                  Description
------------------------------------------------------------------------------------------- 
*Note Warning: 986.                    This is the base class of all warning category
                                       classes.  It is a subclass of *Note Exception: 34d.
*Note UserWarning: 987.                The default category for *Note warn(): 4dc.
*Note DeprecationWarning: 1bd.         Base category for warnings about deprecated
                                       features (ignored by default).
*Note SyntaxWarning: 46e.              Base category for warnings about dubious syntactic
                                       features.
*Note RuntimeWarning: 988.             Base category for warnings about dubious runtime
                                       features.
*Note FutureWarning: 2b7.              Base category for warnings about constructs that
                                       will change semantically in the future.
*Note PendingDeprecationWarning: 1f0.  Base category for warnings about features that
                                       will be deprecated in the future (ignored by
                                       default).
*Note ImportWarning: 3cc.              Base category for warnings triggered during the
                                       process of importing a module (ignored by default).
*Note UnicodeWarning: 989.             Base category for warnings related to Unicode.

While these are technically built-in exceptions, they are documented
here, because conceptually they belong to the warnings mechanism.

User code can define additional warning categories by subclassing one
of the standard warning categories.  A warning category must always be
a subclass of the *Note Warning: 986. class.

Changed in version 2.7: *Note DeprecationWarning: 1bd. is ignored by
default.


File: python.info,  Node: The Warnings Filter,  Next: Temporarily Suppressing Warnings,  Prev: Warning Categories,  Up: warnings — Warning control

5.28.6.2 The Warnings Filter
............................

The warnings filter controls whether warnings are ignored, displayed,
or turned into errors (raising an exception).

Conceptually, the warnings filter maintains an ordered list of filter
specifications; any specific warning is matched against each filter
specification in the list in turn until a match is found; the match
determines the disposition of the match.  Each entry is a tuple of the
form (`action', `message', `category', `module', `lineno'), where:

   * `action' is one of the following strings:

     Value               Disposition
     ----------------------------------------------------------------------- 
     `"error"'           turn matching warnings into exceptions
     `"ignore"'          never print matching warnings
     `"always"'          always print matching warnings
     `"default"'         print the first occurrence of matching warnings
                         for each location where the warning is issued
     `"module"'          print the first occurrence of matching warnings
                         for each module where the warning is issued
     `"once"'            print only the first occurrence of matching
                         warnings, regardless of location

   * `message' is a string containing a regular expression that the
     start of the warning message must match.  The expression is
     compiled to always be case-insensitive.

   * `category' is a class (a subclass of *Note Warning: 986.) of which
     the warning category must be a subclass in order to match.

   * `module' is a string containing a regular expression that the
     module name must match.  The expression is compiled to be
     case-sensitive.

   * `lineno' is an integer that the line number where the warning
     occurred must match, or `0' to match all line numbers.

Since the *Note Warning: 986. class is derived from the built-in *Note
Exception: 34d.  class, to turn a warning into an error we simply raise
`category(message)'.

The warnings filter is initialized by *Note -W: 1be. options passed to
the Python interpreter command line.  The interpreter saves the
arguments for all *Note -W: 1be. options without interpretation in
`sys.warnoptions'; the *Note warnings: 193. module parses these when it
is first imported (invalid options are ignored, after printing a
message to `sys.stderr').

* Menu:

* Default Warning Filters::


File: python.info,  Node: Default Warning Filters,  Up: The Warnings Filter

5.28.6.3 Default Warning Filters
................................

By default, Python installs several warning filters, which can be
overridden by the command-line options passed to *Note -W: 1be. and
calls to *Note filterwarnings(): 46d.

   * *Note DeprecationWarning: 1bd. and *Note
     PendingDeprecationWarning: 1f0, and *Note ImportWarning: 3cc. are
     ignored.

   * `BytesWarning' is ignored unless the `-b' option is given once or
     twice; in this case this warning is either printed (`-b') or
     turned into an exception (`-bb').


File: python.info,  Node: Temporarily Suppressing Warnings,  Next: Testing Warnings,  Prev: The Warnings Filter,  Up: warnings — Warning control

5.28.6.4 Temporarily Suppressing Warnings
.........................................

If you are using code that you know will raise a warning, such as a
deprecated function, but do not want to see the warning, then it is
possible to suppress the warning using the *Note catch_warnings: 23b0.
context manager:

    import warnings

    def fxn():
        warnings.warn("deprecated", DeprecationWarning)

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        fxn()

While within the context manager all warnings will simply be ignored.
This allows you to use known-deprecated code without having to see the
warning while not suppressing the warning for other code that might not
be aware of its use of deprecated code.  Note: this can only be
guaranteed in a single-threaded application. If two or more threads use
the *Note catch_warnings: 23b0. context manager at the same time, the
behavior is undefined.


File: python.info,  Node: Testing Warnings,  Next: Updating Code For New Versions of Python,  Prev: Temporarily Suppressing Warnings,  Up: warnings — Warning control

5.28.6.5 Testing Warnings
.........................

To test warnings raised by code, use the *Note catch_warnings: 23b0.
context manager. With it you can temporarily mutate the warnings filter
to facilitate your testing. For instance, do the following to capture
all raised warnings to check:

    import warnings

    def fxn():
        warnings.warn("deprecated", DeprecationWarning)

    with warnings.catch_warnings(record=True) as w:
        # Cause all warnings to always be triggered.
        warnings.simplefilter("always")
        # Trigger a warning.
        fxn()
        # Verify some things
        assert len(w) == 1
        assert issubclass(w[-1].category, DeprecationWarning)
        assert "deprecated" in str(w[-1].message)

One can also cause all warnings to be exceptions by using `error'
instead of `always'. One thing to be aware of is that if a warning has
already been raised because of a `once'/`default' rule, then no matter
what filters are set the warning will not be seen again unless the
warnings registry related to the warning has been cleared.

Once the context manager exits, the warnings filter is restored to its
state when the context was entered. This prevents tests from changing
the warnings filter in unexpected ways between tests and leading to
indeterminate test results. The *Note showwarning(): 24b6. function in
the module is also restored to its original value.  Note: this can only
be guaranteed in a single-threaded application. If two or more threads
use the *Note catch_warnings: 23b0. context manager at the same time,
the behavior is undefined.

When testing multiple operations that raise the same kind of warning, it
is important to test them in a manner that confirms each operation is
raising a new warning (e.g. set warnings to be raised as exceptions and
check the operations raise exceptions, check that the length of the
warning list continues to increase after each operation, or else delete
the previous entries from the warnings list before each new operation).


File: python.info,  Node: Updating Code For New Versions of Python,  Next: Available Functions,  Prev: Testing Warnings,  Up: warnings — Warning control

5.28.6.6 Updating Code For New Versions of Python
.................................................

Warnings that are only of interest to the developer are ignored by
default. As such you should make sure to test your code with typically
ignored warnings made visible. You can do this from the command-line by
passing *Note -Wd: 1be.  to the interpreter (this is shorthand for `-W
default').  This enables default handling for all warnings, including
those that are ignored by default.  To change what action is taken for
encountered warnings you simply change what argument is passed to *Note
-W: 1be, e.g. `-W error'. See the *Note -W: 1be. flag for more details
on what is possible.

To programmatically do the same as `-Wd', use:

    warnings.simplefilter('default')

Make sure to execute this code as soon as possible. This prevents the
registering of what warnings have been raised from unexpectedly
influencing how future warnings are treated.

Having certain warnings ignored by default is done to prevent a user
from seeing warnings that are only of interest to the developer. As you
do not necessarily have control over what interpreter a user uses to
run their code, it is possible that a new version of Python will be
released between your release cycles.  The new interpreter release
could trigger new warnings in your code that were not there in an older
interpreter, e.g.  *Note DeprecationWarning: 1bd. for a module that you
are using. While you as a developer want to be notified that your code
is using a deprecated module, to a user this information is essentially
noise and provides no benefit to them.


File: python.info,  Node: Available Functions,  Next: Available Context Managers,  Prev: Updating Code For New Versions of Python,  Up: warnings — Warning control

5.28.6.7 Available Functions
............................

 -- Function: warnings.warn (message[, category[, stacklevel]])
     Issue a warning, or maybe ignore it or raise an exception.  The
     `category' argument, if given, must be a warning category class
     (see above); it defaults to *Note UserWarning: 987.  Alternatively
     `message' can be a *Note Warning: 986. instance, in which case
     `category' will be ignored and `message.__class__' will be used.
     In this case the message text will be `str(message)'. This
     function raises an exception if the particular warning issued is
     changed into an error by the warnings filter see above.  The
     `stacklevel' argument can be used by wrapper functions written in
     Python, like this:

         def deprecation(message):
             warnings.warn(message, DeprecationWarning, stacklevel=2)

     This makes the warning refer to `deprecation()'’s caller, rather
     than to the source of `deprecation()' itself (since the latter
     would defeat the purpose of the warning message).

 -- Function: warnings.warn_explicit (message, category, filename,
          lineno[, module[, registry[, module_globals]]])
     This is a low-level interface to the functionality of *Note
     warn(): 4dc, passing in explicitly the message, category, filename
     and line number, and optionally the module name and the registry
     (which should be the `__warningregistry__' dictionary of the
     module).  The module name defaults to the filename with `.py'
     stripped; if no registry is passed, the warning is never
     suppressed.  `message' must be a string and `category' a subclass
     of *Note Warning: 986. or `message' may be a *Note Warning: 986.
     instance, in which case `category' will be ignored.

     `module_globals', if supplied, should be the global namespace in
     use by the code for which the warning is issued.  (This argument
     is used to support displaying source for modules found in zipfiles
     or other non-filesystem import sources).

     Changed in version 2.5: Added the `module_globals' parameter.


 -- Function: warnings.warnpy3k (message[, category[, stacklevel]])
     Issue a warning related to Python 3.x deprecation. Warnings are
     only shown when Python is started with the -3 option. Like *Note
     warn(): 4dc. `message' must be a string and `category' a subclass
     of *Note Warning: 986. *Note warnpy3k(): 24c4.  is using *Note
     DeprecationWarning: 1bd. as default warning class.

     New in version 2.6.


 -- Function: warnings.showwarning (message, category, filename,
          lineno[, file[, line]])
     Write a warning to a file.  The default implementation calls
     `formatwarning(message, category, filename, lineno, line)' and
     writes the resulting string to `file', which defaults to
     `sys.stderr'.  You may replace this function with an alternative
     implementation by assigning to `warnings.showwarning'.  `line' is
     a line of source code to be included in the warning message; if
     `line' is not supplied, *Note showwarning(): 24b6. will try to
     read the line specified by `filename' and `lineno'.

     Changed in version 2.7: The `line' argument is required to be
     supported.


 -- Function: warnings.formatwarning (message, category, filename,
          lineno[, line])
     Format a warning the standard way.  This returns a string which
     may contain embedded newlines and ends in a newline.  `line' is a
     line of source code to be included in the warning message; if
     `line' is not supplied, *Note formatwarning(): 1347. will try to
     read the line specified by `filename' and `lineno'.

     Changed in version 2.6: Added the `line' argument.


 -- Function: warnings.filterwarnings (action[, message[, category[,
          module[, lineno[, append]]]]])
     Insert an entry into the list of *Note warnings filter
     specifications: 24b9.  The entry is inserted at the front by
     default; if `append' is true, it is inserted at the end.  This
     checks the types of the arguments, compiles the `message' and
     `module' regular expressions, and inserts them as a tuple in the
     list of warnings filters.  Entries closer to the front of the list
     override entries later in the list, if both match a particular
     warning.  Omitted arguments default to a value that matches
     everything.

 -- Function: warnings.simplefilter (action[, category[, lineno[,
          append]]])
     Insert a simple entry into the list of *Note warnings filter
     specifications: 24b9.  The meaning of the function parameters is
     as for *Note filterwarnings(): 46d, but regular expressions are
     not needed as the filter inserted always matches any message in
     any module as long as the category and line number match.

 -- Function: warnings.resetwarnings ()
     Reset the warnings filter.  This discards the effect of all
     previous calls to *Note filterwarnings(): 46d, including that of
     the *Note -W: 1be. command line options and calls to *Note
     simplefilter(): 23b1.


File: python.info,  Node: Available Context Managers,  Prev: Available Functions,  Up: warnings — Warning control

5.28.6.8 Available Context Managers
...................................

 -- Class: warnings.catch_warnings ([*, record=False, module=None])
     A context manager that copies and, upon exit, restores the
     warnings filter and the *Note showwarning(): 24b6. function.  If
     the `record' argument is *Note False: 3c9. (the default) the
     context manager returns *Note None: 3b2. on entry. If `record' is
     *Note True: 3c8, a list is returned that is progressively
     populated with objects as seen by a custom *Note showwarning():
     24b6. function (which also suppresses output to `sys.stdout').
     Each object in the list has attributes with the same names as the
     arguments to *Note showwarning(): 24b6.

     The `module' argument takes a module that will be used instead of
     the module returned when you import *Note warnings: 193. whose
     filter will be protected. This argument exists primarily for
     testing the *Note warnings: 193.  module itself.

          Note: The *Note catch_warnings: 23b0. manager works by
          replacing and then later restoring the module’s *Note
          showwarning(): 24b6. function and internal list of filter
          specifications.  This means the context manager is modifying
          global state and therefore is not thread-safe.

          Note: In Python 3, the arguments to the constructor for *Note
          catch_warnings: 23b0. are keyword-only arguments.

     New in version 2.6.



File: python.info,  Node: contextlib — Utilities for with-statement contexts,  Next: abc — Abstract Base Classes,  Prev: warnings — Warning control,  Up: Python Runtime Services

5.28.7 `contextlib' — Utilities for `with'-statement contexts
---------------------------------------------------------------

New in version 2.5.

`Source code:' Lib/contextlib.py(1)

__________________________________________________________________

This module provides utilities for common tasks involving the *Note
with: 1c1.  statement. For more information see also *Note Context
Manager Types: 78c. and *Note With Statement Context Managers: 78b.

Functions provided:

 -- Function: contextlib.contextmanager (func)
     This function is a *Note decorator: 87e. that can be used to
     define a factory function for *Note with: 1c1. statement context
     managers, without needing to create a class or separate *Note
     __enter__(): 1ff. and *Note __exit__(): 200. methods.

     A simple example (this is not recommended as a real way of
     generating HTML!):

         from contextlib import contextmanager

         @contextmanager
         def tag(name):
             print "<%s>" % name
             yield
             print "</%s>" % name

         >>> with tag("h1"):
         ...    print "foo"
         ...
         <h1>
         foo
         </h1>

     The function being decorated must return a *Note generator:
     5f7.-iterator when called. This iterator must yield exactly one
     value, which will be bound to the targets in the *Note with: 1c1.
     statement’s *Note as: 30b. clause, if any.

     At the point where the generator yields, the block nested in the
     *Note with: 1c1.  statement is executed.  The generator is then
     resumed after the block is exited.  If an unhandled exception
     occurs in the block, it is reraised inside the generator at the
     point where the yield occurred.  Thus, you can use a *Note try:
     3ad.…*Note except: 3af.…*Note finally: 3ae. statement to trap
     the error (if any), or ensure that some cleanup takes place. If an
     exception is trapped merely in order to log it or to perform some
     action (rather than to suppress it entirely), the generator must
     reraise that exception. Otherwise the generator context manager
     will indicate to the *Note with: 1c1. statement that the exception
     has been handled, and execution will resume with the statement
     immediately following the *Note with: 1c1. statement.

 -- Function: contextlib.nested (mgr1[, mgr2[, ...]])
     Combine multiple context managers into a single nested context
     manager.

     This function has been deprecated in favour of the multiple
     manager form of the *Note with: 1c1. statement.

     The one advantage of this function over the multiple manager form
     of the *Note with: 1c1. statement is that argument unpacking
     allows it to be used with a variable number of context managers as
     follows:

         from contextlib import nested

         with nested(*managers):
             do_something()

     Note that if the *Note __exit__(): 200. method of one of the
     nested context managers indicates an exception should be
     suppressed, no exception information will be passed to any
     remaining outer context managers. Similarly, if the *Note
     __exit__(): 200. method of one of the nested managers raises an
     exception, any previous exception state will be lost; the new
     exception will be passed to the *Note __exit__(): 200. methods of
     any remaining outer context managers. In general, *Note
     __exit__(): 200. methods should avoid raising exceptions, and in
     particular they should not re-raise a passed-in exception.

     This function has two major quirks that have led to it being
     deprecated. Firstly, as the context managers are all constructed
     before the function is invoked, the *Note __new__(): 724. and
     *Note __init__(): 394. methods of the inner context managers are
     not actually covered by the scope of the outer context managers.
     That means, for example, that using *Note nested(): 1e9. to open
     two files is a programming error as the first file will not be
     closed promptly if an exception is thrown when opening the second
     file.

     Secondly, if the *Note __enter__(): 1ff. method of one of the
     inner context managers raises an exception that is caught and
     suppressed by the *Note __exit__(): 200. method of one of the
     outer context managers, this construct will raise *Note
     RuntimeError: 3b3. rather than skipping the body of the *Note
     with: 1c1.  statement.

     Developers that need to support nesting of a variable number of
     context managers can either use the *Note warnings: 193. module to
     suppress the DeprecationWarning raised by this function or else
     use this function as a model for an application specific
     implementation.

     Deprecated since version 2.7: The with-statement now supports this
     functionality directly (without the confusing error prone quirks).


 -- Function: contextlib.closing (thing)
     Return a context manager that closes `thing' upon completion of
     the block.  This is basically equivalent to:

         from contextlib import contextmanager

         @contextmanager
         def closing(thing):
             try:
                 yield thing
             finally:
                 thing.close()

     And lets you write code like this:

         from contextlib import closing
         import urllib

         with closing(urllib.urlopen('http://www.python.org')) as page:
             for line in page:
                 print line

     without needing to explicitly close `page'.  Even if an error
     occurs, `page.close()' will be called when the *Note with: 1c1.
     block is exited.

See also
........

PEP 343(2) - The “with” statement
     The specification, background, and examples for the Python *Note
     with: 1c1.  statement.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/contextlib.py

(2) https://www.python.org/dev/peps/pep-0343


File: python.info,  Node: abc — Abstract Base Classes,  Next: atexit — Exit handlers,  Prev: contextlib — Utilities for with-statement contexts,  Up: Python Runtime Services

5.28.8 `abc' — Abstract Base Classes
--------------------------------------

New in version 2.6.

`Source code:' Lib/abc.py(1)

__________________________________________________________________

This module provides the infrastructure for defining *Note abstract
base classes: 8af. (ABCs) in Python, as outlined in PEP 3119(2); see
the PEP for why this was added to Python. (See also PEP 3141(3) and the
*Note numbers: 126. module regarding a type hierarchy for numbers based
on ABCs.)

The *Note collections: 65. module has some concrete classes that derive
from ABCs; these can, of course, be further derived. In addition the
*Note collections: 65. module has some ABCs that can be used to test
whether a class or instance provides a particular interface, for
example, is it hashable or a mapping.

This module provides the following class:

 -- Class: abc.ABCMeta
     Metaclass for defining Abstract Base Classes (ABCs).

     Use this metaclass to create an ABC.  An ABC can be subclassed
     directly, and then acts as a mix-in class.  You can also register
     unrelated concrete classes (even built-in classes) and unrelated
     ABCs as “virtual subclasses” – these and their descendants
     will be considered subclasses of the registering ABC by the
     built-in *Note issubclass(): 333. function, but the registering ABC
     won’t show up in their MRO (Method Resolution Order) nor will
     method implementations defined by the registering ABC be callable
     (not even via *Note super(): 395.). (4)

     Classes created with a metaclass of *Note ABCMeta: 746. have the
     following method:

      -- Method: register (subclass)
          Register `subclass' as a “virtual subclass” of this ABC.
          For example:

              from abc import ABCMeta

              class MyABC:
                  __metaclass__ = ABCMeta

              MyABC.register(tuple)

              assert issubclass(tuple, MyABC)
              assert isinstance((), MyABC)

     You can also override this method in an abstract base class:

      -- Method: __subclasshook__ (subclass)
          (Must be defined as a class method.)

          Check whether `subclass' is considered a subclass of this
          ABC.  This means that you can customize the behavior of
          `issubclass' further without the need to call *Note
          register(): 24cb. on every class you want to consider a
          subclass of the ABC.  (This class method is called from the
          `__subclasscheck__()' method of the ABC.)

          This method should return `True', `False' or
          `NotImplemented'.  If it returns `True', the `subclass' is
          considered a subclass of this ABC.  If it returns `False',
          the `subclass' is not considered a subclass of this ABC, even
          if it would normally be one.  If it returns `NotImplemented',
          the subclass check is continued with the usual mechanism.


     For a demonstration of these concepts, look at this example ABC
     definition:

         class Foo(object):
             def __getitem__(self, index):
                 ...
             def __len__(self):
                 ...
             def get_iterator(self):
                 return iter(self)

         class MyIterable:
             __metaclass__ = ABCMeta

             @abstractmethod
             def __iter__(self):
                 while False:
                     yield None

             def get_iterator(self):
                 return self.__iter__()

             @classmethod
             def __subclasshook__(cls, C):
                 if cls is MyIterable:
                     if any("__iter__" in B.__dict__ for B in C.__mro__):
                         return True
                 return NotImplemented

         MyIterable.register(Foo)

     The ABC `MyIterable' defines the standard iterable method, *Note
     __iter__(): 8dd, as an abstract method.  The implementation given
     here can still be called from subclasses.  The `get_iterator()'
     method is also part of the `MyIterable' abstract base class, but
     it does not have to be overridden in non-abstract derived classes.

     The *Note __subclasshook__(): 24cc. class method defined here says
     that any class that has an *Note __iter__(): 8dd. method in its
     *Note __dict__: 4a0. (or in that of one of its base classes,
     accessed via the *Note __mro__: 8b8. list) is considered a
     `MyIterable' too.

     Finally, the last line makes `Foo' a virtual subclass of
     `MyIterable', even though it does not define an *Note __iter__():
     8dd. method (it uses the old-style iterable protocol, defined in
     terms of *Note __len__(): 423. and *Note __getitem__(): 468.).
     Note that this will not make `get_iterator' available as a method
     of `Foo', so it is provided separately.

It also provides the following decorators:

 -- Function: abc.abstractmethod (function)
     A decorator indicating abstract methods.

     Using this decorator requires that the class’s metaclass is
     *Note ABCMeta: 746. or is derived from it.  A class that has a
     metaclass derived from *Note ABCMeta: 746.  cannot be instantiated
     unless all of its abstract methods and properties are overridden.
     The abstract methods can be called using any of the normal
     ‘super’ call mechanisms.

     Dynamically adding abstract methods to a class, or attempting to
     modify the abstraction status of a method or class once it is
     created, are not supported.  The *Note abstractmethod(): 24cd.
     only affects subclasses derived using regular inheritance;
     “virtual subclasses” registered with the ABC’s `register()'
     method are not affected.

     Usage:

         class C:
             __metaclass__ = ABCMeta
             @abstractmethod
             def my_abstract_method(self, ...):
                 ...

          Note: Unlike Java abstract methods, these abstract methods
          may have an implementation. This implementation can be called
          via the *Note super(): 395. mechanism from the class that
          overrides it.  This could be useful as an end-point for a
          super-call in a framework that uses cooperative
          multiple-inheritance.

 -- Function: abc.abstractproperty ([fget[, fset[, fdel[, doc]]]])
     A subclass of the built-in *Note property(): 4a4, indicating an
     abstract property.

     Using this function requires that the class’s metaclass is *Note
     ABCMeta: 746. or is derived from it.  A class that has a metaclass
     derived from *Note ABCMeta: 746. cannot be instantiated unless all
     of its abstract methods and properties are overridden.  The
     abstract properties can be called using any of the normal
     ‘super’ call mechanisms.

     Usage:

         class C:
             __metaclass__ = ABCMeta
             @abstractproperty
             def my_abstract_property(self):
                 ...

     This defines a read-only property; you can also define a
     read-write abstract property using the ‘long’ form of property
     declaration:

         class C:
             __metaclass__ = ABCMeta
             def getx(self): ...
             def setx(self, value): ...
             x = abstractproperty(getx, setx)

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/abc.py

(2) https://www.python.org/dev/peps/pep-3119

(3) https://www.python.org/dev/peps/pep-3141

(4) C++ programmers should note that Python’s virtual base class
concept is not the same as C++’s.


File: python.info,  Node: atexit — Exit handlers,  Next: traceback — Print or retrieve a stack traceback,  Prev: abc — Abstract Base Classes,  Up: Python Runtime Services

5.28.9 `atexit' — Exit handlers
---------------------------------

New in version 2.0.

`Source code:' Lib/atexit.py(1)

__________________________________________________________________

The *Note atexit: 12. module defines a single function to register
cleanup functions.  Functions thus registered are automatically
executed upon normal interpreter termination.  *Note atexit: 12. runs
these functions in the `reverse' order in which they were registered;
if you register `A', `B', and `C', at interpreter termination time they
will be run in the order `C', `B', `A'.

`Note:' The functions registered via this module are not called when the
program is killed by a signal not handled by Python, when a Python fatal
internal error is detected, or when *Note os._exit(): 97b. is called.

This is an alternate interface to the functionality provided by the
*Note sys.exitfunc(): 427. variable.

Note: This module is unlikely to work correctly when used with other
code that sets `sys.exitfunc'.  In particular, other core Python
modules are free to use *Note atexit: 12. without the programmer’s
knowledge.  Authors who use `sys.exitfunc' should convert their code to
use *Note atexit: 12. instead.  The simplest way to convert code that
sets `sys.exitfunc' is to import *Note atexit: 12. and register the
function that had been bound to `sys.exitfunc'.

 -- Function: atexit.register (func[, *args[, **kargs]])
     Register `func' as a function to be executed at termination.  Any
     optional arguments that are to be passed to `func' must be passed
     as arguments to *Note register(): 50e.  It is possible to register
     the same function and arguments more than once.

     At normal program termination (for instance, if *Note sys.exit():
     2aa. is called or the main module’s execution completes), all
     functions registered are called in last in, first out order.  The
     assumption is that lower level modules will normally be imported
     before higher level modules and thus must be cleaned up later.

     If an exception is raised during execution of the exit handlers, a
     traceback is printed (unless *Note SystemExit: 346. is raised) and
     the exception information is saved.  After all exit handlers have
     had a chance to run the last exception to be raised is re-raised.

     Changed in version 2.6: This function now returns `func', which
     makes it possible to use it as a decorator.


See also
........

Module *Note readline: 145.
     Useful example of *Note atexit: 12. to read and write *Note
     readline: 145. history files.

* Menu:

* atexit Example::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/atexit.py


File: python.info,  Node: atexit Example,  Up: atexit — Exit handlers

5.28.9.1 `atexit' Example
.........................

The following simple example demonstrates how a module can initialize a
counter from a file when it is imported and save the counter’s
updated value automatically when the program terminates without relying
on the application making an explicit call into this module at
termination.

    try:
        _count = int(open("counter").read())
    except IOError:
        _count = 0

    def incrcounter(n):
        global _count
        _count = _count + n

    def savecounter():
        open("counter", "w").write("%d" % _count)

    import atexit
    atexit.register(savecounter)

Positional and keyword arguments may also be passed to *Note
register(): 50e. to be passed along to the registered function when it
is called:

    def goodbye(name, adjective):
        print 'Goodbye, %s, it was %s to meet you.' % (name, adjective)

    import atexit
    atexit.register(goodbye, 'Donny', 'nice')

    # or:
    atexit.register(goodbye, adjective='nice', name='Donny')

Usage as a *Note decorator: 87e.:

    import atexit

    @atexit.register
    def goodbye():
        print "You are now leaving the Python sector."

This only works with functions that can be called without arguments.


File: python.info,  Node: traceback — Print or retrieve a stack traceback,  Next: __future__ — Future statement definitions,  Prev: atexit — Exit handlers,  Up: Python Runtime Services

5.28.10 `traceback' — Print or retrieve a stack traceback
-----------------------------------------------------------

This module provides a standard interface to extract, format and print
stack traces of Python programs.  It exactly mimics the behavior of the
Python interpreter when it prints a stack trace.  This is useful when
you want to print stack traces under program control, such as in a
“wrapper” around the interpreter.

The module uses traceback objects — this is the object type that is
stored in the variables *Note sys.exc_traceback: 2392. (deprecated) and
*Note sys.last_traceback: 23f4. and returned as the third item from
*Note sys.exc_info(): 306.

The module defines the following functions:

 -- Function: traceback.print_tb (tb[, limit[, file]])
     Print up to `limit' stack trace entries from the traceback object
     `tb'. If `limit' is omitted or `None', all entries are printed. If
     `file' is omitted or `None', the output goes to `sys.stderr';
     otherwise it should be an open file or file-like object to receive
     the output.

 -- Function: traceback.print_exception (etype, value, tb[, limit[,
          file]])
     Print exception information and up to `limit' stack trace entries
     from the traceback `tb' to `file'. This differs from *Note
     print_tb(): 24d5. in the following ways: (1) if `tb' is not
     `None', it prints a header `Traceback (most recent call last):';
     (2) it prints the exception `etype' and `value' after the stack
     trace; (3) if `etype' is *Note SyntaxError: 4b4. and `value' has
     the appropriate format, it prints the line where the syntax error
     occurred with a caret indicating the approximate position of the
     error.

 -- Function: traceback.print_exc ([limit[, file]])
     This is a shorthand for `print_exception(sys.exc_type,
     sys.exc_value, sys.exc_traceback, limit, file)'.  (In fact, it
     uses *Note sys.exc_info(): 306. to retrieve the same information
     in a thread-safe way instead of using the deprecated variables.)

 -- Function: traceback.format_exc ([limit])
     This is like `print_exc(limit)' but returns a string instead of
     printing to a file.

     New in version 2.4.


 -- Function: traceback.print_last ([limit[, file]])
     This is a shorthand for `print_exception(sys.last_type,
     sys.last_value, sys.last_traceback, limit, file)'.  In general it
     will work only after an exception has reached an interactive
     prompt (see *Note sys.last_type: 2488.).

 -- Function: traceback.print_stack ([f[, limit[, file]]])
     This function prints a stack trace from its invocation point. The
     optional `f' argument can be used to specify an alternate stack
     frame to start. The optional limit* and `file' arguments have the
     same meaning as for *Note print_exception(): 1325.

 -- Function: traceback.extract_tb (tb[, limit])
     Return a list of up to `limit' “pre-processed” stack trace
     entries extracted from the traceback object `tb'.  It is useful
     for alternate formatting of stack traces.  If `limit' is omitted
     or `None', all entries are extracted.  A “pre-processed” stack
     trace entry is a 4-tuple (`filename', `line number', function
     name*, `text') representing the information that is usually printed
     for a stack trace.  The `text' is a string with leading and
     trailing whitespace stripped; if the source is not available it is
     `None'.

 -- Function: traceback.extract_stack ([f[, limit]])
     Extract the raw traceback from the current stack frame.  The
     return value has the same format as for *Note extract_tb(): 24da.
     The optional `f' and `limit' arguments have the same meaning as
     for *Note print_stack(): 24d9.

 -- Function: traceback.format_list (extracted_list)
     Given a list of tuples as returned by *Note extract_tb(): 24da. or
     *Note extract_stack(): 24db, return a list of strings ready for
     printing.  Each string in the resulting list corresponds to the
     item with the same index in the argument list.  Each string ends
     in a newline; the strings may contain internal newlines as well,
     for those items whose source text line is not `None'.

 -- Function: traceback.format_exception_only (etype, value)
     Format the exception part of a traceback.  The arguments are the
     exception type, `etype' and `value' such as given by
     `sys.last_type' and `sys.last_value'.  The return value is a list
     of strings, each ending in a newline.  Normally, the list contains
     a single string; however, for *Note SyntaxError: 4b4. exceptions,
     it contains several lines that (when printed) display detailed
     information about where the syntax error occurred.  The message
     indicating which exception occurred is the always last string in
     the list.

 -- Function: traceback.format_exception (etype, value, tb[, limit])
     Format a stack trace and the exception information.  The arguments
     have the same meaning as the corresponding arguments to *Note
     print_exception(): 1325.  The return value is a list of strings,
     each ending in a newline and some containing internal newlines.
     When these lines are concatenated and printed, exactly the same
     text is printed as does *Note print_exception(): 1325.

 -- Function: traceback.format_tb (tb[, limit])
     A shorthand for `format_list(extract_tb(tb, limit))'.

 -- Function: traceback.format_stack ([f[, limit]])
     A shorthand for `format_list(extract_stack(f, limit))'.

 -- Function: traceback.tb_lineno (tb)
     This function returns the current line number set in the traceback
     object.  This function was necessary because in versions of Python
     prior to 2.3 when the *Note -O: 46c. flag was passed to Python the
     `tb.tb_lineno' was not updated correctly.  This function has no
     use in versions past 2.3.

* Menu:

* Traceback Examples::


File: python.info,  Node: Traceback Examples,  Up: traceback — Print or retrieve a stack traceback

5.28.10.1 Traceback Examples
............................

This simple example implements a basic read-eval-print loop, similar to
(but less useful than) the standard Python interactive interpreter
loop.  For a more complete implementation of the interpreter loop,
refer to the *Note code: 62.  module.

    import sys, traceback

    def run_user_code(envdir):
        source = raw_input(">>> ")
        try:
            exec source in envdir
        except:
            print "Exception in user code:"
            print '-'*60
            traceback.print_exc(file=sys.stdout)
            print '-'*60

    envdir = {}
    while 1:
        run_user_code(envdir)

The following example demonstrates the different ways to print and
format the exception and traceback:

    import sys, traceback

    def lumberjack():
        bright_side_of_death()

    def bright_side_of_death():
        return tuple()[0]

    try:
        lumberjack()
    except IndexError:
        exc_type, exc_value, exc_traceback = sys.exc_info()
        print "*** print_tb:"
        traceback.print_tb(exc_traceback, limit=1, file=sys.stdout)
        print "*** print_exception:"
        traceback.print_exception(exc_type, exc_value, exc_traceback,
                                  limit=2, file=sys.stdout)
        print "*** print_exc:"
        traceback.print_exc()
        print "*** format_exc, first and last line:"
        formatted_lines = traceback.format_exc().splitlines()
        print formatted_lines[0]
        print formatted_lines[-1]
        print "*** format_exception:"
        print repr(traceback.format_exception(exc_type, exc_value,
                                              exc_traceback))
        print "*** extract_tb:"
        print repr(traceback.extract_tb(exc_traceback))
        print "*** format_tb:"
        print repr(traceback.format_tb(exc_traceback))
        print "*** tb_lineno:", exc_traceback.tb_lineno

The output for the example would look similar to this:

    *** print_tb:
      File "<doctest...>", line 10, in <module>
        lumberjack()
    *** print_exception:
    Traceback (most recent call last):
      File "<doctest...>", line 10, in <module>
        lumberjack()
      File "<doctest...>", line 4, in lumberjack
        bright_side_of_death()
    IndexError: tuple index out of range
    *** print_exc:
    Traceback (most recent call last):
      File "<doctest...>", line 10, in <module>
        lumberjack()
      File "<doctest...>", line 4, in lumberjack
        bright_side_of_death()
    IndexError: tuple index out of range
    *** format_exc, first and last line:
    Traceback (most recent call last):
    IndexError: tuple index out of range
    *** format_exception:
    ['Traceback (most recent call last):\n',
     '  File "<doctest...>", line 10, in <module>\n    lumberjack()\n',
     '  File "<doctest...>", line 4, in lumberjack\n    bright_side_of_death()\n',
     '  File "<doctest...>", line 7, in bright_side_of_death\n    return tuple()[0]\n',
     'IndexError: tuple index out of range\n']
    *** extract_tb:
    [('<doctest...>', 10, '<module>', 'lumberjack()'),
     ('<doctest...>', 4, 'lumberjack', 'bright_side_of_death()'),
     ('<doctest...>', 7, 'bright_side_of_death', 'return tuple()[0]')]
    *** format_tb:
    ['  File "<doctest...>", line 10, in <module>\n    lumberjack()\n',
     '  File "<doctest...>", line 4, in lumberjack\n    bright_side_of_death()\n',
     '  File "<doctest...>", line 7, in bright_side_of_death\n    return tuple()[0]\n']
    *** tb_lineno: 10

The following example shows the different ways to print and format the
stack:

    >>> import traceback
    >>> def another_function():
    ...     lumberstack()
    ...
    >>> def lumberstack():
    ...     traceback.print_stack()
    ...     print repr(traceback.extract_stack())
    ...     print repr(traceback.format_stack())
    ...
    >>> another_function()
      File "<doctest>", line 10, in <module>
        another_function()
      File "<doctest>", line 3, in another_function
        lumberstack()
      File "<doctest>", line 6, in lumberstack
        traceback.print_stack()
    [('<doctest>', 10, '<module>', 'another_function()'),
     ('<doctest>', 3, 'another_function', 'lumberstack()'),
     ('<doctest>', 7, 'lumberstack', 'print repr(traceback.extract_stack())')]
    ['  File "<doctest>", line 10, in <module>\n    another_function()\n',
     '  File "<doctest>", line 3, in another_function\n    lumberstack()\n',
     '  File "<doctest>", line 8, in lumberstack\n    print repr(traceback.format_stack())\n']

This last example demonstrates the final few formatting functions:

    >>> import traceback
    >>> traceback.format_list([('spam.py', 3, '<module>', 'spam.eggs()'),
    ...                        ('eggs.py', 42, 'eggs', 'return "bacon"')])
    ['  File "spam.py", line 3, in <module>\n    spam.eggs()\n',
     '  File "eggs.py", line 42, in eggs\n    return "bacon"\n']
    >>> an_error = IndexError('tuple index out of range')
    >>> traceback.format_exception_only(type(an_error), an_error)
    ['IndexError: tuple index out of range\n']


File: python.info,  Node: __future__ — Future statement definitions,  Next: gc — Garbage Collector interface,  Prev: traceback — Print or retrieve a stack traceback,  Up: Python Runtime Services

5.28.11 `__future__' — Future statement definitions
-----------------------------------------------------

`Source code:' Lib/__future__.py(1)

__________________________________________________________________

*Note __future__: 1. is a real module, and serves three purposes:

   * To avoid confusing existing tools that analyze import statements
     and expect to find the modules they’re importing.

   * To ensure that *Note future statements: 853. run under releases
     prior to 2.1 at least yield runtime exceptions (the import of
     *Note __future__: 1. will fail, because there was no module of
     that name prior to 2.1).

   * To document when incompatible changes were introduced, and when
     they will be — or were — made mandatory.  This is a form of
     executable documentation, and can be inspected programmatically
     via importing *Note __future__: 1. and examining its contents.

Each statement in `__future__.py' is of the form:

    FeatureName = _Feature(OptionalRelease, MandatoryRelease,
                           CompilerFlag)

where, normally, `OptionalRelease' is less than `MandatoryRelease', and
both are 5-tuples of the same form as `sys.version_info':

    (PY_MAJOR_VERSION, # the 2 in 2.1.0a3; an int
     PY_MINOR_VERSION, # the 1; an int
     PY_MICRO_VERSION, # the 0; an int
     PY_RELEASE_LEVEL, # "alpha", "beta", "candidate" or "final"; string
     PY_RELEASE_SERIAL # the 3; an int
    )

`OptionalRelease' records the first release in which the feature was
accepted.

In the case of a `MandatoryRelease' that has not yet occurred,
`MandatoryRelease' predicts the release in which the feature will
become part of the language.

Else `MandatoryRelease' records when the feature became part of the
language; in releases at or after that, modules no longer need a future
statement to use the feature in question, but may continue to use such
imports.

`MandatoryRelease' may also be `None', meaning that a planned feature
got dropped.

Instances of class `_Feature' have two corresponding methods,
`getOptionalRelease()' and `getMandatoryRelease()'.

`CompilerFlag' is the (bitfield) flag that should be passed in the
fourth argument to the built-in function *Note compile(): 1fb. to
enable the feature in dynamically compiled code.  This flag is stored
in the `compiler_flag' attribute on `_Feature' instances.

No feature description will ever be deleted from *Note __future__: 1.
Since its introduction in Python 2.1 the following features have found
their way into the language using this mechanism:

feature                optional in       mandatory in       effect
-------------------------------------------------------------------------------------------------------------- 
nested_scopes          2.1.0b1           2.2                PEP 227(2): `Statically Nested Scopes'
generators             2.2.0a1           2.3                PEP 255(3): `Simple Generators'
division               2.2.0a2           3.0                PEP 238(4): `Changing the Division Operator'
absolute_import        2.5.0a1           3.0                PEP 328(5): `Imports: Multi-Line and
                                                            Absolute/Relative'
with_statement         2.5.0a1           2.6                PEP 343(6): `The “with” Statement'
print_function         2.6.0a2           3.0                PEP 3105(7): `Make print a function'
unicode_literals       2.6.0a2           3.0                PEP 3112(8): `Bytes literals in Python 3000'

See also
........

*Note Future statements: 853.
     How the compiler treats future imports.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/__future__.py

(2) https://www.python.org/dev/peps/pep-0227

(3) https://www.python.org/dev/peps/pep-0255

(4) https://www.python.org/dev/peps/pep-0238

(5) https://www.python.org/dev/peps/pep-0328

(6) https://www.python.org/dev/peps/pep-0343

(7) https://www.python.org/dev/peps/pep-3105

(8) https://www.python.org/dev/peps/pep-3112


File: python.info,  Node: gc — Garbage Collector interface,  Next: inspect — Inspect live objects,  Prev: __future__ — Future statement definitions,  Up: Python Runtime Services

5.28.12 `gc' — Garbage Collector interface
--------------------------------------------

This module provides an interface to the optional garbage collector.  It
provides the ability to disable the collector, tune the collection
frequency, and set debugging options.  It also provides access to
unreachable objects that the collector found but cannot free.  Since
the collector supplements the reference counting already used in
Python, you can disable the collector if you are sure your program does
not create reference cycles.  Automatic collection can be disabled by
calling `gc.disable()'.  To debug a leaking program call
`gc.set_debug(gc.DEBUG_LEAK)'. Notice that this includes
`gc.DEBUG_SAVEALL', causing garbage-collected objects to be saved in
gc.garbage for inspection.

The *Note gc: dc. module provides the following functions:

 -- Function: gc.enable ()
     Enable automatic garbage collection.

 -- Function: gc.disable ()
     Disable automatic garbage collection.

 -- Function: gc.isenabled ()
     Returns true if automatic collection is enabled.

 -- Function: gc.collect ([generation])
     With no arguments, run a full collection.  The optional argument
     `generation' may be an integer specifying which generation to
     collect (from 0 to 2).  A *Note ValueError: 236. is raised if the
     generation number  is invalid. The number of unreachable objects
     found is returned.

     Changed in version 2.5: The optional `generation' argument was
     added.

     Changed in version 2.6: The free lists maintained for a number of
     built-in types are cleared whenever a full collection or
     collection of the highest generation (2) is run.  Not all items in
     some free lists may be freed due to the particular implementation,
     in particular *Note int: 1f2. and *Note float: 1eb.


 -- Function: gc.set_debug (flags)
     Set the garbage collection debugging flags. Debugging information
     will be written to `sys.stderr'.  See below for a list of
     debugging flags which can be combined using bit operations to
     control debugging.

 -- Function: gc.get_debug ()
     Return the debugging flags currently set.

 -- Function: gc.get_objects ()
     Returns a list of all objects tracked by the collector, excluding
     the list returned.

     New in version 2.2.


 -- Function: gc.set_threshold (threshold0[, threshold1[, threshold2]])
     Set the garbage collection thresholds (the collection frequency).
     Setting `threshold0' to zero disables collection.

     The GC classifies objects into three generations depending on how
     many collection sweeps they have survived.  New objects are placed
     in the youngest generation (generation `0').  If an object
     survives a collection it is moved into the next older generation.
     Since generation `2' is the oldest generation, objects in that
     generation remain there after a collection.  In order to decide
     when to run, the collector keeps track of the number object
     allocations and deallocations since the last collection.  When the
     number of allocations minus the number of deallocations exceeds
     `threshold0', collection starts.  Initially only generation `0' is
     examined.  If generation `0' has been examined more than
     `threshold1' times since generation `1' has been examined, then
     generation `1' is examined as well.  Similarly, `threshold2'
     controls the number of collections of generation `1' before
     collecting generation `2'.

 -- Function: gc.get_count ()
     Return the current collection  counts as a tuple of `(count0,
     count1, count2)'.

     New in version 2.5.


 -- Function: gc.get_threshold ()
     Return the current collection thresholds as a tuple of
     `(threshold0, threshold1, threshold2)'.

 -- Function: gc.get_referrers (*objs)
     Return the list of objects that directly refer to any of objs.
     This function will only locate those containers which support
     garbage collection; extension types which do refer to other
     objects but do not support garbage collection will not be found.

     Note that objects which have already been dereferenced, but which
     live in cycles and have not yet been collected by the garbage
     collector can be listed among the resulting referrers.  To get
     only currently live objects, call *Note collect(): 3da.  before
     calling *Note get_referrers(): 24f0.

     Care must be taken when using objects returned by *Note
     get_referrers(): 24f0. because some of them could still be under
     construction and hence in a temporarily invalid state. Avoid using
     *Note get_referrers(): 24f0. for any purpose other than debugging.

     New in version 2.2.


 -- Function: gc.get_referents (*objs)
     Return a list of objects directly referred to by any of the
     arguments. The referents returned are those objects visited by the
     arguments’ C-level *Note tp_traverse: 24f2. methods (if any),
     and may not be all objects actually directly reachable.  *Note
     tp_traverse: 24f2. methods are supported only by objects that
     support garbage collection, and are only required to visit objects
     that may be involved in a cycle.  So, for example, if an integer
     is directly reachable from an argument, that integer object may or
     may not appear in the result list.

     New in version 2.3.


 -- Function: gc.is_tracked (obj)
     Returns `True' if the object is currently tracked by the garbage
     collector, `False' otherwise.  As a general rule, instances of
     atomic types aren’t tracked and instances of non-atomic types
     (containers, user-defined objects…) are.  However, some
     type-specific optimizations can be present in order to suppress
     the garbage collector footprint of simple instances (e.g. dicts
     containing only atomic keys and values):

         >>> gc.is_tracked(0)
         False
         >>> gc.is_tracked("a")
         False
         >>> gc.is_tracked([])
         True
         >>> gc.is_tracked({})
         False
         >>> gc.is_tracked({"a": 1})
         False
         >>> gc.is_tracked({"a": []})
         True

     New in version 2.7.


The following variable is provided for read-only access (you can mutate
its value but should not rebind it):

 -- Data: gc.garbage
     A list of objects which the collector found to be unreachable but
     could not be freed (uncollectable objects).  By default, this list
     contains only objects with *Note __del__(): 731. methods. (1)
     Objects that have *Note __del__(): 731. methods and are part of a
     reference cycle cause the entire reference cycle to be
     uncollectable, including objects not necessarily in the cycle but
     reachable only from it.  Python doesn’t collect such cycles
     automatically because, in general, it isn’t possible for Python
     to guess a safe order in which to run the *Note __del__(): 731.
     methods.  If you know a safe order, you can force the issue by
     examining the `garbage' list, and explicitly breaking cycles due
     to your objects within the list.  Note that these objects are kept
     alive even so by virtue of being in the `garbage' list, so they
     should be removed from `garbage' too.  For example, after breaking
     cycles, do `del gc.garbage[:]' to empty the list.  It’s
     generally better to avoid the issue by not creating cycles
     containing objects with *Note __del__(): 731. methods, and
     `garbage' can be examined in that case to verify that no such
     cycles are being created.

     If *Note DEBUG_SAVEALL: 24f4. is set, then all unreachable objects
     will be added to this list rather than freed.

The following constants are provided for use with *Note set_debug():
24ea.:

 -- Data: gc.DEBUG_STATS
     Print statistics during collection.  This information can be
     useful when tuning the collection frequency.

 -- Data: gc.DEBUG_COLLECTABLE
     Print information on collectable objects found.

 -- Data: gc.DEBUG_UNCOLLECTABLE
     Print information of uncollectable objects found (objects which
     are not reachable but cannot be freed by the collector).  These
     objects will be added to the `garbage' list.

 -- Data: gc.DEBUG_INSTANCES
     When *Note DEBUG_COLLECTABLE: 24f6. or *Note DEBUG_UNCOLLECTABLE:
     24f7. is set, print information about instance objects found.

 -- Data: gc.DEBUG_OBJECTS
     When *Note DEBUG_COLLECTABLE: 24f6. or *Note DEBUG_UNCOLLECTABLE:
     24f7. is set, print information about objects other than instance
     objects found.

 -- Data: gc.DEBUG_SAVEALL
     When set, all unreachable objects found will be appended to
     `garbage' rather than being freed.  This can be useful for
     debugging a leaking program.

 -- Data: gc.DEBUG_LEAK
     The debugging flags necessary for the collector to print
     information about a leaking program (equal to `DEBUG_COLLECTABLE |
     DEBUG_UNCOLLECTABLE | DEBUG_INSTANCES | DEBUG_OBJECTS |
     DEBUG_SAVEALL').

---------- Footnotes ----------

(1) Prior to Python 2.2, the list contained all instance objects in
unreachable cycles,  not only those with *Note __del__(): 731. methods.


File: python.info,  Node: inspect — Inspect live objects,  Next: site — Site-specific configuration hook,  Prev: gc — Garbage Collector interface,  Up: Python Runtime Services

5.28.13 `inspect' — Inspect live objects
------------------------------------------

New in version 2.1.

`Source code:' Lib/inspect.py(1)

__________________________________________________________________

The *Note inspect: f9. module provides several useful functions to help
get information about live objects such as modules, classes, methods,
functions, tracebacks, frame objects, and code objects.  For example,
it can help you examine the contents of a class, retrieve the source
code of a method, extract and format the argument list for a function,
or get all the information you need to display a detailed traceback.

There are four main kinds of services provided by this module: type
checking, getting source code, inspecting classes and functions, and
examining the interpreter stack.

* Menu:

* Types and members::
* Retrieving source code::
* Classes and functions: Classes and functions<2>.
* The interpreter stack::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/inspect.py


File: python.info,  Node: Types and members,  Next: Retrieving source code,  Up: inspect — Inspect live objects

5.28.13.1 Types and members
...........................

The *Note getmembers(): 24ff. function retrieves the members of an
object such as a class or module. The sixteen functions whose names
begin with “is” are mainly provided as convenient choices for the
second argument to *Note getmembers(): 24ff.  They also help you
determine when you can expect to find the following special attributes:

Type            Attribute             Description                     Notes
---------------------------------------------------------------------------------- 
module          __doc__               documentation string            
                __file__              filename (missing for built-in  
                                      modules)                        
class           __doc__               documentation string            
                __module__            name of module in which this    
                                      class was defined               
method          __doc__               documentation string            
                __name__              name with which this method     
                                      was defined                     
                im_class              class object that asked for     (1)
                                      this method                     
                im_func or __func__   function object containing      
                                      implementation of method        
                im_self or __self__   instance to which this method   
                                      is bound, or `None'             
function        __doc__               documentation string            
                __name__              name with which this function   
                                      was defined                     
                func_code             code object containing          
                                      compiled function *Note         
                                      bytecode: 59e.                  
                func_defaults         tuple of any default values     
                                      for arguments                   
                func_doc              (same as __doc__)               
                func_globals          global namespace in which this  
                                      function was defined            
                func_name             (same as __name__)              
generator       __iter__              defined to support iteration    
                                      over container                  
                close                 raises new GeneratorExit        
                                      exception inside the generator  
                                      to terminate the iteration      
                gi_code               code object                     
                gi_frame              frame object or possibly        
                                      `None' once the generator has   
                                      been exhausted                  
                gi_running            set to 1 when generator is      
                                      executing, 0 otherwise          
                next                  return the next item from the   
                                      container                       
                send                  resumes the generator and       
                                      “sends” a value that        
                                      becomes the result of the       
                                      current yield-expression        
                throw                 used to raise an exception      
                                      inside the generator            
traceback       tb_frame              frame object at this level      
                tb_lasti              index of last attempted         
                                      instruction in bytecode         
                tb_lineno             current line number in Python   
                                      source code                     
                tb_next               next inner traceback object     
                                      (called by this level)          
frame           f_back                next outer frame object (this   
                                      frame’s caller)               
                f_builtins            builtins namespace seen by      
                                      this frame                      
                f_code                code object being executed in   
                                      this frame                      
                f_exc_traceback       traceback if raised in this     
                                      frame, or `None'                
                f_exc_type            exception type if raised in     
                                      this frame, or `None'           
                f_exc_value           exception value if raised in    
                                      this frame, or `None'           
                f_globals             global namespace seen by this   
                                      frame                           
                f_lasti               index of last attempted         
                                      instruction in bytecode         
                f_lineno              current line number in Python   
                                      source code                     
                f_locals              local namespace seen by this    
                                      frame                           
                f_restricted          0 or 1 if frame is in           
                                      restricted execution mode       
                f_trace               tracing function for this       
                                      frame, or `None'                
code            co_argcount           number of arguments (not        
                                      including * or ** args)         
                co_code               string of raw compiled bytecode 
                co_consts             tuple of constants used in the  
                                      bytecode                        
                co_filename           name of file in which this      
                                      code object was created         
                co_firstlineno        number of first line in Python  
                                      source code                     
                co_flags              bitmap: 1=optimized `|'         
                                      2=newlocals `|' 4=*arg `|'      
                                      8=**arg                         
                co_lnotab             encoded mapping of line         
                                      numbers to bytecode indices     
                co_name               name with which this code       
                                      object was defined              
                co_names              tuple of names of local         
                                      variables                       
                co_nlocals            number of local variables       
                co_stacksize          virtual machine stack space     
                                      required                        
                co_varnames           tuple of names of arguments     
                                      and local variables             
builtin         __doc__               documentation string            
                __name__              original name of this function  
                                      or method                       
                __self__              instance to which a method is   
                                      bound, or `None'                

Note:

  1.  Changed in version 2.2: `im_class' used to refer to the class
     that defined the method.


 -- Function: inspect.getmembers (object[, predicate])
     Return all the members of an object in a list of (name, value)
     pairs sorted by name.  If the optional `predicate' argument is
     supplied, only members for which the predicate returns a true
     value are included.

          Note: *Note getmembers(): 24ff. does not return metaclass
          attributes when the argument is a class (this behavior is
          inherited from the *Note dir(): 34e. function).

 -- Function: inspect.getmoduleinfo (path)
     Return a tuple of values that describe how Python will interpret
     the file identified by `path' if it is a module, or `None' if it
     would not be identified as a module.  The return tuple is `(name,
     suffix, mode, module_type)', where `name' is the name of the
     module without the name of any enclosing package, `suffix' is the
     trailing part of the file name (which may not be a dot-delimited
     extension), `mode' is the *Note open(): 2d9. mode that would be
     used (`'r'' or `'rb''), and `module_type' is an integer giving the
     type of the module.  `module_type' will have a value which can be
     compared to the constants defined in the *Note imp: f6. module;
     see the documentation for that module for more information on
     module types.

     Changed in version 2.6: Returns a *Note named tuple: a4a.
     `ModuleInfo(name, suffix, mode, module_type)'.


 -- Function: inspect.getmodulename (path)
     Return the name of the module named by the file `path', without
     including the names of enclosing packages.  This uses the same
     algorithm as the interpreter uses when searching for modules.  If
     the name cannot be matched according to the interpreter’s rules,
     `None' is returned.

 -- Function: inspect.ismodule (object)
     Return true if the object is a module.

 -- Function: inspect.isclass (object)
     Return true if the object is a class, whether built-in or created
     in Python code.

 -- Function: inspect.ismethod (object)
     Return true if the object is a bound or unbound method written in
     Python.

 -- Function: inspect.isfunction (object)
     Return true if the object is a Python function, which includes
     functions created by a *Note lambda: 2506. expression.

 -- Function: inspect.isgeneratorfunction (object)
     Return true if the object is a Python generator function.

     New in version 2.6.


 -- Function: inspect.isgenerator (object)
     Return true if the object is a generator.

     New in version 2.6.


 -- Function: inspect.istraceback (object)
     Return true if the object is a traceback.

 -- Function: inspect.isframe (object)
     Return true if the object is a frame.

 -- Function: inspect.iscode (object)
     Return true if the object is a code.

 -- Function: inspect.isbuiltin (object)
     Return true if the object is a built-in function or a bound
     built-in method.

 -- Function: inspect.isroutine (object)
     Return true if the object is a user-defined or built-in function
     or method.

 -- Function: inspect.isabstract (object)
     Return true if the object is an abstract base class.

     New in version 2.6.


 -- Function: inspect.ismethoddescriptor (object)
     Return true if the object is a method descriptor, but not if *Note
     ismethod(): 2504, *Note isclass(): 2503, *Note isfunction(): 2505.
     or *Note isbuiltin(): 250c.  are true.

     This is new as of Python 2.2, and, for example, is true of
     `int.__add__'. An object passing this test has a *Note __get__():
     73b. method but not a *Note __set__(): 73c.  method, but beyond
     that the set of attributes varies.  A *Note __name__: 470.
     attribute is usually sensible, and `__doc__' often is.

     Methods implemented via descriptors that also pass one of the
     other tests return false from the *Note ismethoddescriptor():
     250f. test, simply because the other tests promise more – you
     can, e.g., count on having the `im_func' attribute (etc) when an
     object passes *Note ismethod(): 2504.

 -- Function: inspect.isdatadescriptor (object)
     Return true if the object is a data descriptor.

     Data descriptors have both a *Note __get__: 73b. and a *Note
     __set__: 73c. method.  Examples are properties (defined in
     Python), getsets, and members.  The latter two are defined in C
     and there are more specific tests available for those types, which
     is robust across Python implementations.  Typically, data
     descriptors will also have *Note __name__: 470. and `__doc__'
     attributes (properties, getsets, and members have both of these
     attributes), but this is not guaranteed.

     New in version 2.3.


 -- Function: inspect.isgetsetdescriptor (object)
     Return true if the object is a getset descriptor.

     `CPython implementation detail:' getsets are attributes defined in
     extension modules via `PyGetSetDef' structures.  For Python
     implementations without such types, this method will always return
     `False'.

     New in version 2.5.


 -- Function: inspect.ismemberdescriptor (object)
     Return true if the object is a member descriptor.

     `CPython implementation detail:' Member descriptors are attributes
     defined in extension modules via *Note PyMemberDef: 2c7.
     structures.  For Python implementations without such types, this
     method will always return `False'.

     New in version 2.5.



File: python.info,  Node: Retrieving source code,  Next: Classes and functions<2>,  Prev: Types and members,  Up: inspect — Inspect live objects

5.28.13.2 Retrieving source code
................................

 -- Function: inspect.getdoc (object)
     Get the documentation string for an object, cleaned up with *Note
     cleandoc(): 2516.

 -- Function: inspect.getcomments (object)
     Return in a single string any lines of comments immediately
     preceding the object’s source code (for a class, function, or
     method), or at the top of the Python source file (if the object is
     a module).

 -- Function: inspect.getfile (object)
     Return the name of the (text or binary) file in which an object
     was defined.  This will fail with a *Note TypeError: 218. if the
     object is a built-in module, class, or function.

 -- Function: inspect.getmodule (object)
     Try to guess which module an object was defined in.

 -- Function: inspect.getsourcefile (object)
     Return the name of the Python source file in which an object was
     defined.  This will fail with a *Note TypeError: 218. if the
     object is a built-in module, class, or function.

 -- Function: inspect.getsourcelines (object)
     Return a list of source lines and starting line number for an
     object. The argument may be a module, class, method, function,
     traceback, frame, or code object.  The source code is returned as
     a list of the lines corresponding to the object and the line
     number indicates where in the original source file the first line
     of code was found.  An *Note IOError: 1fa. is raised if the source
     code cannot be retrieved.

 -- Function: inspect.getsource (object)
     Return the text of the source code for an object. The argument may
     be a module, class, method, function, traceback, frame, or code
     object.  The source code is returned as a single string.  An *Note
     IOError: 1fa. is raised if the source code cannot be retrieved.

 -- Function: inspect.cleandoc (doc)
     Clean up indentation from docstrings that are indented to line up
     with blocks of code.

     All leading whitespace is removed from the first line.  Any
     leading whitespace that can be uniformly removed from the second
     line onwards is removed.  Empty lines at the beginning and end are
     subsequently removed.  Also, all tabs are expanded to spaces.

     New in version 2.6.



File: python.info,  Node: Classes and functions<2>,  Next: The interpreter stack,  Prev: Retrieving source code,  Up: inspect — Inspect live objects

5.28.13.3 Classes and functions
...............................

 -- Function: inspect.getclasstree (classes[, unique])
     Arrange the given list of classes into a hierarchy of nested
     lists. Where a nested list appears, it contains classes derived
     from the class whose entry immediately precedes the list.  Each
     entry is a 2-tuple containing a class and a tuple of its base
     classes.  If the `unique' argument is true, exactly one entry
     appears in the returned structure for each class in the given
     list.  Otherwise, classes using multiple inheritance and their
     descendants will appear multiple times.

 -- Function: inspect.getargspec (func)
     Get the names and default values of a Python function’s
     arguments. A tuple of four things is returned: `(args, varargs,
     keywords, defaults)'. `args' is a list of the argument names (it
     may contain nested lists). `varargs' and `keywords' are the names
     of the `*' and `**' arguments or `None'. `defaults' is a tuple of
     default argument values or `None' if there are no default
     arguments; if this tuple has `n' elements, they correspond to the
     last `n' elements listed in `args'.

     Changed in version 2.6: Returns a *Note named tuple: a4a.
     `ArgSpec(args, varargs, keywords, defaults)'.


 -- Function: inspect.getargvalues (frame)
     Get information about arguments passed into a particular frame. A
     tuple of four things is returned: `(args, varargs, keywords,
     locals)'. `args' is a list of the argument names (it may contain
     nested lists). `varargs' and `keywords' are the names of the `*'
     and `**' arguments or `None'.  `locals' is the locals dictionary
     of the given frame.

     Changed in version 2.6: Returns a *Note named tuple: a4a.
     `ArgInfo(args, varargs, keywords, locals)'.


 -- Function: inspect.formatargspec (args[, varargs, varkw, defaults,
          formatarg, formatvarargs, formatvarkw, formatvalue, join])
     Format a pretty argument spec from the four values returned by
     *Note getargspec(): 251f.  The format* arguments are the
     corresponding optional formatting functions that are called to
     turn names and values into strings.

 -- Function: inspect.formatargvalues (args[, varargs, varkw, locals,
          formatarg, formatvarargs, formatvarkw, formatvalue, join])
     Format a pretty argument spec from the four values returned by
     *Note getargvalues(): 2520.  The format* arguments are the
     corresponding optional formatting functions that are called to
     turn names and values into strings.

 -- Function: inspect.getmro (cls)
     Return a tuple of class cls’s base classes, including cls, in
     method resolution order.  No class appears more than once in this
     tuple. Note that the method resolution order depends on cls’s
     type.  Unless a very peculiar user-defined metatype is in use, cls
     will be the first element of the tuple.

 -- Function: inspect.getcallargs (func[, *args][, **kwds])
     Bind the `args' and `kwds' to the argument names of the Python
     function or method `func', as if it was called with them. For
     bound methods, bind also the first argument (typically named
     `self') to the associated instance. A dict is returned, mapping
     the argument names (including the names of the `*' and `**'
     arguments, if any) to their values from `args' and `kwds'. In case
     of invoking `func' incorrectly, i.e. whenever `func(*args,
     **kwds)' would raise an exception because of incompatible
     signature, an exception of the same type and the same or similar
     message is raised. For example:

         >>> from inspect import getcallargs
         >>> def f(a, b=1, *pos, **named):
         ...     pass
         >>> getcallargs(f, 1, 2, 3)
         {'a': 1, 'named': {}, 'b': 2, 'pos': (3,)}
         >>> getcallargs(f, a=2, x=4)
         {'a': 2, 'named': {'x': 4}, 'b': 1, 'pos': ()}
         >>> getcallargs(f)
         Traceback (most recent call last):
         ...
         TypeError: f() takes at least 1 argument (0 given)

     New in version 2.7.



File: python.info,  Node: The interpreter stack,  Prev: Classes and functions<2>,  Up: inspect — Inspect live objects

5.28.13.4 The interpreter stack
...............................

When the following functions return “frame records,” each record is
a tuple of six items: the frame object, the filename, the line number
of the current line, the function name, a list of lines of context from
the source code, and the index of the current line within that list.

     Note: Keeping references to frame objects, as found in the first
     element of the frame records these functions return, can cause
     your program to create reference cycles.  Once a reference cycle
     has been created, the lifespan of all objects which can be
     accessed from the objects which form the cycle can become much
     longer even if Python’s optional cycle detector is enabled.  If
     such cycles must be created, it is important to ensure they are
     explicitly broken to avoid the delayed destruction of objects and
     increased memory consumption which occurs.

     Though the cycle detector will catch these, destruction of the
     frames (and local variables) can be made deterministic by removing
     the cycle in a *Note finally: 3ae. clause.  This is also important
     if the cycle detector was disabled when Python was compiled or
     using *Note gc.disable(): 24e8.  For example:

         def handle_stackframe_without_leak():
             frame = inspect.currentframe()
             try:
                 # do something with the frame
             finally:
                 del frame

The optional `context' argument supported by most of these functions
specifies the number of lines of context to return, which are centered
around the current line.

 -- Function: inspect.getframeinfo (frame[, context])
     Get information about a frame or traceback object.  A 5-tuple is
     returned, the last five elements of the frame’s frame record.

     Changed in version 2.6: Returns a *Note named tuple: a4a.
     `Traceback(filename, lineno, function, code_context, index)'.


 -- Function: inspect.getouterframes (frame[, context])
     Get a list of frame records for a frame and all outer frames.
     These frames represent the calls that lead to the creation of
     `frame'. The first entry in the returned list represents `frame';
     the last entry represents the outermost call on `frame'’s stack.

 -- Function: inspect.getinnerframes (traceback[, context])
     Get a list of frame records for a traceback’s frame and all
     inner frames.  These frames represent calls made as a consequence
     of `frame'.  The first entry in the list represents `traceback';
     the last entry represents where the exception was raised.

 -- Function: inspect.currentframe ()
     Return the frame object for the caller’s stack frame.

     `CPython implementation detail:' This function relies on Python
     stack frame support in the interpreter, which isn’t guaranteed
     to exist in all implementations of Python.  If running in an
     implementation without Python stack frame support this function
     returns `None'.

 -- Function: inspect.stack ([context])
     Return a list of frame records for the caller’s stack.  The
     first entry in the returned list represents the caller; the last
     entry represents the outermost call on the stack.

 -- Function: inspect.trace ([context])
     Return a list of frame records for the stack between the current
     frame and the frame in which an exception currently being handled
     was raised in.  The first entry in the list represents the caller;
     the last entry represents where the exception was raised.


File: python.info,  Node: site — Site-specific configuration hook,  Next: user — User-specific configuration hook,  Prev: inspect — Inspect live objects,  Up: Python Runtime Services

5.28.14 `site' — Site-specific configuration hook
---------------------------------------------------

`Source code:' Lib/site.py(1)

__________________________________________________________________

`This module is automatically imported during initialization.' The
automatic import can be suppressed using the interpreter’s *Note -S:
66a. option.

Importing this module will append site-specific paths to the module
search path and add a few builtins.

It starts by constructing up to four directories from a head and a tail
part.  For the head part, it uses `sys.prefix' and `sys.exec_prefix';
empty heads are skipped.  For the tail part, it uses the empty string
and then `lib/site-packages' (on Windows) or
`lib/python`X.Y'/site-packages' and then `lib/site-python' (on Unix and
Macintosh).  For each of the distinct head-tail combinations, it sees
if it refers to an existing directory, and if so, adds it to `sys.path'
and also inspects the newly added path for configuration files.

A path configuration file is a file whose name has the form ``name'.pth'
and exists in one of the four directories mentioned above; its contents
are additional items (one per line) to be added to `sys.path'.
Non-existing items are never added to `sys.path', and no check is made
that the item refers to a directory rather than a file.  No item is
added to `sys.path' more than once.  Blank lines and lines beginning
with `#' are skipped.  Lines starting with `import' (followed by space
or tab) are executed.

Changed in version 2.6: A space or tab is now required after the import
keyword.

For example, suppose `sys.prefix' and `sys.exec_prefix' are set to
`/usr/local'.  The Python X.Y library is then installed in
`/usr/local/lib/python`X.Y''.  Suppose this has a subdirectory
`/usr/local/lib/python`X.Y'/site-packages' with three
subsubdirectories, `foo', `bar' and `spam', and two path configuration
files, `foo.pth' and `bar.pth'.  Assume `foo.pth' contains the
following:

    # foo package configuration

    foo
    bar
    bletch

and `bar.pth' contains:

    # bar package configuration

    bar

Then the following version-specific directories are added to
`sys.path', in this order:

    /usr/local/lib/pythonX.Y/site-packages/bar
    /usr/local/lib/pythonX.Y/site-packages/foo

Note that `bletch' is omitted because it doesn’t exist; the `bar'
directory precedes the `foo' directory because `bar.pth' comes
alphabetically before `foo.pth'; and `spam' is omitted because it is
not mentioned in either path configuration file.

After these path manipulations, an attempt is made to import a module
named `sitecustomize', which can perform arbitrary site-specific
customizations.  It is typically created by a system administrator in
the site-packages directory.  If this import fails with an *Note
ImportError: 388. exception, it is silently ignored.  If Python is
started without output streams available, as with `pythonw.exe' on
Windows (which is used by default to start IDLE), attempted output from
`sitecustomize' is ignored. Any exception other than *Note ImportError:
388. causes a silent and perhaps mysterious failure of the process.

After this, an attempt is made to import a module named `usercustomize',
which can perform arbitrary user-specific customizations, if *Note
ENABLE_USER_SITE: 252e. is true.  This file is intended to be created
in the user site-packages directory (see below), which is part of
`sys.path' unless disabled by *Note -s: 312.  An *Note ImportError:
388. will be silently ignored.

Note that for some non-Unix systems, `sys.prefix' and `sys.exec_prefix'
are empty, and the path manipulations are skipped; however the import of
`sitecustomize' and `usercustomize' is still attempted.

 -- Data: site.PREFIXES
     A list of prefixes for site-packages directories.

     New in version 2.6.


 -- Data: site.ENABLE_USER_SITE
     Flag showing the status of the user site-packages directory.
     `True' means that it is enabled and was added to `sys.path'.
     `False' means that it was disabled by user request (with *Note -s:
     312. or *Note PYTHONNOUSERSITE: 313.).  `None' means it was
     disabled for security reasons (mismatch between user or group id
     and effective id) or by an administrator.

     New in version 2.6.


 -- Data: site.USER_SITE
     Path to the user site-packages for the running Python.  Can be
     `None' if *Note getusersitepackages(): 24f. hasn’t been called
     yet.  Default value is `~/.local/lib/python`X.Y'/site-packages'
     for UNIX and non-framework Mac OS X builds,
     `~/Library/Python/`X.Y'/lib/python/site-packages' for Mac
     framework builds, and ``%APPDATA%'\Python\Python`XY'\site-packages'
     on Windows.  This directory is a site directory, which means that
     `.pth' files in it will be processed.

     New in version 2.6.


 -- Data: site.USER_BASE
     Path to the base directory for the user site-packages.  Can be
     `None' if *Note getuserbase(): 250. hasn’t been called yet.
     Default value is `~/.local' for UNIX and Mac OS X non-framework
     builds, `~/Library/Python/`X.Y'' for Mac framework builds, and
     ``%APPDATA%'\Python' for Windows.  This value is used by Distutils
     to compute the installation directories for scripts, data files,
     Python modules, etc. for the *Note user installation scheme: 67f.
     See also *Note PYTHONUSERBASE: 311.

     New in version 2.6.


 -- Function: site.addsitedir (sitedir, known_paths=None)
     Add a directory to sys.path and process its `.pth' files.
     Typically used in `sitecustomize' or `usercustomize' (see above).

 -- Function: site.getsitepackages ()
     Return a list containing all global site-packages directories (and
     possibly site-python).

     New in version 2.7.


 -- Function: site.getuserbase ()
     Return the path of the user base directory, *Note USER_BASE: 67e.
     If it is not initialized yet, this function will also set it,
     respecting *Note PYTHONUSERBASE: 311.

     New in version 2.7.


 -- Function: site.getusersitepackages ()
     Return the path of the user-specific site-packages directory,
     *Note USER_SITE: 669.  If it is not initialized yet, this function
     will also set it, respecting *Note PYTHONNOUSERSITE: 313. and
     *Note USER_BASE: 67e.

     New in version 2.7.


The *Note site: 158. module also provides a way to get the user
directories from the command line:

    $ python -m site --user-site
    /home/user/.local/lib/python2.7/site-packages

If it is called without arguments, it will print the contents of *Note
sys.path: 59a. on the standard output, followed by the value of *Note
USER_BASE: 67e. and whether the directory exists, then the same thing
for *Note USER_SITE: 669, and finally the value of *Note
ENABLE_USER_SITE: 252e.

 -- Program Option: --user-base
     Print the path to the user base directory.

 -- Program Option: --user-site
     Print the path to the user site-packages directory.

If both options are given, user base and user site will be printed
(always in this order), separated by *Note os.pathsep: 678.

If any option is given, the script will exit with one of these values:
`O' if the user site-packages directory is enabled, `1' if it was
disabled by the user, `2' if it is disabled for security reasons or by
an administrator, and a value greater than 2 if there is an error.

See also
........

PEP 370(2) – Per user site-packages directory

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/site.py

(2) https://www.python.org/dev/peps/pep-0370


File: python.info,  Node: user — User-specific configuration hook,  Next: fpectl — Floating point exception control,  Prev: site — Site-specific configuration hook,  Up: Python Runtime Services

5.28.15 `user' — User-specific configuration hook
---------------------------------------------------

Deprecated since version 2.6: The *Note user: 18b. module has been
removed in Python 3.

As a policy, Python doesn’t run user-specified code on startup of
Python programs.  (Only interactive sessions execute the script
specified in the *Note PYTHONSTARTUP: 63b. environment variable if it
exists).

However, some programs or sites may find it convenient to allow users
to have a standard customization file, which gets run when a program
requests it.  This module implements such a mechanism.  A program that
wishes to use the mechanism must execute the statement

    import user

The *Note user: 18b. module looks for a file `.pythonrc.py' in the
user’s home directory and if it can be opened, executes it (using
*Note execfile(): 44f.) in its own (the module *Note user: 18b.’s)
global namespace.  Errors during this phase are not caught; that’s up
to the program that imports the *Note user: 18b. module, if it wishes.
The home directory is assumed to be named by the `HOME' environment
variable; if this is not set, the current directory is used.

The user’s `.pythonrc.py' could conceivably test for `sys.version' if
it wishes to do different things depending on the Python version.

A warning to users: be very conservative in what you place in your
`.pythonrc.py' file.  Since you don’t know which programs will use it,
changing the behavior of standard modules or functions is generally not
a good idea.

A suggestion for programmers who wish to use this mechanism: a simple
way to let users specify options for your package is to have them
define variables in their `.pythonrc.py' file that you test in your
module.  For example, a module `spam' that has a verbosity level can
look for a variable `user.spam_verbose', as follows:

    import user

    verbose = bool(getattr(user, "spam_verbose", 0))

(The three-argument form of *Note getattr(): 89d. is used in case the
user has not defined `spam_verbose' in their `.pythonrc.py' file.)

Programs with extensive customization needs are better off reading a
program-specific customization file.

Programs with security or privacy concerns should `not' import this
module; a user can easily break into a program by placing arbitrary
code in the `.pythonrc.py' file.

Modules for general use should `not' import this module; it may
interfere with the operation of the importing program.

See also
........

Module *Note site: 158.
     Site-wide customization mechanism.


File: python.info,  Node: fpectl — Floating point exception control,  Prev: user — User-specific configuration hook,  Up: Python Runtime Services

5.28.16 `fpectl' — Floating point exception control
-----------------------------------------------------

     Note: The *Note fpectl: d5. module is not built by default, and
     its usage is discouraged and may be dangerous except in the hands
     of experts.  See also the section *Note Limitations and other
     considerations: 2537. on limitations for more details.

Most computers carry out floating point operations in conformance with
the so-called IEEE-754 standard. On any real computer, some floating
point operations produce results that cannot be expressed as a normal
floating point value. For example, try

    >>> import math
    >>> math.exp(1000)
    inf
    >>> math.exp(1000) / math.exp(1000)
    nan

(The example above will work on many platforms. DEC Alpha may be one
exception.)  “Inf” is a special, non-numeric value in IEEE-754 that
stands for “infinity”, and “nan” means “not a number.” Note
that, other than the non-numeric results, nothing special happened when
you asked Python to carry out those calculations.  That is in fact the
default behaviour prescribed in the IEEE-754 standard, and if it works
for you, stop reading now.

In some circumstances, it would be better to raise an exception and stop
processing at the point where the faulty operation was attempted. The
*Note fpectl: d5. module is for use in that situation. It provides
control over floating point units from several hardware manufacturers,
allowing the user to turn on the generation of `SIGFPE' whenever any of
the IEEE-754 exceptions Division by Zero, Overflow, or Invalid
Operation occurs. In tandem with a pair of wrapper macros that are
inserted into the C code comprising your python system, `SIGFPE' is
trapped and converted into the Python *Note FloatingPointError: 2538.
exception.

The *Note fpectl: d5. module defines the following functions and may
raise the given exception:

 -- Function: fpectl.turnon_sigfpe ()
     Turn on the generation of `SIGFPE', and set up an appropriate
     signal handler.

 -- Function: fpectl.turnoff_sigfpe ()
     Reset default handling of floating point exceptions.

 -- Exception: fpectl.FloatingPointError
     After *Note turnon_sigfpe(): 2539. has been executed, a floating
     point operation that raises one of the IEEE-754 exceptions
     Division by Zero, Overflow, or Invalid operation will in turn
     raise this standard Python exception.

* Menu:

* Example: Example<14>.
* Limitations and other considerations::


File: python.info,  Node: Example<14>,  Next: Limitations and other considerations,  Up: fpectl — Floating point exception control

5.28.16.1 Example
.................

The following example demonstrates how to start up and test operation
of the *Note fpectl: d5. module.

    >>> import fpectl
    >>> import fpetest
    >>> fpectl.turnon_sigfpe()
    >>> fpetest.test()
    overflow        PASS
    FloatingPointError: Overflow

    div by 0        PASS
    FloatingPointError: Division by zero
      [ more output from test elided ]
    >>> import math
    >>> math.exp(1000)
    Traceback (most recent call last):
      File "<stdin>", line 1, in ?
    FloatingPointError: in math_1


File: python.info,  Node: Limitations and other considerations,  Prev: Example<14>,  Up: fpectl — Floating point exception control

5.28.16.2 Limitations and other considerations
..............................................

Setting up a given processor to trap IEEE-754 floating point errors
currently requires custom code on a per-architecture basis. You may
have to modify *Note fpectl: d5. to control your particular hardware.

Conversion of an IEEE-754 exception to a Python exception requires that
the wrapper macros `PyFPE_START_PROTECT' and `PyFPE_END_PROTECT' be
inserted into your code in an appropriate fashion.  Python itself has
been modified to support the *Note fpectl: d5. module, but many other
codes of interest to numerical analysts have not.

The *Note fpectl: d5. module is not thread-safe.

See also
........

Some files in the source distribution may be interesting in learning
more about how this module operates. The include file
Include/pyfpe.h(1) discusses the implementation of this module at some
length. Modules/fpetestmodule.c(2) gives several examples of use. Many
additional examples can be found in Objects/floatobject.c(3).

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Include/pyfpe.h

(2) https://hg.python.org/cpython/file/2.7/Modules/fpetestmodule.c

(3) https://hg.python.org/cpython/file/2.7/Objects/floatobject.c


File: python.info,  Node: Custom Python Interpreters,  Next: Restricted Execution,  Prev: Python Runtime Services,  Up: The Python Standard Library

5.29 Custom Python Interpreters
===============================

The modules described in this chapter allow writing interfaces similar
to Python’s interactive interpreter.  If you want a Python
interpreter that supports some special feature in addition to the
Python language, you should look at the *Note code: 62. module.  (The
*Note codeop: 64. module is lower-level, used to support compiling a
possibly-incomplete chunk of Python code.)

The full list of modules described in this chapter is:

* Menu:

* code — Interpreter base classes::
* codeop — Compile Python code::


File: python.info,  Node: code — Interpreter base classes,  Next: codeop — Compile Python code,  Up: Custom Python Interpreters

5.29.1 `code' — Interpreter base classes
------------------------------------------

The `code' module provides facilities to implement read-eval-print
loops in Python.  Two classes and convenience functions are included
which can be used to build applications which provide an interactive
interpreter prompt.

 -- Class: code.InteractiveInterpreter ([locals])
     This class deals with parsing and interpreter state (the user’s
     namespace); it does not deal with input buffering or prompting or
     input file naming (the filename is always passed in explicitly).
     The optional `locals' argument specifies the dictionary in which
     code will be executed; it defaults to a newly created dictionary
     with key `'__name__'' set to `'__console__'' and key `'__doc__''
     set to `None'.

 -- Class: code.InteractiveConsole ([locals[, filename]])
     Closely emulate the behavior of the interactive Python
     interpreter. This class builds on *Note InteractiveInterpreter:
     2543. and adds prompting using the familiar `sys.ps1' and
     `sys.ps2', and input buffering.

 -- Function: code.interact ([banner[, readfunc[, local]]])
     Convenience function to run a read-eval-print loop.  This creates
     a new instance of *Note InteractiveConsole: 1719. and sets
     `readfunc' to be used as the *Note InteractiveConsole.raw_input():
     2545. method, if provided.  If `local' is provided, it is passed
     to the *Note InteractiveConsole: 1719. constructor for use as the
     default namespace for the interpreter loop.  The *Note interact():
     2544.  method of the instance is then run with `banner' passed as
     the banner to use, if provided.  The console object is discarded
     after use.

 -- Function: code.compile_command (source[, filename[, symbol]])
     This function is useful for programs that want to emulate
     Python’s interpreter main loop (a.k.a. the read-eval-print
     loop).  The tricky part is to determine when the user has entered
     an incomplete command that can be completed by entering more text
     (as opposed to a complete command or a syntax error).  This
     function `almost' always makes the same decision as the real
     interpreter main loop.

     `source' is the source string; `filename' is the optional filename
     from which source was read, defaulting to `'<input>''; and
     `symbol' is the optional grammar start symbol, which should be
     either `'single'' (the default) or `'eval''.

     Returns a code object (the same as `compile(source, filename,
     symbol)') if the command is complete and valid; `None' if the
     command is incomplete; raises *Note SyntaxError: 4b4. if the
     command is complete and contains a syntax error, or raises *Note
     OverflowError: 2dd. or *Note ValueError: 236. if the command
     contains an invalid literal.

* Menu:

* Interactive Interpreter Objects::
* Interactive Console Objects::


File: python.info,  Node: Interactive Interpreter Objects,  Next: Interactive Console Objects,  Up: code — Interpreter base classes

5.29.1.1 Interactive Interpreter Objects
........................................

 -- Method: InteractiveInterpreter.runsource (source[, filename[,
          symbol]])
     Compile and run some source in the interpreter. Arguments are the
     same as for *Note compile_command(): 2546.; the default for
     `filename' is `'<input>'', and for `symbol' is `'single''.  One
     several things can happen:

        * The input is incorrect; *Note compile_command(): 2546. raised
          an exception (*Note SyntaxError: 4b4. or *Note OverflowError:
          2dd.).  A syntax traceback will be printed by calling the
          *Note showsyntaxerror(): 254a. method.  *Note runsource():
          2549.  returns `False'.

        * The input is incomplete, and more input is required; *Note
          compile_command(): 2546.  returned `None'. *Note runsource():
          2549. returns `True'.

        * The input is complete; *Note compile_command(): 2546.
          returned a code object.  The code is executed by calling the
          *Note runcode(): 254b. (which also handles run-time
          exceptions, except for *Note SystemExit: 346.). *Note
          runsource(): 2549. returns `False'.

     The return value can be used to decide whether to use `sys.ps1' or
     `sys.ps2' to prompt the next line.

 -- Method: InteractiveInterpreter.runcode (code)
     Execute a code object. When an exception occurs, *Note
     showtraceback(): 254c. is called to display a traceback.  All
     exceptions are caught except *Note SystemExit: 346, which is
     allowed to propagate.

     A note about *Note KeyboardInterrupt: 251.: this exception may
     occur elsewhere in this code, and may not always be caught.  The
     caller should be prepared to deal with it.

 -- Method: InteractiveInterpreter.showsyntaxerror ([filename])
     Display the syntax error that just occurred.  This does not
     display a stack trace because there isn’t one for syntax errors.
     If `filename' is given, it is stuffed into the exception instead
     of the default filename provided by Python’s parser, because it
     always uses `'<string>'' when reading from a string. The output is
     written by the *Note write(): 254d. method.

 -- Method: InteractiveInterpreter.showtraceback ()
     Display the exception that just occurred.  We remove the first
     stack item because it is within the interpreter object
     implementation. The output is written by the *Note write(): 254d.
     method.

 -- Method: InteractiveInterpreter.write (data)
     Write a string to the standard error stream (`sys.stderr').
     Derived classes should override this to provide the appropriate
     output handling as needed.


File: python.info,  Node: Interactive Console Objects,  Prev: Interactive Interpreter Objects,  Up: code — Interpreter base classes

5.29.1.2 Interactive Console Objects
....................................

The *Note InteractiveConsole: 1719. class is a subclass of *Note
InteractiveInterpreter: 2543, and so offers all the methods of the
interpreter objects as well as the following additions.

 -- Method: InteractiveConsole.interact ([banner])
     Closely emulate the interactive Python console. The optional
     banner argument specify the banner to print before the first
     interaction; by default it prints a banner similar to the one
     printed by the standard Python interpreter, followed by the class
     name of the console object in parentheses (so as not to confuse
     this with the real interpreter – since it’s so close!).

 -- Method: InteractiveConsole.push (line)
     Push a line of source text to the interpreter. The line should not
     have a trailing newline; it may have internal newlines.  The line
     is appended to a buffer and the interpreter’s `runsource()'
     method is called with the concatenated contents of the buffer as
     source.  If this indicates that the command was executed or
     invalid, the buffer is reset; otherwise, the command is
     incomplete, and the buffer is left as it was after the line was
     appended.  The return value is `True' if more input is required,
     `False' if the line was dealt with in some way (this is the same
     as `runsource()').

 -- Method: InteractiveConsole.resetbuffer ()
     Remove any unhandled source text from the input buffer.

 -- Method: InteractiveConsole.raw_input ([prompt])
     Write a prompt and read a line.  The returned line does not
     include the trailing newline.  When the user enters the EOF key
     sequence, *Note EOFError: 8b3. is raised.  The base implementation
     uses the built-in function *Note raw_input(): 891.; a subclass may
     replace this with a different implementation.


File: python.info,  Node: codeop — Compile Python code,  Prev: code — Interpreter base classes,  Up: Custom Python Interpreters

5.29.2 `codeop' — Compile Python code
---------------------------------------

The *Note codeop: 64. module provides utilities upon which the Python
read-eval-print loop can be emulated, as is done in the *Note code: 62.
module.  As a result, you probably don’t want to use the module
directly; if you want to include such a loop in your program you
probably want to use the *Note code: 62.  module instead.

There are two parts to this job:

  1. Being able to tell if a line of input completes a Python
     statement: in short, telling whether to print ‘`>>>'’ or
     ‘`...'’ next.

  2. Remembering which future statements the user has entered, so
     subsequent input can be compiled with these in effect.

The *Note codeop: 64. module provides a way of doing each of these
things, and a way of doing them both.

To do just the former:

 -- Function: codeop.compile_command (source[, filename[, symbol]])
     Tries to compile `source', which should be a string of Python code
     and return a code object if `source' is valid Python code. In that
     case, the filename attribute of the code object will be
     `filename', which defaults to `'<input>''. Returns `None' if
     `source' is `not' valid Python code, but is a prefix of valid
     Python code.

     If there is a problem with `source', an exception will be raised.
     *Note SyntaxError: 4b4. is raised if there is invalid Python
     syntax, and *Note OverflowError: 2dd. or *Note ValueError: 236. if
     there is an invalid literal.

     The `symbol' argument determines whether `source' is compiled as a
     statement (`'single'', the default) or as an *Note expression:
     247d. (`'eval'').  Any other value will cause *Note ValueError:
     236. to  be raised.

          Note: It is possible (but not likely) that the parser stops
          parsing with a successful outcome before reaching the end of
          the source; in this case, trailing symbols may be ignored
          instead of causing an error.  For example, a backslash
          followed by two newlines may be followed by arbitrary garbage.
          This will be fixed once the API for the parser is better.

 -- Class: codeop.Compile
     Instances of this class have *Note __call__(): 725. methods
     identical in signature to the built-in function *Note compile():
     1fb, but with the difference that if the instance compiles program
     text containing a *Note __future__: 1. statement, the instance
     ‘remembers’ and compiles all subsequent program texts with the
     statement in force.

 -- Class: codeop.CommandCompiler
     Instances of this class have *Note __call__(): 725. methods
     identical in signature to *Note compile_command(): 2555.; the
     difference is that if the instance compiles program text
     containing a `__future__' statement, the instance ‘remembers’
     and compiles all subsequent program texts with the statement in
     force.

A note on version compatibility: the *Note Compile: 2556. and *Note
CommandCompiler: 2557. are new in Python 2.2.  If you want to enable the
future-tracking features of 2.2 but also retain compatibility with 2.1
and earlier versions of Python you can either write

    try:
        from codeop import CommandCompiler
        compile_command = CommandCompiler()
        del CommandCompiler
    except ImportError:
        from codeop import compile_command

which is a low-impact change, but introduces possibly unwanted global
state into your program, or you can write:

    try:
        from codeop import CommandCompiler
    except ImportError:
        def CommandCompiler():
            from codeop import compile_command
            return compile_command

and then call `CommandCompiler' every time you need a fresh compiler
object.


File: python.info,  Node: Restricted Execution,  Next: Importing Modules,  Prev: Custom Python Interpreters,  Up: The Python Standard Library

5.30 Restricted Execution
=========================

     Warning: In Python 2.3 these modules have been disabled due to
     various known and not readily fixable security holes.  The modules
     are still documented here to help in reading old code that uses
     the *Note rexec: 147. and *Note Bastion: 17. modules.

`Restricted execution' is the basic framework in Python that allows for
the segregation of trusted and untrusted code.  The framework is based
on the notion that trusted Python code (a `supervisor') can create a
“padded cell’ (or environment) with limited permissions, and run
the untrusted code within this cell.  The untrusted code cannot break
out of its cell, and can only interact with sensitive system resources
through interfaces defined and managed by the trusted code.  The term
“restricted execution” is favored over “safe-Python” since true
safety is hard to define, and is determined by the way the restricted
environment is created.  Note that the restricted environments can be
nested, with inner cells creating subcells of lesser, but never
greater, privilege.

An interesting aspect of Python’s restricted execution model is that
the interfaces presented to untrusted code usually have the same names
as those presented to trusted code.  Therefore no special interfaces
need to be learned to write code designed to run in a restricted
environment.  And because the exact nature of the padded cell is
determined by the supervisor, different restrictions can be imposed,
depending on the application.  For example, it might be deemed
“safe” for untrusted code to read any file within a specified
directory, but never to write a file.  In this case, the supervisor may
redefine the built-in *Note open(): 2d9. function so that it raises an
exception whenever the `mode' parameter is `'w''.  It might also
perform a `chroot()'-like operation on the `filename' parameter, such
that root is always relative to some safe “sandbox” area of the
filesystem.  In this case, the untrusted code would still see a
built-in *Note open(): 2d9. function in its environment, with the same
calling interface.  The semantics would be identical too, with *Note
IOError: 1fa.s being raised when the supervisor determined that an
unallowable parameter is being used.

The Python run-time determines whether a particular code block is
executing in restricted execution mode based on the identity of the
`__builtins__' object in its global variables: if this is (the
dictionary of) the standard *Note __builtin__: 0. module, the code is
deemed to be unrestricted, else it is deemed to be restricted.

Python code executing in restricted mode faces a number of limitations
that are designed to prevent it from escaping from the padded cell. For
instance, the function object attribute `func_globals' and the class
and instance object attribute *Note __dict__: 4a0. are unavailable.

Two modules provide the framework for setting up restricted execution
environments:

* Menu:

* rexec — Restricted execution framework::
* Bastion — Restricting access to objects::


File: python.info,  Node: rexec — Restricted execution framework,  Next: Bastion — Restricting access to objects,  Up: Restricted Execution

5.30.1 `rexec' — Restricted execution framework
-------------------------------------------------

Deprecated since version 2.6: The *Note rexec: 147. module has been
removed in Python 3.

Changed in version 2.3: Disabled module.

     Warning: The documentation has been left in place to help in
     reading old code that uses the module.

This module contains the *Note RExec: 255d. class, which supports
`r_eval()', `r_execfile()', `r_exec()', and `r_import()' methods, which
are restricted versions of the standard Python functions *Note eval():
378, *Note execfile(): 44f. and the *Note exec: 41d. and *Note import:
1f4. statements. Code executed in this restricted environment will only
have access to modules and functions that are deemed safe; you can
subclass *Note RExec: 255d. to add or remove capabilities as desired.

     Warning: While the *Note rexec: 147. module is designed to perform
     as described below, it does have a few known vulnerabilities which
     could be exploited by carefully written code.  Thus it should not
     be relied upon in situations requiring “production ready”
     security.  In such situations, execution via sub-processes or very
     careful “cleansing” of both code and data to be processed may
     be necessary.  Alternatively, help in patching known *Note rexec:
     147. vulnerabilities would be welcomed.

     Note: The *Note RExec: 255d. class can prevent code from
     performing unsafe operations like reading or writing disk files,
     or using TCP/IP sockets.  However, it does not protect against
     code using extremely large amounts of memory or processor time.

 -- Class: rexec.RExec ([hooks[, verbose]])
     Returns an instance of the *Note RExec: 255d. class.

     `hooks' is an instance of the `RHooks' class or a subclass of it.
     If it is omitted or `None', the default `RHooks' class is
     instantiated.  Whenever the *Note rexec: 147. module searches for
     a module (even a built-in one) or reads a module’s code, it
     doesn’t actually go out to the file system itself.  Rather, it
     calls methods of an `RHooks' instance that was passed to or
     created by its constructor.  (Actually, the *Note RExec: 255d.
     object doesn’t make these calls — they are made by a module
     loader object that’s part of the *Note RExec: 255d. object.
     This allows another level of flexibility, which can be useful when
     changing the mechanics of *Note import: 1f4. within the restricted
     environment.)

     By providing an alternate `RHooks' object, we can control the file
     system accesses made to import a module, without changing the
     actual algorithm that controls the order in which those accesses
     are made.  For instance, we could substitute an `RHooks' object
     that passes all filesystem requests to a file server elsewhere,
     via some RPC mechanism such as ILU.  Grail’s applet loader uses
     this to support importing applets from a URL for a directory.

     If `verbose' is true, additional debugging output may be sent to
     standard output.

It is important to be aware that code running in a restricted
environment can still call the *Note sys.exit(): 2aa. function.  To
disallow restricted code from exiting the interpreter, always protect
calls that cause restricted code to run with a *Note try: 3ad./*Note
except: 3af. statement that catches the *Note SystemExit: 346.
exception.  Removing the *Note sys.exit(): 2aa. function from the
restricted environment is not sufficient — the restricted code could
still use `raise SystemExit'.  Removing *Note SystemExit: 346. is not a
reasonable option; some library code makes use of this and would break
were it not available.

See also
........

Grail Home Page(1)
     Grail is a Web browser written entirely in Python.  It uses the
     *Note rexec: 147.  module as a foundation for supporting Python
     applets, and can be used as an example usage of this module.

* Menu:

* RExec Objects::
* Defining restricted environments::
* An example::

---------- Footnotes ----------

(1) http://grail.sourceforge.net/


File: python.info,  Node: RExec Objects,  Next: Defining restricted environments,  Up: rexec — Restricted execution framework

5.30.1.1 RExec Objects
......................

*Note RExec: 255d. instances support the following methods:

 -- Method: RExec.r_eval (code)
     `code' must either be a string containing a Python expression, or
     a compiled code object, which will be evaluated in the restricted
     environment’s *Note __main__: 2. module.  The value of the
     expression or code object will be returned.

 -- Method: RExec.r_exec (code)
     `code' must either be a string containing one or more lines of
     Python code, or a compiled code object, which will be executed in
     the restricted environment’s *Note __main__: 2. module.

 -- Method: RExec.r_execfile (filename)
     Execute the Python code contained in the file `filename' in the
     restricted environment’s *Note __main__: 2. module.

Methods whose names begin with `s_' are similar to the functions
beginning with `r_', but the code will be granted access to restricted
versions of the standard I/O streams `sys.stdin', `sys.stderr', and
`sys.stdout'.

 -- Method: RExec.s_eval (code)
     `code' must be a string containing a Python expression, which will
     be evaluated in the restricted environment.

 -- Method: RExec.s_exec (code)
     `code' must be a string containing one or more lines of Python
     code, which will be executed in the restricted environment.

 -- Method: RExec.s_execfile (code)
     Execute the Python code contained in the file `filename' in the
     restricted environment.

*Note RExec: 255d. objects must also support various methods which will
be implicitly called by code executing in the restricted environment.
Overriding these methods in a subclass is used to change the policies
enforced by a restricted environment.

 -- Method: RExec.r_import (modulename[, globals[, locals[, fromlist]]])
     Import the module `modulename', raising an *Note ImportError: 388.
     exception if the module is considered unsafe.

 -- Method: RExec.r_open (filename[, mode[, bufsize]])
     Method called when *Note open(): 2d9. is called in the restricted
     environment.  The arguments are identical to those of *Note
     open(): 2d9, and a file object (or a class instance compatible
     with file objects) should be returned.  *Note RExec: 255d.’s
     default behaviour is allow opening any file for reading, but
     forbidding any attempt to write a file.  See the example below for
     an implementation of a less restrictive *Note r_open(): 2567.

 -- Method: RExec.r_reload (module)
     Reload the module object `module', re-parsing and re-initializing
     it.

 -- Method: RExec.r_unload (module)
     Unload the module object `module' (remove it from the restricted
     environment’s `sys.modules' dictionary).

And their equivalents with access to restricted standard I/O streams:

 -- Method: RExec.s_import (modulename[, globals[, locals[, fromlist]]])
     Import the module `modulename', raising an *Note ImportError: 388.
     exception if the module is considered unsafe.

 -- Method: RExec.s_reload (module)
     Reload the module object `module', re-parsing and re-initializing
     it.

 -- Method: RExec.s_unload (module)
     Unload the module object `module'.


