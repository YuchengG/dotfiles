This is python.info, produced by makeinfo version 4.8 from python.texi.

Generated by Sphinx 1.6.3.
INFO-DIR-SECTION Python
START-INFO-DIR-ENTRY
* Python: (python.info). The Python reference manual.
END-INFO-DIR-ENTRY

     Python 2.7.13, July 15, 2017

     Copyright (C) 1990-2017, Python Software Foundation


File: python.info,  Node: Subclassing Repr Objects,  Prev: Repr Objects,  Up: repr — Alternate repr implementation

5.8.19.2 Subclassing Repr Objects
.................................

The use of dynamic dispatching by *Note Repr.repr1(): c88. allows
subclasses of *Note Repr: c77. to add support for additional built-in
object types or to modify the handling of types already supported. This
example shows how special support for file objects could be added:

    import repr as reprlib
    import sys

    class MyRepr(reprlib.Repr):
        def repr_file(self, obj, level):
            if obj.name in ['<stdin>', '<stdout>', '<stderr>']:
                return obj.name
            else:
                return repr(obj)

    aRepr = MyRepr()
    print aRepr.repr(sys.stdin)          # prints '<stdin>'


File: python.info,  Node: Numeric and Mathematical Modules,  Next: File and Directory Access,  Prev: Data Types,  Up: The Python Standard Library

5.9 Numeric and Mathematical Modules
====================================

The modules described in this chapter provide numeric and math-related
functions and data types. The *Note numbers: 126. module defines an
abstract hierarchy of numeric types. The *Note math: 10d. and *Note
cmath: 60. modules contain various mathematical functions for
floating-point and complex numbers. For users more interested in
decimal accuracy than in speed, the *Note decimal: 80. module supports
exact representations of decimal numbers.

The following modules are documented in this chapter:

* Menu:

* numbers — Numeric abstract base classes::
* math — Mathematical functions::
* cmath — Mathematical functions for complex numbers::
* decimal — Decimal fixed point and floating point arithmetic::
* fractions — Rational numbers::
* random — Generate pseudo-random numbers::
* itertools — Functions creating iterators for efficient looping::
* functools — Higher-order functions and operations on callable objects::
* operator — Standard operators as functions::


File: python.info,  Node: numbers — Numeric abstract base classes,  Next: math — Mathematical functions,  Up: Numeric and Mathematical Modules

5.9.1 `numbers' — Numeric abstract base classes
-------------------------------------------------

New in version 2.6.

The *Note numbers: 126. module ( PEP 3141(1)) defines a hierarchy of
numeric *Note abstract base classes: 8af. which progressively define
more operations.  None of the types defined in this module can be
instantiated.

 -- Class: numbers.Number
     The root of the numeric hierarchy. If you just want to check if an
     argument `x' is a number, without caring what kind, use
     `isinstance(x, Number)'.

* Menu:

* The numeric tower::
* Notes for type implementors::

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-3141


File: python.info,  Node: The numeric tower,  Next: Notes for type implementors,  Up: numbers — Numeric abstract base classes

5.9.1.1 The numeric tower
.........................

 -- Class: numbers.Complex
     Subclasses of this type describe complex numbers and include the
     operations that work on the built-in *Note complex: 1ec. type.
     These are: conversions to *Note complex: 1ec. and *Note bool: 455,
     *Note real: c91, *Note imag: c92, `+', `-', `*', `/', *Note abs():
     5da, *Note conjugate(): c93, `==', and `!='. All except `-' and
     `!=' are abstract.

      -- Attribute: real
          Abstract. Retrieves the real component of this number.

      -- Attribute: imag
          Abstract. Retrieves the imaginary component of this number.

      -- Method: conjugate ()
          Abstract. Returns the complex conjugate. For example,
          `(1+3j).conjugate() == (1-3j)'.

 -- Class: numbers.Real
     To *Note Complex: 71d, *Note Real: 71c. adds the operations that
     work on real numbers.

     In short, those are: a conversion to *Note float: 1eb, *Note
     math.trunc(): 341, *Note round(): 1c7, *Note math.floor(): 33f,
     *Note math.ceil(): 340, *Note divmod(): 768, `//', `%', `<', `<=',
     `>', and `>='.

     Real also provides defaults for *Note complex(): 1ec, *Note real:
     c91, *Note imag: c92, and *Note conjugate(): c93.

 -- Class: numbers.Rational
     Subtypes *Note Real: 71c. and adds *Note numerator: c94. and *Note
     denominator: c95. properties, which should be in lowest terms.
     With these, it provides a default for *Note float(): 1eb.

      -- Attribute: numerator
          Abstract.

      -- Attribute: denominator
          Abstract.

 -- Class: numbers.Integral
     Subtypes *Note Rational: 33e. and adds a conversion to *Note int:
     1f2.  Provides defaults for *Note float(): 1eb, *Note numerator:
     c94, and *Note denominator: c95.  Adds abstract methods for `**'
     and bit-string operations: `<<', `>>', `&', `^', `|', `~'.


File: python.info,  Node: Notes for type implementors,  Prev: The numeric tower,  Up: numbers — Numeric abstract base classes

5.9.1.2 Notes for type implementors
...................................

Implementors should be careful to make equal numbers equal and hash
them to the same values. This may be subtle if there are two different
extensions of the real numbers. For example, *Note fractions.Fraction:
217.  implements *Note hash(): 733. as follows:

    def __hash__(self):
        if self.denominator == 1:
            # Get integers right.
            return hash(self.numerator)
        # Expensive check, but definitely correct.
        if self == float(self):
            return hash(float(self))
        else:
            # Use tuple's hash to avoid a high collision rate on
            # simple fractions.
            return hash((self.numerator, self.denominator))

* Menu:

* Adding More Numeric ABCs::
* Implementing the arithmetic operations::


File: python.info,  Node: Adding More Numeric ABCs,  Next: Implementing the arithmetic operations,  Up: Notes for type implementors

5.9.1.3 Adding More Numeric ABCs
................................

There are, of course, more possible ABCs for numbers, and this would be
a poor hierarchy if it precluded the possibility of adding those. You
can add `MyFoo' between *Note Complex: 71d. and *Note Real: 71c. with:

    class MyFoo(Complex): ...
    MyFoo.register(Real)


File: python.info,  Node: Implementing the arithmetic operations,  Prev: Adding More Numeric ABCs,  Up: Notes for type implementors

5.9.1.4 Implementing the arithmetic operations
..............................................

We want to implement the arithmetic operations so that mixed-mode
operations either call an implementation whose author knew about the
types of both arguments, or convert both to the nearest built in type
and do the operation there. For subtypes of *Note Integral: 71b, this
means that *Note __add__(): 74e. and *Note __radd__(): 74f. should be
defined as:

    class MyIntegral(Integral):

        def __add__(self, other):
            if isinstance(other, MyIntegral):
                return do_my_adding_stuff(self, other)
            elif isinstance(other, OtherTypeIKnowAbout):
                return do_my_other_adding_stuff(self, other)
            else:
                return NotImplemented

        def __radd__(self, other):
            if isinstance(other, MyIntegral):
                return do_my_adding_stuff(other, self)
            elif isinstance(other, OtherTypeIKnowAbout):
                return do_my_other_adding_stuff(other, self)
            elif isinstance(other, Integral):
                return int(other) + int(self)
            elif isinstance(other, Real):
                return float(other) + float(self)
            elif isinstance(other, Complex):
                return complex(other) + complex(self)
            else:
                return NotImplemented

There are 5 different cases for a mixed-type operation on subclasses of
*Note Complex: 71d. I’ll refer to all of the above code that doesn’t
refer to `MyIntegral' and `OtherTypeIKnowAbout' as “boilerplate”.
`a' will be an instance of `A', which is a subtype of *Note Complex:
71d. (`a : A <: Complex'), and `b : B <: Complex'. I’ll consider `a +
b':

       1. If `A' defines an *Note __add__(): 74e. which accepts `b',
          all is well.

       2. If `A' falls back to the boilerplate code, and it were to
          return a value from *Note __add__(): 74e, we’d miss the
          possibility that `B' defines a more intelligent *Note
          __radd__(): 74f, so the boilerplate should return *Note
          NotImplemented: 20e. from *Note __add__(): 74e. (Or `A' may
          not implement *Note __add__(): 74e. at all.)

       3. Then `B'’s *Note __radd__(): 74f. gets a chance. If it
          accepts `a', all is well.

       4. If it falls back to the boilerplate, there are no more
          possible methods to try, so this is where the default
          implementation should live.

       5. If `B <: A', Python tries `B.__radd__' before `A.__add__'.
          This is ok, because it was implemented with knowledge of `A',
          so it can handle those instances before delegating to *Note
          Complex: 71d.

If `A <: Complex' and `B <: Real' without sharing any other knowledge,
then the appropriate shared operation is the one involving the built in
*Note complex: 1ec, and both *Note __radd__(): 74f. s land there, so
`a+b == b+a'.

Because most of the operations on any given type will be very similar,
it can be useful to define a helper function which generates the
forward and reverse instances of any given operator. For example, *Note
fractions.Fraction: 217. uses:

    def _operator_fallbacks(monomorphic_operator, fallback_operator):
        def forward(a, b):
            if isinstance(b, (int, long, Fraction)):
                return monomorphic_operator(a, b)
            elif isinstance(b, float):
                return fallback_operator(float(a), b)
            elif isinstance(b, complex):
                return fallback_operator(complex(a), b)
            else:
                return NotImplemented
        forward.__name__ = '__' + fallback_operator.__name__ + '__'
        forward.__doc__ = monomorphic_operator.__doc__

        def reverse(b, a):
            if isinstance(a, Rational):
                # Includes ints.
                return monomorphic_operator(a, b)
            elif isinstance(a, numbers.Real):
                return fallback_operator(float(a), float(b))
            elif isinstance(a, numbers.Complex):
                return fallback_operator(complex(a), complex(b))
            else:
                return NotImplemented
        reverse.__name__ = '__r' + fallback_operator.__name__ + '__'
        reverse.__doc__ = monomorphic_operator.__doc__

        return forward, reverse

    def _add(a, b):
        """a + b"""
        return Fraction(a.numerator * b.denominator +
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __add__, __radd__ = _operator_fallbacks(_add, operator.add)

    # ...


File: python.info,  Node: math — Mathematical functions,  Next: cmath — Mathematical functions for complex numbers,  Prev: numbers — Numeric abstract base classes,  Up: Numeric and Mathematical Modules

5.9.2 `math' — Mathematical functions
---------------------------------------

This module is always available.  It provides access to the mathematical
functions defined by the C standard.

These functions cannot be used with complex numbers; use the functions
of the same name from the *Note cmath: 60. module if you require
support for complex numbers.  The distinction between functions which
support complex numbers and those which don’t is made since most
users do not want to learn quite as much mathematics as required to
understand complex numbers.  Receiving an exception instead of a
complex result allows earlier detection of the unexpected complex
number used as a parameter, so that the programmer can determine how
and why it was generated in the first place.

The following functions are provided by this module.  Except when
explicitly noted otherwise, all return values are floats.

* Menu:

* Number-theoretic and representation functions::
* Power and logarithmic functions::
* Trigonometric functions::
* Angular conversion::
* Hyperbolic functions::
* Special functions::
* Constants::


File: python.info,  Node: Number-theoretic and representation functions,  Next: Power and logarithmic functions,  Up: math — Mathematical functions

5.9.2.1 Number-theoretic and representation functions
.....................................................

 -- Function: math.ceil (x)
     Return the ceiling of `x' as a float, the smallest integer value
     greater than or equal to `x'.

 -- Function: math.copysign (x, y)
     Return `x' with the sign of `y'.  On a platform that supports
     signed zeros, `copysign(1.0, -0.0)' returns `-1.0'.

     New in version 2.6.


 -- Function: math.fabs (x)
     Return the absolute value of `x'.

 -- Function: math.factorial (x)
     Return `x' factorial.  Raises *Note ValueError: 236. if `x' is not
     integral or is negative.

     New in version 2.6.


 -- Function: math.floor (x)
     Return the floor of `x' as a float, the largest integer value less
     than or equal to `x'.

 -- Function: math.fmod (x, y)
     Return `fmod(x, y)', as defined by the platform C library. Note
     that the Python expression `x % y' may not return the same result.
     The intent of the C standard is that `fmod(x, y)' be exactly
     (mathematically; to infinite precision) equal to `x - n*y' for
     some integer `n' such that the result has the same sign as `x' and
     magnitude less than `abs(y)'.  Python’s `x % y' returns a result
     with the sign of `y' instead, and may not be exactly computable
     for float arguments. For example, `fmod(-1e-100, 1e100)' is
     `-1e-100', but the result of Python’s `-1e-100 % 1e100' is
     `1e100-1e-100', which cannot be represented exactly as a float,
     and rounds to the surprising `1e100'.  For this reason, function
     *Note fmod(): 7fb. is generally preferred when working with
     floats, while Python’s `x % y' is preferred when working with
     integers.

 -- Function: math.frexp (x)
     Return the mantissa and exponent of `x' as the pair `(m, e)'.  `m'
     is a float and `e' is an integer such that `x == m * 2**e'
     exactly. If `x' is zero, returns `(0.0, 0)', otherwise `0.5 <=
     abs(m) < 1'.  This is used to “pick apart” the internal
     representation of a float in a portable way.

 -- Function: math.fsum (iterable)
     Return an accurate floating point sum of values in the iterable.
     Avoids loss of precision by tracking multiple intermediate partial
     sums:

         >>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
         0.9999999999999999
         >>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
         1.0

     The algorithm’s accuracy depends on IEEE-754 arithmetic
     guarantees and the typical case where the rounding mode is
     half-even.  On some non-Windows builds, the underlying C library
     uses extended precision addition and may occasionally double-round
     an intermediate sum causing it to be off in its least significant
     bit.

     For further discussion and two alternative approaches, see the
     ASPN cookbook recipes for accurate floating point summation(1).

     New in version 2.6.


 -- Function: math.isinf (x)
     Check if the float `x' is positive or negative infinity.

     New in version 2.6.


 -- Function: math.isnan (x)
     Check if the float `x' is a NaN (not a number).  For more
     information on NaNs, see the IEEE 754 standards.

     New in version 2.6.


 -- Function: math.ldexp (x, i)
     Return `x * (2**i)'.  This is essentially the inverse of function
     *Note frexp(): c9d.

 -- Function: math.modf (x)
     Return the fractional and integer parts of `x'.  Both results
     carry the sign of `x' and are floats.

 -- Function: math.trunc (x)
     Return the *Note Real: 71c. value `x' truncated to an *Note
     Integral: 71b. (usually a long integer).  Uses the `__trunc__'
     method.

     New in version 2.6.


Note that *Note frexp(): c9d. and *Note modf(): c9f. have a different
call/return pattern than their C equivalents: they take a single
argument and return a pair of values, rather than returning their
second return value through an ‘output parameter’ (there is no such
thing in Python).

For the *Note ceil(): 340, *Note floor(): 33f, and *Note modf(): c9f.
functions, note that `all' floating-point numbers of sufficiently large
magnitude are exact integers.  Python floats typically carry no more
than 53 bits of precision (the same as the platform C double type), in
which case any float `x' with `abs(x) >= 2**52' necessarily has no
fractional bits.

---------- Footnotes ----------

(1) https://code.activestate.com/recipes/393090/


File: python.info,  Node: Power and logarithmic functions,  Next: Trigonometric functions,  Prev: Number-theoretic and representation functions,  Up: math — Mathematical functions

5.9.2.2 Power and logarithmic functions
.......................................

 -- Function: math.exp (x)
     Return `e**x'.

 -- Function: math.expm1 (x)
     Return `e**x - 1'.  For small floats `x', the subtraction in
     `exp(x) - 1' can result in a significant loss of precision; the
     *Note expm1(): 23b. function provides a way to compute this
     quantity to full precision:

         >>> from math import exp, expm1
         >>> exp(1e-5) - 1  # gives result accurate to 11 places
         1.0000050000069649e-05
         >>> expm1(1e-5)    # result accurate to full precision
         1.0000050000166668e-05

     New in version 2.7.


 -- Function: math.log (x[, base])
     With one argument, return the natural logarithm of `x' (to base
     `e').

     With two arguments, return the logarithm of `x' to the given
     `base', calculated as `log(x)/log(base)'.

     Changed in version 2.3: `base' argument added.


 -- Function: math.log1p (x)
     Return the natural logarithm of `1+x' (base `e'). The result is
     calculated in a way which is accurate for `x' near zero.

     New in version 2.6.


 -- Function: math.log10 (x)
     Return the base-10 logarithm of `x'.  This is usually more accurate
     than `log(x, 10)'.

 -- Function: math.pow (x, y)
     Return `x' raised to the power `y'.  Exceptional cases follow
     Annex ‘F’ of the C99 standard as far as possible.  In
     particular, `pow(1.0, x)' and `pow(x, 0.0)' always return `1.0',
     even when `x' is a zero or a NaN.  If both `x' and `y' are finite,
     `x' is negative, and `y' is not an integer then `pow(x, y)' is
     undefined, and raises *Note ValueError: 236.

     Unlike the built-in `**' operator, *Note math.pow(): ca2. converts
     both its arguments to type *Note float: 1eb.  Use `**' or the
     built-in *Note pow(): 4d1. function for computing exact integer
     powers.

     Changed in version 2.6: The outcome of `1**nan' and `nan**0' was
     undefined.


 -- Function: math.sqrt (x)
     Return the square root of `x'.


File: python.info,  Node: Trigonometric functions,  Next: Angular conversion,  Prev: Power and logarithmic functions,  Up: math — Mathematical functions

5.9.2.3 Trigonometric functions
...............................

 -- Function: math.acos (x)
     Return the arc cosine of `x', in radians.

 -- Function: math.asin (x)
     Return the arc sine of `x', in radians.

 -- Function: math.atan (x)
     Return the arc tangent of `x', in radians.

 -- Function: math.atan2 (y, x)
     Return `atan(y / x)', in radians. The result is between `-pi' and
     `pi'.  The vector in the plane from the origin to point `(x, y)'
     makes this angle with the positive X axis. The point of *Note
     atan2(): ca8. is that the signs of both inputs are known to it, so
     it can compute the correct quadrant for the angle.  For example,
     `atan(1)' and `atan2(1, 1)' are both `pi/4', but `atan2(-1, -1)'
     is `-3*pi/4'.

 -- Function: math.cos (x)
     Return the cosine of `x' radians.

 -- Function: math.hypot (x, y)
     Return the Euclidean norm, `sqrt(x*x + y*y)'. This is the length
     of the vector from the origin to point `(x, y)'.

 -- Function: math.sin (x)
     Return the sine of `x' radians.

 -- Function: math.tan (x)
     Return the tangent of `x' radians.


File: python.info,  Node: Angular conversion,  Next: Hyperbolic functions,  Prev: Trigonometric functions,  Up: math — Mathematical functions

5.9.2.4 Angular conversion
..........................

 -- Function: math.degrees (x)
     Convert angle `x' from radians to degrees.

 -- Function: math.radians (x)
     Convert angle `x' from degrees to radians.


File: python.info,  Node: Hyperbolic functions,  Next: Special functions,  Prev: Angular conversion,  Up: math — Mathematical functions

5.9.2.5 Hyperbolic functions
............................

 -- Function: math.acosh (x)
     Return the inverse hyperbolic cosine of `x'.

     New in version 2.6.


 -- Function: math.asinh (x)
     Return the inverse hyperbolic sine of `x'.

     New in version 2.6.


 -- Function: math.atanh (x)
     Return the inverse hyperbolic tangent of `x'.

     New in version 2.6.


 -- Function: math.cosh (x)
     Return the hyperbolic cosine of `x'.

 -- Function: math.sinh (x)
     Return the hyperbolic sine of `x'.

 -- Function: math.tanh (x)
     Return the hyperbolic tangent of `x'.


File: python.info,  Node: Special functions,  Next: Constants,  Prev: Hyperbolic functions,  Up: math — Mathematical functions

5.9.2.6 Special functions
.........................

 -- Function: math.erf (x)
     Return the error function at `x'.

     New in version 2.7.


 -- Function: math.erfc (x)
     Return the complementary error function at `x'.

     New in version 2.7.


 -- Function: math.gamma (x)
     Return the Gamma function at `x'.

     New in version 2.7.


 -- Function: math.lgamma (x)
     Return the natural logarithm of the absolute value of the Gamma
     function at `x'.

     New in version 2.7.



File: python.info,  Node: Constants,  Prev: Special functions,  Up: math — Mathematical functions

5.9.2.7 Constants
.................

 -- Data: math.pi
     The mathematical constant π = 3.141592…, to available precision.

 -- Data: math.e
     The mathematical constant e = 2.718281…, to available precision.

`CPython implementation detail:' The *Note math: 10d. module consists
mostly of thin wrappers around the platform C math library functions.
Behavior in exceptional cases follows Annex F of the C99 standard where
appropriate.  The current implementation will raise *Note ValueError:
236. for invalid operations like `sqrt(-1.0)' or `log(0.0)' (where C99
Annex F recommends signaling invalid operation or divide-by-zero), and
*Note OverflowError: 2dd. for results that overflow (for example,
`exp(1000.0)').  A NaN will not be returned from any of the functions
above unless one or more of the input arguments was a NaN; in that case,
most functions will return a NaN, but (again following C99 Annex F)
there are some exceptions to this rule, for example `pow(float('nan'),
0.0)' or `hypot(float('nan'), float('inf'))'.

Note that Python makes no effort to distinguish signaling NaNs from
quiet NaNs, and behavior for signaling NaNs remains unspecified.
Typical behavior is to treat all NaNs as though they were quiet.

Changed in version 2.6: Behavior in special cases now aims to follow
C99 Annex F.  In earlier versions of Python the behavior in special
cases was loosely specified.

See also
........

Module *Note cmath: 60.
     Complex number versions of many of these functions.


File: python.info,  Node: cmath — Mathematical functions for complex numbers,  Next: decimal — Decimal fixed point and floating point arithmetic,  Prev: math — Mathematical functions,  Up: Numeric and Mathematical Modules

5.9.3 `cmath' — Mathematical functions for complex numbers
------------------------------------------------------------

This module is always available.  It provides access to mathematical
functions for complex numbers.  The functions in this module accept
integers, floating-point numbers or complex numbers as arguments. They
will also accept any Python object that has either a *Note
__complex__(): 2fa. or a *Note __float__(): 785.  method: these methods
are used to convert the object to a complex or floating-point number,
respectively, and the function is then applied to the result of the
conversion.

     Note: On platforms with hardware and system-level support for
     signed zeros, functions involving branch cuts are continuous on
     `both' sides of the branch cut: the sign of the zero distinguishes
     one side of the branch cut from the other.  On platforms that do
     not support signed zeros the continuity is as specified below.

* Menu:

* Conversions to and from polar coordinates::
* Power and logarithmic functions: Power and logarithmic functions<2>.
* Trigonometric functions: Trigonometric functions<2>.
* Hyperbolic functions: Hyperbolic functions<2>.
* Classification functions::
* Constants: Constants<2>.


File: python.info,  Node: Conversions to and from polar coordinates,  Next: Power and logarithmic functions<2>,  Up: cmath — Mathematical functions for complex numbers

5.9.3.1 Conversions to and from polar coordinates
.................................................

A Python complex number `z' is stored internally using `rectangular' or
`Cartesian' coordinates.  It is completely determined by its `real
part' `z.real' and its `imaginary part' `z.imag'.  In other words:

    z == z.real + z.imag*1j

`Polar coordinates' give an alternative way to represent a complex
number.  In polar coordinates, a complex number `z' is defined by the
modulus `r' and the phase angle `phi'. The modulus `r' is the distance
from `z' to the origin, while the phase `phi' is the counterclockwise
angle, measured in radians, from the positive x-axis to the line
segment that joins the origin to `z'.

The following functions can be used to convert from the native
rectangular coordinates to polar coordinates and back.

 -- Function: cmath.phase (x)
     Return the phase of `x' (also known as the `argument' of `x'), as a
     float.  `phase(x)' is equivalent to `math.atan2(x.imag, x.real)'.
     The result lies in the range [-π, π], and the branch cut for
     this operation lies along the negative real axis, continuous from
     above.  On systems with support for signed zeros (which includes
     most systems in current use), this means that the sign of the
     result is the same as the sign of `x.imag', even when `x.imag' is
     zero:

         >>> phase(complex(-1.0, 0.0))
         3.1415926535897931
         >>> phase(complex(-1.0, -0.0))
         -3.1415926535897931

     New in version 2.6.


     Note: The modulus (absolute value) of a complex number `x' can be
     computed using the built-in *Note abs(): 5da. function.  There is
     no separate *Note cmath: 60. module function for this operation.

 -- Function: cmath.polar (x)
     Return the representation of `x' in polar coordinates.  Returns a
     pair `(r, phi)' where `r' is the modulus of `x' and phi is the
     phase of `x'.  `polar(x)' is equivalent to `(abs(x), phase(x))'.

     New in version 2.6.


 -- Function: cmath.rect (r, phi)
     Return the complex number `x' with polar coordinates `r' and `phi'.
     Equivalent to `r * (math.cos(phi) + math.sin(phi)*1j)'.

     New in version 2.6.



File: python.info,  Node: Power and logarithmic functions<2>,  Next: Trigonometric functions<2>,  Prev: Conversions to and from polar coordinates,  Up: cmath — Mathematical functions for complex numbers

5.9.3.2 Power and logarithmic functions
.......................................

 -- Function: cmath.exp (x)
     Return the exponential value `e**x'.

 -- Function: cmath.log (x[, base])
     Returns the logarithm of `x' to the given `base'. If the `base' is
     not specified, returns the natural logarithm of `x'. There is one
     branch cut, from 0 along the negative real axis to -∞,
     continuous from above.

     Changed in version 2.4: `base' argument added.


 -- Function: cmath.log10 (x)
     Return the base-10 logarithm of `x'. This has the same branch cut
     as *Note log(): cbe.

 -- Function: cmath.sqrt (x)
     Return the square root of `x'. This has the same branch cut as
     *Note log(): cbe.


File: python.info,  Node: Trigonometric functions<2>,  Next: Hyperbolic functions<2>,  Prev: Power and logarithmic functions<2>,  Up: cmath — Mathematical functions for complex numbers

5.9.3.3 Trigonometric functions
...............................

 -- Function: cmath.acos (x)
     Return the arc cosine of `x'. There are two branch cuts: One
     extends right from 1 along the real axis to ∞, continuous from
     below. The other extends left from -1 along the real axis to -∞,
     continuous from above.

 -- Function: cmath.asin (x)
     Return the arc sine of `x'. This has the same branch cuts as *Note
     acos(): cc2.

 -- Function: cmath.atan (x)
     Return the arc tangent of `x'. There are two branch cuts: One
     extends from `1j' along the imaginary axis to `∞j', continuous
     from the right. The other extends from `-1j' along the imaginary
     axis to `-∞j', continuous from the left.

     Changed in version 2.6: direction of continuity of upper cut
     reversed


 -- Function: cmath.cos (x)
     Return the cosine of `x'.

 -- Function: cmath.sin (x)
     Return the sine of `x'.

 -- Function: cmath.tan (x)
     Return the tangent of `x'.


File: python.info,  Node: Hyperbolic functions<2>,  Next: Classification functions,  Prev: Trigonometric functions<2>,  Up: cmath — Mathematical functions for complex numbers

5.9.3.4 Hyperbolic functions
............................

 -- Function: cmath.acosh (x)
     Return the inverse hyperbolic cosine of `x'. There is one branch
     cut, extending left from 1 along the real axis to -∞, continuous
     from above.

 -- Function: cmath.asinh (x)
     Return the inverse hyperbolic sine of `x'. There are two branch
     cuts: One extends from `1j' along the imaginary axis to `∞j',
     continuous from the right.  The other extends from `-1j' along the
     imaginary axis to `-∞j', continuous from the left.

     Changed in version 2.6: branch cuts moved to match those
     recommended by the C99 standard


 -- Function: cmath.atanh (x)
     Return the inverse hyperbolic tangent of `x'. There are two branch
     cuts: One extends from `1' along the real axis to `∞',
     continuous from below. The other extends from `-1' along the real
     axis to `-∞', continuous from above.

     Changed in version 2.6: direction of continuity of right cut
     reversed


 -- Function: cmath.cosh (x)
     Return the hyperbolic cosine of `x'.

 -- Function: cmath.sinh (x)
     Return the hyperbolic sine of `x'.

 -- Function: cmath.tanh (x)
     Return the hyperbolic tangent of `x'.


File: python.info,  Node: Classification functions,  Next: Constants<2>,  Prev: Hyperbolic functions<2>,  Up: cmath — Mathematical functions for complex numbers

5.9.3.5 Classification functions
................................

 -- Function: cmath.isinf (x)
     Return `True' if the real or the imaginary part of x is positive
     or negative infinity.

     New in version 2.6.


 -- Function: cmath.isnan (x)
     Return `True' if the real or imaginary part of x is not a number
     (NaN).

     New in version 2.6.



File: python.info,  Node: Constants<2>,  Prev: Classification functions,  Up: cmath — Mathematical functions for complex numbers

5.9.3.6 Constants
.................

 -- Data: cmath.pi
     The mathematical constant `π', as a float.

 -- Data: cmath.e
     The mathematical constant `e', as a float.

Note that the selection of functions is similar, but not identical, to
that in module *Note math: 10d.  The reason for having two modules is
that some users aren’t interested in complex numbers, and perhaps
don’t even know what they are.  They would rather have
`math.sqrt(-1)' raise an exception than return a complex number. Also
note that the functions defined in *Note cmath: 60. always return a
complex number, even if the answer can be expressed as a real number
(in which case the complex number has an imaginary part of zero).

A note on branch cuts: They are curves along which the given function
fails to be continuous.  They are a necessary feature of many complex
functions.  It is assumed that if you need to compute with complex
functions, you will understand about branch cuts.  Consult almost any
(not too elementary) book on complex variables for enlightenment.  For
information of the proper choice of branch cuts for numerical purposes,
a good reference should be the following:

See also
........

Kahan, W:  Branch cuts for complex elementary functions; or, Much ado
about nothing’s sign bit.  In Iserles, A., and Powell, M. (eds.), The
state of the art in numerical analysis. Clarendon Press (1987)
pp165–211.


File: python.info,  Node: decimal — Decimal fixed point and floating point arithmetic,  Next: fractions — Rational numbers,  Prev: cmath — Mathematical functions for complex numbers,  Up: Numeric and Mathematical Modules

5.9.4 `decimal' — Decimal fixed point and floating point arithmetic
---------------------------------------------------------------------

New in version 2.4.

The *Note decimal: 80. module provides support for decimal floating
point arithmetic.  It offers several advantages over the *Note float:
1eb. datatype:

   * Decimal “is based on a floating-point model which was designed
     with people in mind, and necessarily has a paramount guiding
     principle – computers must provide an arithmetic that works in
     the same way as the arithmetic that people learn at school.” –
     excerpt from the decimal arithmetic specification.

   * Decimal numbers can be represented exactly.  In contrast, numbers
     like `1.1' and `2.2' do not have exact representations in binary
     floating point.  End users typically would not expect `1.1 + 2.2'
     to display as `3.3000000000000003' as it does with binary floating
     point.

   * The exactness carries over into arithmetic.  In decimal floating
     point, `0.1 + 0.1 + 0.1 - 0.3' is exactly equal to zero.  In
     binary floating point, the result is `5.5511151231257827e-017'.
     While near to zero, the differences prevent reliable equality
     testing and differences can accumulate. For this reason, decimal
     is preferred in accounting applications which have strict equality
     invariants.

   * The decimal module incorporates a notion of significant places so
     that `1.30 + 1.20' is `2.50'.  The trailing zero is kept to
     indicate significance.  This is the customary presentation for
     monetary applications. For multiplication, the “schoolbook”
     approach uses all the figures in the multiplicands.  For instance,
     `1.3 * 1.2' gives `1.56' while `1.30 * 1.20' gives `1.5600'.

   * Unlike hardware based binary floating point, the decimal module
     has a user alterable precision (defaulting to 28 places) which can
     be as large as needed for a given problem:

         >>> from decimal import *
         >>> getcontext().prec = 6
         >>> Decimal(1) / Decimal(7)
         Decimal('0.142857')
         >>> getcontext().prec = 28
         >>> Decimal(1) / Decimal(7)
         Decimal('0.1428571428571428571428571429')

   * Both binary and decimal floating point are implemented in terms of
     published standards.  While the built-in float type exposes only a
     modest portion of its capabilities, the decimal module exposes all
     required parts of the standard.  When needed, the programmer has
     full control over rounding and signal handling.  This includes an
     option to enforce exact arithmetic by using exceptions to block
     any inexact operations.

   * The decimal module was designed to support “without prejudice,
     both exact unrounded decimal arithmetic (sometimes called
     fixed-point arithmetic) and rounded floating-point arithmetic.”
     – excerpt from the decimal arithmetic specification.

The module design is centered around three concepts:  the decimal
number, the context for arithmetic, and signals.

A decimal number is immutable.  It has a sign, coefficient digits, and
an exponent.  To preserve significance, the coefficient digits do not
truncate trailing zeros.  Decimals also include special values such as
`Infinity', `-Infinity', and `NaN'.  The standard also differentiates
`-0' from `+0'.

The context for arithmetic is an environment specifying precision,
rounding rules, limits on exponents, flags indicating the results of
operations, and trap enablers which determine whether signals are
treated as exceptions.  Rounding options include `ROUND_CEILING',
`ROUND_DOWN', `ROUND_FLOOR', `ROUND_HALF_DOWN', `ROUND_HALF_EVEN',
`ROUND_HALF_UP', `ROUND_UP', and `ROUND_05UP'.

Signals are groups of exceptional conditions arising during the course
of computation.  Depending on the needs of the application, signals may
be ignored, considered as informational, or treated as exceptions. The
signals in the decimal module are: *Note Clamped: cd7, *Note
InvalidOperation: 2de, *Note DivisionByZero: cd8, *Note Inexact: cd9,
*Note Rounded: cda, *Note Subnormal: cdb, *Note Overflow: cdc, and
*Note Underflow: cdd.

For each signal there is a flag and a trap enabler.  When a signal is
encountered, its flag is set to one, then, if the trap enabler is set
to one, an exception is raised.  Flags are sticky, so the user needs to
reset them before monitoring a calculation.

See also
........

   * IBM’s General Decimal Arithmetic Specification, The General
     Decimal Arithmetic Specification(1).

* Menu:

* Quick-start Tutorial::
* Decimal objects::
* Context objects::
* Signals::
* Floating Point Notes::
* Working with threads::
* Recipes::
* Decimal FAQ::

---------- Footnotes ----------

(1) http://speleotrove.com/decimal/


File: python.info,  Node: Quick-start Tutorial,  Next: Decimal objects,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.1 Quick-start Tutorial
............................

The usual start to using decimals is importing the module, viewing the
current context with *Note getcontext(): ce0. and, if necessary,
setting new values for precision, rounding, or enabled traps:

    >>> from decimal import *
    >>> getcontext()
    Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
            capitals=1, flags=[], traps=[Overflow, DivisionByZero,
            InvalidOperation])

    >>> getcontext().prec = 7       # Set a new precision

Decimal instances can be constructed from integers, strings, floats, or
tuples.  Construction from an integer or a float performs an exact
conversion of the value of that integer or float.  Decimal numbers
include special values such as `NaN' which stands for “Not a
number”, positive and negative `Infinity', and `-0'.

    >>> getcontext().prec = 28
    >>> Decimal(10)
    Decimal('10')
    >>> Decimal('3.14')
    Decimal('3.14')
    >>> Decimal(3.14)
    Decimal('3.140000000000000124344978758017532527446746826171875')
    >>> Decimal((0, (3, 1, 4), -2))
    Decimal('3.14')
    >>> Decimal(str(2.0 ** 0.5))
    Decimal('1.41421356237')
    >>> Decimal(2) ** Decimal('0.5')
    Decimal('1.414213562373095048801688724')
    >>> Decimal('NaN')
    Decimal('NaN')
    >>> Decimal('-Infinity')
    Decimal('-Infinity')

The significance of a new Decimal is determined solely by the number of
digits input.  Context precision and rounding only come into play
during arithmetic operations.

    >>> getcontext().prec = 6
    >>> Decimal('3.0')
    Decimal('3.0')
    >>> Decimal('3.1415926535')
    Decimal('3.1415926535')
    >>> Decimal('3.1415926535') + Decimal('2.7182818285')
    Decimal('5.85987')
    >>> getcontext().rounding = ROUND_UP
    >>> Decimal('3.1415926535') + Decimal('2.7182818285')
    Decimal('5.85988')

Decimals interact well with much of the rest of Python.  Here is a
small decimal floating point flying circus:

    >>> data = map(Decimal, '1.34 1.87 3.45 2.35 1.00 0.03 9.25'.split())
    >>> max(data)
    Decimal('9.25')
    >>> min(data)
    Decimal('0.03')
    >>> sorted(data)
    [Decimal('0.03'), Decimal('1.00'), Decimal('1.34'), Decimal('1.87'),
     Decimal('2.35'), Decimal('3.45'), Decimal('9.25')]
    >>> sum(data)
    Decimal('19.29')
    >>> a,b,c = data[:3]
    >>> str(a)
    '1.34'
    >>> float(a)
    1.34
    >>> round(a, 1)     # round() first converts to binary floating point
    1.3
    >>> int(a)
    1
    >>> a * 5
    Decimal('6.70')
    >>> a * b
    Decimal('2.5058')
    >>> c % a
    Decimal('0.77')

And some mathematical functions are also available to Decimal:

    >>> getcontext().prec = 28
    >>> Decimal(2).sqrt()
    Decimal('1.414213562373095048801688724')
    >>> Decimal(1).exp()
    Decimal('2.718281828459045235360287471')
    >>> Decimal('10').ln()
    Decimal('2.302585092994045684017991455')
    >>> Decimal('10').log10()
    Decimal('1')

The `quantize()' method rounds a number to a fixed exponent.  This
method is useful for monetary applications that often round results to
a fixed number of places:

    >>> Decimal('7.325').quantize(Decimal('.01'), rounding=ROUND_DOWN)
    Decimal('7.32')
    >>> Decimal('7.325').quantize(Decimal('1.'), rounding=ROUND_UP)
    Decimal('8')

As shown above, the *Note getcontext(): ce0. function accesses the
current context and allows the settings to be changed.  This approach
meets the needs of most applications.

For more advanced work, it may be useful to create alternate contexts
using the Context() constructor.  To make an alternate active, use the
*Note setcontext(): ce1.  function.

In accordance with the standard, the *Note decimal: 80. module provides
two ready to use standard contexts, *Note BasicContext: ce2. and *Note
ExtendedContext: ce3. The former is especially useful for debugging
because many of the traps are enabled:

    >>> myothercontext = Context(prec=60, rounding=ROUND_HALF_DOWN)
    >>> setcontext(myothercontext)
    >>> Decimal(1) / Decimal(7)
    Decimal('0.142857142857142857142857142857142857142857142857142857142857')

    >>> ExtendedContext
    Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
            capitals=1, flags=[], traps=[])
    >>> setcontext(ExtendedContext)
    >>> Decimal(1) / Decimal(7)
    Decimal('0.142857143')
    >>> Decimal(42) / Decimal(0)
    Decimal('Infinity')

    >>> setcontext(BasicContext)
    >>> Decimal(42) / Decimal(0)
    Traceback (most recent call last):
      File "<pyshell#143>", line 1, in -toplevel-
        Decimal(42) / Decimal(0)
    DivisionByZero: x / 0

Contexts also have signal flags for monitoring exceptional conditions
encountered during computations.  The flags remain set until explicitly
cleared, so it is best to clear the flags before each set of monitored
computations by using the `clear_flags()' method.

    >>> setcontext(ExtendedContext)
    >>> getcontext().clear_flags()
    >>> Decimal(355) / Decimal(113)
    Decimal('3.14159292')
    >>> getcontext()
    Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
            capitals=1, flags=[Rounded, Inexact], traps=[])

The `flags' entry shows that the rational approximation to `Pi' was
rounded (digits beyond the context precision were thrown away) and that
the result is inexact (some of the discarded digits were non-zero).

Individual traps are set using the dictionary in the `traps' field of a
context:

    >>> setcontext(ExtendedContext)
    >>> Decimal(1) / Decimal(0)
    Decimal('Infinity')
    >>> getcontext().traps[DivisionByZero] = 1
    >>> Decimal(1) / Decimal(0)
    Traceback (most recent call last):
      File "<pyshell#112>", line 1, in -toplevel-
        Decimal(1) / Decimal(0)
    DivisionByZero: x / 0

Most programs adjust the current context only once, at the beginning of
the program.  And, in many applications, data is converted to *Note
Decimal: 1b5. with a single cast inside a loop.  With context set and
decimals created, the bulk of the program manipulates the data no
differently than with other Python numeric types.


File: python.info,  Node: Decimal objects,  Next: Context objects,  Prev: Quick-start Tutorial,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.2 Decimal objects
.......................

 -- Class: decimal.Decimal ([value[, context]])
     Construct a new *Note Decimal: 1b5. object based from `value'.

     `value' can be an integer, string, tuple, *Note float: 1eb, or
     another *Note Decimal: 1b5.  object. If no `value' is given,
     returns `Decimal('0')'.  If `value' is a string, it should conform
     to the decimal numeric string syntax after leading and trailing
     whitespace characters are removed:

         sign           ::=  '+' | '-'
         digit          ::=  '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'
         indicator      ::=  'e' | 'E'
         digits         ::=  digit [digit]...
         decimal-part   ::=  digits '.' [digits] | ['.'] digits
         exponent-part  ::=  indicator [sign] digits
         infinity       ::=  'Infinity' | 'Inf'
         nan            ::=  'NaN' [digits] | 'sNaN' [digits]
         numeric-value  ::=  decimal-part [exponent-part] | infinity
         numeric-string ::=  [sign] numeric-value | [sign] nan

     If `value' is a unicode string then other Unicode decimal digits
     are also permitted where `digit' appears above.  These include
     decimal digits from various other alphabets (for example,
     Arabic-Indic and Devanāgarī digits) along with the fullwidth
     digits `u'\uff10'' through `u'\uff19''.

     If `value' is a *Note tuple: 421, it should have three components,
     a sign (`0' for positive or `1' for negative), a *Note tuple: 421.
     of digits, and an integer exponent. For example, `Decimal((0, (1,
     4, 1, 4), -3))' returns `Decimal('1.414')'.

     If `value' is a *Note float: 1eb, the binary floating point value
     is losslessly converted to its exact decimal equivalent.  This
     conversion can often require 53 or more digits of precision.  For
     example, `Decimal(float('1.1'))' converts to
     `Decimal('1.100000000000000088817841970012523233890533447265625')'.

     The `context' precision does not affect how many digits are
     stored. That is determined exclusively by the number of digits in
     `value'. For example, `Decimal('3.00000')' records all five zeros
     even if the context precision is only three.

     The purpose of the `context' argument is determining what to do if
     `value' is a malformed string.  If the context traps *Note
     InvalidOperation: 2de, an exception is raised; otherwise, the
     constructor returns a new Decimal with the value of `NaN'.

     Once constructed, *Note Decimal: 1b5. objects are immutable.

     Changed in version 2.6: leading and trailing whitespace characters
     are permitted when creating a Decimal instance from a string.

     Changed in version 2.7: The argument to the constructor is now
     permitted to be a *Note float: 1eb. instance.

     Decimal floating point objects share many properties with the
     other built-in numeric types such as *Note float: 1eb. and *Note
     int: 1f2.  All of the usual math operations and special methods
     apply.  Likewise, decimal objects can be copied, pickled, printed,
     used as dictionary keys, used as set elements, compared, sorted,
     and coerced to another type (such as *Note float: 1eb. or *Note
     long: 1f3.).

     There are some small differences between arithmetic on Decimal
     objects and arithmetic on integers and floats.  When the remainder
     operator `%' is applied to Decimal objects, the sign of the result
     is the sign of the `dividend' rather than the sign of the divisor:

         >>> (-7) % 4
         1
         >>> Decimal(-7) % Decimal(4)
         Decimal('-3')

     The integer division operator `//' behaves analogously, returning
     the integer part of the true quotient (truncating towards zero)
     rather than its floor, so as to preserve the usual identity `x ==
     (x // y) * y + x % y':

         >>> -7 // 4
         -2
         >>> Decimal(-7) // Decimal(4)
         Decimal('-1')

     The `%' and `//' operators implement the `remainder' and
     `divide-integer' operations (respectively) as described in the
     specification.

     Decimal objects cannot generally be combined with floats in
     arithmetic operations: an attempt to add a *Note Decimal: 1b5. to a
     *Note float: 1eb, for example, will raise a *Note TypeError: 218.
     There’s one exception to this rule: it’s possible to use
     Python’s comparison operators to compare a *Note float: 1eb.
     instance `x' with a *Note Decimal: 1b5. instance `y'.  Without
     this exception, comparisons between *Note Decimal: 1b5. and *Note
     float: 1eb. instances would follow the general rules for comparing
     objects of different types described in the *Note Expressions:
     799. section of the reference manual, leading to confusing results.

     Changed in version 2.7: A comparison between a *Note float: 1eb.
     instance `x' and a *Note Decimal: 1b5. instance `y' now returns a
     result based on the values of `x' and `y'.  In earlier versions `x
     < y' returned the same (arbitrary) result for any *Note Decimal:
     1b5.  instance `x' and any *Note float: 1eb. instance `y'.

     In addition to the standard numeric properties, decimal floating
     point objects also have a number of specialized methods:

      -- Method: adjusted ()
          Return the adjusted exponent after shifting out the
          coefficient’s rightmost digits until only the lead digit
          remains: `Decimal('321e+5').adjusted()' returns seven.  Used
          for determining the position of the most significant digit
          with respect to the decimal point.

      -- Method: as_tuple ()
          Return a *Note named tuple: a4a. representation of the number:
          `DecimalTuple(sign, digits, exponent)'.

          Changed in version 2.6: Use a named tuple.


      -- Method: canonical ()
          Return the canonical encoding of the argument.  Currently,
          the encoding of a *Note Decimal: 1b5. instance is always
          canonical, so this operation returns its argument unchanged.

          New in version 2.6.


      -- Method: compare (other[, context])
          Compare the values of two Decimal instances.  This operation
          behaves in the same way as the usual comparison method *Note
          __cmp__(): 221, except that *Note compare(): ce9. returns a
          Decimal instance rather than an integer, and if either
          operand is a NaN then the result is a NaN:

              a or b is a NaN ==> Decimal('NaN')
              a < b           ==> Decimal('-1')
              a == b          ==> Decimal('0')
              a > b           ==> Decimal('1')

      -- Method: compare_signal (other[, context])
          This operation is identical to the *Note compare(): ce9.
          method, except that all NaNs signal.  That is, if neither
          operand is a signaling NaN then any quiet NaN operand is
          treated as though it were a signaling NaN.

          New in version 2.6.


      -- Method: compare_total (other)
          Compare two operands using their abstract representation
          rather than their numerical value.  Similar to the *Note
          compare(): ce9. method, but the result gives a total ordering
          on *Note Decimal: 1b5. instances.  Two *Note Decimal: 1b5.
          instances with the same numeric value but different
          representations compare unequal in this ordering:

              >>> Decimal('12.0').compare_total(Decimal('12'))
              Decimal('-1')

          Quiet and signaling NaNs are also included in the total
          ordering.  The result of this function is `Decimal('0')' if
          both operands have the same representation, `Decimal('-1')'
          if the first operand is lower in the total order than the
          second, and `Decimal('1')' if the first operand is higher in
          the total order than the second operand.  See the
          specification for details of the total order.

          New in version 2.6.


      -- Method: compare_total_mag (other)
          Compare two operands using their abstract representation
          rather than their value as in *Note compare_total(): ceb, but
          ignoring the sign of each operand.  `x.compare_total_mag(y)'
          is equivalent to `x.copy_abs().compare_total(y.copy_abs())'.

          New in version 2.6.


      -- Method: conjugate ()
          Just returns self, this method is only to comply with the
          Decimal Specification.

          New in version 2.6.


      -- Method: copy_abs ()
          Return the absolute value of the argument.  This operation is
          unaffected by the context and is quiet: no flags are changed
          and no rounding is performed.

          New in version 2.6.


      -- Method: copy_negate ()
          Return the negation of the argument.  This operation is
          unaffected by the context and is quiet: no flags are changed
          and no rounding is performed.

          New in version 2.6.


      -- Method: copy_sign (other)
          Return a copy of the first operand with the sign set to be
          the same as the sign of the second operand.  For example:

              >>> Decimal('2.3').copy_sign(Decimal('-1.5'))
              Decimal('-2.3')

          This operation is unaffected by the context and is quiet: no
          flags are changed and no rounding is performed.

          New in version 2.6.


      -- Method: exp ([context])
          Return the value of the (natural) exponential function `e**x'
          at the given number.  The result is correctly rounded using
          the `ROUND_HALF_EVEN' rounding mode.

              >>> Decimal(1).exp()
              Decimal('2.718281828459045235360287471')
              >>> Decimal(321).exp()
              Decimal('2.561702493119680037517373933E+139')

          New in version 2.6.


      -- Method: from_float (f)
          Classmethod that converts a float to a decimal number,
          exactly.

          Note `Decimal.from_float(0.1)' is not the same as
          `Decimal(‘0.1’)'.  Since 0.1 is not exactly representable
          in binary floating point, the value is stored as the nearest
          representable value which is `0x1.999999999999ap-4'.  That
          equivalent value in decimal is
          `0.1000000000000000055511151231257827021181583404541015625'.

               Note: From Python 2.7 onwards, a *Note Decimal: 1b5.
               instance can also be constructed directly from a *Note
               float: 1eb.

              >>> Decimal.from_float(0.1)
              Decimal('0.1000000000000000055511151231257827021181583404541015625')
              >>> Decimal.from_float(float('nan'))
              Decimal('NaN')
              >>> Decimal.from_float(float('inf'))
              Decimal('Infinity')
              >>> Decimal.from_float(float('-inf'))
              Decimal('-Infinity')

          New in version 2.7.


      -- Method: fma (other, third[, context])
          Fused multiply-add.  Return self*other+third with no rounding
          of the intermediate product self*other.

              >>> Decimal(2).fma(3, 5)
              Decimal('11')

          New in version 2.6.


      -- Method: is_canonical ()
          Return *Note True: 3c8. if the argument is canonical and
          *Note False: 3c9.  otherwise.  Currently, a *Note Decimal:
          1b5. instance is always canonical, so this operation always
          returns *Note True: 3c8.

          New in version 2.6.


      -- Method: is_finite ()
          Return *Note True: 3c8. if the argument is a finite number,
          and *Note False: 3c9. if the argument is an infinity or a NaN.

          New in version 2.6.


      -- Method: is_infinite ()
          Return *Note True: 3c8. if the argument is either positive or
          negative infinity and *Note False: 3c9. otherwise.

          New in version 2.6.


      -- Method: is_nan ()
          Return *Note True: 3c8. if the argument is a (quiet or
          signaling) NaN and *Note False: 3c9. otherwise.

          New in version 2.6.


      -- Method: is_normal ()
          Return *Note True: 3c8. if the argument is a `normal' finite
          non-zero number with an adjusted exponent greater than or
          equal to `Emin'.  Return *Note False: 3c9. if the argument is
          zero, subnormal, infinite or a NaN.  Note, the term `normal'
          is used here in a different sense with the *Note normalize():
          cf8. method which is used to create canonical values.

          New in version 2.6.


      -- Method: is_qnan ()
          Return *Note True: 3c8. if the argument is a quiet NaN, and
          *Note False: 3c9. otherwise.

          New in version 2.6.


      -- Method: is_signed ()
          Return *Note True: 3c8. if the argument has a negative sign
          and *Note False: 3c9. otherwise.  Note that zeros and NaNs
          can both carry signs.

          New in version 2.6.


      -- Method: is_snan ()
          Return *Note True: 3c8. if the argument is a signaling NaN
          and *Note False: 3c9.  otherwise.

          New in version 2.6.


      -- Method: is_subnormal ()
          Return *Note True: 3c8. if the argument is subnormal, and
          *Note False: 3c9.  otherwise. A number is subnormal is if it
          is nonzero, finite, and has an adjusted exponent less than
          `Emin'.

          New in version 2.6.


      -- Method: is_zero ()
          Return *Note True: 3c8. if the argument is a (positive or
          negative) zero and *Note False: 3c9. otherwise.

          New in version 2.6.


      -- Method: ln ([context])
          Return the natural (base e) logarithm of the operand.  The
          result is correctly rounded using the `ROUND_HALF_EVEN'
          rounding mode.

          New in version 2.6.


      -- Method: log10 ([context])
          Return the base ten logarithm of the operand.  The result is
          correctly rounded using the `ROUND_HALF_EVEN' rounding mode.

          New in version 2.6.


      -- Method: logb ([context])
          For a nonzero number, return the adjusted exponent of its
          operand as a *Note Decimal: 1b5. instance.  If the operand is
          a zero then `Decimal('-Infinity')' is returned and the *Note
          DivisionByZero: cd8. flag is raised.  If the operand is an
          infinity then `Decimal('Infinity')' is returned.

          New in version 2.6.


      -- Method: logical_and (other[, context])
          *Note logical_and(): d01. is a logical operation which takes
          two `logical operands' (see *Note Logical operands: d02.).
          The result is the digit-wise `and' of the two operands.

          New in version 2.6.


      -- Method: logical_invert ([context])
          *Note logical_invert(): d03. is a logical operation.  The
          result is the digit-wise inversion of the operand.

          New in version 2.6.


      -- Method: logical_or (other[, context])
          *Note logical_or(): d04. is a logical operation which takes
          two `logical operands' (see *Note Logical operands: d02.).
          The result is the digit-wise `or' of the two operands.

          New in version 2.6.


      -- Method: logical_xor (other[, context])
          *Note logical_xor(): d05. is a logical operation which takes
          two `logical operands' (see *Note Logical operands: d02.).
          The result is the digit-wise exclusive or of the two operands.

          New in version 2.6.


      -- Method: max (other[, context])
          Like `max(self, other)' except that the context rounding rule
          is applied before returning and that `NaN' values are either
          signaled or ignored (depending on the context and whether
          they are signaling or quiet).

      -- Method: max_mag (other[, context])
          Similar to the *Note max(): d06. method, but the comparison
          is done using the absolute values of the operands.

          New in version 2.6.


      -- Method: min (other[, context])
          Like `min(self, other)' except that the context rounding rule
          is applied before returning and that `NaN' values are either
          signaled or ignored (depending on the context and whether
          they are signaling or quiet).

      -- Method: min_mag (other[, context])
          Similar to the *Note min(): d08. method, but the comparison
          is done using the absolute values of the operands.

          New in version 2.6.


      -- Method: next_minus ([context])
          Return the largest number representable in the given context
          (or in the current thread’s context if no context is given)
          that is smaller than the given operand.

          New in version 2.6.


      -- Method: next_plus ([context])
          Return the smallest number representable in the given context
          (or in the current thread’s context if no context is given)
          that is larger than the given operand.

          New in version 2.6.


      -- Method: next_toward (other[, context])
          If the two operands are unequal, return the number closest to
          the first operand in the direction of the second operand.  If
          both operands are numerically equal, return a copy of the
          first operand with the sign set to be the same as the sign of
          the second operand.

          New in version 2.6.


      -- Method: normalize ([context])
          Normalize the number by stripping the rightmost trailing
          zeros and converting any result equal to `Decimal('0')' to
          `Decimal('0e0')'. Used for producing canonical values for
          attributes of an equivalence class. For example,
          `Decimal('32.100')' and `Decimal('0.321000e+2')' both
          normalize to the equivalent value `Decimal('32.1')'.

      -- Method: number_class ([context])
          Return a string describing the `class' of the operand.  The
          returned value is one of the following ten strings.

             * `"-Infinity"', indicating that the operand is negative
               infinity.

             * `"-Normal"', indicating that the operand is a negative
               normal number.

             * `"-Subnormal"', indicating that the operand is negative
               and subnormal.

             * `"-Zero"', indicating that the operand is a negative
               zero.

             * `"+Zero"', indicating that the operand is a positive
               zero.

             * `"+Subnormal"', indicating that the operand is positive
               and subnormal.

             * `"+Normal"', indicating that the operand is a positive
               normal number.

             * `"+Infinity"', indicating that the operand is positive
               infinity.

             * `"NaN"', indicating that the operand is a quiet NaN (Not
               a Number).

             * `"sNaN"', indicating that the operand is a signaling NaN.

          New in version 2.6.


      -- Method: quantize (exp[, rounding[, context[, watchexp]]])
          Return a value equal to the first operand after rounding and
          having the exponent of the second operand.

              >>> Decimal('1.41421356').quantize(Decimal('1.000'))
              Decimal('1.414')

          Unlike other operations, if the length of the coefficient
          after the quantize operation would be greater than precision,
          then an *Note InvalidOperation: 2de. is signaled. This
          guarantees that, unless there is an error condition, the
          quantized exponent is always equal to that of the right-hand
          operand.

          Also unlike other operations, quantize never signals
          Underflow, even if the result is subnormal and inexact.

          If the exponent of the second operand is larger than that of
          the first then rounding may be necessary.  In this case, the
          rounding mode is determined by the `rounding' argument if
          given, else by the given `context' argument; if neither
          argument is given the rounding mode of the current thread’s
          context is used.

          If `watchexp' is set (default), then an error is returned
          whenever the resulting exponent is greater than `Emax' or
          less than `Etiny'.

      -- Method: radix ()
          Return `Decimal(10)', the radix (base) in which the *Note
          Decimal: 1b5.  class does all its arithmetic.  Included for
          compatibility with the specification.

          New in version 2.6.


      -- Method: remainder_near (other[, context])
          Return the remainder from dividing `self' by `other'.  This
          differs from `self % other' in that the sign of the remainder
          is chosen so as to minimize its absolute value.  More
          precisely, the return value is `self - n * other' where `n'
          is the integer nearest to the exact value of `self / other',
          and if two integers are equally near then the even one is
          chosen.

          If the result is zero then its sign will be the sign of
          `self'.

              >>> Decimal(18).remainder_near(Decimal(10))
              Decimal('-2')
              >>> Decimal(25).remainder_near(Decimal(10))
              Decimal('5')
              >>> Decimal(35).remainder_near(Decimal(10))
              Decimal('-5')

      -- Method: rotate (other[, context])
          Return the result of rotating the digits of the first operand
          by an amount specified by the second operand.  The second
          operand must be an integer in the range -precision through
          precision.  The absolute value of the second operand gives
          the number of places to rotate.  If the second operand is
          positive then rotation is to the left; otherwise rotation is
          to the right.  The coefficient of the first operand is padded
          on the left with zeros to length precision if necessary.  The
          sign and exponent of the first operand are unchanged.

          New in version 2.6.


      -- Method: same_quantum (other[, context])
          Test whether self and other have the same exponent or whether
          both are `NaN'.

      -- Method: scaleb (other[, context])
          Return the first operand with exponent adjusted by the second.
          Equivalently, return the first operand multiplied by
          `10**other'.  The second operand must be an integer.

          New in version 2.6.


      -- Method: shift (other[, context])
          Return the result of shifting the digits of the first operand
          by an amount specified by the second operand.  The second
          operand must be an integer in the range -precision through
          precision.  The absolute value of the second operand gives
          the number of places to shift.  If the second operand is
          positive then the shift is to the left; otherwise the shift
          is to the right.  Digits shifted into the coefficient are
          zeros.  The sign and exponent of the first operand are
          unchanged.

          New in version 2.6.


      -- Method: sqrt ([context])
          Return the square root of the argument to full precision.

      -- Method: to_eng_string ([context])
          Convert to a string, using engineering notation if an
          exponent is needed.

          Engineering notation has an exponent which is a multiple of
          3.  This can leave up to 3 digits to the left of the decimal
          place and may require the addition of either one or two
          trailing zeros.

          For example, this converts `Decimal('123E+1')' to
          `Decimal('1.23E+3')'.

      -- Method: to_integral ([rounding[, context]])
          Identical to the *Note to_integral_value(): d18. method.  The
          `to_integral' name has been kept for compatibility with older
          versions.

      -- Method: to_integral_exact ([rounding[, context]])
          Round to the nearest integer, signaling *Note Inexact: cd9. or
          *Note Rounded: cda. as appropriate if rounding occurs.  The
          rounding mode is determined by the `rounding' parameter if
          given, else by the given `context'.  If neither parameter is
          given then the rounding mode of the current context is used.

          New in version 2.6.


      -- Method: to_integral_value ([rounding[, context]])
          Round to the nearest integer without signaling *Note Inexact:
          cd9. or *Note Rounded: cda.  If given, applies `rounding';
          otherwise, uses the rounding method in either the supplied
          `context' or the current context.

          Changed in version 2.6: renamed from `to_integral' to
          `to_integral_value'.  The old name remains valid for
          compatibility.


* Menu:

* Logical operands::


File: python.info,  Node: Logical operands,  Up: Decimal objects

5.9.4.3 Logical operands
........................

The `logical_and()', `logical_invert()', `logical_or()', and
`logical_xor()' methods expect their arguments to be `logical
operands'.  A `logical operand' is a *Note Decimal: 1b5. instance whose
exponent and sign are both zero, and whose digits are all either `0' or
`1'.


File: python.info,  Node: Context objects,  Next: Signals,  Prev: Decimal objects,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.4 Context objects
.......................

Contexts are environments for arithmetic operations.  They govern
precision, set rules for rounding, determine which signals are treated
as exceptions, and limit the range for exponents.

Each thread has its own current context which is accessed or changed
using the *Note getcontext(): ce0. and *Note setcontext(): ce1.
functions:

 -- Function: decimal.getcontext ()
     Return the current context for the active thread.

 -- Function: decimal.setcontext (c)
     Set the current context for the active thread to `c'.

Beginning with Python 2.5, you can also use the *Note with: 1c1.
statement and the *Note localcontext(): 950. function to temporarily
change the active context.

 -- Function: decimal.localcontext ([c])
     Return a context manager that will set the current context for the
     active thread to a copy of `c' on entry to the with-statement and
     restore the previous context when exiting the with-statement. If
     no context is specified, a copy of the current context is used.

     New in version 2.5.

     For example, the following code sets the current decimal precision
     to 42 places, performs a calculation, and then automatically
     restores the previous context:

         from decimal import localcontext

         with localcontext() as ctx:
             ctx.prec = 42   # Perform a high precision calculation
             s = calculate_something()
         s = +s  # Round the final result back to the default precision

         with localcontext(BasicContext):      # temporarily use the BasicContext
             print Decimal(1) / Decimal(7)
             print Decimal(355) / Decimal(113)

New contexts can also be created using the *Note Context: 213.
constructor described below. In addition, the module provides three
pre-made contexts:

 -- Class: decimal.BasicContext
     This is a standard context defined by the General Decimal
     Arithmetic Specification.  Precision is set to nine.  Rounding is
     set to `ROUND_HALF_UP'.  All flags are cleared.  All traps are
     enabled (treated as exceptions) except *Note Inexact: cd9, *Note
     Rounded: cda, and *Note Subnormal: cdb.

     Because many of the traps are enabled, this context is useful for
     debugging.

 -- Class: decimal.ExtendedContext
     This is a standard context defined by the General Decimal
     Arithmetic Specification.  Precision is set to nine.  Rounding is
     set to `ROUND_HALF_EVEN'.  All flags are cleared.  No traps are
     enabled (so that exceptions are not raised during computations).

     Because the traps are disabled, this context is useful for
     applications that prefer to have result value of `NaN' or
     `Infinity' instead of raising exceptions.  This allows an
     application to complete a run in the presence of conditions that
     would otherwise halt the program.

 -- Class: decimal.DefaultContext
     This context is used by the *Note Context: 213. constructor as a
     prototype for new contexts.  Changing a field (such a precision)
     has the effect of changing the default for new contexts created by
     the *Note Context: 213. constructor.

     This context is most useful in multi-threaded environments.
     Changing one of the fields before threads are started has the
     effect of setting system-wide defaults.  Changing the fields after
     threads have started is not recommended as it would require thread
     synchronization to prevent race conditions.

     In single threaded environments, it is preferable to not use this
     context at all.  Instead, simply create contexts explicitly as
     described below.

     The default values are precision=28, rounding=ROUND_HALF_EVEN, and
     enabled traps for Overflow, InvalidOperation, and DivisionByZero.

In addition to the three supplied contexts, new contexts can be created
with the *Note Context: 213. constructor.

 -- Class: decimal.Context (prec=None, rounding=None, traps=None,
          flags=None, Emin=None, Emax=None, capitals=1)
     Creates a new context.  If a field is not specified or is *Note
     None: 3b2, the default values are copied from the *Note
     DefaultContext: d1d.  If the `flags' field is not specified or is
     *Note None: 3b2, all flags are cleared.

     The `prec' field is a positive integer that sets the precision for
     arithmetic operations in the context.

     The `rounding' option is one of:

        * `ROUND_CEILING' (towards `Infinity'),

        * `ROUND_DOWN' (towards zero),

        * `ROUND_FLOOR' (towards `-Infinity'),

        * `ROUND_HALF_DOWN' (to nearest with ties going towards zero),

        * `ROUND_HALF_EVEN' (to nearest with ties going to nearest even
          integer),

        * `ROUND_HALF_UP' (to nearest with ties going away from zero),
          or

        * `ROUND_UP' (away from zero).

        * `ROUND_05UP' (away from zero if last digit after rounding
          towards zero would have been 0 or 5; otherwise towards zero)

     The `traps' and `flags' fields list any signals to be set.
     Generally, new contexts should only set traps and leave the flags
     clear.

     The `Emin' and `Emax' fields are integers specifying the outer
     limits allowable for exponents.

     The `capitals' field is either `0' or `1' (the default). If set to
     `1', exponents are printed with a capital `E'; otherwise, a
     lowercase `e' is used: `Decimal('6.02e+23')'.

     Changed in version 2.6: The `ROUND_05UP' rounding mode was added.

     The *Note Context: 213. class defines several general purpose
     methods as well as a large number of methods for doing arithmetic
     directly in a given context.  In addition, for each of the *Note
     Decimal: 1b5. methods described above (with the exception of the
     `adjusted()' and `as_tuple()' methods) there is a corresponding
     *Note Context: 213. method.  For example, for a *Note Context: 213.
     instance `C' and *Note Decimal: 1b5. instance `x', `C.exp(x)' is
     equivalent to `x.exp(context=C)'.  Each *Note Context: 213. method
     accepts a Python integer (an instance of *Note int: 1f2. or *Note
     long: 1f3.) anywhere that a Decimal instance is accepted.

      -- Method: clear_flags ()
          Resets all of the flags to `0'.

      -- Method: copy ()
          Return a duplicate of the context.

      -- Method: copy_decimal (num)
          Return a copy of the Decimal instance num.

      -- Method: create_decimal (num)
          Creates a new Decimal instance from `num' but using `self' as
          context. Unlike the *Note Decimal: 1b5. constructor, the
          context precision, rounding method, flags, and traps are
          applied to the conversion.

          This is useful because constants are often given to a greater
          precision than is needed by the application.  Another benefit
          is that rounding immediately eliminates unintended effects
          from digits beyond the current precision. In the following
          example, using unrounded inputs means that adding zero to a
          sum can change the result:

              >>> getcontext().prec = 3
              >>> Decimal('3.4445') + Decimal('1.0023')
              Decimal('4.45')
              >>> Decimal('3.4445') + Decimal(0) + Decimal('1.0023')
              Decimal('4.44')

          This method implements the to-number operation of the IBM
          specification.  If the argument is a string, no leading or
          trailing whitespace is permitted.

      -- Method: create_decimal_from_float (f)
          Creates a new Decimal instance from a float `f' but rounding
          using `self' as the context.  Unlike the *Note
          Decimal.from_float(): 212. class method, the context
          precision, rounding method, flags, and traps are applied to
          the conversion.

              >>> context = Context(prec=5, rounding=ROUND_DOWN)
              >>> context.create_decimal_from_float(math.pi)
              Decimal('3.1415')
              >>> context = Context(prec=5, traps=[Inexact])
              >>> context.create_decimal_from_float(math.pi)
              Traceback (most recent call last):
                  ...
              Inexact: None

          New in version 2.7.


      -- Method: Etiny ()
          Returns a value equal to `Emin - prec + 1' which is the
          minimum exponent value for subnormal results.  When underflow
          occurs, the exponent is set to *Note Etiny: d23.

      -- Method: Etop ()
          Returns a value equal to `Emax - prec + 1'.

     The usual approach to working with decimals is to create *Note
     Decimal: 1b5.  instances and then apply arithmetic operations
     which take place within the current context for the active thread.
     An alternative approach is to use context methods for calculating
     within a specific context.  The methods are similar to those for
     the *Note Decimal: 1b5. class and are only briefly recounted here.

      -- Method: abs (x)
          Returns the absolute value of `x'.

      -- Method: add (x, y)
          Return the sum of `x' and `y'.

      -- Method: canonical (x)
          Returns the same Decimal object `x'.

      -- Method: compare (x, y)
          Compares `x' and `y' numerically.

      -- Method: compare_signal (x, y)
          Compares the values of the two operands numerically.

      -- Method: compare_total (x, y)
          Compares two operands using their abstract representation.

      -- Method: compare_total_mag (x, y)
          Compares two operands using their abstract representation,
          ignoring sign.

      -- Method: copy_abs (x)
          Returns a copy of `x' with the sign set to 0.

      -- Method: copy_negate (x)
          Returns a copy of `x' with the sign inverted.

      -- Method: copy_sign (x, y)
          Copies the sign from `y' to `x'.

      -- Method: divide (x, y)
          Return `x' divided by `y'.

      -- Method: divide_int (x, y)
          Return `x' divided by `y', truncated to an integer.

      -- Method: divmod (x, y)
          Divides two numbers and returns the integer part of the
          result.

      -- Method: exp (x)
          Returns `e ** x'.

      -- Method: fma (x, y, z)
          Returns `x' multiplied by `y', plus `z'.

      -- Method: is_canonical (x)
          Returns `True' if `x' is canonical; otherwise returns `False'.

      -- Method: is_finite (x)
          Returns `True' if `x' is finite; otherwise returns `False'.

      -- Method: is_infinite (x)
          Returns `True' if `x' is infinite; otherwise returns `False'.

      -- Method: is_nan (x)
          Returns `True' if `x' is a qNaN or sNaN; otherwise returns
          `False'.

      -- Method: is_normal (x)
          Returns `True' if `x' is a normal number; otherwise returns
          `False'.

      -- Method: is_qnan (x)
          Returns `True' if `x' is a quiet NaN; otherwise returns
          `False'.

      -- Method: is_signed (x)
          Returns `True' if `x' is negative; otherwise returns `False'.

      -- Method: is_snan (x)
          Returns `True' if `x' is a signaling NaN; otherwise returns
          `False'.

      -- Method: is_subnormal (x)
          Returns `True' if `x' is subnormal; otherwise returns `False'.

      -- Method: is_zero (x)
          Returns `True' if `x' is a zero; otherwise returns `False'.

      -- Method: ln (x)
          Returns the natural (base e) logarithm of `x'.

      -- Method: log10 (x)
          Returns the base 10 logarithm of `x'.

      -- Method: logb (x)
          Returns the exponent of the magnitude of the operand’s MSD.

      -- Method: logical_and (x, y)
          Applies the logical operation `and' between each operand’s
          digits.

      -- Method: logical_invert (x)
          Invert all the digits in `x'.

      -- Method: logical_or (x, y)
          Applies the logical operation `or' between each operand’s
          digits.

      -- Method: logical_xor (x, y)
          Applies the logical operation `xor' between each operand’s
          digits.

      -- Method: max (x, y)
          Compares two values numerically and returns the maximum.

      -- Method: max_mag (x, y)
          Compares the values numerically with their sign ignored.

      -- Method: min (x, y)
          Compares two values numerically and returns the minimum.

      -- Method: min_mag (x, y)
          Compares the values numerically with their sign ignored.

      -- Method: minus (x)
          Minus corresponds to the unary prefix minus operator in
          Python.

      -- Method: multiply (x, y)
          Return the product of `x' and `y'.

      -- Method: next_minus (x)
          Returns the largest representable number smaller than `x'.

      -- Method: next_plus (x)
          Returns the smallest representable number larger than `x'.

      -- Method: next_toward (x, y)
          Returns the number closest to `x', in direction towards `y'.

      -- Method: normalize (x)
          Reduces `x' to its simplest form.

      -- Method: number_class (x)
          Returns an indication of the class of `x'.

      -- Method: plus (x)
          Plus corresponds to the unary prefix plus operator in Python.
          This operation applies the context precision and rounding,
          so it is `not' an identity operation.

      -- Method: power (x, y[, modulo])
          Return `x' to the power of `y', reduced modulo `modulo' if
          given.

          With two arguments, compute `x**y'.  If `x' is negative then
          `y' must be integral.  The result will be inexact unless `y'
          is integral and the result is finite and can be expressed
          exactly in ‘precision’ digits.  The result should always
          be correctly rounded, using the rounding mode of the current
          thread’s context.

          With three arguments, compute `(x**y) % modulo'.  For the
          three argument form, the following restrictions on the
          arguments hold:

                  - all three arguments must be integral

                  - `y' must be nonnegative

                  - at least one of `x' or `y' must be nonzero

                  - `modulo' must be nonzero and have at most
                    ‘precision’ digits

          The value resulting from `Context.power(x, y, modulo)' is
          equal to the value that would be obtained by computing `(x**y)
          % modulo' with unbounded precision, but is computed more
          efficiently.  The exponent of the result is zero, regardless
          of the exponents of `x', `y' and `modulo'.  The result is
          always exact.

          Changed in version 2.6: `y' may now be nonintegral in `x**y'.
          Stricter requirements for the three-argument version.


      -- Method: quantize (x, y)
          Returns a value equal to `x' (rounded), having the exponent
          of `y'.

      -- Method: radix ()
          Just returns 10, as this is Decimal, :)

      -- Method: remainder (x, y)
          Returns the remainder from integer division.

          The sign of the result, if non-zero, is the same as that of
          the original dividend.

      -- Method: remainder_near (x, y)
          Returns `x - y * n', where `n' is the integer nearest the
          exact value of `x / y' (if the result is 0 then its sign will
          be the sign of `x').

      -- Method: rotate (x, y)
          Returns a rotated copy of `x', `y' times.

      -- Method: same_quantum (x, y)
          Returns `True' if the two operands have the same exponent.

      -- Method: scaleb (x, y)
          Returns the first operand after adding the second value its
          exp.

      -- Method: shift (x, y)
          Returns a shifted copy of `x', `y' times.

      -- Method: sqrt (x)
          Square root of a non-negative number to context precision.

      -- Method: subtract (x, y)
          Return the difference between `x' and `y'.

      -- Method: to_eng_string (x)
          Convert to a string, using engineering notation if an
          exponent is needed.

          Engineering notation has an exponent which is a multiple of
          3.  This can leave up to 3 digits to the left of the decimal
          place and may require the addition of either one or two
          trailing zeros.

      -- Method: to_integral_exact (x)
          Rounds to an integer.

      -- Method: to_sci_string (x)
          Converts a number to a string using scientific notation.


File: python.info,  Node: Signals,  Next: Floating Point Notes,  Prev: Context objects,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.5 Signals
...............

Signals represent conditions that arise during computation. Each
corresponds to one context flag and one context trap enabler.

The context flag is set whenever the condition is encountered. After the
computation, flags may be checked for informational purposes (for
instance, to determine whether a computation was exact). After checking
the flags, be sure to clear all flags before starting the next
computation.

If the context’s trap enabler is set for the signal, then the
condition causes a Python exception to be raised.  For example, if the
*Note DivisionByZero: cd8. trap is set, then a *Note DivisionByZero:
cd8. exception is raised upon encountering the condition.

 -- Class: decimal.Clamped
     Altered an exponent to fit representation constraints.

     Typically, clamping occurs when an exponent falls outside the
     context’s `Emin' and `Emax' limits.  If possible, the exponent
     is reduced to fit by adding zeros to the coefficient.

 -- Class: decimal.DecimalException
     Base class for other signals and a subclass of *Note
     ArithmeticError: 971.

 -- Class: decimal.DivisionByZero
     Signals the division of a non-infinite number by zero.

     Can occur with division, modulo division, or when raising a number
     to a negative power.  If this signal is not trapped, returns
     `Infinity' or `-Infinity' with the sign determined by the inputs
     to the calculation.

 -- Class: decimal.Inexact
     Indicates that rounding occurred and the result is not exact.

     Signals when non-zero digits were discarded during rounding. The
     rounded result is returned.  The signal flag or trap is used to
     detect when results are inexact.

 -- Class: decimal.InvalidOperation
     An invalid operation was performed.

     Indicates that an operation was requested that does not make
     sense. If not trapped, returns `NaN'.  Possible causes include:

         Infinity - Infinity
         0 * Infinity
         Infinity / Infinity
         x % 0
         Infinity % x
         x._rescale( non-integer )
         sqrt(-x) and x > 0
         0 ** 0
         x ** (non-integer)
         x ** Infinity

 -- Class: decimal.Overflow
     Numerical overflow.

     Indicates the exponent is larger than `Emax' after rounding has
     occurred.  If not trapped, the result depends on the rounding
     mode, either pulling inward to the largest representable finite
     number or rounding outward to `Infinity'.  In either case, *Note
     Inexact: cd9. and *Note Rounded: cda.  are also signaled.

 -- Class: decimal.Rounded
     Rounding occurred though possibly no information was lost.

     Signaled whenever rounding discards digits; even if those digits
     are zero (such as rounding `5.00' to `5.0').  If not trapped,
     returns the result unchanged.  This signal is used to detect loss
     of significant digits.

 -- Class: decimal.Subnormal
     Exponent was lower than `Emin' prior to rounding.

     Occurs when an operation result is subnormal (the exponent is too
     small). If not trapped, returns the result unchanged.

 -- Class: decimal.Underflow
     Numerical underflow with result rounded to zero.

     Occurs when a subnormal result is pushed to zero by rounding.
     *Note Inexact: cd9.  and *Note Subnormal: cdb. are also signaled.

The following table summarizes the hierarchy of signals:

    exceptions.ArithmeticError(exceptions.StandardError)
        DecimalException
            Clamped
            DivisionByZero(DecimalException, exceptions.ZeroDivisionError)
            Inexact
                Overflow(Inexact, Rounded)
                Underflow(Inexact, Rounded, Subnormal)
            InvalidOperation
            Rounded
            Subnormal


File: python.info,  Node: Floating Point Notes,  Next: Working with threads,  Prev: Signals,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.6 Floating Point Notes
............................

* Menu:

* Mitigating round-off error with increased precision::
* Special values::


File: python.info,  Node: Mitigating round-off error with increased precision,  Next: Special values,  Up: Floating Point Notes

5.9.4.7 Mitigating round-off error with increased precision
...........................................................

The use of decimal floating point eliminates decimal representation
error (making it possible to represent `0.1' exactly); however, some
operations can still incur round-off error when non-zero digits exceed
the fixed precision.

The effects of round-off error can be amplified by the addition or
subtraction of nearly offsetting quantities resulting in loss of
significance.  Knuth provides two instructive examples where rounded
floating point arithmetic with insufficient precision causes the
breakdown of the associative and distributive properties of addition:

    # Examples from Seminumerical Algorithms, Section 4.2.2.
    >>> from decimal import Decimal, getcontext
    >>> getcontext().prec = 8

    >>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
    >>> (u + v) + w
    Decimal('9.5111111')
    >>> u + (v + w)
    Decimal('10')

    >>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
    >>> (u*v) + (u*w)
    Decimal('0.01')
    >>> u * (v+w)
    Decimal('0.0060000')

The *Note decimal: 80. module makes it possible to restore the
identities by expanding the precision sufficiently to avoid loss of
significance:

    >>> getcontext().prec = 20
    >>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
    >>> (u + v) + w
    Decimal('9.51111111')
    >>> u + (v + w)
    Decimal('9.51111111')
    >>>
    >>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
    >>> (u*v) + (u*w)
    Decimal('0.0060000')
    >>> u * (v+w)
    Decimal('0.0060000')


File: python.info,  Node: Special values,  Prev: Mitigating round-off error with increased precision,  Up: Floating Point Notes

5.9.4.8 Special values
......................

The number system for the *Note decimal: 80. module provides special
values including `NaN', `sNaN', `-Infinity', `Infinity', and two zeros,
`+0' and `-0'.

Infinities can be constructed directly with:  `Decimal('Infinity')'.
Also, they can arise from dividing by zero when the *Note
DivisionByZero: cd8. signal is not trapped.  Likewise, when the *Note
Overflow: cdc. signal is not trapped, infinity can result from rounding
beyond the limits of the largest representable number.

The infinities are signed (affine) and can be used in arithmetic
operations where they get treated as very large, indeterminate numbers.
For instance, adding a constant to infinity gives another infinite
result.

Some operations are indeterminate and return `NaN', or if the *Note
InvalidOperation: 2de. signal is trapped, raise an exception.  For
example, `0/0' returns `NaN' which means “not a number”.  This
variety of `NaN' is quiet and, once created, will flow through other
computations always resulting in another `NaN'.  This behavior can be
useful for a series of computations that occasionally have missing
inputs — it allows the calculation to proceed while flagging specific
results as invalid.

A variant is `sNaN' which signals rather than remaining quiet after
every operation.  This is a useful return value when an invalid result
needs to interrupt a calculation for special handling.

The behavior of Python’s comparison operators can be a little
surprising where a `NaN' is involved.  A test for equality where one of
the operands is a quiet or signaling `NaN' always returns *Note False:
3c9. (even when doing `Decimal('NaN')==Decimal('NaN')'), while a test
for inequality always returns *Note True: 3c8.  An attempt to compare
two Decimals using any of the `<', `<=', `>' or `>=' operators will
raise the *Note InvalidOperation: 2de. signal if either operand is a
`NaN', and return *Note False: 3c9. if this signal is not trapped.
Note that the General Decimal Arithmetic specification does not specify
the behavior of direct comparisons; these rules for comparisons
involving a `NaN' were taken from the IEEE 854 standard (see Table 3 in
section 5.7).  To ensure strict standards-compliance, use the
`compare()' and `compare-signal()' methods instead.

The signed zeros can result from calculations that underflow. They keep
the sign that would have resulted if the calculation had been carried
out to greater precision.  Since their magnitude is zero, both positive
and negative zeros are treated as equal and their sign is informational.

In addition to the two signed zeros which are distinct yet equal, there
are various representations of zero with differing precisions yet
equivalent in value.  This takes a bit of getting used to.  For an eye
accustomed to normalized floating point representations, it is not
immediately obvious that the following calculation returns a value
equal to zero:

    >>> 1 / Decimal('Infinity')
    Decimal('0E-1000000026')


File: python.info,  Node: Working with threads,  Next: Recipes,  Prev: Floating Point Notes,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.9 Working with threads
............................

The *Note getcontext(): ce0. function accesses a different *Note
Context: 213. object for each thread.  Having separate thread contexts
means that threads may make changes (such as `getcontext.prec=10')
without interfering with other threads.

Likewise, the *Note setcontext(): ce1. function automatically assigns
its target to the current thread.

If *Note setcontext(): ce1. has not been called before *Note
getcontext(): ce0, then *Note getcontext(): ce0. will automatically
create a new context for use in the current thread.

The new context is copied from a prototype context called
`DefaultContext'. To control the defaults so that each thread will use
the same values throughout the application, directly modify the
`DefaultContext' object. This should be done `before' any threads are
started so that there won’t be a race condition between threads
calling *Note getcontext(): ce0. For example:

    # Set applicationwide defaults for all threads about to be launched
    DefaultContext.prec = 12
    DefaultContext.rounding = ROUND_DOWN
    DefaultContext.traps = ExtendedContext.traps.copy()
    DefaultContext.traps[InvalidOperation] = 1
    setcontext(DefaultContext)

    # Afterwards, the threads can be started
    t1.start()
    t2.start()
    t3.start()
     . . .


File: python.info,  Node: Recipes,  Next: Decimal FAQ,  Prev: Working with threads,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.10 Recipes
................

Here are a few recipes that serve as utility functions and that
demonstrate ways to work with the *Note Decimal: 1b5. class:

    def moneyfmt(value, places=2, curr='', sep=',', dp='.',
                 pos='', neg='-', trailneg=''):
        """Convert Decimal to a money formatted string.

        places:  required number of places after the decimal point
        curr:    optional currency symbol before the sign (may be blank)
        sep:     optional grouping separator (comma, period, space, or blank)
        dp:      decimal point indicator (comma or period)
                 only specify as blank when places is zero
        pos:     optional sign for positive numbers: '+', space or blank
        neg:     optional sign for negative numbers: '-', '(', space or blank
        trailneg:optional trailing minus indicator:  '-', ')', space or blank

        >>> d = Decimal('-1234567.8901')
        >>> moneyfmt(d, curr='$')
        '-$1,234,567.89'
        >>> moneyfmt(d, places=0, sep='.', dp='', neg='', trailneg='-')
        '1.234.568-'
        >>> moneyfmt(d, curr='$', neg='(', trailneg=')')
        '($1,234,567.89)'
        >>> moneyfmt(Decimal(123456789), sep=' ')
        '123 456 789.00'
        >>> moneyfmt(Decimal('-0.02'), neg='<', trailneg='>')
        '<0.02>'

        """
        q = Decimal(10) ** -places      # 2 places --> '0.01'
        sign, digits, exp = value.quantize(q).as_tuple()
        result = []
        digits = map(str, digits)
        build, next = result.append, digits.pop
        if sign:
            build(trailneg)
        for i in range(places):
            build(next() if digits else '0')
        build(dp)
        if not digits:
            build('0')
        i = 0
        while digits:
            build(next())
            i += 1
            if i == 3 and digits:
                i = 0
                build(sep)
        build(curr)
        build(neg if sign else pos)
        return ''.join(reversed(result))

    def pi():
        """Compute Pi to the current precision.

        >>> print pi()
        3.141592653589793238462643383

        """
        getcontext().prec += 2  # extra digits for intermediate steps
        three = Decimal(3)      # substitute "three=3.0" for regular floats
        lasts, t, s, n, na, d, da = 0, three, 3, 1, 0, 0, 24
        while s != lasts:
            lasts = s
            n, na = n+na, na+8
            d, da = d+da, da+32
            t = (t * n) / d
            s += t
        getcontext().prec -= 2
        return +s               # unary plus applies the new precision

    def exp(x):
        """Return e raised to the power of x.  Result type matches input type.

        >>> print exp(Decimal(1))
        2.718281828459045235360287471
        >>> print exp(Decimal(2))
        7.389056098930650227230427461
        >>> print exp(2.0)
        7.38905609893
        >>> print exp(2+0j)
        (7.38905609893+0j)

        """
        getcontext().prec += 2
        i, lasts, s, fact, num = 0, 0, 1, 1, 1
        while s != lasts:
            lasts = s
            i += 1
            fact *= i
            num *= x
            s += num / fact
        getcontext().prec -= 2
        return +s

    def cos(x):
        """Return the cosine of x as measured in radians.

        >>> print cos(Decimal('0.5'))
        0.8775825618903727161162815826
        >>> print cos(0.5)
        0.87758256189
        >>> print cos(0.5+0j)
        (0.87758256189+0j)

        """
        getcontext().prec += 2
        i, lasts, s, fact, num, sign = 0, 0, 1, 1, 1, 1
        while s != lasts:
            lasts = s
            i += 2
            fact *= i * (i-1)
            num *= x * x
            sign *= -1
            s += num / fact * sign
        getcontext().prec -= 2
        return +s

    def sin(x):
        """Return the sine of x as measured in radians.

        >>> print sin(Decimal('0.5'))
        0.4794255386042030002732879352
        >>> print sin(0.5)
        0.479425538604
        >>> print sin(0.5+0j)
        (0.479425538604+0j)

        """
        getcontext().prec += 2
        i, lasts, s, fact, num, sign = 1, 0, x, 1, x, 1
        while s != lasts:
            lasts = s
            i += 2
            fact *= i * (i-1)
            num *= x * x
            sign *= -1
            s += num / fact * sign
        getcontext().prec -= 2
        return +s


File: python.info,  Node: Decimal FAQ,  Prev: Recipes,  Up: decimal — Decimal fixed point and floating point arithmetic

5.9.4.11 Decimal FAQ
....................

Q. It is cumbersome to type `decimal.Decimal('1234.5')'.  Is there a
way to minimize typing when using the interactive interpreter?

A. Some users abbreviate the constructor to just a single letter:

    >>> D = decimal.Decimal
    >>> D('1.23') + D('3.45')
    Decimal('4.68')

Q. In a fixed-point application with two decimal places, some inputs
have many places and need to be rounded.  Others are not supposed to
have excess digits and need to be validated.  What methods should be
used?

A. The `quantize()' method rounds to a fixed number of decimal places.
If the *Note Inexact: cd9. trap is set, it is also useful for
validation:

    >>> TWOPLACES = Decimal(10) ** -2       # same as Decimal('0.01')

    >>> # Round to two places
    >>> Decimal('3.214').quantize(TWOPLACES)
    Decimal('3.21')

    >>> # Validate that a number does not exceed two places
    >>> Decimal('3.21').quantize(TWOPLACES, context=Context(traps=[Inexact]))
    Decimal('3.21')

    >>> Decimal('3.214').quantize(TWOPLACES, context=Context(traps=[Inexact]))
    Traceback (most recent call last):
       ...
    Inexact: None

Q. Once I have valid two place inputs, how do I maintain that invariant
throughout an application?

A. Some operations like addition, subtraction, and multiplication by an
integer will automatically preserve fixed point.  Others operations,
like division and non-integer multiplication, will change the number of
decimal places and need to be followed-up with a `quantize()' step:

    >>> a = Decimal('102.72')           # Initial fixed-point values
    >>> b = Decimal('3.17')
    >>> a + b                           # Addition preserves fixed-point
    Decimal('105.89')
    >>> a - b
    Decimal('99.55')
    >>> a * 42                          # So does integer multiplication
    Decimal('4314.24')
    >>> (a * b).quantize(TWOPLACES)     # Must quantize non-integer multiplication
    Decimal('325.62')
    >>> (b / a).quantize(TWOPLACES)     # And quantize division
    Decimal('0.03')

In developing fixed-point applications, it is convenient to define
functions to handle the `quantize()' step:

    >>> def mul(x, y, fp=TWOPLACES):
    ...     return (x * y).quantize(fp)
    >>> def div(x, y, fp=TWOPLACES):
    ...     return (x / y).quantize(fp)

    >>> mul(a, b)                       # Automatically preserve fixed-point
    Decimal('325.62')
    >>> div(b, a)
    Decimal('0.03')

Q. There are many ways to express the same value.  The numbers `200',
`200.000', `2E2', and `02E+4' all have the same value at various
precisions. Is there a way to transform them to a single recognizable
canonical value?

A. The `normalize()' method maps all equivalent values to a single
representative:

    >>> values = map(Decimal, '200 200.000 2E2 .02E+4'.split())
    >>> [v.normalize() for v in values]
    [Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2')]

Q. Some decimal values always print with exponential notation.  Is
there a way to get a non-exponential representation?

A. For some values, exponential notation is the only way to express the
number of significant places in the coefficient.  For example,
expressing `5.0E+3' as `5000' keeps the value constant but cannot show
the original’s two-place significance.

If an application does not care about tracking significance, it is easy
to remove the exponent and trailing zeros, losing significance, but
keeping the value unchanged:

    def remove_exponent(d):
        '''Remove exponent and trailing zeros.

        >>> remove_exponent(Decimal('5E+3'))
        Decimal('5000')

        '''
        return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()

Q. Is there a way to convert a regular float to a *Note Decimal: 1b5.?

A. Yes, any binary floating point number can be exactly expressed as a
Decimal though an exact conversion may take more precision than
intuition would suggest:

    >>> Decimal(math.pi)
    Decimal('3.141592653589793115997963468544185161590576171875')

Q. Within a complex calculation, how can I make sure that I haven’t
gotten a spurious result because of insufficient precision or rounding
anomalies.

A. The decimal module makes it easy to test results.  A best practice
is to re-run calculations using greater precision and with various
rounding modes.  Widely differing results indicate insufficient
precision, rounding mode issues, ill-conditioned inputs, or a
numerically unstable algorithm.

Q. I noticed that context precision is applied to the results of
operations but not to the inputs.  Is there anything to watch out for
when mixing values of different precisions?

A. Yes.  The principle is that all values are considered to be exact
and so is the arithmetic on those values.  Only the results are
rounded.  The advantage for inputs is that “what you type is what you
get”.  A disadvantage is that the results can look odd if you forget
that the inputs haven’t been rounded:

    >>> getcontext().prec = 3
    >>> Decimal('3.104') + Decimal('2.104')
    Decimal('5.21')
    >>> Decimal('3.104') + Decimal('0.000') + Decimal('2.104')
    Decimal('5.20')

The solution is either to increase precision or to force rounding of
inputs using the unary plus operation:

    >>> getcontext().prec = 3
    >>> +Decimal('1.23456789')      # unary plus triggers rounding
    Decimal('1.23')

Alternatively, inputs can be rounded upon creation using the *Note
Context.create_decimal(): d21. method:

    >>> Context(prec=5, rounding=ROUND_DOWN).create_decimal('1.2345678')
    Decimal('1.2345')


File: python.info,  Node: fractions — Rational numbers,  Next: random — Generate pseudo-random numbers,  Prev: decimal — Decimal fixed point and floating point arithmetic,  Up: Numeric and Mathematical Modules

5.9.5 `fractions' — Rational numbers
--------------------------------------

New in version 2.6.

`Source code:' Lib/fractions.py(1)

__________________________________________________________________

The *Note fractions: d7. module provides support for rational number
arithmetic.

A Fraction instance can be constructed from a pair of integers, from
another rational number, or from a string.

 -- Class: fractions.Fraction (numerator=0, denominator=1)
 -- Class: fractions.Fraction (other_fraction)
 -- Class: fractions.Fraction (float)
 -- Class: fractions.Fraction (decimal)
 -- Class: fractions.Fraction (string)
     The first version requires that `numerator' and `denominator' are
     instances of *Note numbers.Rational: 33e. and returns a new *Note
     Fraction: 217. instance with value `numerator/denominator'. If
     `denominator' is `0', it raises a *Note ZeroDivisionError: 5c7.
     The second version requires that `other_fraction' is an instance
     of *Note numbers.Rational: 33e. and returns a *Note Fraction: 217.
     instance with the same value.  The next two versions accept either
     a *Note float: 1eb. or a *Note decimal.Decimal: 1b5. instance, and
     return a *Note Fraction: 217. instance with exactly the same
     value.  Note that due to the usual issues with binary
     floating-point (see *Note Floating Point Arithmetic; Issues and
     Limitations: 640.), the argument to `Fraction(1.1)' is not exactly
     equal to 11/10, and so `Fraction(1.1)' does `not' return
     `Fraction(11, 10)' as one might expect.  (But see the
     documentation for the *Note limit_denominator(): d6c. method
     below.)  The last version of the constructor expects a string or
     unicode instance.  The usual form for this instance is:

         [sign] numerator ['/' denominator]

     where the optional `sign' may be either ‘+’ or ‘-‘ and
     `numerator' and `denominator' (if present) are strings of decimal
     digits.  In addition, any string that represents a finite value
     and is accepted by the *Note float: 1eb. constructor is also
     accepted by the *Note Fraction: 217. constructor.  In either form
     the input string may also have leading and/or trailing whitespace.
     Here are some examples:

         >>> from fractions import Fraction
         >>> Fraction(16, -10)
         Fraction(-8, 5)
         >>> Fraction(123)
         Fraction(123, 1)
         >>> Fraction()
         Fraction(0, 1)
         >>> Fraction('3/7')
         Fraction(3, 7)
         >>> Fraction(' -3/7 ')
         Fraction(-3, 7)
         >>> Fraction('1.414213 \t\n')
         Fraction(1414213, 1000000)
         >>> Fraction('-.125')
         Fraction(-1, 8)
         >>> Fraction('7e-6')
         Fraction(7, 1000000)
         >>> Fraction(2.25)
         Fraction(9, 4)
         >>> Fraction(1.1)
         Fraction(2476979795053773, 2251799813685248)
         >>> from decimal import Decimal
         >>> Fraction(Decimal('1.1'))
         Fraction(11, 10)

     The *Note Fraction: 217. class inherits from the abstract base
     class *Note numbers.Rational: 33e, and implements all of the
     methods and operations from that class.  *Note Fraction: 217.
     instances are hashable, and should be treated as immutable.  In
     addition, *Note Fraction: 217. has the following methods:

     Changed in version 2.7: The *Note Fraction: 217. constructor now
     accepts *Note float: 1eb. and *Note decimal.Decimal: 1b5.
     instances.

      -- Method: from_float (flt)
          This class method constructs a *Note Fraction: 217.
          representing the exact value of `flt', which must be a *Note
          float: 1eb. Beware that `Fraction.from_float(0.3)' is not the
          same value as `Fraction(3, 10)'.

               Note: From Python 2.7 onwards, you can also construct a
               *Note Fraction: 217. instance directly from a *Note
               float: 1eb.

      -- Method: from_decimal (dec)
          This class method constructs a *Note Fraction: 217.
          representing the exact value of `dec', which must be a *Note
          decimal.Decimal: 1b5.

               Note: From Python 2.7 onwards, you can also construct a
               *Note Fraction: 217. instance directly from a *Note
               decimal.Decimal: 1b5.  instance.

      -- Method: limit_denominator (max_denominator=1000000)
          Finds and returns the closest *Note Fraction: 217. to `self'
          that has denominator at most max_denominator.  This method is
          useful for finding rational approximations to a given
          floating-point number:

              >>> from fractions import Fraction
              >>> Fraction('3.1415926535897932').limit_denominator(1000)
              Fraction(355, 113)

          or for recovering a rational number that’s represented as a
          float:

              >>> from math import pi, cos
              >>> Fraction(cos(pi/3))
              Fraction(4503599627370497, 9007199254740992)
              >>> Fraction(cos(pi/3)).limit_denominator()
              Fraction(1, 2)
              >>> Fraction(1.1).limit_denominator()
              Fraction(11, 10)

 -- Function: fractions.gcd (a, b)
     Return the greatest common divisor of the integers `a' and `b'.
     If either `a' or `b' is nonzero, then the absolute value of
     `gcd(a, b)' is the largest integer that divides both `a' and `b'.
     `gcd(a,b)' has the same sign as `b' if `b' is nonzero; otherwise
     it takes the sign of `a'.  `gcd(0, 0)' returns `0'.

See also
........

Module *Note numbers: 126.
     The abstract base classes making up the numeric tower.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/fractions.py


File: python.info,  Node: random — Generate pseudo-random numbers,  Next: itertools — Functions creating iterators for efficient looping,  Prev: fractions — Rational numbers,  Up: Numeric and Mathematical Modules

5.9.6 `random' — Generate pseudo-random numbers
-------------------------------------------------

`Source code:' Lib/random.py(1)

__________________________________________________________________

This module implements pseudo-random number generators for various
distributions.

For integers, uniform selection from a range. For sequences, uniform
selection of a random element, a function to generate a random
permutation of a list in-place, and a function for random sampling
without replacement.

On the real line, there are functions to compute uniform, normal
(Gaussian), lognormal, negative exponential, gamma, and beta
distributions. For generating distributions of angles, the von Mises
distribution is available.

Almost all module functions depend on the basic function *Note
random(): d72, which generates a random float uniformly in the
semi-open range [0.0, 1.0).  Python uses the Mersenne Twister as the
core generator.  It produces 53-bit precision floats and has a period
of 2**19937-1.  The underlying implementation in C is both fast and
threadsafe.  The Mersenne Twister is one of the most extensively tested
random number generators in existence.  However, being completely
deterministic, it is not suitable for all purposes, and is completely
unsuitable for cryptographic purposes.

The functions supplied by this module are actually bound methods of a
hidden instance of the `random.Random' class.  You can instantiate your
own instances of `Random' to get generators that don’t share state.
This is especially useful for multi-threaded programs, creating a
different instance of `Random' for each thread, and using the *Note
jumpahead(): d73. method to make it likely that the generated sequences
seen by each thread don’t overlap.

Class `Random' can also be subclassed if you want to use a different
basic generator of your own devising: in that case, override the
`random()', `seed()', `getstate()', `setstate()' and `jumpahead()'
methods.  Optionally, a new generator can supply a `getrandbits()'
method — this allows *Note randrange(): d74. to produce selections
over an arbitrarily large range.

New in version 2.4: the *Note getrandbits(): d75. method.

As an example of subclassing, the *Note random: 143. module provides the
*Note WichmannHill: d76. class that implements an alternative generator
in pure Python.  The class provides a backward compatible way to
reproduce results from earlier versions of Python, which used the
Wichmann-Hill algorithm as the core generator.  Note that this
Wichmann-Hill generator can no longer be recommended: its period is too
short by contemporary standards, and the sequence generated is known to
fail some stringent randomness tests.  See the references below for a
recent variant that repairs these flaws.

Changed in version 2.3: MersenneTwister replaced Wichmann-Hill as the
default generator.

The *Note random: 143. module also provides the *Note SystemRandom:
d77. class which uses the system function *Note os.urandom(): 2e6. to
generate random numbers from sources provided by the operating system.

     Warning: The pseudo-random generators of this module should not be
     used for security purposes.  Use *Note os.urandom(): 2e6. or *Note
     SystemRandom: d77. if you require a cryptographically secure
     pseudo-random number generator.

Bookkeeping functions:

 -- Function: random.seed ([x])
     Initialize the basic random number generator. Optional argument
     `x' can be any *Note hashable: 720. object. If `x' is omitted or
     `None', current system time is used; current system time is also
     used to initialize the generator when the module is first
     imported.  If randomness sources are provided by the operating
     system, they are used instead of the system time (see the *Note
     os.urandom(): 2e6. function for details on availability).

     If a *Note hashable: 720. object is given, deterministic results
     are only assured when *Note PYTHONHASHSEED: 668. is disabled.

     Changed in version 2.4: formerly, operating system resources were
     not used.


 -- Function: random.getstate ()
     Return an object capturing the current internal state of the
     generator.  This object can be passed to *Note setstate(): d7a. to
     restore the state.

     New in version 2.1.

     Changed in version 2.6: State values produced in Python 2.6 cannot
     be loaded into earlier versions.


 -- Function: random.setstate (state)
     `state' should have been obtained from a previous call to *Note
     getstate(): d79, and *Note setstate(): d7a. restores the internal
     state of the generator to what it was at the time *Note
     getstate(): d79. was called.

     New in version 2.1.


 -- Function: random.jumpahead (n)
     Change the internal state to one different from and likely far
     away from the current state.  `n' is a non-negative integer which
     is used to scramble the current state vector.  This is most useful
     in multi-threaded programs, in conjunction with multiple instances
     of the `Random' class: *Note setstate(): d7a. or *Note seed():
     d78. can be used to force all instances into the same internal
     state, and then *Note jumpahead(): d73. can be used to force the
     instances’ states far apart.

     New in version 2.1.

     Changed in version 2.3: Instead of jumping to a specific state,
     `n' steps ahead, `jumpahead(n)' jumps to another state likely to
     be separated by many steps.


 -- Function: random.getrandbits (k)
     Returns a python *Note long: 1f3. int with `k' random bits. This
     method is supplied with the MersenneTwister generator and some
     other generators may also provide it as an optional part of the
     API. When available, *Note getrandbits(): d75. enables *Note
     randrange(): d74. to handle arbitrarily large ranges.

     New in version 2.4.


Functions for integers:

 -- Function: random.randrange (stop)
 -- Function: random.randrange (start, stop[, step])
     Return a randomly selected element from `range(start, stop,
     step)'.  This is equivalent to `choice(range(start, stop, step))',
     but doesn’t actually build a range object.

     New in version 1.5.2.


 -- Function: random.randint (a, b)
     Return a random integer `N' such that `a <= N <= b'.

Functions for sequences:

 -- Function: random.choice (seq)
     Return a random element from the non-empty sequence `seq'. If
     `seq' is empty, raises *Note IndexError: 4fe.

 -- Function: random.shuffle (x[, random])
     Shuffle the sequence `x' in place. The optional argument `random'
     is a 0-argument function returning a random float in [0.0, 1.0);
     by default, this is the function *Note random(): d72.

     Note that for even rather small `len(x)', the total number of
     permutations of `x' is larger than the period of most random
     number generators; this implies that most permutations of a long
     sequence can never be generated.

 -- Function: random.sample (population, k)
     Return a `k' length list of unique elements chosen from the
     population sequence.  Used for random sampling without replacement.

     New in version 2.3.

     Returns a new list containing elements from the population while
     leaving the original population unchanged.  The resulting list is
     in selection order so that all sub-slices will also be valid
     random samples.  This allows raffle winners (the sample) to be
     partitioned into grand prize and second place winners (the
     subslices).

     Members of the population need not be *Note hashable: 720. or
     unique.  If the population contains repeats, then each occurrence
     is a possible selection in the sample.

     To choose a sample from a range of integers, use an *Note
     xrange(): 477. object as an argument.  This is especially fast and
     space efficient for sampling from a large population:
     `sample(xrange(10000000), 60)'.

The following functions generate specific real-valued distributions.
Function parameters are named after the corresponding variables in the
distribution’s equation, as used in common mathematical practice;
most of these equations can be found in any statistics text.

 -- Function: random.random ()
     Return the next random floating point number in the range [0.0,
     1.0).

 -- Function: random.uniform (a, b)
     Return a random floating point number `N' such that `a <= N <= b'
     for `a <= b' and `b <= N <= a' for `b < a'.

     The end-point value `b' may or may not be included in the range
     depending on floating-point rounding in the equation `a + (b-a) *
     random()'.

 -- Function: random.triangular (low, high, mode)
     Return a random floating point number `N' such that `low <= N <=
     high' and with the specified `mode' between those bounds.  The
     `low' and `high' bounds default to zero and one.  The `mode'
     argument defaults to the midpoint between the bounds, giving a
     symmetric distribution.

     New in version 2.6.


 -- Function: random.betavariate (alpha, beta)
     Beta distribution.  Conditions on the parameters are `alpha > 0'
     and `beta > 0'. Returned values range between 0 and 1.

 -- Function: random.expovariate (lambd)
     Exponential distribution.  `lambd' is 1.0 divided by the desired
     mean.  It should be nonzero.  (The parameter would be called
     “lambda”, but that is a reserved word in Python.)  Returned
     values range from 0 to positive infinity if `lambd' is positive,
     and from negative infinity to 0 if `lambd' is negative.

 -- Function: random.gammavariate (alpha, beta)
     Gamma distribution.  (`Not' the gamma function!)  Conditions on the
     parameters are `alpha > 0' and `beta > 0'.

     The probability distribution function is:

                   x ** (alpha - 1) * math.exp(-x / beta)
         pdf(x) =  --------------------------------------
                     math.gamma(alpha) * beta ** alpha

 -- Function: random.gauss (mu, sigma)
     Gaussian distribution.  `mu' is the mean, and `sigma' is the
     standard deviation.  This is slightly faster than the *Note
     normalvariate(): d85. function defined below.

 -- Function: random.lognormvariate (mu, sigma)
     Log normal distribution.  If you take the natural logarithm of this
     distribution, you’ll get a normal distribution with mean `mu'
     and standard deviation `sigma'.  `mu' can have any value, and
     `sigma' must be greater than zero.

 -- Function: random.normalvariate (mu, sigma)
     Normal distribution.  `mu' is the mean, and `sigma' is the
     standard deviation.

 -- Function: random.vonmisesvariate (mu, kappa)
     `mu' is the mean angle, expressed in radians between 0 and 2*`pi',
     and `kappa' is the concentration parameter, which must be greater
     than or equal to zero.  If `kappa' is equal to zero, this
     distribution reduces to a uniform random angle over the range 0 to
     2*`pi'.

 -- Function: random.paretovariate (alpha)
     Pareto distribution.  `alpha' is the shape parameter.

 -- Function: random.weibullvariate (alpha, beta)
     Weibull distribution.  `alpha' is the scale parameter and `beta'
     is the shape parameter.

Alternative Generators:

 -- Class: random.WichmannHill ([seed])
     Class that implements the Wichmann-Hill algorithm as the core
     generator. Has all of the same methods as `Random' plus the *Note
     whseed(): d8a. method described below.  Because this class is
     implemented in pure Python, it is not threadsafe and may require
     locks between calls.  The period of the generator is
     6,953,607,871,644 which is small enough to require care that two
     independent random sequences do not overlap.

 -- Function: random.whseed ([x])
     This is obsolete, supplied for bit-level compatibility with
     versions of Python prior to 2.1. See *Note seed(): d78. for
     details.  *Note whseed(): d8a. does not guarantee that distinct
     integer arguments yield distinct internal states, and can yield no
     more than about 2**24 distinct internal states in all.

 -- Class: random.SystemRandom ([seed])
     Class that uses the *Note os.urandom(): 2e6. function for
     generating random numbers from sources provided by the operating
     system. Not available on all systems.  Does not rely on software
     state and sequences are not reproducible. Accordingly, the *Note
     seed(): d78. and *Note jumpahead(): d73. methods have no effect
     and are ignored.  The *Note getstate(): d79. and *Note setstate():
     d7a. methods raise *Note NotImplementedError: 978. if called.

     New in version 2.4.


Examples of basic usage:

    >>> random.random()        # Random float x, 0.0 <= x < 1.0
    0.37444887175646646
    >>> random.uniform(1, 10)  # Random float x, 1.0 <= x < 10.0
    1.1800146073117523
    >>> random.randint(1, 10)  # Integer from 1 to 10, endpoints included
    7
    >>> random.randrange(0, 101, 2)  # Even integer from 0 to 100
    26
    >>> random.choice('abcdefghij')  # Choose a random element
    'c'

    >>> items = [1, 2, 3, 4, 5, 6, 7]
    >>> random.shuffle(items)
    >>> items
    [7, 3, 2, 5, 6, 4, 1]

    >>> random.sample([1, 2, 3, 4, 5],  3)  # Choose 3 elements
    [4, 1, 5]

See also
........

M. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally
equidistributed uniform pseudorandom number generator”, ACM
Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January
pp.3–30 1998.

Wichmann, B. A. & Hill, I. D., “Algorithm AS 183: An efficient and
portable pseudo-random number generator”, Applied Statistics 31
(1982) 188-190.

Complementary-Multiply-with-Carry recipe(2) for a compatible alternative
random number generator with a long period and comparatively simple
update operations.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/random.py

(2) http://code.activestate.com/recipes/576707/


File: python.info,  Node: itertools — Functions creating iterators for efficient looping,  Next: functools — Higher-order functions and operations on callable objects,  Prev: random — Generate pseudo-random numbers,  Up: Numeric and Mathematical Modules

5.9.7 `itertools' — Functions creating iterators for efficient looping
------------------------------------------------------------------------

New in version 2.3.

This module implements a number of *Note iterator: 8a8. building blocks
inspired by constructs from APL, Haskell, and SML.  Each has been
recast in a form suitable for Python.

The module standardizes a core set of fast, memory efficient tools that
are useful by themselves or in combination.  Together, they form an
“iterator algebra” making it possible to construct specialized
tools succinctly and efficiently in pure Python.

For instance, SML provides a tabulation tool: `tabulate(f)' which
produces a sequence `f(0), f(1), ...'.  The same effect can be achieved
in Python by combining *Note imap(): d8d. and *Note count(): 234. to
form `imap(f, count())'.

These tools and their built-in counterparts also work well with the
high-speed functions in the *Note operator: 127. module.  For example,
the multiplication operator can be mapped across two vectors to form an
efficient dot-product: `sum(imap(operator.mul, vector1, vector2))'.

`Infinite Iterators:'

Iterator               Arguments             Results                                               Example
------------------------------------------------------------------------------------------------------------------------------------------------- 
*Note count(): 234.    start, [step]         start, start+step, start+2*step, …                  `count(10) --> 10 11 12 13 14 ...'
*Note cycle(): d8e.    p                     p0, p1, … plast, p0, p1, …                        `cycle('ABCD') --> A B C D A B C D ...'
*Note repeat(): b9a.   elem [,n]             elem, elem, elem, … endlessly or up to n times      `repeat(10, 3) --> 10 10 10'

`Iterators terminating on the shortest input sequence:'

Iterator                 Arguments                        Results                                               Example
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
*Note chain(): 8b7.      p, q, …                        p0, p1, … plast, q0, q1, …                        `chain('ABC', 'DEF') --> A B C D E F'
*Note compress(): d8f.   data, selectors                  (d[0] if s[0]), (d[1] if s[1]), …                   `compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F'
*Note dropwhile(): d90.  pred, seq                        seq[n], seq[n+1], starting when pred fails            `dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1'
*Note groupby(): d91.    iterable[, keyfunc]              sub-iterators grouped by value of keyfunc(v)          
*Note ifilter(): 8aa.    pred, seq                        elements of seq where pred(elem) is true              `ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9'
*Note ifilterfalse():    pred, seq                        elements of seq where pred(elem) is false             `ifilterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8'
8ab.                                                                                                            
*Note islice(): 3db.     seq, [start,] stop [, step]      elements from seq[start:stop:step]                    `islice('ABCDEFG', 2, None) --> C D E F G'
*Note imap(): d8d.       func, p, q, …                  func(p0, q0), func(p1, q1), …                       `imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000'
*Note starmap(): d92.    func, seq                        func(*seq[0]), func(*seq[1]), …                     `starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000'
*Note tee(): d93.        it, n                            it1, it2, … itn  splits one iterator into n         
*Note takewhile(): d94.  pred, seq                        seq[0], seq[1], until pred fails                      `takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4'
*Note izip(): 41f.       p, q, …                        (p[0], q[0]), (p[1], q[1]), …                       `izip('ABCD', 'xy') --> Ax By'
*Note izip_longest():    p, q, …                        (p[0], q[0]), (p[1], q[1]), …                       `izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-'
d95.                                                                                                            

`Combinatoric generators:'

Iterator                                           Arguments                Results
---------------------------------------------------------------------------------------------------------------------------------------------- 
*Note product(): 235.                              p, q, … [repeat=1]     cartesian product, equivalent to a nested for-loop
*Note permutations(): d96.                         p[, r]                   r-length tuples, all possible orderings, no repeated elements
*Note combinations(): 233.                         p, r                     r-length tuples, in sorted order, no repeated elements
*Note combinations_with_replacement(): b8a.        p, r                     r-length tuples, in sorted order, with repeated elements
`product('ABCD', repeat=2)'                                                 `AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD'
`permutations('ABCD', 2)'                                                   `AB AC AD BA BC BD CA CB CD DA DB DC'
`combinations('ABCD', 2)'                                                   `AB AC AD BC BD CD'
`combinations_with_replacement('ABCD', 2)'                                  `AA AB AC AD BB BC BD CC CD DD'

* Menu:

* Itertool functions::
* Recipes: Recipes<2>.


File: python.info,  Node: Itertool functions,  Next: Recipes<2>,  Up: itertools — Functions creating iterators for efficient looping

5.9.7.1 Itertool functions
..........................

The following module functions all construct and return iterators. Some
provide streams of infinite length, so they should only be accessed by
functions or loops that truncate the stream.

 -- Function: itertools.chain (*iterables)
     Make an iterator that returns elements from the first iterable
     until it is exhausted, then proceeds to the next iterable, until
     all of the iterables are exhausted.  Used for treating consecutive
     sequences as a single sequence.  Roughly equivalent to:

         def chain(*iterables):
             # chain('ABC', 'DEF') --> A B C D E F
             for it in iterables:
                 for element in it:
                     yield element

 -- Class Method: chain.from_iterable (iterable)
     Alternate constructor for *Note chain(): 8b7.  Gets chained inputs
     from a single iterable argument that is evaluated lazily.  Roughly
     equivalent to:

         def from_iterable(iterables):
             # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
             for it in iterables:
                 for element in it:
                     yield element

     New in version 2.6.


 -- Function: itertools.combinations (iterable, r)
     Return `r' length subsequences of elements from the input
     `iterable'.

     Combinations are emitted in lexicographic sort order.  So, if the
     input `iterable' is sorted, the combination tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, there will be
     no repeat values in each combination.

     Roughly equivalent to:

         def combinations(iterable, r):
             # combinations('ABCD', 2) --> AB AC AD BC BD CD
             # combinations(range(4), 3) --> 012 013 023 123
             pool = tuple(iterable)
             n = len(pool)
             if r > n:
                 return
             indices = range(r)
             yield tuple(pool[i] for i in indices)
             while True:
                 for i in reversed(range(r)):
                     if indices[i] != i + n - r:
                         break
                 else:
                     return
                 indices[i] += 1
                 for j in range(i+1, r):
                     indices[j] = indices[j-1] + 1
                 yield tuple(pool[i] for i in indices)

     The code for *Note combinations(): 233. can be also expressed as a
     subsequence of *Note permutations(): d96. after filtering entries
     where the elements are not in sorted order (according to their
     position in the input pool):

         def combinations(iterable, r):
             pool = tuple(iterable)
             n = len(pool)
             for indices in permutations(range(n), r):
                 if sorted(indices) == list(indices):
                     yield tuple(pool[i] for i in indices)

     The number of items returned is `n! / r! / (n-r)!' when `0 <= r <=
     n' or zero when `r > n'.

     New in version 2.6.


 -- Function: itertools.combinations_with_replacement (iterable, r)
     Return `r' length subsequences of elements from the input
     `iterable' allowing individual elements to be repeated more than
     once.

     Combinations are emitted in lexicographic sort order.  So, if the
     input `iterable' is sorted, the combination tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, the generated
     combinations will also be unique.

     Roughly equivalent to:

         def combinations_with_replacement(iterable, r):
             # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
             pool = tuple(iterable)
             n = len(pool)
             if not n and r:
                 return
             indices = [0] * r
             yield tuple(pool[i] for i in indices)
             while True:
                 for i in reversed(range(r)):
                     if indices[i] != n - 1:
                         break
                 else:
                     return
                 indices[i:] = [indices[i] + 1] * (r - i)
                 yield tuple(pool[i] for i in indices)

     The code for *Note combinations_with_replacement(): b8a. can be
     also expressed as a subsequence of *Note product(): 235. after
     filtering entries where the elements are not in sorted order
     (according to their position in the input pool):

         def combinations_with_replacement(iterable, r):
             pool = tuple(iterable)
             n = len(pool)
             for indices in product(range(n), repeat=r):
                 if sorted(indices) == list(indices):
                     yield tuple(pool[i] for i in indices)

     The number of items returned is `(n+r-1)! / r! / (n-1)!' when `n >
     0'.

     New in version 2.7.


 -- Function: itertools.compress (data, selectors)
     Make an iterator that filters elements from `data' returning only
     those that have a corresponding element in `selectors' that
     evaluates to `True'.  Stops when either the `data' or `selectors'
     iterables has been exhausted.  Roughly equivalent to:

         def compress(data, selectors):
             # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
             return (d for d, s in izip(data, selectors) if s)

     New in version 2.7.


 -- Function: itertools.count (start=0, step=1)
     Make an iterator that returns evenly spaced values starting with
     `n'. Often used as an argument to *Note imap(): d8d. to generate
     consecutive data points.  Also, used with *Note izip(): 41f. to
     add sequence numbers.  Equivalent to:

         def count(start=0, step=1):
             # count(10) --> 10 11 12 13 14 ...
             # count(2.5, 0.5) -> 2.5 3.0 3.5 ...
             n = start
             while True:
                 yield n
                 n += step

     When counting with floating point numbers, better accuracy can
     sometimes be achieved by substituting multiplicative code such as:
     `(start + step * i for i in count())'.

     Changed in version 2.7: added `step' argument and allowed
     non-integer arguments.


 -- Function: itertools.cycle (iterable)
     Make an iterator returning elements from the iterable and saving a
     copy of each.  When the iterable is exhausted, return elements
     from the saved copy.  Repeats indefinitely.  Roughly equivalent to:

         def cycle(iterable):
             # cycle('ABCD') --> A B C D A B C D A B C D ...
             saved = []
             for element in iterable:
                 yield element
                 saved.append(element)
             while saved:
                 for element in saved:
                       yield element

     Note, this member of the toolkit may require significant auxiliary
     storage (depending on the length of the iterable).

 -- Function: itertools.dropwhile (predicate, iterable)
     Make an iterator that drops elements from the iterable as long as
     the predicate is true; afterwards, returns every element.  Note,
     the iterator does not produce `any' output until the predicate
     first becomes false, so it may have a lengthy start-up time.
     Roughly equivalent to:

         def dropwhile(predicate, iterable):
             # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
             iterable = iter(iterable)
             for x in iterable:
                 if not predicate(x):
                     yield x
                     break
             for x in iterable:
                 yield x

 -- Function: itertools.groupby (iterable[, key])
     Make an iterator that returns consecutive keys and groups from the
     `iterable'.  The `key' is a function computing a key value for
     each element.  If not specified or is `None', `key' defaults to an
     identity function and returns the element unchanged.  Generally,
     the iterable needs to already be sorted on the same key function.

     The operation of *Note groupby(): d91. is similar to the `uniq'
     filter in Unix.  It generates a break or new group every time the
     value of the key function changes (which is why it is usually
     necessary to have sorted the data using the same key function).
     That behavior differs from SQL’s GROUP BY which aggregates common
     elements regardless of their input order.

     The returned group is itself an iterator that shares the
     underlying iterable with *Note groupby(): d91.  Because the source
     is shared, when the *Note groupby(): d91.  object is advanced, the
     previous group is no longer visible.  So, if that data is needed
     later, it should be stored as a list:

         groups = []
         uniquekeys = []
         data = sorted(data, key=keyfunc)
         for k, g in groupby(data, keyfunc):
             groups.append(list(g))      # Store group iterator as a list
             uniquekeys.append(k)

     *Note groupby(): d91. is roughly equivalent to:

         class groupby(object):
             # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
             # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
             def __init__(self, iterable, key=None):
                 if key is None:
                     key = lambda x: x
                 self.keyfunc = key
                 self.it = iter(iterable)
                 self.tgtkey = self.currkey = self.currvalue = object()
             def __iter__(self):
                 return self
             def next(self):
                 while self.currkey == self.tgtkey:
                     self.currvalue = next(self.it)    # Exit on StopIteration
                     self.currkey = self.keyfunc(self.currvalue)
                 self.tgtkey = self.currkey
                 return (self.currkey, self._grouper(self.tgtkey))
             def _grouper(self, tgtkey):
                 while self.currkey == tgtkey:
                     yield self.currvalue
                     self.currvalue = next(self.it)    # Exit on StopIteration
                     self.currkey = self.keyfunc(self.currvalue)

     New in version 2.4.


 -- Function: itertools.ifilter (predicate, iterable)
     Make an iterator that filters elements from iterable returning
     only those for which the predicate is `True'. If `predicate' is
     `None', return the items that are true. Roughly equivalent to:

         def ifilter(predicate, iterable):
             # ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9
             if predicate is None:
                 predicate = bool
             for x in iterable:
                 if predicate(x):
                     yield x

 -- Function: itertools.ifilterfalse (predicate, iterable)
     Make an iterator that filters elements from iterable returning
     only those for which the predicate is `False'. If `predicate' is
     `None', return the items that are false. Roughly equivalent to:

         def ifilterfalse(predicate, iterable):
             # ifilterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
             if predicate is None:
                 predicate = bool
             for x in iterable:
                 if not predicate(x):
                     yield x

 -- Function: itertools.imap (function, *iterables)
     Make an iterator that computes the function using arguments from
     each of the iterables.  If `function' is set to `None', then *Note
     imap(): d8d. returns the arguments as a tuple.  Like *Note map():
     318. but stops when the shortest iterable is exhausted instead of
     filling in `None' for shorter iterables.  The reason for the
     difference is that infinite iterator arguments are typically an
     error for *Note map(): 318. (because the output is fully
     evaluated) but represent a common and useful way of supplying
     arguments to *Note imap(): d8d. Roughly equivalent to:

         def imap(function, *iterables):
             # imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000
             iterables = map(iter, iterables)
             while True:
                 args = [next(it) for it in iterables]
                 if function is None:
                     yield tuple(args)
                 else:
                     yield function(*args)

 -- Function: itertools.islice (iterable, stop)
 -- Function: itertools.islice (iterable, start, stop[, step])
     Make an iterator that returns selected elements from the iterable.
     If `start' is non-zero, then elements from the iterable are
     skipped until start is reached.  Afterward, elements are returned
     consecutively unless `step' is set higher than one which results
     in items being skipped.  If `stop' is `None', then iteration
     continues until the iterator is exhausted, if at all; otherwise,
     it stops at the specified position.  Unlike regular slicing, *Note
     islice(): 3db. does not support negative values for `start',
     `stop', or `step'.  Can be used to extract related fields from
     data where the internal structure has been flattened (for example,
     a multi-line report may list a name field on every third line).
     Roughly equivalent to:

         def islice(iterable, *args):
             # islice('ABCDEFG', 2) --> A B
             # islice('ABCDEFG', 2, 4) --> C D
             # islice('ABCDEFG', 2, None) --> C D E F G
             # islice('ABCDEFG', 0, None, 2) --> A C E G
             s = slice(*args)
             it = iter(xrange(s.start or 0, s.stop or sys.maxint, s.step or 1))
             nexti = next(it)
             for i, element in enumerate(iterable):
                 if i == nexti:
                     yield element
                     nexti = next(it)

     If `start' is `None', then iteration starts at zero. If `step' is
     `None', then the step defaults to one.

     Changed in version 2.5: accept `None' values for default `start'
     and `step'.


 -- Function: itertools.izip (*iterables)
     Make an iterator that aggregates elements from each of the
     iterables. Like *Note zip(): 41e. except that it returns an
     iterator instead of a list.  Used for lock-step iteration over
     several iterables at a time.  Roughly equivalent to:

         def izip(*iterables):
             # izip('ABCD', 'xy') --> Ax By
             iterators = map(iter, iterables)
             while iterators:
                 yield tuple(map(next, iterators))

     Changed in version 2.4: When no iterables are specified, returns a
     zero length iterator instead of raising a *Note TypeError: 218.
     exception.

     The left-to-right evaluation order of the iterables is guaranteed.
     This makes possible an idiom for clustering a data series into
     n-length groups using `izip(*[iter(s)]*n)'.

     *Note izip(): 41f. should only be used with unequal length inputs
     when you don’t care about trailing, unmatched values from the
     longer iterables.  If those values are important, use *Note
     izip_longest(): d95. instead.

 -- Function: itertools.izip_longest (*iterables[, fillvalue])
     Make an iterator that aggregates elements from each of the
     iterables. If the iterables are of uneven length, missing values
     are filled-in with `fillvalue'.  Iteration continues until the
     longest iterable is exhausted.  Roughly equivalent to:

         class ZipExhausted(Exception):
             pass

         def izip_longest(*args, **kwds):
             # izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
             fillvalue = kwds.get('fillvalue')
             counter = [len(args) - 1]
             def sentinel():
                 if not counter[0]:
                     raise ZipExhausted
                 counter[0] -= 1
                 yield fillvalue
             fillers = repeat(fillvalue)
             iterators = [chain(it, sentinel(), fillers) for it in args]
             try:
                 while iterators:
                     yield tuple(map(next, iterators))
             except ZipExhausted:
                 pass

     If one of the iterables is potentially infinite, then the *Note
     izip_longest(): d95. function should be wrapped with something
     that limits the number of calls (for example *Note islice(): 3db.
     or *Note takewhile(): d94.).  If not specified, `fillvalue'
     defaults to `None'.

     New in version 2.6.


 -- Function: itertools.permutations (iterable[, r])
     Return successive `r' length permutations of elements in the
     `iterable'.

     If `r' is not specified or is `None', then `r' defaults to the
     length of the `iterable' and all possible full-length permutations
     are generated.

     Permutations are emitted in lexicographic sort order.  So, if the
     input `iterable' is sorted, the permutation tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, there will be
     no repeat values in each permutation.

     Roughly equivalent to:

         def permutations(iterable, r=None):
             # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
             # permutations(range(3)) --> 012 021 102 120 201 210
             pool = tuple(iterable)
             n = len(pool)
             r = n if r is None else r
             if r > n:
                 return
             indices = range(n)
             cycles = range(n, n-r, -1)
             yield tuple(pool[i] for i in indices[:r])
             while n:
                 for i in reversed(range(r)):
                     cycles[i] -= 1
                     if cycles[i] == 0:
                         indices[i:] = indices[i+1:] + indices[i:i+1]
                         cycles[i] = n - i
                     else:
                         j = cycles[i]
                         indices[i], indices[-j] = indices[-j], indices[i]
                         yield tuple(pool[i] for i in indices[:r])
                         break
                 else:
                     return

     The code for *Note permutations(): d96. can be also expressed as a
     subsequence of *Note product(): 235, filtered to exclude entries
     with repeated elements (those from the same position in the input
     pool):

         def permutations(iterable, r=None):
             pool = tuple(iterable)
             n = len(pool)
             r = n if r is None else r
             for indices in product(range(n), repeat=r):
                 if len(set(indices)) == r:
                     yield tuple(pool[i] for i in indices)

     The number of items returned is `n! / (n-r)!' when `0 <= r <= n'
     or zero when `r > n'.

     New in version 2.6.


 -- Function: itertools.product (*iterables[, repeat])
     Cartesian product of input iterables.

     Roughly equivalent to nested for-loops in a generator expression.
     For example, `product(A, B)' returns the same as `((x,y) for x in
     A for y in B)'.

     The nested loops cycle like an odometer with the rightmost element
     advancing on every iteration.  This pattern creates a
     lexicographic ordering so that if the input’s iterables are
     sorted, the product tuples are emitted in sorted order.

     To compute the product of an iterable with itself, specify the
     number of repetitions with the optional `repeat' keyword argument.
     For example, `product(A, repeat=4)' means the same as `product(A,
     A, A, A)'.

     This function is roughly equivalent to the following code, except
     that the actual implementation does not build up intermediate
     results in memory:

         def product(*args, **kwds):
             # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
             # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
             pools = map(tuple, args) * kwds.get('repeat', 1)
             result = [[]]
             for pool in pools:
                 result = [x+[y] for x in result for y in pool]
             for prod in result:
                 yield tuple(prod)

     New in version 2.6.


 -- Function: itertools.repeat (object[, times])
     Make an iterator that returns `object' over and over again. Runs
     indefinitely unless the `times' argument is specified. Used as
     argument to *Note imap(): d8d. for invariant function parameters.
     Also used with *Note izip(): 41f. to create constant fields in a
     tuple record.  Roughly equivalent to:

         def repeat(object, times=None):
             # repeat(10, 3) --> 10 10 10
             if times is None:
                 while True:
                     yield object
             else:
                 for i in xrange(times):
                     yield object

     A common use for `repeat' is to supply a stream of constant values
     to `imap' or `zip':

         >>> list(imap(pow, xrange(10), repeat(2)))
         [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

 -- Function: itertools.starmap (function, iterable)
     Make an iterator that computes the function using arguments
     obtained from the iterable.  Used instead of *Note imap(): d8d.
     when argument parameters are already grouped in tuples from a
     single iterable (the data has been “pre-zipped”).  The
     difference between *Note imap(): d8d. and *Note starmap(): d92.
     parallels the distinction between `function(a,b)' and
     `function(*c)'. Roughly equivalent to:

         def starmap(function, iterable):
             # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
             for args in iterable:
                 yield function(*args)

     Changed in version 2.6: Previously, *Note starmap(): d92. required
     the function arguments to be tuples.  Now, any iterable is allowed.


 -- Function: itertools.takewhile (predicate, iterable)
     Make an iterator that returns elements from the iterable as long
     as the predicate is true.  Roughly equivalent to:

         def takewhile(predicate, iterable):
             # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
             for x in iterable:
                 if predicate(x):
                     yield x
                 else:
                     break

 -- Function: itertools.tee (iterable[, n=2])
     Return `n' independent iterators from a single iterable.  Roughly
     equivalent to:

         def tee(iterable, n=2):
             it = iter(iterable)
             deques = [collections.deque() for i in range(n)]
             def gen(mydeque):
                 while True:
                     if not mydeque:             # when the local deque is empty
                         newval = next(it)       # fetch a new value and
                         for d in deques:        # load it to all the deques
                             d.append(newval)
                     yield mydeque.popleft()
             return tuple(gen(d) for d in deques)

     Once *Note tee(): d93. has made a split, the original `iterable'
     should not be used anywhere else; otherwise, the `iterable' could
     get advanced without the tee objects being informed.

     This itertool may require significant auxiliary storage (depending
     on how much temporary data needs to be stored). In general, if one
     iterator uses most or all of the data before another iterator
     starts, it is faster to use *Note list(): 3d6. instead of *Note
     tee(): d93.

     New in version 2.4.



File: python.info,  Node: Recipes<2>,  Prev: Itertool functions,  Up: itertools — Functions creating iterators for efficient looping

5.9.7.2 Recipes
...............

This section shows recipes for creating an extended toolset using the
existing itertools as building blocks.

The extended tools offer the same high performance as the underlying
toolset.  The superior memory performance is kept by processing
elements one at a time rather than bringing the whole iterable into
memory all at once. Code volume is kept small by linking the tools
together in a functional style which helps eliminate temporary
variables.  High speed is retained by preferring “vectorized”
building blocks over the use of for-loops and *Note generator: 5f7.s
which incur interpreter overhead.

    def take(n, iterable):
        "Return first n items of the iterable as a list"
        return list(islice(iterable, n))

    def tabulate(function, start=0):
        "Return function(0), function(1), ..."
        return imap(function, count(start))

    def consume(iterator, n):
        "Advance the iterator n-steps ahead. If n is none, consume entirely."
        # Use functions that consume iterators at C speed.
        if n is None:
            # feed the entire iterator into a zero-length deque
            collections.deque(iterator, maxlen=0)
        else:
            # advance to the empty slice starting at position n
            next(islice(iterator, n, n), None)

    def nth(iterable, n, default=None):
        "Returns the nth item or a default value"
        return next(islice(iterable, n, None), default)

    def all_equal(iterable):
        "Returns True if all the elements are equal to each other"
        g = groupby(iterable)
        return next(g, True) and not next(g, False)

    def quantify(iterable, pred=bool):
        "Count how many times the predicate is true"
        return sum(imap(pred, iterable))

    def padnone(iterable):
        """Returns the sequence elements and then returns None indefinitely.

        Useful for emulating the behavior of the built-in map() function.
        """
        return chain(iterable, repeat(None))

    def ncycles(iterable, n):
        "Returns the sequence elements n times"
        return chain.from_iterable(repeat(tuple(iterable), n))

    def dotproduct(vec1, vec2):
        return sum(imap(operator.mul, vec1, vec2))

    def flatten(listOfLists):
        "Flatten one level of nesting"
        return chain.from_iterable(listOfLists)

    def repeatfunc(func, times=None, *args):
        """Repeat calls to func with specified arguments.

        Example:  repeatfunc(random.random)
        """
        if times is None:
            return starmap(func, repeat(args))
        return starmap(func, repeat(args, times))

    def pairwise(iterable):
        "s -> (s0,s1), (s1,s2), (s2, s3), ..."
        a, b = tee(iterable)
        next(b, None)
        return izip(a, b)

    def grouper(iterable, n, fillvalue=None):
        "Collect data into fixed-length chunks or blocks"
        # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx
        args = [iter(iterable)] * n
        return izip_longest(fillvalue=fillvalue, *args)

    def roundrobin(*iterables):
        "roundrobin('ABC', 'D', 'EF') --> A D E B F C"
        # Recipe credited to George Sakkis
        pending = len(iterables)
        nexts = cycle(iter(it).next for it in iterables)
        while pending:
            try:
                for next in nexts:
                    yield next()
            except StopIteration:
                pending -= 1
                nexts = cycle(islice(nexts, pending))

    def powerset(iterable):
        "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
        s = list(iterable)
        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))

    def unique_everseen(iterable, key=None):
        "List unique elements, preserving order. Remember all elements ever seen."
        # unique_everseen('AAAABBBCCDAABBB') --> A B C D
        # unique_everseen('ABBCcAD', str.lower) --> A B C D
        seen = set()
        seen_add = seen.add
        if key is None:
            for element in ifilterfalse(seen.__contains__, iterable):
                seen_add(element)
                yield element
        else:
            for element in iterable:
                k = key(element)
                if k not in seen:
                    seen_add(k)
                    yield element

    def unique_justseen(iterable, key=None):
        "List unique elements, preserving order. Remember only the element just seen."
        # unique_justseen('AAAABBBCCDAABBB') --> A B C D A B
        # unique_justseen('ABBCcAD', str.lower) --> A B C A D
        return imap(next, imap(itemgetter(1), groupby(iterable, key)))

    def iter_except(func, exception, first=None):
        """ Call a function repeatedly until an exception is raised.

        Converts a call-until-exception interface to an iterator interface.
        Like __builtin__.iter(func, sentinel) but uses an exception instead
        of a sentinel to end the loop.

        Examples:
            bsddbiter = iter_except(db.next, bsddb.error, db.first)
            heapiter = iter_except(functools.partial(heappop, h), IndexError)
            dictiter = iter_except(d.popitem, KeyError)
            dequeiter = iter_except(d.popleft, IndexError)
            queueiter = iter_except(q.get_nowait, Queue.Empty)
            setiter = iter_except(s.pop, KeyError)

        """
        try:
            if first is not None:
                yield first()
            while 1:
                yield func()
        except exception:
            pass

    def random_product(*args, **kwds):
        "Random selection from itertools.product(*args, **kwds)"
        pools = map(tuple, args) * kwds.get('repeat', 1)
        return tuple(random.choice(pool) for pool in pools)

    def random_permutation(iterable, r=None):
        "Random selection from itertools.permutations(iterable, r)"
        pool = tuple(iterable)
        r = len(pool) if r is None else r
        return tuple(random.sample(pool, r))

    def random_combination(iterable, r):
        "Random selection from itertools.combinations(iterable, r)"
        pool = tuple(iterable)
        n = len(pool)
        indices = sorted(random.sample(xrange(n), r))
        return tuple(pool[i] for i in indices)

    def random_combination_with_replacement(iterable, r):
        "Random selection from itertools.combinations_with_replacement(iterable, r)"
        pool = tuple(iterable)
        n = len(pool)
        indices = sorted(random.randrange(n) for i in xrange(r))
        return tuple(pool[i] for i in indices)

    def tee_lookahead(t, i):
        """Inspect the i-th upcomping value from a tee object
           while leaving the tee object at its current position.

           Raise an IndexError if the underlying iterator doesn't
           have enough values.

        """
        for value in islice(t.__copy__(), i, None):
            return value
        raise IndexError(i)

Note, many of the above recipes can be optimized by replacing global
lookups with local variables defined as default values.  For example,
the `dotproduct' recipe can be written as:

    def dotproduct(vec1, vec2, sum=sum, imap=imap, mul=operator.mul):
        return sum(imap(mul, vec1, vec2))


File: python.info,  Node: functools — Higher-order functions and operations on callable objects,  Next: operator — Standard operators as functions,  Prev: itertools — Functions creating iterators for efficient looping,  Up: Numeric and Mathematical Modules

5.9.8 `functools' — Higher-order functions and operations on callable objects
-------------------------------------------------------------------------------

New in version 2.5.

`Source code:' Lib/functools.py(1)

__________________________________________________________________

The *Note functools: da. module is for higher-order functions:
functions that act on or return other functions. In general, any
callable object can be treated as a function for the purposes of this
module.

The *Note functools: da. module defines the following functions:

 -- Function: functools.cmp_to_key (func)
     Transform an old-style comparison function to a *Note key
     function: d9e.  Used with tools that accept key functions (such as
     *Note sorted(): 223, *Note min(): 224, *Note max(): 225, *Note
     heapq.nlargest(): bba, *Note heapq.nsmallest(): bbb, *Note
     itertools.groupby(): d91.).  This function is primarily used as a
     transition tool for programs being converted to Python 3 where
     comparison functions are no longer supported.

     A comparison function is any callable that accept two arguments,
     compares them, and returns a negative number for less-than, zero
     for equality, or a positive number for greater-than.  A key
     function is a callable that accepts one argument and returns
     another value to be used as the sort key.

     Example:

         sorted(iterable, key=cmp_to_key(locale.strcoll))  # locale-aware sort order

     For sorting examples and a brief sorting tutorial, see *Note
     Sorting HOW TO: 8b5.

     New in version 2.7.


 -- Function: functools.total_ordering (cls)
     Given a class defining one or more rich comparison ordering
     methods, this class decorator supplies the rest.  This simplifies
     the effort involved in specifying all of the possible rich
     comparison operations:

     The class must define one of *Note __lt__(): 21d, *Note __le__():
     21e, *Note __gt__(): 21f, or *Note __ge__(): 220.  In addition,
     the class should supply an *Note __eq__(): 21c. method.

     For example:

         @total_ordering
         class Student:
             def __eq__(self, other):
                 return ((self.lastname.lower(), self.firstname.lower()) ==
                         (other.lastname.lower(), other.firstname.lower()))
             def __lt__(self, other):
                 return ((self.lastname.lower(), self.firstname.lower()) <
                         (other.lastname.lower(), other.firstname.lower()))

     New in version 2.7.


 -- Function: functools.reduce (function, iterable[, initializer])
     This is the same function as *Note reduce(): 2fc.  It is made
     available in this module to allow writing code more
     forward-compatible with Python 3.

     New in version 2.6.


 -- Function: functools.partial (func[,*args][, **keywords])
     Return a new *Note partial: d9f. object which when called will
     behave like `func' called with the positional arguments `args' and
     keyword arguments `keywords'. If more arguments are supplied to
     the call, they are appended to `args'. If additional keyword
     arguments are supplied, they extend and override `keywords'.
     Roughly equivalent to:

         def partial(func, *args, **keywords):
             def newfunc(*fargs, **fkeywords):
                 newkeywords = keywords.copy()
                 newkeywords.update(fkeywords)
                 return func(*(args + fargs), **newkeywords)
             newfunc.func = func
             newfunc.args = args
             newfunc.keywords = keywords
             return newfunc

     The *Note partial(): d9f. is used for partial function application
     which “freezes” some portion of a function’s arguments
     and/or keywords resulting in a new object with a simplified
     signature.  For example, *Note partial(): d9f. can be used to
     create a callable that behaves like the *Note int(): 1f2. function
     where the `base' argument defaults to two:

         >>> from functools import partial
         >>> basetwo = partial(int, base=2)
         >>> basetwo.__doc__ = 'Convert base 2 string to an int.'
         >>> basetwo('10010')
         18

 -- Function: functools.update_wrapper (wrapper, wrapped[, assigned][,
          updated])
     Update a `wrapper' function to look like the `wrapped' function.
     The optional arguments are tuples to specify which attributes of
     the original function are assigned directly to the matching
     attributes on the wrapper function and which attributes of the
     wrapper function are updated with the corresponding attributes
     from the original function. The default values for these arguments
     are the module level constants `WRAPPER_ASSIGNMENTS' (which
     assigns to the wrapper function’s `__name__', `__module__' and
     `__doc__', the documentation string) and `WRAPPER_UPDATES' (which
     updates the wrapper function’s `__dict__', i.e. the instance
     dictionary).

     The main intended use for this function is in *Note decorator:
     87e. functions which wrap the decorated function and return the
     wrapper. If the wrapper function is not updated, the metadata of
     the returned function will reflect the wrapper definition rather
     than the original function definition, which is typically less
     than helpful.

 -- Function: functools.wraps (wrapped[, assigned][, updated])
     This is a convenience function for invoking *Note
     update_wrapper(): da0. as a function decorator when defining a
     wrapper function.  It is equivalent to `partial(update_wrapper,
     wrapped=wrapped, assigned=assigned, updated=updated)'.  For
     example:

         >>> from functools import wraps
         >>> def my_decorator(f):
         ...     @wraps(f)
         ...     def wrapper(*args, **kwds):
         ...         print 'Calling decorated function'
         ...         return f(*args, **kwds)
         ...     return wrapper
         ...
         >>> @my_decorator
         ... def example():
         ...     """Docstring"""
         ...     print 'Called example function'
         ...
         >>> example()
         Calling decorated function
         Called example function
         >>> example.__name__
         'example'
         >>> example.__doc__
         'Docstring'

     Without the use of this decorator factory, the name of the example
     function would have been `'wrapper'', and the docstring of the
     original `example()' would have been lost.

* Menu:

* partial Objects::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/functools.py


File: python.info,  Node: partial Objects,  Up: functools — Higher-order functions and operations on callable objects

5.9.8.1 `partial' Objects
.........................

*Note partial: d9f. objects are callable objects created by *Note
partial(): d9f. They have three read-only attributes:

 -- Attribute: partial.func
     A callable object or function.  Calls to the *Note partial: d9f.
     object will be forwarded to *Note func: da4. with new arguments
     and keywords.

 -- Attribute: partial.args
     The leftmost positional arguments that will be prepended to the
     positional arguments provided to a *Note partial: d9f. object call.

 -- Attribute: partial.keywords
     The keyword arguments that will be supplied when the *Note
     partial: d9f. object is called.

*Note partial: d9f. objects are like `function' objects in that they are
callable, weak referencable, and can have attributes.  There are some
important differences.  For instance, the *Note __name__: 470. and
`__doc__' attributes are not created automatically.  Also, *Note
partial: d9f. objects defined in classes behave like static methods and
do not transform into bound methods during instance attribute look-up.


File: python.info,  Node: operator — Standard operators as functions,  Prev: functools — Higher-order functions and operations on callable objects,  Up: Numeric and Mathematical Modules

5.9.9 `operator' — Standard operators as functions
----------------------------------------------------

The *Note operator: 127. module exports a set of efficient functions
corresponding to the intrinsic operators of Python.  For example,
`operator.add(x, y)' is equivalent to the expression `x+y'.  The
function names are those used for special class methods; variants
without leading and trailing `__' are also provided for convenience.

The functions fall into categories that perform object comparisons,
logical operations, mathematical operations, sequence operations, and
abstract type tests.

The object comparison functions are useful for all objects, and are
named after the rich comparison operators they support:

 -- Function: operator.lt (a, b)
 -- Function: operator.le (a, b)
 -- Function: operator.eq (a, b)
 -- Function: operator.ne (a, b)
 -- Function: operator.ge (a, b)
 -- Function: operator.gt (a, b)
 -- Function: operator.__lt__ (a, b)
 -- Function: operator.__le__ (a, b)
 -- Function: operator.__eq__ (a, b)
 -- Function: operator.__ne__ (a, b)
 -- Function: operator.__ge__ (a, b)
 -- Function: operator.__gt__ (a, b)
     Perform “rich comparisons” between `a' and `b'. Specifically,
     `lt(a, b)' is equivalent to `a < b', `le(a, b)' is equivalent to
     `a <= b', `eq(a, b)' is equivalent to `a == b', `ne(a, b)' is
     equivalent to `a != b', `gt(a, b)' is equivalent to `a > b' and
     `ge(a, b)' is equivalent to `a >= b'.  Note that unlike the
     built-in *Note cmp(): 4da, these functions can return any value,
     which may or may not be interpretable as a Boolean value.  See
     *Note Comparisons: 804. for more information about rich
     comparisons.

     New in version 2.2.


The logical operations are also generally applicable to all objects,
and support truth tests, identity tests, and boolean operations:

 -- Function: operator.not_ (obj)
 -- Function: operator.__not__ (obj)
     Return the outcome of *Note not: 80d. `obj'.  (Note that there is
     no *Note __not__(): db6. method for object instances; only the
     interpreter core defines this operation.  The result is affected
     by the *Note __nonzero__(): 734. and *Note __len__(): 423.
     methods.)

 -- Function: operator.truth (obj)
     Return *Note True: 3c8. if `obj' is true, and *Note False: 3c9.
     otherwise.  This is equivalent to using the *Note bool: 455.
     constructor.

 -- Function: operator.is_ (a, b)
     Return `a is b'.  Tests object identity.

     New in version 2.3.


 -- Function: operator.is_not (a, b)
     Return `a is not b'.  Tests object identity.

     New in version 2.3.


The mathematical and bitwise operations are the most numerous:

 -- Function: operator.abs (obj)
 -- Function: operator.__abs__ (obj)
     Return the absolute value of `obj'.

 -- Function: operator.add (a, b)
 -- Function: operator.__add__ (a, b)
     Return `a + b', for `a' and `b' numbers.

 -- Function: operator.and_ (a, b)
 -- Function: operator.__and__ (a, b)
     Return the bitwise and of `a' and `b'.

 -- Function: operator.div (a, b)
 -- Function: operator.__div__ (a, b)
     Return `a / b' when `__future__.division' is not in effect.  This
     is also known as “classic” division.

 -- Function: operator.floordiv (a, b)
 -- Function: operator.__floordiv__ (a, b)
     Return `a // b'.

     New in version 2.2.


 -- Function: operator.index (a)
 -- Function: operator.__index__ (a)
     Return `a' converted to an integer.  Equivalent to `a.__index__()'.

     New in version 2.5.


 -- Function: operator.inv (obj)
 -- Function: operator.invert (obj)
 -- Function: operator.__inv__ (obj)
 -- Function: operator.__invert__ (obj)
     Return the bitwise inverse of the number `obj'.  This is
     equivalent to `~obj'.

     New in version 2.0: The names *Note invert(): dc6. and *Note
     __invert__(): dc8.


 -- Function: operator.lshift (a, b)
 -- Function: operator.__lshift__ (a, b)
     Return `a' shifted left by `b'.

 -- Function: operator.mod (a, b)
 -- Function: operator.__mod__ (a, b)
     Return `a % b'.

 -- Function: operator.mul (a, b)
 -- Function: operator.__mul__ (a, b)
     Return `a * b', for `a' and `b' numbers.

 -- Function: operator.neg (obj)
 -- Function: operator.__neg__ (obj)
     Return `obj' negated (`-obj').

 -- Function: operator.or_ (a, b)
 -- Function: operator.__or__ (a, b)
     Return the bitwise or of `a' and `b'.

 -- Function: operator.pos (obj)
 -- Function: operator.__pos__ (obj)
     Return `obj' positive (`+obj').

 -- Function: operator.pow (a, b)
 -- Function: operator.__pow__ (a, b)
     Return `a ** b', for `a' and `b' numbers.

     New in version 2.3.


 -- Function: operator.rshift (a, b)
 -- Function: operator.__rshift__ (a, b)
     Return `a' shifted right by `b'.

 -- Function: operator.sub (a, b)
 -- Function: operator.__sub__ (a, b)
     Return `a - b'.

 -- Function: operator.truediv (a, b)
 -- Function: operator.__truediv__ (a, b)
     Return `a / b' when `__future__.division' is in effect.  This is
     also known as “true” division.

     New in version 2.2.


 -- Function: operator.xor (a, b)
 -- Function: operator.__xor__ (a, b)
     Return the bitwise exclusive or of `a' and `b'.

Operations which work with sequences (some of them with mappings too)
include:

 -- Function: operator.concat (a, b)
 -- Function: operator.__concat__ (a, b)
     Return `a + b' for `a' and `b' sequences.

 -- Function: operator.contains (a, b)
 -- Function: operator.__contains__ (a, b)
     Return the outcome of the test `b in a'. Note the reversed
     operands.

     New in version 2.0: The name *Note __contains__(): de2.


 -- Function: operator.countOf (a, b)
     Return the number of occurrences of `b' in `a'.

 -- Function: operator.delitem (a, b)
 -- Function: operator.__delitem__ (a, b)
     Remove the value of `a' at index `b'.

 -- Function: operator.delslice (a, b, c)
 -- Function: operator.__delslice__ (a, b, c)
     Delete the slice of `a' from index `b' to index `c-1'.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *Note delitem(): de4. with a slice index.


 -- Function: operator.getitem (a, b)
 -- Function: operator.__getitem__ (a, b)
     Return the value of `a' at index `b'.

 -- Function: operator.getslice (a, b, c)
 -- Function: operator.__getslice__ (a, b, c)
     Return the slice of `a' from index `b' to index `c-1'.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *Note getitem(): de8. with a slice index.


 -- Function: operator.indexOf (a, b)
     Return the index of the first of occurrence of `b' in `a'.

 -- Function: operator.repeat (a, b)
 -- Function: operator.__repeat__ (a, b)
     Deprecated since version 2.7: Use *Note __mul__(): dce. instead.

     Return `a * b' where `a' is a sequence and `b' is an integer.

 -- Function: operator.sequenceIncludes (...)
     Deprecated since version 2.0: Use *Note contains(): de1. instead.

     Alias for *Note contains(): de1.

 -- Function: operator.setitem (a, b, c)
 -- Function: operator.__setitem__ (a, b, c)
     Set the value of `a' at index `b' to `c'.

 -- Function: operator.setslice (a, b, c, v)
 -- Function: operator.__setslice__ (a, b, c, v)
     Set the slice of `a' from index `b' to index `c-1' to the sequence
     `v'.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *Note setitem(): def. with a slice index.


Example use of operator functions:

    >>> # Elementwise multiplication
    >>> map(mul, [0, 1, 2, 3], [10, 20, 30, 40])
    [0, 20, 60, 120]

    >>> # Dot product
    >>> sum(map(mul, [0, 1, 2, 3], [10, 20, 30, 40]))
    200

Many operations have an “in-place” version.  The following
functions provide a more primitive access to in-place operators than
the usual syntax does; for example, the *Note statement: df3. `x += y'
is equivalent to `x = operator.iadd(x, y)'.  Another way to put it is
to say that `z = operator.iadd(x, y)' is equivalent to the compound
statement `z = x; z += y'.

 -- Function: operator.iadd (a, b)
 -- Function: operator.__iadd__ (a, b)
     `a = iadd(a, b)' is equivalent to `a += b'.

     New in version 2.5.


 -- Function: operator.iand (a, b)
 -- Function: operator.__iand__ (a, b)
     `a = iand(a, b)' is equivalent to `a &= b'.

     New in version 2.5.


 -- Function: operator.iconcat (a, b)
 -- Function: operator.__iconcat__ (a, b)
     `a = iconcat(a, b)' is equivalent to `a += b' for `a' and `b'
     sequences.

     New in version 2.5.


 -- Function: operator.idiv (a, b)
 -- Function: operator.__idiv__ (a, b)
     `a = idiv(a, b)' is equivalent to `a /= b' when
     `__future__.division' is not in effect.

     New in version 2.5.


 -- Function: operator.ifloordiv (a, b)
 -- Function: operator.__ifloordiv__ (a, b)
     `a = ifloordiv(a, b)' is equivalent to `a //= b'.

     New in version 2.5.


 -- Function: operator.ilshift (a, b)
 -- Function: operator.__ilshift__ (a, b)
     `a = ilshift(a, b)' is equivalent to `a <<= b'.

     New in version 2.5.


 -- Function: operator.imod (a, b)
 -- Function: operator.__imod__ (a, b)
     `a = imod(a, b)' is equivalent to `a %= b'.

     New in version 2.5.


 -- Function: operator.imul (a, b)
 -- Function: operator.__imul__ (a, b)
     `a = imul(a, b)' is equivalent to `a *= b'.

     New in version 2.5.


 -- Function: operator.ior (a, b)
 -- Function: operator.__ior__ (a, b)
     `a = ior(a, b)' is equivalent to `a |= b'.

     New in version 2.5.


 -- Function: operator.ipow (a, b)
 -- Function: operator.__ipow__ (a, b)
     `a = ipow(a, b)' is equivalent to `a **= b'.

     New in version 2.5.


 -- Function: operator.irepeat (a, b)
 -- Function: operator.__irepeat__ (a, b)
     Deprecated since version 2.7: Use *Note __imul__(): e03. instead.

     `a = irepeat(a, b)' is equivalent to `a *= b' where `a' is a
     sequence and `b' is an integer.

     New in version 2.5.


 -- Function: operator.irshift (a, b)
 -- Function: operator.__irshift__ (a, b)
     `a = irshift(a, b)' is equivalent to `a >>= b'.

     New in version 2.5.


 -- Function: operator.isub (a, b)
 -- Function: operator.__isub__ (a, b)
     `a = isub(a, b)' is equivalent to `a -= b'.

     New in version 2.5.


 -- Function: operator.itruediv (a, b)
 -- Function: operator.__itruediv__ (a, b)
     `a = itruediv(a, b)' is equivalent to `a /= b' when
     `__future__.division' is in effect.

     New in version 2.5.


 -- Function: operator.ixor (a, b)
 -- Function: operator.__ixor__ (a, b)
     `a = ixor(a, b)' is equivalent to `a ^= b'.

     New in version 2.5.


The *Note operator: 127. module also defines a few predicates to test
the type of objects; however, these are not all reliable.  It is
preferable to test abstract base classes instead (see *Note
collections: 65. and *Note numbers: 126. for details).

 -- Function: operator.isCallable (obj)
     Deprecated since version 2.0: Use `isinstance(x,
     collections.Callable)' instead.

     Returns true if the object `obj' can be called like a function,
     otherwise it returns false.  True is returned for functions, bound
     and unbound methods, class objects, and instance objects which
     support the *Note __call__(): 725. method.

 -- Function: operator.isMappingType (obj)
     Deprecated since version 2.7: Use `isinstance(x,
     collections.Mapping)' instead.

     Returns true if the object `obj' supports the mapping interface.
     This is true for dictionaries and all instance objects defining
     *Note __getitem__(): de9.

 -- Function: operator.isNumberType (obj)
     Deprecated since version 2.7: Use `isinstance(x, numbers.Number)'
     instead.

     Returns true if the object `obj' represents a number.  This is
     true for all numeric types implemented in C.

 -- Function: operator.isSequenceType (obj)
     Deprecated since version 2.7: Use `isinstance(x,
     collections.Sequence)' instead.

     Returns true if the object `obj' supports the sequence protocol.
     This returns true for all objects which define sequence methods in
     C, and for all instance objects defining *Note __getitem__(): de9.

The *Note operator: 127. module also defines tools for generalized
attribute and item lookups.  These are useful for making fast field
extractors as arguments for *Note map(): 318, *Note sorted(): 223,
*Note itertools.groupby(): d91, or other functions that expect a
function argument.

 -- Function: operator.attrgetter (attr)
 -- Function: operator.attrgetter (*attrs)
     Return a callable object that fetches `attr' from its operand.  If
     more than one attribute is requested, returns a tuple of
     attributes.  The attribute names can also contain dots. For
     example:

        * After `f = attrgetter('name')', the call `f(b)' returns
          `b.name'.

        * After `f = attrgetter('name', 'date')', the call `f(b)'
          returns `(b.name, b.date)'.

        * After `f = attrgetter('name.first', 'name.last')', the call
          `f(b)' returns `(b.name.first, b.name.last)'.

     Equivalent to:

         def attrgetter(*items):
             if len(items) == 1:
                 attr = items[0]
                 def g(obj):
                     return resolve_attr(obj, attr)
             else:
                 def g(obj):
                     return tuple(resolve_attr(obj, attr) for attr in items)
             return g

         def resolve_attr(obj, attr):
             for name in attr.split("."):
                 obj = getattr(obj, name)
             return obj

     New in version 2.4.

     Changed in version 2.5: Added support for multiple attributes.

     Changed in version 2.6: Added support for dotted attributes.


 -- Function: operator.itemgetter (item)
 -- Function: operator.itemgetter (*items)
     Return a callable object that fetches `item' from its operand
     using the operand’s *Note __getitem__(): de9. method.  If
     multiple items are specified, returns a tuple of lookup values.
     For example:

        * After `f = itemgetter(2)', the call `f(r)' returns `r[2]'.

        * After `g = itemgetter(2, 5, 3)', the call `g(r)' returns
          `(r[2], r[5], r[3])'.

     Equivalent to:

         def itemgetter(*items):
             if len(items) == 1:
                 item = items[0]
                 def g(obj):
                     return obj[item]
             else:
                 def g(obj):
                     return tuple(obj[item] for item in items)
             return g

     The items can be any type accepted by the operand’s *Note
     __getitem__(): de9.  method.  Dictionaries accept any hashable
     value.  Lists, tuples, and strings accept an index or a slice:

         >>> itemgetter(1)('ABCDEFG')
         'B'
         >>> itemgetter(1,3,5)('ABCDEFG')
         ('B', 'D', 'F')
         >>> itemgetter(slice(2,None))('ABCDEFG')
         'CDEFG'

     New in version 2.4.

     Changed in version 2.5: Added support for multiple item extraction.

     Example of using *Note itemgetter(): e16. to retrieve specific
     fields from a tuple record:

         >>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]
         >>> getcount = itemgetter(1)
         >>> map(getcount, inventory)
         [3, 2, 5, 1]
         >>> sorted(inventory, key=getcount)
         [('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]

 -- Function: operator.methodcaller (name[, args...])
     Return a callable object that calls the method `name' on its
     operand.  If additional arguments and/or keyword arguments are
     given, they will be given to the method as well.  For example:

        * After `f = methodcaller('name')', the call `f(b)' returns
          `b.name()'.

        * After `f = methodcaller('name', 'foo', bar=1)', the call
          `f(b)' returns `b.name('foo', bar=1)'.

     Equivalent to:

         def methodcaller(name, *args, **kwargs):
             def caller(obj):
                 return getattr(obj, name)(*args, **kwargs)
             return caller

     New in version 2.6.


* Menu:

* Mapping Operators to Functions::


File: python.info,  Node: Mapping Operators to Functions,  Up: operator — Standard operators as functions

5.9.9.1 Mapping Operators to Functions
......................................

This table shows how abstract operations correspond to operator symbols
in the Python syntax and the functions in the *Note operator: 127.
module.

Operation                   Syntax                        Function
------------------------------------------------------------------------------------------------------ 
Addition                    `a + b'                       `add(a, b)'
Concatenation               `seq1 + seq2'                 `concat(seq1, seq2)'
Containment Test            `obj in seq'                  `contains(seq, obj)'
Division                    `a / b'                       `div(a, b)' (without `__future__.division')
Division                    `a / b'                       `truediv(a, b)' (with
                                                          `__future__.division')
Division                    `a // b'                      `floordiv(a, b)'
Bitwise And                 `a & b'                       `and_(a, b)'
Bitwise Exclusive Or        `a ^ b'                       `xor(a, b)'
Bitwise Inversion           `~ a'                         `invert(a)'
Bitwise Or                  `a | b'                       `or_(a, b)'
Exponentiation              `a ** b'                      `pow(a, b)'
Identity                    `a is b'                      `is_(a, b)'
Identity                    `a is not b'                  `is_not(a, b)'
Indexed Assignment          `obj[k] = v'                  `setitem(obj, k, v)'
Indexed Deletion            `del obj[k]'                  `delitem(obj, k)'
Indexing                    `obj[k]'                      `getitem(obj, k)'
Left Shift                  `a << b'                      `lshift(a, b)'
Modulo                      `a % b'                       `mod(a, b)'
Multiplication              `a * b'                       `mul(a, b)'
Negation (Arithmetic)       `- a'                         `neg(a)'
Negation (Logical)          `not a'                       `not_(a)'
Positive                    `+ a'                         `pos(a)'
Right Shift                 `a >> b'                      `rshift(a, b)'
Sequence Repetition         `seq * i'                     `repeat(seq, i)'
Slice Assignment            `seq[i:j] = values'           `setitem(seq, slice(i, j), values)'
Slice Deletion              `del seq[i:j]'                `delitem(seq, slice(i, j))'
Slicing                     `seq[i:j]'                    `getitem(seq, slice(i, j))'
String Formatting           `s % obj'                     `mod(s, obj)'
Subtraction                 `a - b'                       `sub(a, b)'
Truth Test                  `obj'                         `truth(obj)'
Ordering                    `a < b'                       `lt(a, b)'
Ordering                    `a <= b'                      `le(a, b)'
Equality                    `a == b'                      `eq(a, b)'
Difference                  `a != b'                      `ne(a, b)'
Ordering                    `a >= b'                      `ge(a, b)'
Ordering                    `a > b'                       `gt(a, b)'


File: python.info,  Node: File and Directory Access,  Next: Data Persistence,  Prev: Numeric and Mathematical Modules,  Up: The Python Standard Library

5.10 File and Directory Access
==============================

The modules described in this chapter deal with disk files and
directories.  For example, there are modules for reading the properties
of files, manipulating paths in a portable way, and creating temporary
files.  The full list of modules in this chapter is:

* Menu:

* os.path — Common pathname manipulations: os path — Common pathname manipulations.
* fileinput — Iterate over lines from multiple input streams::
* stat — Interpreting stat() results: stat — Interpreting stat results.
* statvfs — Constants used with os.statvfs(): statvfs — Constants used with os statvfs.
* filecmp — File and Directory Comparisons::
* tempfile — Generate temporary files and directories::
* glob — Unix style pathname pattern expansion::
* fnmatch — Unix filename pattern matching::
* linecache — Random access to text lines::
* shutil — High-level file operations::
* dircache — Cached directory listings::
* macpath — Mac OS 9 path manipulation functions::


File: python.info,  Node: os path — Common pathname manipulations,  Next: fileinput — Iterate over lines from multiple input streams,  Up: File and Directory Access

5.10.1 `os.path' — Common pathname manipulations
--------------------------------------------------

This module implements some useful functions on pathnames. To read or
write files see *Note open(): 2d9, and for accessing the filesystem see
the *Note os: 129. module.

     Note: On Windows, many of these functions do not properly support
     UNC pathnames.  *Note splitunc(): e1f. and *Note ismount(): e20.
     do handle them correctly.

Unlike a unix shell, Python does not do any `automatic' path expansions.
Functions such as *Note expanduser(): e21. and *Note expandvars(): 369.
can be invoked explicitly when an application desires shell-like path
expansion.  (See also the *Note glob: e4. module.)

     Note: Since different operating systems have different path name
     conventions, there are several versions of this module in the
     standard library.  The *Note os.path: 12a. module is always the
     path module suitable for the operating system Python is running
     on, and therefore usable for local paths.  However, you can also
     import and use the individual modules if you want to manipulate a
     path that is `always' in one of the different formats.  They all
     have the same interface:

        * `posixpath' for UNIX-style paths

        * `ntpath' for Windows paths

        * *Note macpath: 108. for old-style MacOS paths

        * `os2emxpath' for OS/2 EMX paths

 -- Function: os.path.abspath (path)
     Return a normalized absolutized version of the pathname `path'. On
     most platforms, this is equivalent to calling the function *Note
     normpath(): 245. as follows: `normpath(join(os.getcwd(), path))'.

     New in version 1.5.2.


 -- Function: os.path.basename (path)
     Return the base name of pathname `path'.  This is the second
     element of the pair returned by passing `path' to the function
     *Note split(): e23.  Note that the result of this function is
     different from the Unix `basename' program; where `basename' for
     `'/foo/bar/'' returns `'bar'', the *Note basename(): e22. function
     returns an empty string (`''').

 -- Function: os.path.commonprefix (list)
     Return the longest path prefix (taken character-by-character) that
     is a prefix of all paths in  `list'.  If `list' is empty, return
     the empty string (`''').  Note that this may return invalid paths
     because it works a character at a time.

 -- Function: os.path.dirname (path)
     Return the directory name of pathname `path'.  This is the first
     element of the pair returned by passing `path' to the function
     *Note split(): e23.

 -- Function: os.path.exists (path)
     Return `True' if `path' refers to an existing path.  Returns
     `False' for broken symbolic links. On some platforms, this
     function may return `False' if permission is not granted to
     execute *Note os.stat(): 3de. on the requested file, even if the
     `path' physically exists.

 -- Function: os.path.lexists (path)
     Return `True' if `path' refers to an existing path. Returns `True'
     for broken symbolic links.   Equivalent to *Note exists(): e26. on
     platforms lacking *Note os.lstat(): e28.

     New in version 2.4.


 -- Function: os.path.expanduser (path)
     On Unix and Windows, return the argument with an initial component
     of `~' or `~user' replaced by that `user'’s home directory.

     On Unix, an initial `~' is replaced by the environment variable `HOME'
     if it is set; otherwise the current user’s home directory is
     looked up in the password directory through the built-in module
     *Note pwd: 13d. An initial `~user' is looked up directly in the
     password directory.

     On Windows, `HOME' and `USERPROFILE' will be used if set,
     otherwise a combination of `HOMEPATH' and `HOMEDRIVE' will be
     used.  An initial `~user' is handled by stripping the last
     directory component from the created user path derived above.

     If the expansion fails or if the path does not begin with a tilde,
     the path is returned unchanged.

 -- Function: os.path.expandvars (path)
     Return the argument with environment variables expanded.
     Substrings of the form `$name' or `${name}' are replaced by the
     value of environment variable `name'.  Malformed variable names
     and references to non-existing variables are left unchanged.

     On Windows, `%name%' expansions are supported in addition to
     `$name' and `${name}'.

 -- Function: os.path.getatime (path)
     Return the time of last access of `path'.  The return value is a
     number giving the number of seconds since the epoch (see the
     *Note time: 17a. module).  Raise *Note os.error: e2a. if the file
     does not exist or is inaccessible.

     New in version 1.5.2.

     Changed in version 2.3: If *Note os.stat_float_times(): 47e.
     returns `True', the result is a floating point number.


 -- Function: os.path.getmtime (path)
     Return the time of last modification of `path'.  The return value
     is a number giving the number of seconds since the epoch (see the
     *Note time: 17a. module).  Raise *Note os.error: e2a. if the file
     does not exist or is inaccessible.

     New in version 1.5.2.

     Changed in version 2.3: If *Note os.stat_float_times(): 47e.
     returns `True', the result is a floating point number.


 -- Function: os.path.getctime (path)
     Return the system’s ctime which, on some systems (like Unix) is
     the time of the last metadata change, and, on others (like
     Windows), is the creation time for `path'.  The return value is a
     number giving the number of seconds since the epoch (see the
     *Note time: 17a. module).  Raise *Note os.error: e2a. if the file
     does not exist or is inaccessible.

     New in version 2.3.


 -- Function: os.path.getsize (path)
     Return the size, in bytes, of `path'.  Raise *Note os.error: e2a.
     if the file does not exist or is inaccessible.

     New in version 1.5.2.


 -- Function: os.path.isabs (path)
     Return `True' if `path' is an absolute pathname.  On Unix, that
     means it begins with a slash, on Windows that it begins with a
     (back)slash after chopping off a potential drive letter.

 -- Function: os.path.isfile (path)
     Return `True' if `path' is an existing regular file.  This follows
     symbolic links, so both *Note islink(): e30. and *Note isfile():
     e2f. can be true for the same path.

 -- Function: os.path.isdir (path)
     Return `True' if `path' is an existing directory.  This follows
     symbolic links, so both *Note islink(): e30. and *Note isdir():
     e31. can be true for the same path.

 -- Function: os.path.islink (path)
     Return `True' if `path' refers to a directory entry that is a
     symbolic link.  Always `False' if symbolic links are not supported
     by the Python runtime.

 -- Function: os.path.ismount (path)
     Return `True' if pathname `path' is a `mount point': a point in a
     file system where a different file system has been mounted.  The
     function checks whether `path'’s parent, `path/..', is on a
     different device than `path', or whether `path/..' and `path'
     point to the same i-node on the same device — this should detect
     mount points for all Unix and POSIX variants.

 -- Function: os.path.join (path, *paths)
     Join one or more path components intelligently.  The return value
     is the concatenation of `path' and any members of `*paths' with
     exactly one directory separator (`os.sep') following each
     non-empty part except the last, meaning that the result will only
     end in a separator if the last part is empty.  If a component is
     an absolute path, all previous components are thrown away and
     joining continues from the absolute path component.

     On Windows, the drive letter is not reset when an absolute path
     component (e.g., `r'\foo'') is encountered.  If a component
     contains a drive letter, all previous components are thrown away
     and the drive letter is reset.  Note that since there is a current
     directory for each drive, `os.path.join("c:", "foo")' represents a
     path relative to the current directory on drive `C:' (`c:foo'),
     not `c:\foo'.

 -- Function: os.path.normcase (path)
     Normalize the case of a pathname.  On Unix and Mac OS X, this
     returns the path unchanged; on case-insensitive filesystems, it
     converts the path to lowercase.  On Windows, it also converts
     forward slashes to backward slashes.

 -- Function: os.path.normpath (path)
     Normalize a pathname by collapsing redundant separators and
     up-level references so that `A//B', `A/B/', `A/./B' and
     `A/foo/../B' all become `A/B'.  This string manipulation may
     change the meaning of a path that contains symbolic links.  On
     Windows, it converts forward slashes to backward slashes. To
     normalize case, use *Note normcase(): e33.

 -- Function: os.path.realpath (path)
     Return the canonical path of the specified filename, eliminating
     any symbolic links encountered in the path (if they are supported
     by the operating system).

     New in version 2.2.


 -- Function: os.path.relpath (path[, start])
     Return a relative filepath to `path' either from the current
     directory or from an optional `start' directory.  This is a path
     computation:  the filesystem is not accessed to confirm the
     existence or nature of `path' or `start'.

     `start' defaults to *Note os.curdir: e36.

     Availability:  Windows, Unix.

     New in version 2.6.


 -- Function: os.path.samefile (path1, path2)
     Return `True' if both pathname arguments refer to the same file or
     directory (as indicated by device number and i-node number). Raise
     an exception if an *Note os.stat(): 3de. call on either pathname
     fails.

     Availability: Unix.

 -- Function: os.path.sameopenfile (fp1, fp2)
     Return `True' if the file descriptors `fp1' and `fp2' refer to the
     same file.

     Availability: Unix.

 -- Function: os.path.samestat (stat1, stat2)
     Return `True' if the stat tuples `stat1' and `stat2' refer to the
     same file.  These structures may have been returned by *Note
     os.fstat(): e3a, *Note os.lstat(): e28, or *Note os.stat(): 3de.
     This function implements the underlying comparison used by *Note
     samefile(): e37. and *Note sameopenfile(): e38.

     Availability: Unix.

 -- Function: os.path.split (path)
     Split the pathname `path' into a pair, `(head, tail)' where `tail'
     is the last pathname component and `head' is everything leading up
     to that.  The `tail' part will never contain a slash; if `path'
     ends in a slash, `tail' will be empty.  If there is no slash in
     `path', `head' will be empty.  If `path' is empty, both `head' and
     `tail' are empty.  Trailing slashes are stripped from `head'
     unless it is the root (one or more slashes only).  In all cases,
     `join(head, tail)' returns a path to the same location as `path'
     (but the strings may differ).  Also see the functions *Note
     dirname(): e25. and *Note basename(): e22.

 -- Function: os.path.splitdrive (path)
     Split the pathname `path' into a pair `(drive, tail)' where
     `drive' is either a drive specification or the empty string.  On
     systems which do not use drive specifications, `drive' will always
     be the empty string.  In all cases, `drive + tail' will be the
     same as `path'.

     New in version 1.3.


 -- Function: os.path.splitext (path)
     Split the pathname `path' into a pair `(root, ext)'  such that
     `root + ext == path', and `ext' is empty or begins with a period
     and contains at most one period. Leading periods on the basename
     are  ignored; `splitext('.cshrc')' returns  `('.cshrc', '')'.

     Changed in version 2.6: Earlier versions could produce an empty
     root when the only period was the first character.


 -- Function: os.path.splitunc (path)
     Split the pathname `path' into a pair `(unc, rest)' so that `unc'
     is the UNC mount point (such as `r'\\host\mount''), if present,
     and `rest' the rest of the path (such as  `r'\path\file.ext'').
     For paths containing drive letters, `unc' will always be the empty
     string.

     Availability:  Windows.

 -- Function: os.path.walk (path, visit, arg)
     Calls the function `visit' with arguments `(arg, dirname, names)'
     for each directory in the directory tree rooted at `path'
     (including `path' itself, if it is a directory).  The argument
     `dirname' specifies the visited directory, the argument `names'
     lists the files in the directory (gotten from
     `os.listdir(dirname)'). The `visit' function may modify `names' to
     influence the set of directories visited below `dirname', e.g. to
     avoid visiting certain parts of the tree.  (The object referred to
     by `names' must be modified in place, using *Note del: 585. or
     slice assignment.)

          Note: Symbolic links to directories are not treated as
          subdirectories, and that *Note walk(): e3d. therefore will
          not visit them. To visit linked directories you must identify
          them with `os.path.islink(file)' and `os.path.isdir(file)',
          and invoke *Note walk(): e3d. as necessary.

          Note: This function is deprecated and has been removed in
          Python 3 in favor of *Note os.walk(): 368.

 -- Data: os.path.supports_unicode_filenames
     `True' if arbitrary Unicode strings can be used as file names
     (within limitations imposed by the file system).

     New in version 2.3.



File: python.info,  Node: fileinput — Iterate over lines from multiple input streams,  Next: stat — Interpreting stat results,  Prev: os path — Common pathname manipulations,  Up: File and Directory Access

5.10.2 `fileinput' — Iterate over lines from multiple input streams
---------------------------------------------------------------------

`Source code:' Lib/fileinput.py(1)

__________________________________________________________________

This module implements a helper class and functions to quickly write a
loop over standard input or a list of files. If you just want to read or
write one file see *Note open(): 2d9.

The typical use is:

    import fileinput
    for line in fileinput.input():
        process(line)

This iterates over the lines of all files listed in `sys.argv[1:]',
defaulting to `sys.stdin' if the list is empty.  If a filename is
`'-'', it is also replaced by `sys.stdin'.  To specify an alternative
list of filenames, pass it as the first argument to *Note input(): e40.
A single file name is also allowed.

All files are opened in text mode by default, but you can override this
by specifying the `mode' parameter in the call to *Note input(): e40. or
*Note FileInput(): e41.  If an I/O error occurs during opening or
reading a file, *Note IOError: 1fa. is raised.

If `sys.stdin' is used more than once, the second and further use will
return no lines, except perhaps for interactive use, or if it has been
explicitly reset (e.g. using `sys.stdin.seek(0)').

Empty files are opened and immediately closed; the only time their
presence in the list of filenames is noticeable at all is when the last
file opened is empty.

Lines are returned with any newlines intact, which means that the last
line in a file may not have one.

You can control how files are opened by providing an opening hook via
the `openhook' parameter to *Note fileinput.input(): e40. or *Note
FileInput(): e41. The hook must be a function that takes two arguments,
`filename' and `mode', and returns an accordingly opened file-like
object. Two useful hooks are already provided by this module.

The following function is the primary interface of this module:

 -- Function: fileinput.input ([files[, inplace[, backup[, bufsize[,
          mode[, openhook]]]]]])
     Create an instance of the *Note FileInput: e41. class.  The
     instance will be used as global state for the functions of this
     module, and is also returned to use during iteration.  The
     parameters to this function will be passed along to the
     constructor of the *Note FileInput: e41. class.

     Changed in version 2.5: Added the `mode' and `openhook' parameters.

     Changed in version 2.7.12: The `bufsize' parameter is no longer
     used.


The following functions use the global state created by *Note
fileinput.input(): e40.; if there is no active state, *Note
RuntimeError: 3b3. is raised.

 -- Function: fileinput.filename ()
     Return the name of the file currently being read.  Before the
     first line has been read, returns `None'.

 -- Function: fileinput.fileno ()
     Return the integer “file descriptor” for the current file.
     When no file is opened (before the first line and between files),
     returns `-1'.

     New in version 2.5.


 -- Function: fileinput.lineno ()
     Return the cumulative line number of the line that has just been
     read.  Before the first line has been read, returns `0'.  After
     the last line of the last file has been read, returns the line
     number of that line.

 -- Function: fileinput.filelineno ()
     Return the line number in the current file.  Before the first line
     has been read, returns `0'.  After the last line of the last file
     has been read, returns the line number of that line within the
     file.

 -- Function: fileinput.isfirstline ()
     Returns true if the line just read is the first line of its file,
     otherwise returns false.

 -- Function: fileinput.isstdin ()
     Returns true if the last line was read from `sys.stdin', otherwise
     returns false.

 -- Function: fileinput.nextfile ()
     Close the current file so that the next iteration will read the
     first line from the next file (if any); lines not read from the
     file will not count towards the cumulative line count.  The
     filename is not changed until after the first line of the next
     file has been read.  Before the first line has been read, this
     function has no effect; it cannot be used to skip the first file.
     After the last line of the last file has been read, this function
     has no effect.

 -- Function: fileinput.close ()
     Close the sequence.

The class which implements the sequence behavior provided by the module
is available for subclassing as well:

 -- Class: fileinput.FileInput ([files[, inplace[, backup[, bufsize[,
          mode[, openhook]]]]]])
     Class *Note FileInput: e41. is the implementation; its methods
     *Note filename(): e42, *Note fileno(): e43, *Note lineno(): e44,
     *Note filelineno(): e45, *Note isfirstline(): e46, *Note
     isstdin(): e47, *Note nextfile(): e48. and *Note close(): e49.
     correspond to the functions of the same name in the module. In
     addition it has a *Note readline(): 66f. method which returns the
     next input line, and a *Note __getitem__(): 468. method which
     implements the sequence behavior.  The sequence must be accessed
     in strictly sequential order; random access and *Note readline():
     66f. cannot be mixed.

     With `mode' you can specify which file mode will be passed to
     *Note open(): 2d9. It must be one of `'r'', `'rU'', `'U'' and
     `'rb''.

     The `openhook', when given, must be a function that takes two
     arguments, `filename' and `mode', and returns an accordingly
     opened file-like object. You cannot use `inplace' and `openhook'
     together.

     Changed in version 2.5: Added the `mode' and `openhook' parameters.

     Changed in version 2.7.12: The `bufsize' parameter is no longer
     used.


`Optional in-place filtering:' if the keyword argument `inplace=1' is
passed to *Note fileinput.input(): e40. or to the *Note FileInput: e41.
constructor, the file is moved to a backup file and standard output is
directed to the input file (if a file of the same name as the backup
file already exists, it will be replaced silently).  This makes it
possible to write a filter that rewrites its input file in place.  If
the `backup' parameter is given (typically as `backup='.<some
extension>''), it specifies the extension for the backup file, and the
backup file remains around; by default, the extension is `'.bak'' and
it is deleted when the output file is closed.  In-place filtering is
disabled when standard input is read.

     Note: The current implementation does not work for MS-DOS 8+3
     filesystems.

The two following opening hooks are provided by this module:

 -- Function: fileinput.hook_compressed (filename, mode)
     Transparently opens files compressed with gzip and bzip2
     (recognized by the extensions `'.gz'' and `'.bz2'') using the
     *Note gzip: e6. and *Note bz2: 1e.  modules.  If the filename
     extension is not `'.gz'' or `'.bz2'', the file is opened normally
     (ie, using *Note open(): 2d9. without any decompression).

     Usage example:  `fi =
     fileinput.FileInput(openhook=fileinput.hook_compressed)'

     New in version 2.5.


 -- Function: fileinput.hook_encoded (encoding)
     Returns a hook which opens each file with *Note io.open(): e4c,
     using the given `encoding' to read the file.

     Usage example: `fi =
     fileinput.FileInput(openhook=fileinput.hook_encoded("iso-8859-1"))'

          Note: With this hook, *Note FileInput: e41. might return
          Unicode strings depending on the specified `encoding'.

     New in version 2.5.


---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/fileinput.py


File: python.info,  Node: stat — Interpreting stat results,  Next: statvfs — Constants used with os statvfs,  Prev: fileinput — Iterate over lines from multiple input streams,  Up: File and Directory Access

5.10.3 `stat' — Interpreting `stat()' results
-----------------------------------------------

`Source code:' Lib/stat.py(1)

__________________________________________________________________

The *Note stat: 161. module defines constants and functions for
interpreting the results of *Note os.stat(): 3de, *Note os.fstat():
e3a. and *Note os.lstat(): e28. (if they exist).  For complete details
about the `stat()', `fstat()' and `lstat()' calls, consult the
documentation for your system.

The *Note stat: 161. module defines the following functions to test for
specific file types:

 -- Function: stat.S_ISDIR (mode)
     Return non-zero if the mode is from a directory.

 -- Function: stat.S_ISCHR (mode)
     Return non-zero if the mode is from a character special device
     file.

 -- Function: stat.S_ISBLK (mode)
     Return non-zero if the mode is from a block special device file.

 -- Function: stat.S_ISREG (mode)
     Return non-zero if the mode is from a regular file.

 -- Function: stat.S_ISFIFO (mode)
     Return non-zero if the mode is from a FIFO (named pipe).

 -- Function: stat.S_ISLNK (mode)
     Return non-zero if the mode is from a symbolic link.

 -- Function: stat.S_ISSOCK (mode)
     Return non-zero if the mode is from a socket.

Two additional functions are defined for more general manipulation of
the file’s mode:

 -- Function: stat.S_IMODE (mode)
     Return the portion of the file’s mode that can be set by *Note
     os.chmod(): e57.—that is, the file’s permission bits, plus the
     sticky bit, set-group-id, and set-user-id bits (on systems that
     support them).

 -- Function: stat.S_IFMT (mode)
     Return the portion of the file’s mode that describes the file
     type (used by the `S_IS*()' functions above).

Normally, you would use the `os.path.is*()' functions for testing the
type of a file; the functions here are useful when you are doing
multiple tests of the same file and wish to avoid the overhead of the
`stat()' system call for each test.  These are also useful when
checking for information about a file that isn’t handled by *Note
os.path: 12a, like the tests for block and character devices.

Example:

    import os, sys
    from stat import *

    def walktree(top, callback):
        '''recursively descend the directory tree rooted at top,
           calling the callback function for each regular file'''

        for f in os.listdir(top):
            pathname = os.path.join(top, f)
            mode = os.stat(pathname).st_mode
            if S_ISDIR(mode):
                # It's a directory, recurse into it
                walktree(pathname, callback)
            elif S_ISREG(mode):
                # It's a file, call the callback function
                callback(pathname)
            else:
                # Unknown file type, print a message
                print 'Skipping %s' % pathname

    def visitfile(file):
        print 'visiting', file

    if __name__ == '__main__':
        walktree(sys.argv[1], visitfile)

All the variables below are simply symbolic indexes into the 10-tuple
returned by *Note os.stat(): 3de, *Note os.fstat(): e3a. or *Note
os.lstat(): e28.

 -- Data: stat.ST_MODE
     Inode protection mode.

 -- Data: stat.ST_INO
     Inode number.

 -- Data: stat.ST_DEV
     Device inode resides on.

 -- Data: stat.ST_NLINK
     Number of links to the inode.

 -- Data: stat.ST_UID
     User id of the owner.

 -- Data: stat.ST_GID
     Group id of the owner.

 -- Data: stat.ST_SIZE
     Size in bytes of a plain file; amount of data waiting on some
     special files.

 -- Data: stat.ST_ATIME
     Time of last access.

 -- Data: stat.ST_MTIME
     Time of last modification.

 -- Data: stat.ST_CTIME
     The “ctime” as reported by the operating system.  On some
     systems (like Unix) is the time of the last metadata change, and,
     on others (like Windows), is the creation time (see platform
     documentation for details).

The interpretation of “file size” changes according to the file
type.  For plain files this is the size of the file in bytes.  For
FIFOs and sockets under most flavors of Unix (including Linux in
particular), the “size” is the number of bytes waiting to be read
at the time of the call to *Note os.stat(): 3de, *Note os.fstat(): e3a,
or *Note os.lstat(): e28.; this can sometimes be useful, especially for
polling one of these special files after a non-blocking open.  The
meaning of the size field for other character and block devices varies
more, depending on the implementation of the underlying system call.

The variables below define the flags used in the *Note ST_MODE: e59.
field.

Use of the functions above is more portable than use of the first set
of flags:

 -- Data: stat.S_IFSOCK
     Socket.

 -- Data: stat.S_IFLNK
     Symbolic link.

 -- Data: stat.S_IFREG
     Regular file.

 -- Data: stat.S_IFBLK
     Block device.

 -- Data: stat.S_IFDIR
     Directory.

 -- Data: stat.S_IFCHR
     Character device.

 -- Data: stat.S_IFIFO
     FIFO.

The following flags can also be used in the `mode' argument of *Note
os.chmod(): e57.:

 -- Data: stat.S_ISUID
     Set UID bit.

 -- Data: stat.S_ISGID
     Set-group-ID bit.  This bit has several special uses.  For a
     directory it indicates that BSD semantics is to be used for that
     directory: files created there inherit their group ID from the
     directory, not from the effective group ID of the creating
     process, and directories created there will also get the *Note
     S_ISGID: e6b. bit set.  For a file that does not have the group
     execution bit (*Note S_IXGRP: e6c.)  set, the set-group-ID bit
     indicates mandatory file/record locking (see also *Note S_ENFMT:
     e6d.).

 -- Data: stat.S_ISVTX
     Sticky bit.  When this bit is set on a directory it means that a
     file in that directory can be renamed or deleted only by the owner
     of the file, by the owner of the directory, or by a privileged
     process.

 -- Data: stat.S_IRWXU
     Mask for file owner permissions.

 -- Data: stat.S_IRUSR
     Owner has read permission.

 -- Data: stat.S_IWUSR
     Owner has write permission.

 -- Data: stat.S_IXUSR
     Owner has execute permission.

 -- Data: stat.S_IRWXG
     Mask for group permissions.

 -- Data: stat.S_IRGRP
     Group has read permission.

 -- Data: stat.S_IWGRP
     Group has write permission.

 -- Data: stat.S_IXGRP
     Group has execute permission.

 -- Data: stat.S_IRWXO
     Mask for permissions for others (not in group).

 -- Data: stat.S_IROTH
     Others have read permission.

 -- Data: stat.S_IWOTH
     Others have write permission.

 -- Data: stat.S_IXOTH
     Others have execute permission.

 -- Data: stat.S_ENFMT
     System V file locking enforcement.  This flag is shared with *Note
     S_ISGID: e6b.: file/record locking is enforced on files that do
     not have the group execution bit (*Note S_IXGRP: e6c.) set.

 -- Data: stat.S_IREAD
     Unix V7 synonym for *Note S_IRUSR: e70.

 -- Data: stat.S_IWRITE
     Unix V7 synonym for *Note S_IWUSR: e71.

 -- Data: stat.S_IEXEC
     Unix V7 synonym for *Note S_IXUSR: e72.

The following flags can be used in the `flags' argument of *Note
os.chflags(): e7d.:

 -- Data: stat.UF_NODUMP
     Do not dump the file.

 -- Data: stat.UF_IMMUTABLE
     The file may not be changed.

 -- Data: stat.UF_APPEND
     The file may only be appended to.

 -- Data: stat.UF_OPAQUE
     The directory is opaque when viewed through a union stack.

 -- Data: stat.UF_NOUNLINK
     The file may not be renamed or deleted.

 -- Data: stat.UF_COMPRESSED
     The file is stored compressed (Mac OS X 10.6+).

 -- Data: stat.UF_HIDDEN
     The file should not be displayed in a GUI (Mac OS X 10.5+).

 -- Data: stat.SF_ARCHIVED
     The file may be archived.

 -- Data: stat.SF_IMMUTABLE
     The file may not be changed.

 -- Data: stat.SF_APPEND
     The file may only be appended to.

 -- Data: stat.SF_NOUNLINK
     The file may not be renamed or deleted.

 -- Data: stat.SF_SNAPSHOT
     The file is a snapshot file.

See the *BSD or Mac OS systems man page `chflags(2)' for more
information.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/stat.py


File: python.info,  Node: statvfs — Constants used with os statvfs,  Next: filecmp — File and Directory Comparisons,  Prev: stat — Interpreting stat results,  Up: File and Directory Access

5.10.4 `statvfs' — Constants used with `os.statvfs()'
-------------------------------------------------------

Deprecated since version 2.6: The *Note statvfs: 162. module has been
removed in Python 3.

The *Note statvfs: 162. module defines constants so interpreting the
result if *Note os.statvfs(): e8c, which returns a tuple, can be made
without remembering “magic numbers.”  Each of the constants defined
in this module is the `index' of the entry in the tuple returned by
*Note os.statvfs(): e8c. that contains the specified information.

 -- Data: statvfs.F_BSIZE
     Preferred file system block size.

 -- Data: statvfs.F_FRSIZE
     Fundamental file system block size.

 -- Data: statvfs.F_BLOCKS
     Total number of blocks in the filesystem.

 -- Data: statvfs.F_BFREE
     Total number of free blocks.

 -- Data: statvfs.F_BAVAIL
     Free blocks available to non-super user.

 -- Data: statvfs.F_FILES
     Total number of file nodes.

 -- Data: statvfs.F_FFREE
     Total number of free file nodes.

 -- Data: statvfs.F_FAVAIL
     Free nodes available to non-super user.

 -- Data: statvfs.F_FLAG
     Flags. System dependent: see `statvfs()' man page.

 -- Data: statvfs.F_NAMEMAX
     Maximum file name length.


File: python.info,  Node: filecmp — File and Directory Comparisons,  Next: tempfile — Generate temporary files and directories,  Prev: statvfs — Constants used with os statvfs,  Up: File and Directory Access

5.10.5 `filecmp' — File and Directory Comparisons
---------------------------------------------------

`Source code:' Lib/filecmp.py(1)

__________________________________________________________________

The *Note filecmp: cc. module defines functions to compare files and
directories, with various optional time/correctness trade-offs. For
comparing files, see also the *Note difflib: 82. module.

The *Note filecmp: cc. module defines the following functions:

 -- Function: filecmp.cmp (f1, f2[, shallow])
     Compare the files named `f1' and `f2', returning `True' if they
     seem equal, `False' otherwise.

     Unless `shallow' is given and is false, files with identical *Note
     os.stat(): 3de.  signatures are taken to be equal.

     Files that were compared using this function will not be compared
     again unless their *Note os.stat(): 3de. signature changes.

     Note that no external programs are called from this function,
     giving it portability and efficiency.

 -- Function: filecmp.cmpfiles (dir1, dir2, common[, shallow])
     Compare the files in the two directories `dir1' and `dir2' whose
     names are given by `common'.

     Returns three lists of file names: `match', `mismatch', `errors'.
     `match' contains the list of files that match, `mismatch' contains
     the names of those that don’t, and `errors' lists the names of
     files which could not be compared.  Files are listed in `errors'
     if they don’t exist in one of the directories, the user lacks
     permission to read them or if the comparison could not be done for
     some other reason.

     The `shallow' parameter has the same meaning and default value as
     for *Note filecmp.cmp(): e99.

     For example, `cmpfiles('a', 'b', ['c', 'd/e'])' will compare `a/c'
     with `b/c' and `a/d/e' with `b/d/e'.  `'c'' and `'d/e'' will each
     be in one of the three returned lists.

Example:

    >>> import filecmp
    >>> filecmp.cmp('undoc.rst', 'undoc.rst') # doctest: +SKIP
    True
    >>> filecmp.cmp('undoc.rst', 'index.rst') # doctest: +SKIP
    False

* Menu:

* The dircmp class::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/filecmp.py


File: python.info,  Node: The dircmp class,  Up: filecmp — File and Directory Comparisons

5.10.5.1 The `dircmp' class
...........................

*Note dircmp: e9d. instances are built using this constructor:

 -- Class: filecmp.dircmp (a, b[, ignore[, hide]])
     Construct a new directory comparison object, to compare the
     directories `a' and `b'. `ignore' is a list of names to ignore,
     and defaults to `['RCS', 'CVS', 'tags']'. `hide' is a list of
     names to hide, and defaults to `[os.curdir, os.pardir]'.

     The *Note dircmp: e9d. class compares files by doing `shallow'
     comparisons as described for *Note filecmp.cmp(): e99.

     The *Note dircmp: e9d. class provides the following methods:

      -- Method: report ()
          Print (to `sys.stdout') a comparison between `a' and `b'.

      -- Method: report_partial_closure ()
          Print a comparison between `a' and `b' and common immediate
          subdirectories.

      -- Method: report_full_closure ()
          Print a comparison between `a' and `b' and common
          subdirectories (recursively).

     The *Note dircmp: e9d. class offers a number of interesting
     attributes that may be used to get various bits of information
     about the directory trees being compared.

     Note that via *Note __getattr__(): 345. hooks, all attributes are
     computed lazily, so there is no speed penalty if only those
     attributes which are lightweight to compute are used.

      -- Attribute: left
          The directory `a'.

      -- Attribute: right
          The directory `b'.

      -- Attribute: left_list
          Files and subdirectories in `a', filtered by `hide' and
          `ignore'.

      -- Attribute: right_list
          Files and subdirectories in `b', filtered by `hide' and
          `ignore'.

      -- Attribute: common
          Files and subdirectories in both `a' and `b'.

      -- Attribute: left_only
          Files and subdirectories only in `a'.

      -- Attribute: right_only
          Files and subdirectories only in `b'.

      -- Attribute: common_dirs
          Subdirectories in both `a' and `b'.

      -- Attribute: common_files
          Files in both `a' and `b'

      -- Attribute: common_funny
          Names in both `a' and `b', such that the type differs between
          the directories, or names for which *Note os.stat(): 3de.
          reports an error.

      -- Attribute: same_files
          Files which are identical in both `a' and `b', using the
          class’s file comparison operator.

      -- Attribute: diff_files
          Files which are in both `a' and `b', whose contents differ
          according to the class’s file comparison operator.

      -- Attribute: funny_files
          Files which are in both `a' and `b', but could not be
          compared.

      -- Attribute: subdirs
          A dictionary mapping names in *Note common_dirs: ea8. to
          *Note dircmp: e9d. objects.

Here is a simplified example of using the `subdirs' attribute to search
recursively through two directories to show common different files:

    >>> from filecmp import dircmp
    >>> def print_diff_files(dcmp):
    ...     for name in dcmp.diff_files:
    ...         print "diff_file %s found in %s and %s" % (name, dcmp.left,
    ...               dcmp.right)
    ...     for sub_dcmp in dcmp.subdirs.values():
    ...         print_diff_files(sub_dcmp)
    ...
    >>> dcmp = dircmp('dir1', 'dir2') # doctest: +SKIP
    >>> print_diff_files(dcmp) # doctest: +SKIP


File: python.info,  Node: tempfile — Generate temporary files and directories,  Next: glob — Unix style pathname pattern expansion,  Prev: filecmp — File and Directory Comparisons,  Up: File and Directory Access

5.10.6 `tempfile' — Generate temporary files and directories
--------------------------------------------------------------

`Source code:' Lib/tempfile.py(1)

__________________________________________________________________

This module generates temporary files and directories.  It works on all
supported platforms.

In version 2.3 of Python, this module was overhauled for enhanced
security.  It now provides three new functions, *Note
NamedTemporaryFile(): 36f, *Note mkstemp(): eb1, and *Note mkdtemp():
eb2, which should eliminate all remaining need to use the insecure
*Note mktemp(): eb3. function.  Temporary file names created by this
module no longer contain the process ID; instead a string of six random
characters is used.

Also, all the user-callable functions now take additional arguments
which allow direct control over the location and name of temporary
files.  It is no longer necessary to use the global `tempdir' and
`template' variables.  To maintain backward compatibility, the argument
order is somewhat odd; it is recommended to use keyword arguments for
clarity.

The module defines the following user-callable functions:

 -- Function: tempfile.TemporaryFile ([mode='w+b'[, bufsize=-1[,
          suffix=''[, prefix='tmp'[, dir=None]]]]])
     Return a file-like object that can be used as a temporary storage
     area.  The file is created using *Note mkstemp(): eb1. It will be
     destroyed as soon as it is closed (including an implicit close
     when the object is garbage collected).  Under Unix, the directory
     entry for the file is removed immediately after the file is
     created.  Other platforms do not support this; your code should
     not rely on a temporary file created using this function having or
     not having a visible name in the file system.

     The `mode' parameter defaults to `'w+b'' so that the file created
     can be read and written without being closed.  Binary mode is used
     so that it behaves consistently on all platforms without regard
     for the data that is stored.  `bufsize' defaults to `-1', meaning
     that the operating system default is used.

     The `dir', `prefix' and `suffix' parameters are passed to *Note
     mkstemp(): eb1.

     The returned object is a true file object on POSIX platforms.  On
     other platforms, it is a file-like object whose `file' attribute
     is the underlying true file object. This file-like object can be
     used in a *Note with: 1c1. statement, just like a normal file.

 -- Function: tempfile.NamedTemporaryFile ([mode='w+b'[, bufsize=-1[,
          suffix=''[, prefix='tmp'[, dir=None[, delete=True]]]]]])
     This function operates exactly as *Note TemporaryFile(): eb4.
     does, except that the file is guaranteed to have a visible name in
     the file system (on Unix, the directory entry is not unlinked).
     That name can be retrieved from the `name' attribute of the
     returned file-like object.  Whether the name can be used to open
     the file a second time, while the named temporary file is still
     open, varies across platforms (it can be so used on Unix; it cannot
     on Windows NT or later).  If `delete' is true (the default), the
     file is deleted as soon as it is closed.

     The returned object is always a file-like object whose `file'
     attribute is the underlying true file object. This file-like
     object can be used in a *Note with: 1c1. statement, just like a
     normal file.

     New in version 2.3.

     New in version 2.6: The `delete' parameter.


 -- Function: tempfile.SpooledTemporaryFile ([max_size=0[, mode='w+b'[,
          bufsize=-1[, suffix=''[, prefix='tmp'[, dir=None]]]]]])
     This function operates exactly as *Note TemporaryFile(): eb4.
     does, except that data is spooled in memory until the file size
     exceeds `max_size', or until the file’s `fileno()' method is
     called, at which point the contents are written to disk and
     operation proceeds as with *Note TemporaryFile(): eb4.  Also,
     it’s `truncate' method does not accept a `size' argument.

     The resulting file has one additional method, `rollover()', which
     causes the file to roll over to an on-disk file regardless of its
     size.

     The returned object is a file-like object whose `_file' attribute
     is either a *Note StringIO: 2df. object or a true file object,
     depending on whether `rollover()' has been called. This file-like
     object can be used in a *Note with: 1c1. statement, just like a
     normal file.

     New in version 2.6.


 -- Function: tempfile.mkstemp ([suffix=''[, prefix='tmp'[, dir=None[,
          text=False]]]])
     Creates a temporary file in the most secure manner possible.
     There are no race conditions in the file’s creation, assuming
     that the platform properly implements the *Note os.O_EXCL: eb6.
     flag for *Note os.open(): 600.  The file is readable and writable
     only by the creating user ID.  If the platform uses permission
     bits to indicate whether a file is executable, the file is
     executable by no one.  The file descriptor is not inherited by
     child processes.

     Unlike *Note TemporaryFile(): eb4, the user of *Note mkstemp():
     eb1. is responsible for deleting the temporary file when done with
     it.

     If `suffix' is specified, the file name will end with that suffix,
     otherwise there will be no suffix.  *Note mkstemp(): eb1. does not
     put a dot between the file name and the suffix; if you need one,
     put it at the beginning of `suffix'.

     If `prefix' is specified, the file name will begin with that
     prefix; otherwise, a default prefix is used.

     If `dir' is specified, the file will be created in that directory;
     otherwise, a default directory is used.  The default directory is
     chosen from a platform-dependent list, but the user of the
     application can control the directory location by setting the
     `TMPDIR', `TEMP' or `TMP' environment variables.  There is thus no
     guarantee that the generated filename will have any nice
     properties, such as not requiring quoting when passed to external
     commands via `os.popen()'.

     If `text' is specified, it indicates whether to open the file in
     binary mode (the default) or text mode.  On some platforms, this
     makes no difference.

     *Note mkstemp(): eb1. returns a tuple containing an OS-level
     handle to an open file (as would be returned by *Note os.open():
     600.) and the absolute pathname of that file, in that order.

     New in version 2.3.


 -- Function: tempfile.mkdtemp ([suffix=''[, prefix='tmp'[, dir=None]]])
     Creates a temporary directory in the most secure manner possible.
     There are no race conditions in the directory’s creation.  The
     directory is readable, writable, and searchable only by the
     creating user ID.

     The user of *Note mkdtemp(): eb2. is responsible for deleting the
     temporary directory and its contents when done with it.

     The `prefix', `suffix', and `dir' arguments are the same as for
     *Note mkstemp(): eb1.

     *Note mkdtemp(): eb2. returns the absolute pathname of the new
     directory.

     New in version 2.3.


 -- Function: tempfile.mktemp ([suffix=''[, prefix='tmp'[, dir=None]]])
     Deprecated since version 2.3: Use *Note mkstemp(): eb1. instead.

     Return an absolute pathname of a file that did not exist at the
     time the call is made.  The `prefix', `suffix', and `dir'
     arguments are the same as for *Note mkstemp(): eb1.

          Warning: Use of this function may introduce a security hole
          in your program.  By the time you get around to doing
          anything with the file name it returns, someone else may have
          beaten you to the punch.  *Note mktemp(): eb3. usage can be
          replaced easily with *Note NamedTemporaryFile(): 36f, passing
          it the `delete=False' parameter:

              >>> f = NamedTemporaryFile(delete=False)
              >>> f
              <open file '<fdopen>', mode 'w+b' at 0x384698>
              >>> f.name
              '/var/folders/5q/5qTPn6xq2RaWqk+1Ytw3-U+++TI/-Tmp-/tmpG7V1Y0'
              >>> f.write("Hello World!\n")
              >>> f.close()
              >>> os.unlink(f.name)
              >>> os.path.exists(f.name)
              False

The module uses a global variable that tell it how to construct a
temporary name.  They are initialized at the first call to any of the
functions above.  The caller may change them, but this is discouraged;
use the appropriate function arguments, instead.

 -- Data: tempfile.tempdir
     When set to a value other than `None', this variable defines the
     default value for the `dir' argument to all the functions defined
     in this module.

     If `tempdir' is unset or `None' at any call to any of the above
     functions, Python searches a standard list of directories and sets
     `tempdir' to the first one which the calling user can create files
     in.  The list is:

       1. The directory named by the `TMPDIR' environment variable.

       2. The directory named by the `TEMP' environment variable.

       3. The directory named by the `TMP' environment variable.

       4. A platform-specific location:

             * On RiscOS, the directory named by the `Wimp$ScrapDir'
               environment variable.

             * On Windows, the directories `C:\TEMP', `C:\TMP',
               `\TEMP', and `\TMP', in that order.

             * On all other platforms, the directories `/tmp',
               `/var/tmp', and `/usr/tmp', in that order.

       5. As a last resort, the current working directory.

 -- Function: tempfile.gettempdir ()
     Return the directory currently selected to create temporary files
     in. If *Note tempdir: eb7. is not `None', this simply returns its
     contents; otherwise, the search described above is performed, and
     the result returned.

     New in version 2.3.


 -- Data: tempfile.template
     Deprecated since version 2.0: Use *Note gettempprefix(): eba.
     instead.

     When set to a value other than `None', this variable defines the
     prefix of the final component of the filenames returned by *Note
     mktemp(): eb3.  A string of six random letters and digits is
     appended to the prefix to make the filename unique.  The default
     prefix is `tmp'.

     Older versions of this module used to require that `template' be
     set to `None' after a call to *Note os.fork(): 244.; this has not
     been necessary since version 1.5.2.

 -- Function: tempfile.gettempprefix ()
     Return the filename prefix used to create temporary files.  This
     does not contain the directory component.  Using this function is
     preferred over reading the `template' variable directly.

     New in version 1.5.2.


---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/tempfile.py


File: python.info,  Node: glob — Unix style pathname pattern expansion,  Next: fnmatch — Unix filename pattern matching,  Prev: tempfile — Generate temporary files and directories,  Up: File and Directory Access

5.10.7 `glob' — Unix style pathname pattern expansion
-------------------------------------------------------

`Source code:' Lib/glob.py(1)

__________________________________________________________________

The *Note glob: e4. module finds all the pathnames matching a specified
pattern according to the rules used by the Unix shell, although results
are returned in arbitrary order.  No tilde expansion is done, but `*',
`?', and character ranges expressed with `[]' will be correctly
matched.  This is done by using the *Note os.listdir(): 2d5. and *Note
fnmatch.fnmatch(): ebd. functions in concert, and not by actually
invoking a subshell.  Note that unlike *Note fnmatch.fnmatch(): ebd,
*Note glob: e4. treats filenames beginning with a dot (`.') as special
cases.  (For tilde and shell variable expansion, use *Note
os.path.expanduser(): e21. and *Note os.path.expandvars(): 369.)

For a literal match, wrap the meta-characters in brackets.  For
example, `'[?]'' matches the character `'?''.

 -- Function: glob.glob (pathname)
     Return a possibly-empty list of path names that match `pathname',
     which must be a string containing a path specification. `pathname'
     can be either absolute (like `/usr/src/Python-1.5/Makefile') or
     relative (like `../../Tools/*/*.gif'), and can contain shell-style
     wildcards. Broken symlinks are included in the results (as in the
     shell).

 -- Function: glob.iglob (pathname)
     Return an *Note iterator: 8a8. which yields the same values as
     *Note glob(): e4.  without actually storing them all
     simultaneously.

     New in version 2.5.


For example, consider a directory containing only the following files:
`1.gif', `2.txt', and `card.gif'.  *Note glob(): e4. will produce the
following results.  Notice how any leading components of the path are
preserved.

    >>> import glob
    >>> glob.glob('./[0-9].*')
    ['./1.gif', './2.txt']
    >>> glob.glob('*.gif')
    ['1.gif', 'card.gif']
    >>> glob.glob('?.gif')
    ['1.gif']

If the directory contains files starting with `.' they won’t be
matched by default. For example, consider a directory containing
`card.gif' and `.card.gif':

    >>> import glob
    >>> glob.glob('*.gif')
    ['card.gif']
    >>> glob.glob('.c*')
    ['.card.gif']

See also
........

Module *Note fnmatch: d3.
     Shell-style filename (not path) expansion

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/glob.py


File: python.info,  Node: fnmatch — Unix filename pattern matching,  Next: linecache — Random access to text lines,  Prev: glob — Unix style pathname pattern expansion,  Up: File and Directory Access

5.10.8 `fnmatch' — Unix filename pattern matching
---------------------------------------------------

`Source code:' Lib/fnmatch.py(1)

__________________________________________________________________

This module provides support for Unix shell-style wildcards, which are
`not' the same as regular expressions (which are documented in the
*Note re: 144. module).  The special characters used in shell-style
wildcards are:

Pattern          Meaning
---------------------------------------------------------- 
`*'              matches everything
`?'              matches any single character
`[seq]'          matches any character in `seq'
`[!seq]'         matches any character not in `seq'

For a literal match, wrap the meta-characters in brackets.  For
example, `'[?]'' matches the character `'?''.

Note that the filename separator (`'/'' on Unix) is `not' special to
this module.  See module *Note glob: e4. for pathname expansion (*Note
glob: e4. uses *Note fnmatch(): d3. to match pathname segments).
Similarly, filenames starting with a period are not special for this
module, and are matched by the `*' and `?' patterns.

 -- Function: fnmatch.fnmatch (filename, pattern)
     Test whether the `filename' string matches the `pattern' string,
     returning *Note True: 3c8. or *Note False: 3c9.  If the operating
     system is case-insensitive, then both parameters will be
     normalized to all lower- or upper-case before the comparison is
     performed.  *Note fnmatchcase(): ec1. can be used to perform a
     case-sensitive comparison, regardless of whether that’s standard
     for the operating system.

     This example will print all file names in the current directory
     with the extension `.txt':

         import fnmatch
         import os

         for file in os.listdir('.'):
             if fnmatch.fnmatch(file, '*.txt'):
                 print file

 -- Function: fnmatch.fnmatchcase (filename, pattern)
     Test whether `filename' matches `pattern', returning *Note True:
     3c8. or *Note False: 3c9.; the comparison is case-sensitive.

 -- Function: fnmatch.filter (names, pattern)
     Return the subset of the list of `names' that match `pattern'. It
     is the same as `[n for n in names if fnmatch(n, pattern)]', but
     implemented more efficiently.

     New in version 2.2.


 -- Function: fnmatch.translate (pattern)
     Return the shell-style `pattern' converted to a regular expression
     for using with *Note re.match(): 9ec.

     Example:

         >>> import fnmatch, re
         >>>
         >>> regex = fnmatch.translate('*.txt')
         >>> regex
         '.*\\.txt\\Z(?ms)'
         >>> reobj = re.compile(regex)
         >>> reobj.match('foobar.txt')
         <_sre.SRE_Match object at 0x...>

See also
........

Module *Note glob: e4.
     Unix shell-style path expansion.

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/fnmatch.py


File: python.info,  Node: linecache — Random access to text lines,  Next: shutil — High-level file operations,  Prev: fnmatch — Unix filename pattern matching,  Up: File and Directory Access

5.10.9 `linecache' — Random access to text lines
--------------------------------------------------

`Source code:' Lib/linecache.py(1)

__________________________________________________________________

The *Note linecache: 100. module allows one to get any line from any
file, while attempting to optimize internally, using a cache, the
common case where many lines are read from a single file.  This is used
by the *Note traceback: 181. module to retrieve source lines for
inclusion in  the formatted traceback.

The *Note linecache: 100. module defines the following functions:

 -- Function: linecache.getline (filename, lineno[, module_globals])
     Get line `lineno' from file named `filename'. This function will
     never raise an exception — it will return `''' on errors (the
     terminating newline character will be included for lines that are
     found).

     If a file named `filename' is not found, the function will look
     for it in the module search path, `sys.path', after first checking
     for a PEP 302(2) `__loader__' in `module_globals', in case the
     module was imported from a zipfile or other non-filesystem import
     source.

     New in version 2.5: The `module_globals' parameter was added.


 -- Function: linecache.clearcache ()
     Clear the cache.  Use this function if you no longer need lines
     from files previously read using *Note getline(): ec6.

 -- Function: linecache.checkcache ([filename])
     Check the cache for validity.  Use this function if files in the
     cache  may have changed on disk, and you require the updated
     version.  If `filename' is omitted, it will check all the entries
     in the cache.

Example:

    >>> import linecache
    >>> linecache.getline('/etc/passwd', 4)
    'sys:x:3:3:sys:/dev:/bin/sh\n'

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/linecache.py

(2) https://www.python.org/dev/peps/pep-0302


File: python.info,  Node: shutil — High-level file operations,  Next: dircache — Cached directory listings,  Prev: linecache — Random access to text lines,  Up: File and Directory Access

5.10.10 `shutil' — High-level file operations
-----------------------------------------------

`Source code:' Lib/shutil.py(1)

__________________________________________________________________

The *Note shutil: 154. module offers a number of high-level operations
on files and collections of files.  In particular, functions are
provided  which support file copying and removal. For operations on
individual files, see also the *Note os: 129. module.

     Warning: Even the higher-level file copying functions (*Note
     shutil.copy(): ecb, *Note shutil.copy2(): ecc.) can’t copy all
     file metadata.

     On POSIX platforms, this means that file owner and group are lost
     as well as ACLs.  On Mac OS, the resource fork and other metadata
     are not used.  This means that resources will be lost and file
     type and creator codes will not be correct. On Windows, file
     owners, ACLs and alternate data streams are not copied.

* Menu:

* Directory and files operations::
* Archiving operations::

---------- Footnotes ----------

(1) https://hg.python.org/cpython/file/2.7/Lib/shutil.py


File: python.info,  Node: Directory and files operations,  Next: Archiving operations,  Up: shutil — High-level file operations

5.10.10.1 Directory and files operations
........................................

 -- Function: shutil.copyfileobj (fsrc, fdst[, length])
     Copy the contents of the file-like object `fsrc' to the file-like
     object `fdst'.  The integer `length', if given, is the buffer
     size. In particular, a negative `length' value means to copy the
     data without looping over the source data in chunks; by default
     the data is read in chunks to avoid uncontrolled memory
     consumption. Note that if the current file position of the `fsrc'
     object is not 0, only the contents from the current file position
     to the end of the file will be copied.

 -- Function: shutil.copyfile (src, dst)
     Copy the contents (no metadata) of the file named `src' to a file
     named `dst'.  `dst' must be the complete target file name; look at
     *Note shutil.copy(): ecb. for a copy that accepts a target
     directory path.  If `src' and `dst' are the same files, *Note
     Error: ed0. is raised.  The destination location must be writable;
     otherwise,  an *Note IOError: 1fa. exception will be raised. If
     `dst' already exists, it will be replaced.   Special files such as
     character or block devices and pipes cannot be copied with this
     function.  `src' and `dst' are path names given as strings.

 -- Function: shutil.copymode (src, dst)
     Copy the permission bits from `src' to `dst'.  The file contents,
     owner, and group are unaffected.  `src' and `dst' are path names
     given as strings.

 -- Function: shutil.copystat (src, dst)
     Copy the permission bits, last access time, last modification
     time, and flags from `src' to `dst'.  The file contents, owner,
     and group are unaffected.  `src' and `dst' are path names given as
     strings.

 -- Function: shutil.copy (src, dst)
     Copy the file `src' to the file or directory `dst'.  If `dst' is a
     directory, a file with the same basename as `src'  is created (or
     overwritten) in the directory specified.  Permission bits are
     copied.  `src' and `dst' are path names given as strings.

 -- Function: shutil.copy2 (src, dst)
     Similar to *Note shutil.copy(): ecb, but metadata is copied as
     well – in fact, this is just *Note shutil.copy(): ecb. followed
     by *Note copystat(): ed2.  This is similar to the Unix command `cp
     -p'.

 -- Function: shutil.ignore_patterns (*patterns)
     This factory function creates a function that can be used as a
     callable for *Note copytree(): 24d.’s `ignore' argument,
     ignoring files and directories that match one of the glob-style
     `patterns' provided.  See the example below.

     New in version 2.6.


 -- Function: shutil.copytree (src, dst, symlinks=False, ignore=None)
     Recursively copy an entire directory tree rooted at `src'.  The
     destination directory, named by `dst', must not already exist; it
     will be created as well as missing parent directories.
     Permissions and times of directories are copied with *Note
     copystat(): ed2, individual files are copied using *Note
     shutil.copy2(): ecc.

     If `symlinks' is true, symbolic links in the source tree are
     represented as symbolic links in the new tree, but the metadata of
     the original links is NOT copied; if false or omitted, the
     contents and metadata of the linked files are copied to the new
     tree.

     If `ignore' is given, it must be a callable that will receive as
     its arguments the directory being visited by *Note copytree():
     24d, and a list of its contents, as returned by *Note
     os.listdir(): 2d5.  Since *Note copytree(): 24d. is called
     recursively, the `ignore' callable will be called once for each
     directory that is copied.  The callable must return a sequence of
     directory and file names relative to the current directory (i.e. a
     subset of the items in its second argument); these names will then
     be ignored in the copy process.  *Note ignore_patterns(): ed3. can
     be used to create such a callable that ignores names based on
     glob-style patterns.

     If exception(s) occur, an *Note Error: ed0. is raised with a list
     of reasons.

     The source code for this should be considered an example rather
     than the ultimate tool.

     Changed in version 2.3: *Note Error: ed0. is raised if any
     exceptions occur during copying, rather than printing a message.

     Changed in version 2.5: Create intermediate directories needed to
     create `dst', rather than raising an error. Copy permissions and
     times of directories using *Note copystat(): ed2.

     Changed in version 2.6: Added the `ignore' argument to be able to
     influence what is being copied.


 -- Function: shutil.rmtree (path[, ignore_errors[, onerror]])
     Delete an entire directory tree; `path' must point to a directory
     (but not a symbolic link to a directory).  If `ignore_errors' is
     true, errors resulting from failed removals will be ignored; if
     false or omitted, such errors are handled by calling a handler
     specified by `onerror' or, if that is omitted, they raise an
     exception.

     If `onerror' is provided, it must be a callable that accepts three
     parameters: `function', `path', and `excinfo'. The first parameter,
     `function', is the function which raised the exception; it will be
     *Note os.path.islink(): e30, *Note os.listdir(): 2d5, *Note
     os.remove(): ed5. or *Note os.rmdir(): ed6.  The second parameter,
     `path', will be the path name passed to `function'.  The third
     parameter, `excinfo', will be the exception information return by
     *Note sys.exc_info(): 306.  Exceptions raised by `onerror' will
     not be caught.

     Changed in version 2.6: Explicitly check for `path' being a
     symbolic link and raise *Note OSError: 231.  in that case.


 -- Function: shutil.move (src, dst)
     Recursively move a file or directory (`src') to another location
     (`dst').

     If the destination is an existing directory, then `src' is moved
     inside that directory. If the destination already exists but is
     not a directory, it may be overwritten depending on *Note
     os.rename(): ed8. semantics.

     If the destination is on the current filesystem, then *Note
     os.rename(): ed8. is used.  Otherwise, `src' is copied (using
     *Note shutil.copy2(): ecc.) to `dst' and then removed.

     New in version 2.3.


 -- Exception: shutil.Error
     This exception collects exceptions that are raised during a
     multi-file operation. For *Note copytree(): 24d, the exception
     argument is a list of 3-tuples (`srcname', `dstname', `exception').

     New in version 2.3.


* Menu:

* copytree example::


File: python.info,  Node: copytree example,  Up: Directory and files operations

5.10.10.2 copytree example
..........................

This example is the implementation of the *Note copytree(): 24d.
function, described above, with the docstring omitted.  It demonstrates
many of the other functions provided by this module.

    def copytree(src, dst, symlinks=False, ignore=None):
        names = os.listdir(src)
        if ignore is not None:
            ignored_names = ignore(src, names)
        else:
            ignored_names = set()

        os.makedirs(dst)
        errors = []
        for name in names:
            if name in ignored_names:
                continue
            srcname = os.path.join(src, name)
            dstname = os.path.join(dst, name)
            try:
                if symlinks and os.path.islink(srcname):
                    linkto = os.readlink(srcname)
                    os.symlink(linkto, dstname)
                elif os.path.isdir(srcname):
                    copytree(srcname, dstname, symlinks, ignore)
                else:
                    copy2(srcname, dstname)
                # XXX What about devices, sockets etc.?
            except (IOError, os.error) as why:
                errors.append((srcname, dstname, str(why)))
            # catch the Error from the recursive copytree so that we can
            # continue with other files
            except Error as err:
                errors.extend(err.args[0])
        try:
            copystat(src, dst)
        except WindowsError:
            # can't copy file access times on Windows
            pass
        except OSError as why:
            errors.extend((src, dst, str(why)))
        if errors:
            raise Error(errors)

Another example that uses the *Note ignore_patterns(): ed3. helper:

    from shutil import copytree, ignore_patterns

    copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))

This will copy everything except `.pyc' files and files or directories
whose name starts with `tmp'.

Another example that uses the `ignore' argument to add a logging call:

    from shutil import copytree
    import logging

    def _logpath(path, names):
        logging.info('Working in %s' % path)
        return []   # nothing will be ignored

    copytree(source, destination, ignore=_logpath)


File: python.info,  Node: Archiving operations,  Prev: Directory and files operations,  Up: shutil — High-level file operations

5.10.10.3 Archiving operations
..............................

High-level utilities to create and read compressed and archived files
are also provided.  They rely on the *Note zipfile: 1ab. and *Note
tarfile: 171. modules.

 -- Function: shutil.make_archive (base_name, format[, root_dir[,
          base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])
     Create an archive file (eg. zip or tar) and returns its name.

     `base_name' is the name of the file to create, including the path,
     minus any format-specific extension. `format' is the archive
     format: one of “zip”, “tar”, “bztar” or “gztar”.

     `root_dir' is a directory that will be the root directory of the
     archive; ie. we typically chdir into `root_dir' before creating the
     archive.

     `base_dir' is the directory where we start archiving from; ie.
     `base_dir' will be the common prefix of all files and directories
     in the archive.

     `root_dir' and `base_dir' both default to the current directory.

     `owner' and `group' are used when creating a tar archive. By
     default, uses the current owner and group.

     `logger' must be an object compatible with PEP 282(1), usually an
     instance of *Note logging.Logger: 1dd.

     New in version 2.7.


 -- Function: shutil.get_archive_formats ()
     Return a list of supported formats for archiving.  Each element of
     the returned sequence is a tuple `(name, description)'.

     By default *Note shutil: 154. provides these formats:

        - `gztar': gzip’ed tar-file

        - `bztar': bzip2’ed tar-file

        - `tar': uncompressed tar file

        - `zip': ZIP file

     You can register new formats or provide your own archiver for any
     existing formats, by using *Note register_archive_format(): ede.

     New in version 2.7.


 -- Function: shutil.register_archive_format (name, function[,
          extra_args[, description]])
     Register an archiver for the format `name'. `function' is a
     callable that will be used to invoke the archiver.

     If given, `extra_args' is a sequence of `(name, value)' that will
     be used as extra keywords arguments when the archiver callable is
     used.

     `description' is used by *Note get_archive_formats(): edd. which
     returns the list of archivers. Defaults to an empty list.

     New in version 2.7.


 -- Function: shutil.unregister_archive_format (name)
     Remove the archive format `name' from the list of supported
     formats.

     New in version 2.7.


* Menu:

* Archiving example::

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-0282


File: python.info,  Node: Archiving example,  Up: Archiving operations

5.10.10.4 Archiving example
...........................

In this example, we create a gzip’ed tar-file archive containing all
files found in the `.ssh' directory of the user:

    >>> from shutil import make_archive
    >>> import os
    >>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive'))
    >>> root_dir = os.path.expanduser(os.path.join('~', '.ssh'))
    >>> make_archive(archive_name, 'gztar', root_dir)
    '/Users/tarek/myarchive.tar.gz'

The resulting archive contains:

    $ tar -tzvf /Users/tarek/myarchive.tar.gz
    drwx------ tarek/staff       0 2010-02-01 16:23:40 ./
    -rw-r--r-- tarek/staff     609 2008-06-09 13:26:54 ./authorized_keys
    -rwxr-xr-x tarek/staff      65 2008-06-09 13:26:54 ./config
    -rwx------ tarek/staff     668 2008-06-09 13:26:54 ./id_dsa
    -rwxr-xr-x tarek/staff     609 2008-06-09 13:26:54 ./id_dsa.pub
    -rw------- tarek/staff    1675 2008-06-09 13:26:54 ./id_rsa
    -rw-r--r-- tarek/staff     397 2008-06-09 13:26:54 ./id_rsa.pub
    -rw-r--r-- tarek/staff   37192 2010-02-06 18:23:10 ./known_hosts


File: python.info,  Node: dircache — Cached directory listings,  Next: macpath — Mac OS 9 path manipulation functions,  Prev: shutil — High-level file operations,  Up: File and Directory Access

5.10.11 `dircache' — Cached directory listings
------------------------------------------------

Deprecated since version 2.6: The *Note dircache: 83. module has been
removed in Python 3.

The *Note dircache: 83. module defines a function for reading directory
listing using a cache, and cache invalidation using the `mtime' of the
directory.  Additionally, it defines a function to annotate directories
by appending a slash.

The *Note dircache: 83. module defines the following functions:

 -- Function: dircache.reset ()
     Resets the directory cache.

 -- Function: dircache.listdir (path)
     Return a directory listing of `path', as gotten from *Note
     os.listdir(): 2d5. Note that unless `path' changes, further call
     to *Note listdir(): 439. will not re-read the directory structure.

     Note that the list returned should be regarded as read-only.
     (Perhaps a future version should change it to return a tuple?)

 -- Function: dircache.opendir (path)
     Same as *Note listdir(): 439. Defined for backwards compatibility.

 -- Function: dircache.annotate (head, list)
     Assume `list' is a list of paths relative to `head', and append,
     in place, a `'/'' to each path which points to a directory.

    >>> import dircache
    >>> a = dircache.listdir('/')
    >>> a = a[:] # Copy the return value so we can change 'a'
    >>> a
    ['bin', 'boot', 'cdrom', 'dev', 'etc', 'floppy', 'home', 'initrd', 'lib', 'lost+
    found', 'mnt', 'proc', 'root', 'sbin', 'tmp', 'usr', 'var', 'vmlinuz']
    >>> dircache.annotate('/', a)
    >>> a
    ['bin/', 'boot/', 'cdrom/', 'dev/', 'etc/', 'floppy/', 'home/', 'initrd/', 'lib/
    ', 'lost+found/', 'mnt/', 'proc/', 'root/', 'sbin/', 'tmp/', 'usr/', 'var/', 'vm
    linuz']


File: python.info,  Node: macpath — Mac OS 9 path manipulation functions,  Prev: dircache — Cached directory listings,  Up: File and Directory Access

5.10.12 `macpath' — Mac OS 9 path manipulation functions
----------------------------------------------------------

This module is the Mac OS 9 (and earlier) implementation of the *Note
os.path: 12a.  module. It can be used to manipulate old-style Macintosh
pathnames on Mac OS X (or any other platform).

The following functions are available in this module: `normcase()',
`normpath()', `isabs()', `join()', `split()', `isdir()', `isfile()',
`walk()', `exists()'. For other functions available in *Note os.path:
12a. dummy counterparts are available.

See also
........

Section *Note File Objects: 66e.
     A description of Python’s built-in file objects.

Module *Note os: 129.
     Operating system interfaces, including functions to work with
     files at a lower level than the built-in file object.


File: python.info,  Node: Data Persistence,  Next: Data Compression and Archiving,  Prev: File and Directory Access,  Up: The Python Standard Library

5.11 Data Persistence
=====================

The modules described in this chapter support storing Python data in a
persistent form on disk.  The *Note pickle: 12e. and *Note marshal:
10c. modules can turn many Python data types into a stream of bytes and
then recreate the objects from the bytes.  The various DBM-related
modules support a family of hash-based file formats that store a
mapping of strings to other strings.  The *Note bsddb: 1c.  module also
provides such disk-based string-to-string mappings based on hashing,
and also supports B-Tree and record-based formats.

The list of modules described in this chapter is:

* Menu:

* pickle — Python object serialization::
* cPickle — A faster pickle::
* copy_reg — Register pickle support functions::
* shelve — Python object persistence::
* marshal — Internal Python object serialization::
* anydbm — Generic access to DBM-style databases::
* whichdb — Guess which DBM module created a database::
* dbm — Simple “database” interface::
* gdbm — GNU’s reinterpretation of dbm::
* dbhash — DBM-style interface to the BSD database library::
* bsddb — Interface to Berkeley DB library::
* dumbdbm — Portable DBM implementation::
* sqlite3 — DB-API 2.0 interface for SQLite databases: sqlite3 — DB-API 2 0 interface for SQLite databases.


File: python.info,  Node: pickle — Python object serialization,  Next: cPickle — A faster pickle,  Up: Data Persistence

5.11.1 `pickle' — Python object serialization
-----------------------------------------------

The *Note pickle: 12e. module implements a fundamental, but powerful
algorithm for serializing and de-serializing a Python object structure.
“Pickling” is the process whereby a Python object hierarchy is
converted into a byte stream, and “unpickling” is the inverse
operation, whereby a byte stream is converted back into an object
hierarchy.  Pickling (and unpickling) is alternatively known as
“serialization”, “marshalling,” (1) or “flattening”,
however, to avoid confusion, the terms used here are “pickling” and
“unpickling”.

This documentation describes both the *Note pickle: 12e. module and the
*Note cPickle: 73. module.

     Warning: The *Note pickle: 12e. module is not secure against
     erroneous or maliciously constructed data.  Never unpickle data
     received from an untrusted or unauthenticated source.

* Menu:

* Relationship to other Python modules::
* Data stream format::
* Usage::
* What can be pickled and unpickled?::
* The pickle protocol::
* Subclassing Unpicklers::
* Example: Example<3>.

---------- Footnotes ----------

(1) Don’t confuse this with the *Note marshal: 10c. module


File: python.info,  Node: Relationship to other Python modules,  Next: Data stream format,  Up: pickle — Python object serialization

5.11.1.1 Relationship to other Python modules
.............................................

The *Note pickle: 12e. module has an optimized cousin called the *Note
cPickle: 73.  module.  As its name implies, *Note cPickle: 73. is
written in C, so it can be up to 1000 times faster than *Note pickle:
12e.  However it does not support subclassing of the *Note Pickler():
eef. and *Note Unpickler(): ef0. classes, because in *Note cPickle: 73.
these are functions, not classes.  Most applications have no need for
this functionality, and can benefit from the improved performance of
*Note cPickle: 73.  Other than that, the interfaces of the two modules
are nearly identical; the common interface is described in this manual
and differences are pointed out where necessary.  In the following
discussions, we use the term “pickle” to collectively describe the
*Note pickle: 12e. and *Note cPickle: 73. modules.

The data streams the two modules produce are guaranteed to be
interchangeable.

Python has a more primitive serialization module called *Note marshal:
10c, but in general *Note pickle: 12e. should always be the preferred
way to serialize Python objects.  *Note marshal: 10c. exists primarily
to support Python’s `.pyc' files.

The *Note pickle: 12e. module differs from *Note marshal: 10c. in
several significant ways:

   * The *Note pickle: 12e. module keeps track of the objects it has
     already serialized, so that later references to the same object
     won’t be serialized again.  *Note marshal: 10c. doesn’t do
     this.

     This has implications both for recursive objects and object
     sharing.  Recursive objects are objects that contain references to
     themselves.  These are not handled by marshal, and in fact,
     attempting to marshal recursive objects will crash your Python
     interpreter.  Object sharing happens when there are multiple
     references to the same object in different places in the object
     hierarchy being serialized.  *Note pickle: 12e. stores such
     objects only once, and ensures that all other references point to
     the master copy.  Shared objects remain shared, which can be very
     important for mutable objects.

   * *Note marshal: 10c. cannot be used to serialize user-defined
     classes and their instances.  *Note pickle: 12e. can save and
     restore class instances transparently, however the class
     definition must be importable and live in the same module as when
     the object was stored.

   * The *Note marshal: 10c. serialization format is not guaranteed to
     be portable across Python versions.  Because its primary job in
     life is to support `.pyc' files, the Python implementers reserve
     the right to change the serialization format in non-backwards
     compatible ways should the need arise.  The *Note pickle: 12e.
     serialization format is guaranteed to be backwards compatible
     across Python releases.

Note that serialization is a more primitive notion than persistence;
although *Note pickle: 12e. reads and writes file objects, it does not
handle the issue of naming persistent objects, nor the (even more
complicated) issue of concurrent access to persistent objects.  The
*Note pickle: 12e. module can transform a complex object into a byte
stream and it can transform the byte stream into an object with the
same internal structure.  Perhaps the most obvious thing to do with
these byte streams is to write them onto a file, but it is also
conceivable to send them across a network or store them in a database.
The module *Note shelve: 152. provides a simple interface to pickle and
unpickle objects on DBM-style database files.


File: python.info,  Node: Data stream format,  Next: Usage,  Prev: Relationship to other Python modules,  Up: pickle — Python object serialization

5.11.1.2 Data stream format
...........................

The data format used by *Note pickle: 12e. is Python-specific.  This
has the advantage that there are no restrictions imposed by external
standards such as XDR (which can’t represent pointer sharing);
however it means that non-Python programs may not be able to
reconstruct pickled Python objects.

By default, the *Note pickle: 12e. data format uses a printable ASCII
representation.  This is slightly more voluminous than a binary
representation.  The big advantage of using printable ASCII (and of
some other characteristics of *Note pickle: 12e.’s representation) is
that for debugging or recovery purposes it is possible for a human to
read the pickled file with a standard text editor.

There are currently 3 different protocols which can be used for
pickling.

   * Protocol version 0 is the original ASCII protocol and is backwards
     compatible with earlier versions of Python.

   * Protocol version 1 is the old binary format which is also
     compatible with earlier versions of Python.

   * Protocol version 2 was introduced in Python 2.3.  It provides much
     more efficient pickling of *Note new-style class: 5ec.es.

Refer to PEP 307(1) for more information.

If a `protocol' is not specified, protocol 0 is used. If `protocol' is
specified as a negative value or *Note HIGHEST_PROTOCOL: 462, the
highest protocol version available will be used.

Changed in version 2.3: Introduced the `protocol' parameter.

A binary format, which is slightly more efficient, can be chosen by
specifying a `protocol' version >= 1.

---------- Footnotes ----------

(1) https://www.python.org/dev/peps/pep-0307


File: python.info,  Node: Usage,  Next: What can be pickled and unpickled?,  Prev: Data stream format,  Up: pickle — Python object serialization

5.11.1.3 Usage
..............

To serialize an object hierarchy, you first create a pickler, then you
call the pickler’s *Note dump(): ef3. method.  To de-serialize a data
stream, you first create an unpickler, then you call the unpickler’s
*Note load(): ef4. method.  The *Note pickle: 12e. module provides the
following constant:

 -- Data: pickle.HIGHEST_PROTOCOL
     The highest protocol version available.  This value can be passed
     as a `protocol' value.

     New in version 2.3.


     Note: Be sure to always open pickle files created with protocols
     >= 1 in binary mode.  For the old ASCII-based pickle protocol 0
     you can use either text mode or binary mode as long as you stay
     consistent.

     A pickle file written with protocol 0 in binary mode will contain
     lone linefeeds as line terminators and therefore will look
     “funny” when viewed in Notepad or other editors which do not
     support this format.

The *Note pickle: 12e. module provides the following functions to make
the pickling process more convenient:

 -- Function: pickle.dump (obj, file[, protocol])
     Write a pickled representation of `obj' to the open file object
     `file'.  This is equivalent to `Pickler(file, protocol).dump(obj)'.

     If the `protocol' parameter is omitted, protocol 0 is used. If
     `protocol' is specified as a negative value or *Note
     HIGHEST_PROTOCOL: 462, the highest protocol version will be used.

     Changed in version 2.3: Introduced the `protocol' parameter.

     `file' must have a `write()' method that accepts a single string
     argument.  It can thus be a file object opened for writing, a
     *Note StringIO: 164. object, or any other custom object that meets
     this interface.

 -- Function: pickle.load (file)
     Read a string from the open file object `file' and interpret it as
     a pickle data stream, reconstructing and returning the original
     object hierarchy.  This is equivalent to `Unpickler(file).load()'.

     `file' must have two methods, a `read()' method that takes an
     integer argument, and a *Note readline(): 145. method that
     requires no arguments.  Both methods should return a string.  Thus
     `file' can be a file object opened for reading, a *Note StringIO:
     164. object, or any other custom object that meets this interface.

     This function automatically determines whether the data stream was
     written in binary mode or not.

 -- Function: pickle.dumps (obj[, protocol])
     Return the pickled representation of the object as a string,
     instead of writing it to a file.

     If the `protocol' parameter is omitted, protocol 0 is used. If
     `protocol' is specified as a negative value or *Note
     HIGHEST_PROTOCOL: 462, the highest protocol version will be used.

     Changed in version 2.3: The `protocol' parameter was added.


 -- Function: pickle.loads (string)
     Read a pickled object hierarchy from a string.  Characters in the
     string past the pickled object’s representation are ignored.

The *Note pickle: 12e. module also defines three exceptions:

 -- Exception: pickle.PickleError
     A common base class for the other exceptions defined below.  This
     inherits from *Note Exception: 34d.

 -- Exception: pickle.PicklingError
     This exception is raised when an unpicklable object is passed to
     the *Note dump(): ef3. method.

 -- Exception: pickle.UnpicklingError
     This exception is raised when there is a problem unpickling an
     object. Note that other exceptions may also be raised during
     unpickling, including (but not necessarily limited to) *Note
     AttributeError: 1f8, *Note EOFError: 8b3, *Note ImportError: 388,
     and *Note IndexError: 4fe.

The *Note pickle: 12e. module also exports two callables (1), *Note
Pickler: eef. and *Note Unpickler: ef0.:

 -- Class: pickle.Pickler (file[, protocol])
     This takes a file-like object to which it will write a pickle data
     stream.

     If the `protocol' parameter is omitted, protocol 0 is used. If
     `protocol' is specified as a negative value or *Note
     HIGHEST_PROTOCOL: 462, the highest protocol version will be used.

     Changed in version 2.3: Introduced the `protocol' parameter.

     `file' must have a `write()' method that accepts a single string
     argument.  It can thus be an open file object, a *Note StringIO:
     164. object, or any other custom object that meets this interface.

     *Note Pickler: eef. objects define one (or two) public methods:

      -- Method: dump (obj)
          Write a pickled representation of `obj' to the open file
          object given in the constructor.  Either the binary or ASCII
          format will be used, depending on the value of the `protocol'
          argument passed to the constructor.

      -- Method: clear_memo ()
          Clears the pickler’s “memo”.  The memo is the data
          structure that remembers which objects the pickler has
          already seen, so that shared or recursive objects pickled by
          reference and not by value.  This method is useful when
          re-using picklers.

               Note: Prior to Python 2.3, *Note clear_memo(): efb. was
               only available on the picklers created by *Note cPickle:
               73.  In the *Note pickle: 12e. module, picklers have an
               instance variable called `memo' which is a Python
               dictionary.  So to clear the memo for a *Note pickle:
               12e. module pickler, you could do the following:

                   mypickler.memo.clear()

               Code that does not need to support older versions of
               Python should simply use *Note clear_memo(): efb.

It is possible to make multiple calls to the *Note dump(): ef3. method
of the same *Note Pickler: eef. instance.  These must then be matched
to the same number of calls to the *Note load(): ef4. method of the
corresponding *Note Unpickler: ef0.  instance.  If the same object is
pickled by multiple *Note dump(): ef3. calls, the *Note load(): ef4.
will all yield references to the same object. (2)

*Note Unpickler: ef0. objects are defined as:

 -- Class: pickle.Unpickler (file)
     This takes a file-like object from which it will read a pickle
     data stream.  This class automatically determines whether the data
     stream was written in binary mode or not, so it does not need a
     flag as in the *Note Pickler: eef.  factory.

     `file' must have two methods, a `read()' method that takes an
     integer argument, and a *Note readline(): 145. method that
     requires no arguments.  Both methods should return a string.  Thus
     `file' can be a file object opened for reading, a *Note StringIO:
     164. object, or any other custom object that meets this interface.

     *Note Unpickler: ef0. objects have one (or two) public methods:

      -- Method: load ()
          Read a pickled object representation from the open file
          object given in the constructor, and return the reconstituted
          object hierarchy specified therein.

          This method automatically determines whether the data stream
          was written in binary mode or not.

      -- Method: noload ()
          This is just like *Note load(): ef4. except that it doesn’t
          actually create any objects.  This is useful primarily for
          finding what’s called “persistent ids” that may be
          referenced in a pickle data stream.  See section *Note The
          pickle protocol: efe. below for more details.

          `Note:' the *Note noload(): efd. method is currently only
          available on *Note Unpickler: ef0. objects created with the
          *Note cPickle: 73. module.  *Note pickle: 12e. module *Note
          Unpickler: ef0.s do not have the *Note noload(): efd.  method.

---------- Footnotes ----------

(1) In the *Note pickle: 12e. module these callables are classes, which
you could subclass to customize the behavior.  However, in the *Note
cPickle: 73. module these callables are factory functions and so cannot
be subclassed.  One common reason to subclass is to control what
objects can actually be unpickled.  See section *Note Subclassing
Unpicklers: ef9. for more details.

(2) `Warning': this is intended for pickling multiple objects without
intervening modifications to the objects or their parts.  If you modify
an object and then pickle it again using the same `Pickler' instance,
the object is not pickled again — a reference to it is pickled and
the `Unpickler' will return the old value, not the modified one. There
are two problems here: (1) detecting changes, and (2) marshalling a
minimal set of changes.  Garbage Collection may also become a problem
here.


File: python.info,  Node: What can be pickled and unpickled?,  Next: The pickle protocol,  Prev: Usage,  Up: pickle — Python object serialization

5.11.1.4 What can be pickled and unpickled?
...........................................

The following types can be pickled:

   * `None', `True', and `False'

   * integers, long integers, floating point numbers, complex numbers

   * normal and Unicode strings

   * tuples, lists, sets, and dictionaries containing only picklable
     objects

   * functions defined at the top level of a module

   * built-in functions defined at the top level of a module

   * classes that are defined at the top level of a module

   * instances of such classes whose *Note __dict__: 4a0. or the result
     of calling *Note __getstate__(): 463. is picklable  (see section
     *Note The pickle protocol: efe.  for details).

Attempts to pickle unpicklable objects will raise the *Note
PicklingError: ef7.  exception; when this happens, an unspecified
number of bytes may have already been written to the underlying file.
Trying to pickle a highly recursive data structure may exceed the
maximum recursion depth, a *Note RuntimeError: 3b3. will be raised in
this case. You can carefully raise this limit with *Note
sys.setrecursionlimit(): 504.

Note that functions (built-in and user-defined) are pickled by “fully
qualified” name reference, not by value.  This means that only the
function name is pickled, along with the name of the module the
function is defined in.  Neither the function’s code, nor any of its
function attributes are pickled.  Thus the defining module must be
importable in the unpickling environment, and the module must contain
the named object, otherwise an exception will be raised. (1)

Similarly, classes are pickled by named reference, so the same
restrictions in the unpickling environment apply.  Note that none of
the class’s code or data is pickled, so in the following example the
class attribute `attr' is not restored in the unpickling environment:

    class Foo:
        attr = 'a class attr'

    picklestring = pickle.dumps(Foo)

These restrictions are why picklable functions and classes must be
defined in the top level of a module.

Similarly, when class instances are pickled, their class’s code and
data are not pickled along with them.  Only the instance data are
pickled.  This is done on purpose, so you can fix bugs in a class or
add methods to the class and still load objects that were created with
an earlier version of the class.  If you plan to have long-lived
objects that will see many versions of a class, it may be worthwhile to
put a version number in the objects so that suitable conversions can be
made by the class’s *Note __setstate__(): 464. method.

---------- Footnotes ----------

(1) The exception raised will likely be an *Note ImportError: 388. or an
*Note AttributeError: 1f8. but it could be something else.


File: python.info,  Node: The pickle protocol,  Next: Subclassing Unpicklers,  Prev: What can be pickled and unpickled?,  Up: pickle — Python object serialization

5.11.1.5 The pickle protocol
............................

This section describes the “pickling protocol” that defines the
interface between the pickler/unpickler and the objects that are being
serialized.  This protocol provides a standard way for you to define,
customize, and control how your objects are serialized and
de-serialized.  The description in this section doesn’t cover
specific customizations that you can employ to make the unpickling
environment slightly safer from untrusted pickle data streams; see
section *Note Subclassing Unpicklers: ef9. for more details.

* Menu:

* Pickling and unpickling normal class instances::
* Pickling and unpickling extension types::
* Pickling and unpickling external objects::


File: python.info,  Node: Pickling and unpickling normal class instances,  Next: Pickling and unpickling extension types,  Up: The pickle protocol

5.11.1.6 Pickling and unpickling normal class instances
.......................................................

 -- Method: object.__getinitargs__ ()
     When a pickled class instance is unpickled, its *Note __init__():
     394. method is normally `not' invoked.  If it is desirable that
     the *Note __init__(): 394. method be called on unpickling, an
     old-style class can define a method *Note __getinitargs__(): f03,
     which should return a `tuple' containing the arguments to be
     passed to the class constructor (*Note __init__(): 394. for
     example).  The *Note __getinitargs__(): f03. method is called at
     pickle time; the tuple it returns is incorporated in the pickle
     for the instance.

 -- Method: object.__getnewargs__ ()
     New-style types can provide a *Note __getnewargs__(): 465. method
     that is used for protocol 2.  Implementing this method is needed
     if the type establishes some internal invariants when the instance
     is created, or if the memory allocation is affected by the values
     passed to the *Note __new__(): 724. method for the type (as it is
     for tuples and strings).  Instances of a *Note new-style class:
     5ec.  `C' are created using

         obj = C.__new__(C, *args)

     where `args' is the result of calling *Note __getnewargs__(): 465.
     on the original object; if there is no *Note __getnewargs__():
     465, an empty tuple is assumed.

 -- Method: object.__getstate__ ()
     Classes can further influence how their instances are pickled; if
     the class defines the method *Note __getstate__(): 463, it is
     called and the return state is pickled as the contents for the
     instance, instead of the contents of the instance’s dictionary.
     If there is no *Note __getstate__(): 463. method, the instance’s
     *Note __dict__: 4a0. is pickled.

 -- Method: object.__setstate__ (state)
     Upon unpickling, if the class also defines the method *Note
     __setstate__(): 464, it is called with the unpickled state. (1) If
     there is no *Note __setstate__(): 464. method, the pickled state
     must be a dictionary and its items are assigned to the new
     instance’s dictionary.  If a class defines both *Note
     __getstate__(): 463. and *Note __setstate__(): 464, the state
     object needn’t be a dictionary and these methods can do what
     they want. (2)

          Note: For *Note new-style class: 5ec.es, if *Note
          __getstate__(): 463. returns a false value, the *Note
          __setstate__(): 464. method will not be called.

     Note: At unpickling time, some methods like *Note __getattr__():
     345, *Note __getattribute__(): 34f, or *Note __setattr__(): 4a5.
     may be called upon the instance.  In case those methods rely on
     some internal invariant being true, the type should implement
     either *Note __getinitargs__(): f03. or *Note __getnewargs__():
     465. to establish such an invariant; otherwise, neither *Note
     __new__(): 724. nor *Note __init__(): 394. will be called.

---------- Footnotes ----------

(1) These methods can also be used to implement copying class instances.

(2) This protocol is also used by the shallow and deep copying
operations defined in the *Note copy: 71. module.


File: python.info,  Node: Pickling and unpickling extension types,  Next: Pickling and unpickling external objects,  Prev: Pickling and unpickling normal class instances,  Up: The pickle protocol

5.11.1.7 Pickling and unpickling extension types
................................................

 -- Method: object.__reduce__ ()
     When the `Pickler' encounters an object of a type it knows nothing
     about — such as an extension type — it looks in two places for
     a hint of how to pickle it.  One alternative is for the object to
     implement a *Note __reduce__(): 3e6. method.  If provided, at
     pickling time *Note __reduce__(): 3e6.  will be called with no
     arguments, and it must return either a string or a tuple.

     If a string is returned, it names a global variable whose contents
     are pickled as normal.  The string returned by *Note __reduce__():
     3e6. should be the object’s local name relative to its module;
     the pickle module searches the module namespace to determine the
     object’s module.

     When a tuple is returned, it must be between two and five elements
     long.  Optional elements can either be omitted, or `None' can be
     provided as their value.  The contents of this tuple are pickled
     as normal and used to reconstruct the object at unpickling time.
     The semantics of each element are:

        * A callable object that will be called to create the initial
          version of the object.  The next element of the tuple will
          provide arguments for this callable, and later elements
          provide additional state information that will subsequently
          be used to fully reconstruct the pickled data.

          In the unpickling environment this object must be either a
          class, a callable registered as a “safe constructor” (see
          below), or it must have an attribute
          `__safe_for_unpickling__' with a true value. Otherwise, an
          `UnpicklingError' will be raised in the unpickling
          environment.  Note that as usual, the callable itself is
          pickled by name.

        * A tuple of arguments for the callable object.

          Changed in version 2.5: Formerly, this argument could also be
          `None'.

        * Optionally, the object’s state, which will be passed to the
          object’s *Note __setstate__(): 464. method as described in
          section *Note Pickling and unpickling normal class instances:
          f02.  If the object has no *Note __setstate__(): 464. method,
          then, as above, the value must be a dictionary and it will be
          added to the object’s *Note __dict__: 4a0.

        * Optionally, an iterator (and not a sequence) yielding
          successive list items.  These list items will be pickled, and
          appended to the object using either `obj.append(item)' or
          `obj.extend(list_of_items)'.  This is primarily used for list
          subclasses, but may be used by other classes as long as they
          have `append()' and `extend()' methods with the appropriate
          signature.  (Whether `append()' or `extend()' is used depends
          on which pickle protocol version is used as well as the
          number of items to append, so both must be supported.)

        * Optionally, an iterator (not a sequence) yielding successive
          dictionary items, which should be tuples of the form `(key,
          value)'.  These items will be pickled and stored to the
          object using `obj[key] = value'. This is primarily used for
          dictionary subclasses, but may be used by other classes as
          long as they implement *Note __setitem__(): 481.

 -- Method: object.__reduce_ex__ (protocol)
     It is sometimes useful to know the protocol version when
     implementing *Note __reduce__(): 3e6.  This can be done by
     implementing a method named *Note __reduce_ex__(): f05. instead of
     *Note __reduce__(): 3e6. *Note __reduce_ex__(): f05, when it
     exists, is called in preference over *Note __reduce__(): 3e6. (you
     may still provide *Note __reduce__(): 3e6. for backwards
     compatibility).  The *Note __reduce_ex__(): f05. method will be
     called with a single integer argument, the protocol version.

     The *Note object: 1f1. class implements both *Note __reduce__():
     3e6. and *Note __reduce_ex__(): f05.; however, if a subclass
     overrides *Note __reduce__(): 3e6.  but not *Note __reduce_ex__():
     f05, the *Note __reduce_ex__(): f05. implementation detects this
     and calls *Note __reduce__(): 3e6.

An alternative to implementing a *Note __reduce__(): 3e6. method on the
object to be pickled, is to register the callable with the *Note
copy_reg: 72. module.  This module provides a way for programs to
register “reduction functions” and constructors for user-defined
types.   Reduction functions have the same semantics and interface as
the *Note __reduce__(): 3e6. method described above, except that they
are called with a single argument, the object to be pickled.

The registered constructor is deemed a “safe constructor” for
purposes of unpickling as described above.


File: python.info,  Node: Pickling and unpickling external objects,  Prev: Pickling and unpickling extension types,  Up: The pickle protocol

5.11.1.8 Pickling and unpickling external objects
.................................................

For the benefit of object persistence, the *Note pickle: 12e. module
supports the notion of a reference to an object outside the pickled
data stream.  Such objects are referenced by a “persistent id”,
which is just an arbitrary string of printable ASCII characters. The
resolution of such names is not defined by the *Note pickle: 12e.
module; it will delegate this resolution to user defined functions on
the pickler and unpickler. (1)

To define external persistent id resolution, you need to set the
`persistent_id' attribute of the pickler object and the
`persistent_load' attribute of the unpickler object.

To pickle objects that have an external persistent id, the pickler must
have a custom `persistent_id()' method that takes an object as an
argument and returns either `None' or the persistent id for that object.
When `None' is returned, the pickler simply pickles the object as
normal.  When a persistent id string is returned, the pickler will
pickle that string, along with a marker so that the unpickler will
recognize the string as a persistent id.

To unpickle external objects, the unpickler must have a custom
`persistent_load()' function that takes a persistent id string and
returns the referenced object.

Here’s a silly example that `might' shed more light:

    import pickle
    from cStringIO import StringIO

    src = StringIO()
    p = pickle.Pickler(src)

    def persistent_id(obj):
        if hasattr(obj, 'x'):
            return 'the value %d' % obj.x
        else:
            return None

    p.persistent_id = persistent_id

    class Integer:
        def __init__(self, x):
            self.x = x
        def __str__(self):
            return 'My name is integer %d' % self.x

    i = Integer(7)
    print i
    p.dump(i)

    datastream = src.getvalue()
    print repr(datastream)
    dst = StringIO(datastream)

    up = pickle.Unpickler(dst)

    class FancyInteger(Integer):
        def __str__(self):
            return 'I am the integer %d' % self.x

    def persistent_load(persid):
        if persid.startswith('the value '):
            value = int(persid.split()[2])
            return FancyInteger(value)
        else:
            raise pickle.UnpicklingError, 'Invalid persistent id'

    up.persistent_load = persistent_load

    j = up.load()
    print j

In the *Note cPickle: 73. module, the unpickler’s `persistent_load'
attribute can also be set to a Python list, in which case, when the
unpickler reaches a persistent id, the persistent id string will simply
be appended to this list.  This functionality exists so that a pickle
data stream can be “sniffed” for object references without actually
instantiating all the objects in a pickle.  (2)  Setting
`persistent_load' to a list is usually used in conjunction with the
`noload()' method on the Unpickler.

---------- Footnotes ----------

(1) The actual mechanism for associating these user defined functions
is slightly different for *Note pickle: 12e. and *Note cPickle: 73.
The description given here works the same for both implementations.
Users of the *Note pickle: 12e. module could also use subclassing to
effect the same results, overriding the `persistent_id()' and
`persistent_load()' methods in the derived classes.

(2) We’ll leave you with the image of Guido and Jim sitting around
sniffing pickles in their living rooms.

